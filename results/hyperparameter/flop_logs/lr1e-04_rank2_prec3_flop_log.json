{
  "experiment_name": "lr1e-04_rank2_prec3",
  "model_config": {
    "hidden_size": 896,
    "num_attention_heads": 14,
    "num_hidden_layers": 24,
    "intermediate_size": 4864,
    "head_dim": 64,
    "vocab_size": 151936,
    "lora_r": 2,
    "lora_target_modules": [
      "q_proj",
      "v_proj"
    ]
  },
  "max_budget": 1e+17,
  "start_time": "2025-03-31 15:30:31",
  "operations": [
    {
      "type": "training",
      "description": "Training step 0",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:35",
      "total_flops_so_far": 1430567036928.0,
      "budget_used_percent": 0.0014305670369280001
    },
    {
      "type": "training",
      "description": "Training step 1",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:35",
      "total_flops_so_far": 2861134073856.0,
      "budget_used_percent": 0.0028611340738560003
    },
    {
      "type": "training",
      "description": "Training step 2",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:35",
      "total_flops_so_far": 4291701110784.0,
      "budget_used_percent": 0.004291701110784
    },
    {
      "type": "training",
      "description": "Training step 3",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:36",
      "total_flops_so_far": 5722268147712.0,
      "budget_used_percent": 0.005722268147712001
    },
    {
      "type": "training",
      "description": "Training step 4",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:36",
      "total_flops_so_far": 7152835184640.0,
      "budget_used_percent": 0.007152835184639999
    },
    {
      "type": "training",
      "description": "Training step 5",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:36",
      "total_flops_so_far": 8583402221568.0,
      "budget_used_percent": 0.008583402221568
    },
    {
      "type": "training",
      "description": "Training step 6",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:36",
      "total_flops_so_far": 10013969258496.0,
      "budget_used_percent": 0.010013969258496
    },
    {
      "type": "training",
      "description": "Training step 7",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:36",
      "total_flops_so_far": 11444536295424.0,
      "budget_used_percent": 0.011444536295424001
    },
    {
      "type": "training",
      "description": "Training step 8",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:36",
      "total_flops_so_far": 12875103332352.0,
      "budget_used_percent": 0.012875103332351999
    },
    {
      "type": "training",
      "description": "Training step 9",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:36",
      "total_flops_so_far": 14305670369280.0,
      "budget_used_percent": 0.014305670369279998
    },
    {
      "type": "training",
      "description": "Training step 10",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:36",
      "total_flops_so_far": 15736237406208.0,
      "budget_used_percent": 0.015736237406208
    },
    {
      "type": "training",
      "description": "Training step 11",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:37",
      "total_flops_so_far": 17166804443136.0,
      "budget_used_percent": 0.017166804443136
    },
    {
      "type": "training",
      "description": "Training step 12",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:37",
      "total_flops_so_far": 18597371480064.0,
      "budget_used_percent": 0.018597371480063997
    },
    {
      "type": "training",
      "description": "Training step 13",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:37",
      "total_flops_so_far": 20027938516992.0,
      "budget_used_percent": 0.020027938516992
    },
    {
      "type": "training",
      "description": "Training step 14",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:37",
      "total_flops_so_far": 21458505553920.0,
      "budget_used_percent": 0.02145850555392
    },
    {
      "type": "training",
      "description": "Training step 15",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:37",
      "total_flops_so_far": 22889072590848.0,
      "budget_used_percent": 0.022889072590848002
    },
    {
      "type": "training",
      "description": "Training step 16",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:37",
      "total_flops_so_far": 24319639627776.0,
      "budget_used_percent": 0.024319639627776002
    },
    {
      "type": "training",
      "description": "Training step 17",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:37",
      "total_flops_so_far": 25750206664704.0,
      "budget_used_percent": 0.025750206664703998
    },
    {
      "type": "training",
      "description": "Training step 18",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:37",
      "total_flops_so_far": 27180773701632.0,
      "budget_used_percent": 0.027180773701631997
    },
    {
      "type": "training",
      "description": "Training step 19",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:37",
      "total_flops_so_far": 28611340738560.0,
      "budget_used_percent": 0.028611340738559997
    },
    {
      "type": "training",
      "description": "Training step 20",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:38",
      "total_flops_so_far": 30041907775488.0,
      "budget_used_percent": 0.030041907775488003
    },
    {
      "type": "training",
      "description": "Training step 21",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:38",
      "total_flops_so_far": 31472474812416.0,
      "budget_used_percent": 0.031472474812416
    },
    {
      "type": "training",
      "description": "Training step 22",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:38",
      "total_flops_so_far": 32903041849344.0,
      "budget_used_percent": 0.032903041849344
    },
    {
      "type": "training",
      "description": "Training step 23",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:38",
      "total_flops_so_far": 34333608886272.0,
      "budget_used_percent": 0.034333608886272
    },
    {
      "type": "training",
      "description": "Training step 24",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:38",
      "total_flops_so_far": 35764175923200.0,
      "budget_used_percent": 0.0357641759232
    },
    {
      "type": "training",
      "description": "Training step 25",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:38",
      "total_flops_so_far": 37194742960128.0,
      "budget_used_percent": 0.037194742960127994
    },
    {
      "type": "training",
      "description": "Training step 26",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:38",
      "total_flops_so_far": 38625309997056.0,
      "budget_used_percent": 0.038625309997056004
    },
    {
      "type": "training",
      "description": "Training step 27",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:38",
      "total_flops_so_far": 40055877033984.0,
      "budget_used_percent": 0.040055877033984
    },
    {
      "type": "training",
      "description": "Training step 28",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:39",
      "total_flops_so_far": 41486444070912.0,
      "budget_used_percent": 0.041486444070912
    },
    {
      "type": "training",
      "description": "Training step 29",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:39",
      "total_flops_so_far": 42917011107840.0,
      "budget_used_percent": 0.04291701110784
    },
    {
      "type": "training",
      "description": "Training step 30",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:39",
      "total_flops_so_far": 44347578144768.0,
      "budget_used_percent": 0.044347578144767995
    },
    {
      "type": "training",
      "description": "Training step 31",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:39",
      "total_flops_so_far": 45778145181696.0,
      "budget_used_percent": 0.045778145181696005
    },
    {
      "type": "training",
      "description": "Training step 32",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:39",
      "total_flops_so_far": 47208712218624.0,
      "budget_used_percent": 0.047208712218624
    },
    {
      "type": "training",
      "description": "Training step 33",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:39",
      "total_flops_so_far": 48639279255552.0,
      "budget_used_percent": 0.048639279255552004
    },
    {
      "type": "training",
      "description": "Training step 34",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:39",
      "total_flops_so_far": 50069846292480.0,
      "budget_used_percent": 0.05006984629248
    },
    {
      "type": "training",
      "description": "Training step 35",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:39",
      "total_flops_so_far": 51500413329408.0,
      "budget_used_percent": 0.051500413329407996
    },
    {
      "type": "training",
      "description": "Training step 36",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:39",
      "total_flops_so_far": 52930980366336.0,
      "budget_used_percent": 0.052930980366336
    },
    {
      "type": "training",
      "description": "Training step 37",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:40",
      "total_flops_so_far": 54361547403264.0,
      "budget_used_percent": 0.054361547403263995
    },
    {
      "type": "training",
      "description": "Training step 38",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:40",
      "total_flops_so_far": 55792114440192.0,
      "budget_used_percent": 0.055792114440192
    },
    {
      "type": "training",
      "description": "Training step 39",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:40",
      "total_flops_so_far": 57222681477120.0,
      "budget_used_percent": 0.057222681477119994
    },
    {
      "type": "training",
      "description": "Training step 40",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:40",
      "total_flops_so_far": 58653248514048.0,
      "budget_used_percent": 0.058653248514048004
    },
    {
      "type": "training",
      "description": "Training step 41",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:40",
      "total_flops_so_far": 60083815550976.0,
      "budget_used_percent": 0.06008381555097601
    },
    {
      "type": "training",
      "description": "Training step 42",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:40",
      "total_flops_so_far": 61514382587904.0,
      "budget_used_percent": 0.061514382587904
    },
    {
      "type": "training",
      "description": "Training step 43",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:40",
      "total_flops_so_far": 62944949624832.0,
      "budget_used_percent": 0.062944949624832
    },
    {
      "type": "training",
      "description": "Training step 44",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:40",
      "total_flops_so_far": 64375516661760.0,
      "budget_used_percent": 0.06437551666176
    },
    {
      "type": "training",
      "description": "Training step 45",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:41",
      "total_flops_so_far": 65806083698688.0,
      "budget_used_percent": 0.065806083698688
    },
    {
      "type": "training",
      "description": "Training step 46",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:41",
      "total_flops_so_far": 67236650735616.0,
      "budget_used_percent": 0.067236650735616
    },
    {
      "type": "training",
      "description": "Training step 47",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:41",
      "total_flops_so_far": 68667217772544.0,
      "budget_used_percent": 0.068667217772544
    },
    {
      "type": "training",
      "description": "Training step 48",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:41",
      "total_flops_so_far": 70097784809472.0,
      "budget_used_percent": 0.070097784809472
    },
    {
      "type": "training",
      "description": "Training step 49",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:41",
      "total_flops_so_far": 71528351846400.0,
      "budget_used_percent": 0.0715283518464
    },
    {
      "type": "training",
      "description": "Training step 50",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:41",
      "total_flops_so_far": 72958918883328.0,
      "budget_used_percent": 0.07295891888332799
    },
    {
      "type": "training",
      "description": "Training step 51",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:41",
      "total_flops_so_far": 74389485920256.0,
      "budget_used_percent": 0.07438948592025599
    },
    {
      "type": "training",
      "description": "Training step 52",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:42",
      "total_flops_so_far": 75820052957184.0,
      "budget_used_percent": 0.075820052957184
    },
    {
      "type": "training",
      "description": "Training step 53",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:42",
      "total_flops_so_far": 77250619994112.0,
      "budget_used_percent": 0.07725061999411201
    },
    {
      "type": "training",
      "description": "Training step 54",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:42",
      "total_flops_so_far": 78681187031040.0,
      "budget_used_percent": 0.07868118703104
    },
    {
      "type": "training",
      "description": "Training step 55",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:42",
      "total_flops_so_far": 80111754067968.0,
      "budget_used_percent": 0.080111754067968
    },
    {
      "type": "training",
      "description": "Training step 56",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:42",
      "total_flops_so_far": 81542321104896.0,
      "budget_used_percent": 0.081542321104896
    },
    {
      "type": "training",
      "description": "Training step 57",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:42",
      "total_flops_so_far": 82972888141824.0,
      "budget_used_percent": 0.082972888141824
    },
    {
      "type": "training",
      "description": "Training step 58",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:42",
      "total_flops_so_far": 84403455178752.0,
      "budget_used_percent": 0.084403455178752
    },
    {
      "type": "training",
      "description": "Training step 59",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:42",
      "total_flops_so_far": 85834022215680.0,
      "budget_used_percent": 0.08583402221568
    },
    {
      "type": "training",
      "description": "Training step 60",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:43",
      "total_flops_so_far": 87264589252608.0,
      "budget_used_percent": 0.087264589252608
    },
    {
      "type": "training",
      "description": "Training step 61",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:43",
      "total_flops_so_far": 88695156289536.0,
      "budget_used_percent": 0.08869515628953599
    },
    {
      "type": "training",
      "description": "Training step 62",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:43",
      "total_flops_so_far": 90125723326464.0,
      "budget_used_percent": 0.090125723326464
    },
    {
      "type": "training",
      "description": "Training step 63",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:43",
      "total_flops_so_far": 91556290363392.0,
      "budget_used_percent": 0.09155629036339201
    },
    {
      "type": "training",
      "description": "Training step 64",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:43",
      "total_flops_so_far": 92986857400320.0,
      "budget_used_percent": 0.09298685740032
    },
    {
      "type": "training",
      "description": "Training step 65",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:43",
      "total_flops_so_far": 94417424437248.0,
      "budget_used_percent": 0.094417424437248
    },
    {
      "type": "training",
      "description": "Training step 66",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:43",
      "total_flops_so_far": 95847991474176.0,
      "budget_used_percent": 0.095847991474176
    },
    {
      "type": "training",
      "description": "Training step 67",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:43",
      "total_flops_so_far": 97278558511104.0,
      "budget_used_percent": 0.09727855851110401
    },
    {
      "type": "training",
      "description": "Training step 68",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:43",
      "total_flops_so_far": 98709125548032.0,
      "budget_used_percent": 0.09870912554803199
    },
    {
      "type": "training",
      "description": "Training step 69",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:44",
      "total_flops_so_far": 100139692584960.0,
      "budget_used_percent": 0.10013969258496
    },
    {
      "type": "training",
      "description": "Training step 70",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:44",
      "total_flops_so_far": 101570259621888.0,
      "budget_used_percent": 0.10157025962188801
    },
    {
      "type": "training",
      "description": "Training step 71",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:44",
      "total_flops_so_far": 103000826658816.0,
      "budget_used_percent": 0.10300082665881599
    },
    {
      "type": "training",
      "description": "Training step 72",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:44",
      "total_flops_so_far": 104431393695744.0,
      "budget_used_percent": 0.104431393695744
    },
    {
      "type": "training",
      "description": "Training step 73",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:44",
      "total_flops_so_far": 105861960732672.0,
      "budget_used_percent": 0.105861960732672
    },
    {
      "type": "training",
      "description": "Training step 74",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:44",
      "total_flops_so_far": 107292527769600.0,
      "budget_used_percent": 0.10729252776960001
    },
    {
      "type": "training",
      "description": "Training step 75",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:44",
      "total_flops_so_far": 108723094806528.0,
      "budget_used_percent": 0.10872309480652799
    },
    {
      "type": "training",
      "description": "Training step 76",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:44",
      "total_flops_so_far": 110153661843456.0,
      "budget_used_percent": 0.110153661843456
    },
    {
      "type": "training",
      "description": "Training step 77",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:45",
      "total_flops_so_far": 111584228880384.0,
      "budget_used_percent": 0.111584228880384
    },
    {
      "type": "training",
      "description": "Training step 78",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:45",
      "total_flops_so_far": 113014795917312.0,
      "budget_used_percent": 0.113014795917312
    },
    {
      "type": "training",
      "description": "Training step 79",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:45",
      "total_flops_so_far": 114445362954240.0,
      "budget_used_percent": 0.11444536295423999
    },
    {
      "type": "training",
      "description": "Training step 80",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:45",
      "total_flops_so_far": 115875929991168.0,
      "budget_used_percent": 0.115875929991168
    },
    {
      "type": "training",
      "description": "Training step 81",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:45",
      "total_flops_so_far": 117306497028096.0,
      "budget_used_percent": 0.11730649702809601
    },
    {
      "type": "training",
      "description": "Training step 82",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:45",
      "total_flops_so_far": 118737064065024.0,
      "budget_used_percent": 0.118737064065024
    },
    {
      "type": "training",
      "description": "Training step 83",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:45",
      "total_flops_so_far": 120167631101952.0,
      "budget_used_percent": 0.12016763110195201
    },
    {
      "type": "training",
      "description": "Training step 84",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:45",
      "total_flops_so_far": 121598198138880.0,
      "budget_used_percent": 0.12159819813888
    },
    {
      "type": "training",
      "description": "Training step 85",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:46",
      "total_flops_so_far": 123028765175808.0,
      "budget_used_percent": 0.123028765175808
    },
    {
      "type": "training",
      "description": "Training step 86",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:46",
      "total_flops_so_far": 124459332212736.0,
      "budget_used_percent": 0.124459332212736
    },
    {
      "type": "training",
      "description": "Training step 87",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:46",
      "total_flops_so_far": 125889899249664.0,
      "budget_used_percent": 0.125889899249664
    },
    {
      "type": "training",
      "description": "Training step 88",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:46",
      "total_flops_so_far": 127320466286592.0,
      "budget_used_percent": 0.127320466286592
    },
    {
      "type": "training",
      "description": "Training step 89",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:46",
      "total_flops_so_far": 128751033323520.0,
      "budget_used_percent": 0.12875103332352
    },
    {
      "type": "training",
      "description": "Training step 90",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:46",
      "total_flops_so_far": 130181600360448.0,
      "budget_used_percent": 0.13018160036044799
    },
    {
      "type": "training",
      "description": "Training step 91",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:46",
      "total_flops_so_far": 131612167397376.0,
      "budget_used_percent": 0.131612167397376
    },
    {
      "type": "training",
      "description": "Training step 92",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:46",
      "total_flops_so_far": 133042734434304.0,
      "budget_used_percent": 0.133042734434304
    },
    {
      "type": "training",
      "description": "Training step 93",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:47",
      "total_flops_so_far": 134473301471232.0,
      "budget_used_percent": 0.134473301471232
    },
    {
      "type": "training",
      "description": "Training step 94",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:47",
      "total_flops_so_far": 135903868508160.0,
      "budget_used_percent": 0.13590386850816
    },
    {
      "type": "training",
      "description": "Training step 95",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:47",
      "total_flops_so_far": 137334435545088.0,
      "budget_used_percent": 0.137334435545088
    },
    {
      "type": "training",
      "description": "Training step 96",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:47",
      "total_flops_so_far": 138765002582016.0,
      "budget_used_percent": 0.13876500258201602
    },
    {
      "type": "training",
      "description": "Training step 97",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:47",
      "total_flops_so_far": 140195569618944.0,
      "budget_used_percent": 0.140195569618944
    },
    {
      "type": "training",
      "description": "Training step 98",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:47",
      "total_flops_so_far": 141626136655872.0,
      "budget_used_percent": 0.141626136655872
    },
    {
      "type": "training",
      "description": "Training step 99",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:47",
      "total_flops_so_far": 143056703692800.0,
      "budget_used_percent": 0.1430567036928
    },
    {
      "type": "training",
      "description": "Training step 100",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:47",
      "total_flops_so_far": 144487270729728.0,
      "budget_used_percent": 0.144487270729728
    },
    {
      "type": "training",
      "description": "Training step 101",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:48",
      "total_flops_so_far": 145917837766656.0,
      "budget_used_percent": 0.14591783776665598
    },
    {
      "type": "training",
      "description": "Training step 102",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:48",
      "total_flops_so_far": 147348404803584.0,
      "budget_used_percent": 0.147348404803584
    },
    {
      "type": "training",
      "description": "Training step 103",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:48",
      "total_flops_so_far": 148778971840512.0,
      "budget_used_percent": 0.14877897184051198
    },
    {
      "type": "training",
      "description": "Training step 104",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:48",
      "total_flops_so_far": 150209538877440.0,
      "budget_used_percent": 0.15020953887743999
    },
    {
      "type": "training",
      "description": "Training step 105",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:48",
      "total_flops_so_far": 151640105914368.0,
      "budget_used_percent": 0.151640105914368
    },
    {
      "type": "training",
      "description": "Training step 106",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:48",
      "total_flops_so_far": 153070672951296.0,
      "budget_used_percent": 0.153070672951296
    },
    {
      "type": "training",
      "description": "Training step 107",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:48",
      "total_flops_so_far": 154501239988224.0,
      "budget_used_percent": 0.15450123998822402
    },
    {
      "type": "training",
      "description": "Training step 108",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:48",
      "total_flops_so_far": 155931807025152.0,
      "budget_used_percent": 0.155931807025152
    },
    {
      "type": "training",
      "description": "Training step 109",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:48",
      "total_flops_so_far": 157362374062080.0,
      "budget_used_percent": 0.15736237406208
    },
    {
      "type": "training",
      "description": "Training step 110",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:49",
      "total_flops_so_far": 158792941099008.0,
      "budget_used_percent": 0.158792941099008
    },
    {
      "type": "training",
      "description": "Training step 111",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:49",
      "total_flops_so_far": 160223508135936.0,
      "budget_used_percent": 0.160223508135936
    },
    {
      "type": "training",
      "description": "Training step 112",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:49",
      "total_flops_so_far": 161654075172864.0,
      "budget_used_percent": 0.16165407517286398
    },
    {
      "type": "training",
      "description": "Training step 113",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:49",
      "total_flops_so_far": 163084642209792.0,
      "budget_used_percent": 0.163084642209792
    },
    {
      "type": "training",
      "description": "Training step 114",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:49",
      "total_flops_so_far": 164515209246720.0,
      "budget_used_percent": 0.16451520924672
    },
    {
      "type": "training",
      "description": "Training step 115",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:49",
      "total_flops_so_far": 165945776283648.0,
      "budget_used_percent": 0.165945776283648
    },
    {
      "type": "training",
      "description": "Training step 116",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:49",
      "total_flops_so_far": 167376343320576.0,
      "budget_used_percent": 0.16737634332057602
    },
    {
      "type": "training",
      "description": "Training step 117",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:49",
      "total_flops_so_far": 168806910357504.0,
      "budget_used_percent": 0.168806910357504
    },
    {
      "type": "training",
      "description": "Training step 118",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:50",
      "total_flops_so_far": 170237477394432.0,
      "budget_used_percent": 0.170237477394432
    },
    {
      "type": "training",
      "description": "Training step 119",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:50",
      "total_flops_so_far": 171668044431360.0,
      "budget_used_percent": 0.17166804443136
    },
    {
      "type": "training",
      "description": "Training step 120",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:50",
      "total_flops_so_far": 173098611468288.0,
      "budget_used_percent": 0.173098611468288
    },
    {
      "type": "training",
      "description": "Training step 121",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:50",
      "total_flops_so_far": 174529178505216.0,
      "budget_used_percent": 0.174529178505216
    },
    {
      "type": "training",
      "description": "Training step 122",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:50",
      "total_flops_so_far": 175959745542144.0,
      "budget_used_percent": 0.175959745542144
    },
    {
      "type": "training",
      "description": "Training step 123",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:50",
      "total_flops_so_far": 177390312579072.0,
      "budget_used_percent": 0.17739031257907198
    },
    {
      "type": "training",
      "description": "Training step 124",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:50",
      "total_flops_so_far": 178820879616000.0,
      "budget_used_percent": 0.178820879616
    },
    {
      "type": "training",
      "description": "Training step 125",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:50",
      "total_flops_so_far": 180251446652928.0,
      "budget_used_percent": 0.180251446652928
    },
    {
      "type": "training",
      "description": "Training step 126",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:51",
      "total_flops_so_far": 181682013689856.0,
      "budget_used_percent": 0.181682013689856
    },
    {
      "type": "training",
      "description": "Training step 127",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:51",
      "total_flops_so_far": 183112580726784.0,
      "budget_used_percent": 0.18311258072678402
    },
    {
      "type": "training",
      "description": "Training step 128",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:51",
      "total_flops_so_far": 184543147763712.0,
      "budget_used_percent": 0.184543147763712
    },
    {
      "type": "training",
      "description": "Training step 129",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:51",
      "total_flops_so_far": 185973714800640.0,
      "budget_used_percent": 0.18597371480064
    },
    {
      "type": "training",
      "description": "Training step 130",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:51",
      "total_flops_so_far": 187404281837568.0,
      "budget_used_percent": 0.187404281837568
    },
    {
      "type": "training",
      "description": "Training step 131",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:51",
      "total_flops_so_far": 188834848874496.0,
      "budget_used_percent": 0.188834848874496
    },
    {
      "type": "training",
      "description": "Training step 132",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:51",
      "total_flops_so_far": 190265415911424.0,
      "budget_used_percent": 0.19026541591142399
    },
    {
      "type": "training",
      "description": "Training step 133",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:51",
      "total_flops_so_far": 191695982948352.0,
      "budget_used_percent": 0.191695982948352
    },
    {
      "type": "training",
      "description": "Training step 134",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:52",
      "total_flops_so_far": 193126549985280.0,
      "budget_used_percent": 0.19312654998528
    },
    {
      "type": "training",
      "description": "Training step 135",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:52",
      "total_flops_so_far": 194557117022208.0,
      "budget_used_percent": 0.19455711702220801
    },
    {
      "type": "training",
      "description": "Training step 136",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:52",
      "total_flops_so_far": 195987684059136.0,
      "budget_used_percent": 0.19598768405913602
    },
    {
      "type": "training",
      "description": "Training step 137",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:52",
      "total_flops_so_far": 197418251096064.0,
      "budget_used_percent": 0.19741825109606398
    },
    {
      "type": "training",
      "description": "Training step 138",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:52",
      "total_flops_so_far": 198848818132992.0,
      "budget_used_percent": 0.198848818132992
    },
    {
      "type": "training",
      "description": "Training step 139",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:52",
      "total_flops_so_far": 200279385169920.0,
      "budget_used_percent": 0.20027938516992
    },
    {
      "type": "training",
      "description": "Training step 140",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:52",
      "total_flops_so_far": 201709952206848.0,
      "budget_used_percent": 0.201709952206848
    },
    {
      "type": "training",
      "description": "Training step 141",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:52",
      "total_flops_so_far": 203140519243776.0,
      "budget_used_percent": 0.20314051924377602
    },
    {
      "type": "training",
      "description": "Training step 142",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:52",
      "total_flops_so_far": 204571086280704.0,
      "budget_used_percent": 0.20457108628070397
    },
    {
      "type": "training",
      "description": "Training step 143",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:53",
      "total_flops_so_far": 206001653317632.0,
      "budget_used_percent": 0.20600165331763198
    },
    {
      "type": "training",
      "description": "Training step 144",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:53",
      "total_flops_so_far": 207432220354560.0,
      "budget_used_percent": 0.20743222035456
    },
    {
      "type": "training",
      "description": "Training step 145",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:53",
      "total_flops_so_far": 208862787391488.0,
      "budget_used_percent": 0.208862787391488
    },
    {
      "type": "training",
      "description": "Training step 146",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:53",
      "total_flops_so_far": 210293354428416.0,
      "budget_used_percent": 0.21029335442841599
    },
    {
      "type": "training",
      "description": "Training step 147",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:53",
      "total_flops_so_far": 211723921465344.0,
      "budget_used_percent": 0.211723921465344
    },
    {
      "type": "training",
      "description": "Training step 148",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:53",
      "total_flops_so_far": 213154488502272.0,
      "budget_used_percent": 0.213154488502272
    },
    {
      "type": "training",
      "description": "Training step 149",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:53",
      "total_flops_so_far": 214585055539200.0,
      "budget_used_percent": 0.21458505553920001
    },
    {
      "type": "training",
      "description": "Training step 150",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:53",
      "total_flops_so_far": 216015622576128.0,
      "budget_used_percent": 0.21601562257612802
    },
    {
      "type": "training",
      "description": "Training step 151",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:54",
      "total_flops_so_far": 217446189613056.0,
      "budget_used_percent": 0.21744618961305598
    },
    {
      "type": "training",
      "description": "Training step 152",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:54",
      "total_flops_so_far": 218876756649984.0,
      "budget_used_percent": 0.218876756649984
    },
    {
      "type": "training",
      "description": "Training step 153",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:54",
      "total_flops_so_far": 220307323686912.0,
      "budget_used_percent": 0.220307323686912
    },
    {
      "type": "training",
      "description": "Training step 154",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:54",
      "total_flops_so_far": 221737890723840.0,
      "budget_used_percent": 0.22173789072384
    },
    {
      "type": "training",
      "description": "Training step 155",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:54",
      "total_flops_so_far": 223168457760768.0,
      "budget_used_percent": 0.223168457760768
    },
    {
      "type": "training",
      "description": "Training step 156",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:54",
      "total_flops_so_far": 224599024797696.0,
      "budget_used_percent": 0.224599024797696
    },
    {
      "type": "training",
      "description": "Training step 157",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:54",
      "total_flops_so_far": 226029591834624.0,
      "budget_used_percent": 0.226029591834624
    },
    {
      "type": "training",
      "description": "Training step 158",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:54",
      "total_flops_so_far": 227460158871552.0,
      "budget_used_percent": 0.22746015887155202
    },
    {
      "type": "training",
      "description": "Training step 159",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:55",
      "total_flops_so_far": 228890725908480.0,
      "budget_used_percent": 0.22889072590847998
    },
    {
      "type": "training",
      "description": "Training step 160",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:55",
      "total_flops_so_far": 230321292945408.0,
      "budget_used_percent": 0.23032129294540798
    },
    {
      "type": "training",
      "description": "Training step 161",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:55",
      "total_flops_so_far": 231751859982336.0,
      "budget_used_percent": 0.231751859982336
    },
    {
      "type": "training",
      "description": "Training step 162",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:55",
      "total_flops_so_far": 233182427019264.0,
      "budget_used_percent": 0.233182427019264
    },
    {
      "type": "training",
      "description": "Training step 163",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:55",
      "total_flops_so_far": 234612994056192.0,
      "budget_used_percent": 0.23461299405619201
    },
    {
      "type": "training",
      "description": "Training step 164",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:55",
      "total_flops_so_far": 236043561093120.0,
      "budget_used_percent": 0.23604356109312
    },
    {
      "type": "training",
      "description": "Training step 165",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:55",
      "total_flops_so_far": 237474128130048.0,
      "budget_used_percent": 0.237474128130048
    },
    {
      "type": "training",
      "description": "Training step 166",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:55",
      "total_flops_so_far": 238904695166976.0,
      "budget_used_percent": 0.23890469516697602
    },
    {
      "type": "training",
      "description": "Training step 167",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:56",
      "total_flops_so_far": 240335262203904.0,
      "budget_used_percent": 0.24033526220390403
    },
    {
      "type": "training",
      "description": "Training step 168",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:56",
      "total_flops_so_far": 241765829240832.0,
      "budget_used_percent": 0.24176582924083198
    },
    {
      "type": "training",
      "description": "Training step 169",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:56",
      "total_flops_so_far": 243196396277760.0,
      "budget_used_percent": 0.24319639627776
    },
    {
      "type": "training",
      "description": "Training step 170",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:56",
      "total_flops_so_far": 244626963314688.0,
      "budget_used_percent": 0.244626963314688
    },
    {
      "type": "training",
      "description": "Training step 171",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:56",
      "total_flops_so_far": 246057530351616.0,
      "budget_used_percent": 0.246057530351616
    },
    {
      "type": "training",
      "description": "Training step 172",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:56",
      "total_flops_so_far": 247488097388544.0,
      "budget_used_percent": 0.247488097388544
    },
    {
      "type": "training",
      "description": "Training step 173",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:56",
      "total_flops_so_far": 248918664425472.0,
      "budget_used_percent": 0.248918664425472
    },
    {
      "type": "training",
      "description": "Training step 174",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:56",
      "total_flops_so_far": 250349231462400.0,
      "budget_used_percent": 0.2503492314624
    },
    {
      "type": "training",
      "description": "Training step 175",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:57",
      "total_flops_so_far": 251779798499328.0,
      "budget_used_percent": 0.251779798499328
    },
    {
      "type": "training",
      "description": "Training step 176",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:57",
      "total_flops_so_far": 253210365536256.0,
      "budget_used_percent": 0.25321036553625603
    },
    {
      "type": "training",
      "description": "Training step 177",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:57",
      "total_flops_so_far": 254640932573184.0,
      "budget_used_percent": 0.254640932573184
    },
    {
      "type": "training",
      "description": "Training step 178",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:57",
      "total_flops_so_far": 256071499610112.0,
      "budget_used_percent": 0.256071499610112
    },
    {
      "type": "training",
      "description": "Training step 179",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:57",
      "total_flops_so_far": 257502066647040.0,
      "budget_used_percent": 0.25750206664704
    },
    {
      "type": "training",
      "description": "Training step 180",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:57",
      "total_flops_so_far": 258932633683968.0,
      "budget_used_percent": 0.258932633683968
    },
    {
      "type": "training",
      "description": "Training step 181",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:57",
      "total_flops_so_far": 260363200720896.0,
      "budget_used_percent": 0.26036320072089597
    },
    {
      "type": "training",
      "description": "Training step 182",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:57",
      "total_flops_so_far": 261793767757824.0,
      "budget_used_percent": 0.261793767757824
    },
    {
      "type": "training",
      "description": "Training step 183",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:58",
      "total_flops_so_far": 263224334794752.0,
      "budget_used_percent": 0.263224334794752
    },
    {
      "type": "training",
      "description": "Training step 184",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:58",
      "total_flops_so_far": 264654901831680.0,
      "budget_used_percent": 0.26465490183168
    },
    {
      "type": "training",
      "description": "Training step 185",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:58",
      "total_flops_so_far": 266085468868608.0,
      "budget_used_percent": 0.266085468868608
    },
    {
      "type": "training",
      "description": "Training step 186",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:58",
      "total_flops_so_far": 267516035905536.0,
      "budget_used_percent": 0.26751603590553596
    },
    {
      "type": "training",
      "description": "Training step 187",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:58",
      "total_flops_so_far": 268946602942464.0,
      "budget_used_percent": 0.268946602942464
    },
    {
      "type": "training",
      "description": "Training step 188",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:58",
      "total_flops_so_far": 270377169979392.0,
      "budget_used_percent": 0.270377169979392
    },
    {
      "type": "training",
      "description": "Training step 189",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:58",
      "total_flops_so_far": 271807737016320.0,
      "budget_used_percent": 0.27180773701632
    },
    {
      "type": "training",
      "description": "Training step 190",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:58",
      "total_flops_so_far": 273238304053248.0,
      "budget_used_percent": 0.273238304053248
    },
    {
      "type": "training",
      "description": "Training step 191",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:59",
      "total_flops_so_far": 274668871090176.0,
      "budget_used_percent": 0.274668871090176
    },
    {
      "type": "training",
      "description": "Training step 192",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:59",
      "total_flops_so_far": 276099438127104.0,
      "budget_used_percent": 0.276099438127104
    },
    {
      "type": "training",
      "description": "Training step 193",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:59",
      "total_flops_so_far": 277530005164032.0,
      "budget_used_percent": 0.27753000516403203
    },
    {
      "type": "training",
      "description": "Training step 194",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:59",
      "total_flops_so_far": 278960572200960.0,
      "budget_used_percent": 0.27896057220096
    },
    {
      "type": "training",
      "description": "Training step 195",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:59",
      "total_flops_so_far": 280391139237888.0,
      "budget_used_percent": 0.280391139237888
    },
    {
      "type": "training",
      "description": "Training step 196",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:59",
      "total_flops_so_far": 281821706274816.0,
      "budget_used_percent": 0.281821706274816
    },
    {
      "type": "training",
      "description": "Training step 197",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:59",
      "total_flops_so_far": 283252273311744.0,
      "budget_used_percent": 0.283252273311744
    },
    {
      "type": "training",
      "description": "Training step 198",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:59",
      "total_flops_so_far": 284682840348672.0,
      "budget_used_percent": 0.28468284034867203
    },
    {
      "type": "training",
      "description": "Training step 199",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:30:59",
      "total_flops_so_far": 286113407385600.0,
      "budget_used_percent": 0.2861134073856
    },
    {
      "type": "training",
      "description": "Training step 200",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:00",
      "total_flops_so_far": 287543974422528.0,
      "budget_used_percent": 0.287543974422528
    },
    {
      "type": "training",
      "description": "Training step 201",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:00",
      "total_flops_so_far": 288974541459456.0,
      "budget_used_percent": 0.288974541459456
    },
    {
      "type": "training",
      "description": "Training step 202",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:00",
      "total_flops_so_far": 290405108496384.0,
      "budget_used_percent": 0.290405108496384
    },
    {
      "type": "training",
      "description": "Training step 203",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:00",
      "total_flops_so_far": 291835675533312.0,
      "budget_used_percent": 0.29183567553331197
    },
    {
      "type": "training",
      "description": "Training step 204",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:00",
      "total_flops_so_far": 293266242570240.0,
      "budget_used_percent": 0.29326624257024
    },
    {
      "type": "training",
      "description": "Training step 205",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:00",
      "total_flops_so_far": 294696809607168.0,
      "budget_used_percent": 0.294696809607168
    },
    {
      "type": "training",
      "description": "Training step 206",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:00",
      "total_flops_so_far": 296127376644096.0,
      "budget_used_percent": 0.296127376644096
    },
    {
      "type": "training",
      "description": "Training step 207",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:00",
      "total_flops_so_far": 297557943681024.0,
      "budget_used_percent": 0.29755794368102395
    },
    {
      "type": "training",
      "description": "Training step 208",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:01",
      "total_flops_so_far": 298988510717952.0,
      "budget_used_percent": 0.29898851071795196
    },
    {
      "type": "training",
      "description": "Training step 209",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:01",
      "total_flops_so_far": 300419077754880.0,
      "budget_used_percent": 0.30041907775487997
    },
    {
      "type": "training",
      "description": "Training step 210",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:01",
      "total_flops_so_far": 301849644791808.0,
      "budget_used_percent": 0.301849644791808
    },
    {
      "type": "training",
      "description": "Training step 211",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:01",
      "total_flops_so_far": 303280211828736.0,
      "budget_used_percent": 0.303280211828736
    },
    {
      "type": "training",
      "description": "Training step 212",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:01",
      "total_flops_so_far": 304710778865664.0,
      "budget_used_percent": 0.304710778865664
    },
    {
      "type": "training",
      "description": "Training step 213",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:01",
      "total_flops_so_far": 306141345902592.0,
      "budget_used_percent": 0.306141345902592
    },
    {
      "type": "training",
      "description": "Training step 214",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:01",
      "total_flops_so_far": 307571912939520.0,
      "budget_used_percent": 0.30757191293952
    },
    {
      "type": "training",
      "description": "Training step 215",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:01",
      "total_flops_so_far": 309002479976448.0,
      "budget_used_percent": 0.30900247997644803
    },
    {
      "type": "training",
      "description": "Training step 216",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:02",
      "total_flops_so_far": 310433047013376.0,
      "budget_used_percent": 0.310433047013376
    },
    {
      "type": "training",
      "description": "Training step 217",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:02",
      "total_flops_so_far": 311863614050304.0,
      "budget_used_percent": 0.311863614050304
    },
    {
      "type": "training",
      "description": "Training step 218",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:02",
      "total_flops_so_far": 313294181087232.0,
      "budget_used_percent": 0.313294181087232
    },
    {
      "type": "training",
      "description": "Training step 219",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:02",
      "total_flops_so_far": 314724748124160.0,
      "budget_used_percent": 0.31472474812416
    },
    {
      "type": "training",
      "description": "Training step 220",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:02",
      "total_flops_so_far": 316155315161088.0,
      "budget_used_percent": 0.316155315161088
    },
    {
      "type": "training",
      "description": "Training step 221",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:02",
      "total_flops_so_far": 317585882198016.0,
      "budget_used_percent": 0.317585882198016
    },
    {
      "type": "training",
      "description": "Training step 222",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:02",
      "total_flops_so_far": 319016449234944.0,
      "budget_used_percent": 0.319016449234944
    },
    {
      "type": "training",
      "description": "Training step 223",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:02",
      "total_flops_so_far": 320447016271872.0,
      "budget_used_percent": 0.320447016271872
    },
    {
      "type": "training",
      "description": "Training step 224",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:03",
      "total_flops_so_far": 321877583308800.0,
      "budget_used_percent": 0.3218775833088
    },
    {
      "type": "training",
      "description": "Training step 225",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:03",
      "total_flops_so_far": 323308150345728.0,
      "budget_used_percent": 0.32330815034572796
    },
    {
      "type": "training",
      "description": "Training step 226",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:03",
      "total_flops_so_far": 324738717382656.0,
      "budget_used_percent": 0.324738717382656
    },
    {
      "type": "training",
      "description": "Training step 227",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:03",
      "total_flops_so_far": 326169284419584.0,
      "budget_used_percent": 0.326169284419584
    },
    {
      "type": "training",
      "description": "Training step 228",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:03",
      "total_flops_so_far": 327599851456512.0,
      "budget_used_percent": 0.327599851456512
    },
    {
      "type": "training",
      "description": "Training step 229",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:03",
      "total_flops_so_far": 329030418493440.0,
      "budget_used_percent": 0.32903041849344
    },
    {
      "type": "training",
      "description": "Training step 230",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:03",
      "total_flops_so_far": 330460985530368.0,
      "budget_used_percent": 0.330460985530368
    },
    {
      "type": "training",
      "description": "Training step 231",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:03",
      "total_flops_so_far": 331891552567296.0,
      "budget_used_percent": 0.331891552567296
    },
    {
      "type": "training",
      "description": "Training step 232",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:04",
      "total_flops_so_far": 333322119604224.0,
      "budget_used_percent": 0.33332211960422403
    },
    {
      "type": "training",
      "description": "Training step 233",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:04",
      "total_flops_so_far": 334752686641152.0,
      "budget_used_percent": 0.33475268664115204
    },
    {
      "type": "training",
      "description": "Training step 234",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:04",
      "total_flops_so_far": 336183253678080.0,
      "budget_used_percent": 0.33618325367808
    },
    {
      "type": "training",
      "description": "Training step 235",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:04",
      "total_flops_so_far": 337613820715008.0,
      "budget_used_percent": 0.337613820715008
    },
    {
      "type": "training",
      "description": "Training step 236",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:04",
      "total_flops_so_far": 339044387751936.0,
      "budget_used_percent": 0.339044387751936
    },
    {
      "type": "training",
      "description": "Training step 237",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:04",
      "total_flops_so_far": 340474954788864.0,
      "budget_used_percent": 0.340474954788864
    },
    {
      "type": "training",
      "description": "Training step 238",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:04",
      "total_flops_so_far": 341905521825792.0,
      "budget_used_percent": 0.341905521825792
    },
    {
      "type": "training",
      "description": "Training step 239",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:05",
      "total_flops_so_far": 343336088862720.0,
      "budget_used_percent": 0.34333608886272
    },
    {
      "type": "training",
      "description": "Training step 240",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:05",
      "total_flops_so_far": 344766655899648.0,
      "budget_used_percent": 0.344766655899648
    },
    {
      "type": "training",
      "description": "Training step 241",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:05",
      "total_flops_so_far": 346197222936576.0,
      "budget_used_percent": 0.346197222936576
    },
    {
      "type": "training",
      "description": "Training step 242",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:05",
      "total_flops_so_far": 347627789973504.0,
      "budget_used_percent": 0.34762778997350396
    },
    {
      "type": "training",
      "description": "Training step 243",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:05",
      "total_flops_so_far": 349058357010432.0,
      "budget_used_percent": 0.349058357010432
    },
    {
      "type": "training",
      "description": "Training step 244",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:05",
      "total_flops_so_far": 350488924047360.0,
      "budget_used_percent": 0.35048892404736
    },
    {
      "type": "training",
      "description": "Training step 245",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:05",
      "total_flops_so_far": 351919491084288.0,
      "budget_used_percent": 0.351919491084288
    },
    {
      "type": "training",
      "description": "Training step 246",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:05",
      "total_flops_so_far": 353350058121216.0,
      "budget_used_percent": 0.353350058121216
    },
    {
      "type": "training",
      "description": "Training step 247",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:06",
      "total_flops_so_far": 354780625158144.0,
      "budget_used_percent": 0.35478062515814396
    },
    {
      "type": "training",
      "description": "Training step 248",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:06",
      "total_flops_so_far": 356211192195072.0,
      "budget_used_percent": 0.35621119219507197
    },
    {
      "type": "training",
      "description": "Training step 249",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:06",
      "total_flops_so_far": 357641759232000.0,
      "budget_used_percent": 0.357641759232
    },
    {
      "type": "training",
      "description": "Training step 250",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:06",
      "total_flops_so_far": 359072326268928.0,
      "budget_used_percent": 0.359072326268928
    },
    {
      "type": "training",
      "description": "Training step 251",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:06",
      "total_flops_so_far": 360502893305856.0,
      "budget_used_percent": 0.360502893305856
    },
    {
      "type": "training",
      "description": "Training step 252",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:06",
      "total_flops_so_far": 361933460342784.0,
      "budget_used_percent": 0.361933460342784
    },
    {
      "type": "training",
      "description": "Training step 253",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:06",
      "total_flops_so_far": 363364027379712.0,
      "budget_used_percent": 0.363364027379712
    },
    {
      "type": "training",
      "description": "Training step 254",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:06",
      "total_flops_so_far": 364794594416640.0,
      "budget_used_percent": 0.36479459441664003
    },
    {
      "type": "training",
      "description": "Training step 255",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:07",
      "total_flops_so_far": 366225161453568.0,
      "budget_used_percent": 0.36622516145356804
    },
    {
      "type": "training",
      "description": "Training step 256",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:07",
      "total_flops_so_far": 367655728490496.0,
      "budget_used_percent": 0.367655728490496
    },
    {
      "type": "training",
      "description": "Training step 257",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:07",
      "total_flops_so_far": 369086295527424.0,
      "budget_used_percent": 0.369086295527424
    },
    {
      "type": "training",
      "description": "Training step 258",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:07",
      "total_flops_so_far": 370516862564352.0,
      "budget_used_percent": 0.370516862564352
    },
    {
      "type": "training",
      "description": "Training step 259",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:07",
      "total_flops_so_far": 371947429601280.0,
      "budget_used_percent": 0.37194742960128
    },
    {
      "type": "training",
      "description": "Training step 260",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:07",
      "total_flops_so_far": 373377996638208.0,
      "budget_used_percent": 0.373377996638208
    },
    {
      "type": "training",
      "description": "Training step 261",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:07",
      "total_flops_so_far": 374808563675136.0,
      "budget_used_percent": 0.374808563675136
    },
    {
      "type": "training",
      "description": "Training step 262",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:07",
      "total_flops_so_far": 376239130712064.0,
      "budget_used_percent": 0.376239130712064
    },
    {
      "type": "training",
      "description": "Training step 263",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:08",
      "total_flops_so_far": 377669697748992.0,
      "budget_used_percent": 0.377669697748992
    },
    {
      "type": "training",
      "description": "Training step 264",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:08",
      "total_flops_so_far": 379100264785920.0,
      "budget_used_percent": 0.37910026478591996
    },
    {
      "type": "training",
      "description": "Training step 265",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:08",
      "total_flops_so_far": 380530831822848.0,
      "budget_used_percent": 0.38053083182284797
    },
    {
      "type": "training",
      "description": "Training step 266",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:08",
      "total_flops_so_far": 381961398859776.0,
      "budget_used_percent": 0.381961398859776
    },
    {
      "type": "training",
      "description": "Training step 267",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:08",
      "total_flops_so_far": 383391965896704.0,
      "budget_used_percent": 0.383391965896704
    },
    {
      "type": "training",
      "description": "Training step 268",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:08",
      "total_flops_so_far": 384822532933632.0,
      "budget_used_percent": 0.384822532933632
    },
    {
      "type": "training",
      "description": "Training step 269",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:08",
      "total_flops_so_far": 386253099970560.0,
      "budget_used_percent": 0.38625309997056
    },
    {
      "type": "training",
      "description": "Training step 270",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:08",
      "total_flops_so_far": 387683667007488.0,
      "budget_used_percent": 0.387683667007488
    },
    {
      "type": "training",
      "description": "Training step 271",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:09",
      "total_flops_so_far": 389114234044416.0,
      "budget_used_percent": 0.38911423404441603
    },
    {
      "type": "training",
      "description": "Training step 272",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:09",
      "total_flops_so_far": 390544801081344.0,
      "budget_used_percent": 0.39054480108134404
    },
    {
      "type": "training",
      "description": "Training step 273",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:09",
      "total_flops_so_far": 391975368118272.0,
      "budget_used_percent": 0.39197536811827205
    },
    {
      "type": "training",
      "description": "Training step 274",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:09",
      "total_flops_so_far": 393405935155200.0,
      "budget_used_percent": 0.39340593515520006
    },
    {
      "type": "training",
      "description": "Training step 275",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:09",
      "total_flops_so_far": 394836502192128.0,
      "budget_used_percent": 0.39483650219212796
    },
    {
      "type": "training",
      "description": "Training step 276",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:09",
      "total_flops_so_far": 396267069229056.0,
      "budget_used_percent": 0.39626706922905597
    },
    {
      "type": "training",
      "description": "Training step 277",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:09",
      "total_flops_so_far": 397697636265984.0,
      "budget_used_percent": 0.397697636265984
    },
    {
      "type": "training",
      "description": "Training step 278",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:09",
      "total_flops_so_far": 399128203302912.0,
      "budget_used_percent": 0.399128203302912
    },
    {
      "type": "training",
      "description": "Training step 279",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:10",
      "total_flops_so_far": 400558770339840.0,
      "budget_used_percent": 0.40055877033984
    },
    {
      "type": "training",
      "description": "Training step 280",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:10",
      "total_flops_so_far": 401989337376768.0,
      "budget_used_percent": 0.401989337376768
    },
    {
      "type": "training",
      "description": "Training step 281",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:10",
      "total_flops_so_far": 403419904413696.0,
      "budget_used_percent": 0.403419904413696
    },
    {
      "type": "training",
      "description": "Training step 282",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:10",
      "total_flops_so_far": 404850471450624.0,
      "budget_used_percent": 0.404850471450624
    },
    {
      "type": "training",
      "description": "Training step 283",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:10",
      "total_flops_so_far": 406281038487552.0,
      "budget_used_percent": 0.40628103848755204
    },
    {
      "type": "training",
      "description": "Training step 284",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:10",
      "total_flops_so_far": 407711605524480.0,
      "budget_used_percent": 0.40771160552447994
    },
    {
      "type": "training",
      "description": "Training step 285",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:10",
      "total_flops_so_far": 409142172561408.0,
      "budget_used_percent": 0.40914217256140795
    },
    {
      "type": "training",
      "description": "Training step 286",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:10",
      "total_flops_so_far": 410572739598336.0,
      "budget_used_percent": 0.41057273959833596
    },
    {
      "type": "training",
      "description": "Training step 287",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:11",
      "total_flops_so_far": 412003306635264.0,
      "budget_used_percent": 0.41200330663526397
    },
    {
      "type": "training",
      "description": "Training step 288",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:11",
      "total_flops_so_far": 413433873672192.0,
      "budget_used_percent": 0.413433873672192
    },
    {
      "type": "training",
      "description": "Training step 289",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:11",
      "total_flops_so_far": 414864440709120.0,
      "budget_used_percent": 0.41486444070912
    },
    {
      "type": "training",
      "description": "Training step 290",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:11",
      "total_flops_so_far": 416295007746048.0,
      "budget_used_percent": 0.416295007746048
    },
    {
      "type": "training",
      "description": "Training step 291",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:11",
      "total_flops_so_far": 417725574782976.0,
      "budget_used_percent": 0.417725574782976
    },
    {
      "type": "training",
      "description": "Training step 292",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:11",
      "total_flops_so_far": 419156141819904.0,
      "budget_used_percent": 0.419156141819904
    },
    {
      "type": "training",
      "description": "Training step 293",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:11",
      "total_flops_so_far": 420586708856832.0,
      "budget_used_percent": 0.42058670885683197
    },
    {
      "type": "training",
      "description": "Training step 294",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:11",
      "total_flops_so_far": 422017275893760.0,
      "budget_used_percent": 0.42201727589376
    },
    {
      "type": "training",
      "description": "Training step 295",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:12",
      "total_flops_so_far": 423447842930688.0,
      "budget_used_percent": 0.423447842930688
    },
    {
      "type": "training",
      "description": "Training step 296",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:12",
      "total_flops_so_far": 424878409967616.0,
      "budget_used_percent": 0.424878409967616
    },
    {
      "type": "training",
      "description": "Training step 297",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:12",
      "total_flops_so_far": 426308977004544.0,
      "budget_used_percent": 0.426308977004544
    },
    {
      "type": "training",
      "description": "Training step 298",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:12",
      "total_flops_so_far": 427739544041472.0,
      "budget_used_percent": 0.427739544041472
    },
    {
      "type": "training",
      "description": "Training step 299",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:12",
      "total_flops_so_far": 429170111078400.0,
      "budget_used_percent": 0.42917011107840003
    },
    {
      "type": "training",
      "description": "Training step 300",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:12",
      "total_flops_so_far": 430600678115328.0,
      "budget_used_percent": 0.43060067811532804
    },
    {
      "type": "training",
      "description": "Training step 301",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:12",
      "total_flops_so_far": 432031245152256.0,
      "budget_used_percent": 0.43203124515225605
    },
    {
      "type": "training",
      "description": "Training step 302",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:12",
      "total_flops_so_far": 433461812189184.0,
      "budget_used_percent": 0.43346181218918395
    },
    {
      "type": "training",
      "description": "Training step 303",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:13",
      "total_flops_so_far": 434892379226112.0,
      "budget_used_percent": 0.43489237922611196
    },
    {
      "type": "training",
      "description": "Training step 304",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:13",
      "total_flops_so_far": 436322946263040.0,
      "budget_used_percent": 0.43632294626303997
    },
    {
      "type": "training",
      "description": "Training step 305",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:13",
      "total_flops_so_far": 437753513299968.0,
      "budget_used_percent": 0.437753513299968
    },
    {
      "type": "training",
      "description": "Training step 306",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:13",
      "total_flops_so_far": 439184080336896.0,
      "budget_used_percent": 0.439184080336896
    },
    {
      "type": "training",
      "description": "Training step 307",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:13",
      "total_flops_so_far": 440614647373824.0,
      "budget_used_percent": 0.440614647373824
    },
    {
      "type": "training",
      "description": "Training step 308",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:13",
      "total_flops_so_far": 442045214410752.0,
      "budget_used_percent": 0.442045214410752
    },
    {
      "type": "training",
      "description": "Training step 309",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:13",
      "total_flops_so_far": 443475781447680.0,
      "budget_used_percent": 0.44347578144768
    },
    {
      "type": "training",
      "description": "Training step 310",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:13",
      "total_flops_so_far": 444906348484608.0,
      "budget_used_percent": 0.44490634848460797
    },
    {
      "type": "training",
      "description": "Training step 311",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:14",
      "total_flops_so_far": 446336915521536.0,
      "budget_used_percent": 0.446336915521536
    },
    {
      "type": "training",
      "description": "Training step 312",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:14",
      "total_flops_so_far": 447767482558464.0,
      "budget_used_percent": 0.447767482558464
    },
    {
      "type": "training",
      "description": "Training step 313",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:14",
      "total_flops_so_far": 449198049595392.0,
      "budget_used_percent": 0.449198049595392
    },
    {
      "type": "training",
      "description": "Training step 314",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:14",
      "total_flops_so_far": 450628616632320.0,
      "budget_used_percent": 0.45062861663232
    },
    {
      "type": "training",
      "description": "Training step 315",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:14",
      "total_flops_so_far": 452059183669248.0,
      "budget_used_percent": 0.452059183669248
    },
    {
      "type": "training",
      "description": "Training step 316",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:14",
      "total_flops_so_far": 453489750706176.0,
      "budget_used_percent": 0.45348975070617603
    },
    {
      "type": "training",
      "description": "Training step 317",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:14",
      "total_flops_so_far": 454920317743104.0,
      "budget_used_percent": 0.45492031774310404
    },
    {
      "type": "training",
      "description": "Training step 318",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:14",
      "total_flops_so_far": 456350884780032.0,
      "budget_used_percent": 0.45635088478003205
    },
    {
      "type": "training",
      "description": "Training step 319",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:15",
      "total_flops_so_far": 457781451816960.0,
      "budget_used_percent": 0.45778145181695995
    },
    {
      "type": "training",
      "description": "Training step 320",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:15",
      "total_flops_so_far": 459212018853888.0,
      "budget_used_percent": 0.45921201885388796
    },
    {
      "type": "training",
      "description": "Training step 321",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:15",
      "total_flops_so_far": 460642585890816.0,
      "budget_used_percent": 0.46064258589081597
    },
    {
      "type": "training",
      "description": "Training step 322",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:15",
      "total_flops_so_far": 462073152927744.0,
      "budget_used_percent": 0.462073152927744
    },
    {
      "type": "training",
      "description": "Training step 323",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:15",
      "total_flops_so_far": 463503719964672.0,
      "budget_used_percent": 0.463503719964672
    },
    {
      "type": "training",
      "description": "Training step 324",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:15",
      "total_flops_so_far": 464934287001600.0,
      "budget_used_percent": 0.4649342870016
    },
    {
      "type": "training",
      "description": "Training step 325",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:15",
      "total_flops_so_far": 466364854038528.0,
      "budget_used_percent": 0.466364854038528
    },
    {
      "type": "training",
      "description": "Training step 326",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:15",
      "total_flops_so_far": 467795421075456.0,
      "budget_used_percent": 0.467795421075456
    },
    {
      "type": "training",
      "description": "Training step 327",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:16",
      "total_flops_so_far": 469225988112384.0,
      "budget_used_percent": 0.46922598811238403
    },
    {
      "type": "training",
      "description": "Training step 328",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:16",
      "total_flops_so_far": 470656555149312.0,
      "budget_used_percent": 0.470656555149312
    },
    {
      "type": "training",
      "description": "Training step 329",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:16",
      "total_flops_so_far": 472087122186240.0,
      "budget_used_percent": 0.47208712218624
    },
    {
      "type": "training",
      "description": "Training step 330",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:16",
      "total_flops_so_far": 473517689223168.0,
      "budget_used_percent": 0.473517689223168
    },
    {
      "type": "training",
      "description": "Training step 331",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:16",
      "total_flops_so_far": 474948256260096.0,
      "budget_used_percent": 0.474948256260096
    },
    {
      "type": "training",
      "description": "Training step 332",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:16",
      "total_flops_so_far": 476378823297024.0,
      "budget_used_percent": 0.476378823297024
    },
    {
      "type": "training",
      "description": "Training step 333",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:16",
      "total_flops_so_far": 477809390333952.0,
      "budget_used_percent": 0.47780939033395203
    },
    {
      "type": "training",
      "description": "Training step 334",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:16",
      "total_flops_so_far": 479239957370880.0,
      "budget_used_percent": 0.47923995737088004
    },
    {
      "type": "training",
      "description": "Training step 335",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:17",
      "total_flops_so_far": 480670524407808.0,
      "budget_used_percent": 0.48067052440780805
    },
    {
      "type": "training",
      "description": "Training step 336",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:17",
      "total_flops_so_far": 482101091444736.0,
      "budget_used_percent": 0.48210109144473606
    },
    {
      "type": "training",
      "description": "Training step 337",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:17",
      "total_flops_so_far": 483531658481664.0,
      "budget_used_percent": 0.48353165848166396
    },
    {
      "type": "training",
      "description": "Training step 338",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:17",
      "total_flops_so_far": 484962225518592.0,
      "budget_used_percent": 0.48496222551859197
    },
    {
      "type": "training",
      "description": "Training step 339",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:17",
      "total_flops_so_far": 486392792555520.0,
      "budget_used_percent": 0.48639279255552
    },
    {
      "type": "training",
      "description": "Training step 340",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:17",
      "total_flops_so_far": 487823359592448.0,
      "budget_used_percent": 0.487823359592448
    },
    {
      "type": "training",
      "description": "Training step 341",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:17",
      "total_flops_so_far": 489253926629376.0,
      "budget_used_percent": 0.489253926629376
    },
    {
      "type": "training",
      "description": "Training step 342",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:18",
      "total_flops_so_far": 490684493666304.0,
      "budget_used_percent": 0.490684493666304
    },
    {
      "type": "training",
      "description": "Training step 343",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:18",
      "total_flops_so_far": 492115060703232.0,
      "budget_used_percent": 0.492115060703232
    },
    {
      "type": "training",
      "description": "Training step 344",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:18",
      "total_flops_so_far": 493545627740160.0,
      "budget_used_percent": 0.49354562774016003
    },
    {
      "type": "training",
      "description": "Training step 345",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:18",
      "total_flops_so_far": 494976194777088.0,
      "budget_used_percent": 0.494976194777088
    },
    {
      "type": "training",
      "description": "Training step 346",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:18",
      "total_flops_so_far": 496406761814016.0,
      "budget_used_percent": 0.496406761814016
    },
    {
      "type": "training",
      "description": "Training step 347",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:18",
      "total_flops_so_far": 497837328850944.0,
      "budget_used_percent": 0.497837328850944
    },
    {
      "type": "training",
      "description": "Training step 348",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:18",
      "total_flops_so_far": 499267895887872.0,
      "budget_used_percent": 0.499267895887872
    },
    {
      "type": "training",
      "description": "Training step 349",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:18",
      "total_flops_so_far": 500698462924800.0,
      "budget_used_percent": 0.5006984629248
    },
    {
      "type": "training",
      "description": "Training step 350",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:19",
      "total_flops_so_far": 502129029961728.0,
      "budget_used_percent": 0.502129029961728
    },
    {
      "type": "training",
      "description": "Training step 351",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:19",
      "total_flops_so_far": 503559596998656.0,
      "budget_used_percent": 0.503559596998656
    },
    {
      "type": "training",
      "description": "Training step 352",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:19",
      "total_flops_so_far": 504990164035584.0,
      "budget_used_percent": 0.504990164035584
    },
    {
      "type": "training",
      "description": "Training step 353",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:19",
      "total_flops_so_far": 506420731072512.0,
      "budget_used_percent": 0.5064207310725121
    },
    {
      "type": "training",
      "description": "Training step 354",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:19",
      "total_flops_so_far": 507851298109440.0,
      "budget_used_percent": 0.50785129810944
    },
    {
      "type": "training",
      "description": "Training step 355",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:19",
      "total_flops_so_far": 509281865146368.0,
      "budget_used_percent": 0.509281865146368
    },
    {
      "type": "training",
      "description": "Training step 356",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:19",
      "total_flops_so_far": 510712432183296.0,
      "budget_used_percent": 0.510712432183296
    },
    {
      "type": "training",
      "description": "Training step 357",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:19",
      "total_flops_so_far": 512142999220224.0,
      "budget_used_percent": 0.512142999220224
    },
    {
      "type": "training",
      "description": "Training step 358",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:20",
      "total_flops_so_far": 513573566257152.0,
      "budget_used_percent": 0.513573566257152
    },
    {
      "type": "training",
      "description": "Training step 359",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:20",
      "total_flops_so_far": 515004133294080.0,
      "budget_used_percent": 0.51500413329408
    },
    {
      "type": "training",
      "description": "Training step 360",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:20",
      "total_flops_so_far": 516434700331008.0,
      "budget_used_percent": 0.516434700331008
    },
    {
      "type": "training",
      "description": "Training step 361",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:20",
      "total_flops_so_far": 517865267367936.0,
      "budget_used_percent": 0.517865267367936
    },
    {
      "type": "training",
      "description": "Training step 362",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:20",
      "total_flops_so_far": 519295834404864.0,
      "budget_used_percent": 0.519295834404864
    },
    {
      "type": "training",
      "description": "Training step 363",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:20",
      "total_flops_so_far": 520726401441792.0,
      "budget_used_percent": 0.5207264014417919
    },
    {
      "type": "training",
      "description": "Training step 364",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:20",
      "total_flops_so_far": 522156968478720.0,
      "budget_used_percent": 0.52215696847872
    },
    {
      "type": "training",
      "description": "Training step 365",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:20",
      "total_flops_so_far": 523587535515648.0,
      "budget_used_percent": 0.523587535515648
    },
    {
      "type": "training",
      "description": "Training step 366",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:21",
      "total_flops_so_far": 525018102552576.0,
      "budget_used_percent": 0.525018102552576
    },
    {
      "type": "training",
      "description": "Training step 367",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:21",
      "total_flops_so_far": 526448669589504.0,
      "budget_used_percent": 0.526448669589504
    },
    {
      "type": "training",
      "description": "Training step 368",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:21",
      "total_flops_so_far": 527879236626432.0,
      "budget_used_percent": 0.527879236626432
    },
    {
      "type": "training",
      "description": "Training step 369",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:21",
      "total_flops_so_far": 529309803663360.0,
      "budget_used_percent": 0.52930980366336
    },
    {
      "type": "training",
      "description": "Training step 370",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:21",
      "total_flops_so_far": 530740370700288.0,
      "budget_used_percent": 0.530740370700288
    },
    {
      "type": "training",
      "description": "Training step 371",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:21",
      "total_flops_so_far": 532170937737216.0,
      "budget_used_percent": 0.532170937737216
    },
    {
      "type": "training",
      "description": "Training step 372",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:21",
      "total_flops_so_far": 533601504774144.0,
      "budget_used_percent": 0.5336015047741439
    },
    {
      "type": "training",
      "description": "Training step 373",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:21",
      "total_flops_so_far": 535032071811072.0,
      "budget_used_percent": 0.5350320718110719
    },
    {
      "type": "training",
      "description": "Training step 374",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:22",
      "total_flops_so_far": 536462638848000.0,
      "budget_used_percent": 0.5364626388479999
    },
    {
      "type": "training",
      "description": "Training step 375",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:22",
      "total_flops_so_far": 537893205884928.0,
      "budget_used_percent": 0.537893205884928
    },
    {
      "type": "training",
      "description": "Training step 376",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:22",
      "total_flops_so_far": 539323772921856.0,
      "budget_used_percent": 0.539323772921856
    },
    {
      "type": "training",
      "description": "Training step 377",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:22",
      "total_flops_so_far": 540754339958784.0,
      "budget_used_percent": 0.540754339958784
    },
    {
      "type": "training",
      "description": "Training step 378",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:22",
      "total_flops_so_far": 542184906995712.0,
      "budget_used_percent": 0.542184906995712
    },
    {
      "type": "training",
      "description": "Training step 379",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:22",
      "total_flops_so_far": 543615474032640.0,
      "budget_used_percent": 0.54361547403264
    },
    {
      "type": "training",
      "description": "Training step 380",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:22",
      "total_flops_so_far": 545046041069568.0,
      "budget_used_percent": 0.545046041069568
    },
    {
      "type": "training",
      "description": "Training step 381",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:22",
      "total_flops_so_far": 546476608106496.0,
      "budget_used_percent": 0.546476608106496
    },
    {
      "type": "training",
      "description": "Training step 382",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:23",
      "total_flops_so_far": 547907175143424.0,
      "budget_used_percent": 0.547907175143424
    },
    {
      "type": "training",
      "description": "Training step 383",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:23",
      "total_flops_so_far": 549337742180352.0,
      "budget_used_percent": 0.549337742180352
    },
    {
      "type": "training",
      "description": "Training step 384",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:23",
      "total_flops_so_far": 550768309217280.0,
      "budget_used_percent": 0.55076830921728
    },
    {
      "type": "training",
      "description": "Training step 385",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:23",
      "total_flops_so_far": 552198876254208.0,
      "budget_used_percent": 0.552198876254208
    },
    {
      "type": "training",
      "description": "Training step 386",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:23",
      "total_flops_so_far": 553629443291136.0,
      "budget_used_percent": 0.5536294432911361
    },
    {
      "type": "training",
      "description": "Training step 387",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:23",
      "total_flops_so_far": 555060010328064.0,
      "budget_used_percent": 0.5550600103280641
    },
    {
      "type": "training",
      "description": "Training step 388",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:23",
      "total_flops_so_far": 556490577364992.0,
      "budget_used_percent": 0.5564905773649921
    },
    {
      "type": "training",
      "description": "Training step 389",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:23",
      "total_flops_so_far": 557921144401920.0,
      "budget_used_percent": 0.55792114440192
    },
    {
      "type": "training",
      "description": "Training step 390",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:24",
      "total_flops_so_far": 559351711438848.0,
      "budget_used_percent": 0.559351711438848
    },
    {
      "type": "training",
      "description": "Training step 391",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:24",
      "total_flops_so_far": 560782278475776.0,
      "budget_used_percent": 0.560782278475776
    },
    {
      "type": "training",
      "description": "Training step 392",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:24",
      "total_flops_so_far": 562212845512704.0,
      "budget_used_percent": 0.562212845512704
    },
    {
      "type": "training",
      "description": "Training step 393",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:24",
      "total_flops_so_far": 563643412549632.0,
      "budget_used_percent": 0.563643412549632
    },
    {
      "type": "training",
      "description": "Training step 394",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:24",
      "total_flops_so_far": 565073979586560.0,
      "budget_used_percent": 0.56507397958656
    },
    {
      "type": "training",
      "description": "Training step 395",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:24",
      "total_flops_so_far": 566504546623488.0,
      "budget_used_percent": 0.566504546623488
    },
    {
      "type": "training",
      "description": "Training step 396",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:24",
      "total_flops_so_far": 567935113660416.0,
      "budget_used_percent": 0.567935113660416
    },
    {
      "type": "training",
      "description": "Training step 397",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:24",
      "total_flops_so_far": 569365680697344.0,
      "budget_used_percent": 0.5693656806973441
    },
    {
      "type": "training",
      "description": "Training step 398",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:25",
      "total_flops_so_far": 570796247734272.0,
      "budget_used_percent": 0.570796247734272
    },
    {
      "type": "training",
      "description": "Training step 399",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:25",
      "total_flops_so_far": 572226814771200.0,
      "budget_used_percent": 0.5722268147712
    },
    {
      "type": "training",
      "description": "Training step 400",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:25",
      "total_flops_so_far": 573657381808128.0,
      "budget_used_percent": 0.573657381808128
    },
    {
      "type": "training",
      "description": "Training step 401",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:25",
      "total_flops_so_far": 575087948845056.0,
      "budget_used_percent": 0.575087948845056
    },
    {
      "type": "training",
      "description": "Training step 402",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:25",
      "total_flops_so_far": 576518515881984.0,
      "budget_used_percent": 0.576518515881984
    },
    {
      "type": "training",
      "description": "Training step 403",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:25",
      "total_flops_so_far": 577949082918912.0,
      "budget_used_percent": 0.577949082918912
    },
    {
      "type": "training",
      "description": "Training step 404",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:25",
      "total_flops_so_far": 579379649955840.0,
      "budget_used_percent": 0.57937964995584
    },
    {
      "type": "training",
      "description": "Training step 405",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:26",
      "total_flops_so_far": 580810216992768.0,
      "budget_used_percent": 0.580810216992768
    },
    {
      "type": "training",
      "description": "Training step 406",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:26",
      "total_flops_so_far": 582240784029696.0,
      "budget_used_percent": 0.582240784029696
    },
    {
      "type": "training",
      "description": "Training step 407",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:26",
      "total_flops_so_far": 583671351066624.0,
      "budget_used_percent": 0.5836713510666239
    },
    {
      "type": "training",
      "description": "Training step 408",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:26",
      "total_flops_so_far": 585101918103552.0,
      "budget_used_percent": 0.5851019181035519
    },
    {
      "type": "training",
      "description": "Training step 409",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:26",
      "total_flops_so_far": 586532485140480.0,
      "budget_used_percent": 0.58653248514048
    },
    {
      "type": "training",
      "description": "Training step 410",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:26",
      "total_flops_so_far": 587963052177408.0,
      "budget_used_percent": 0.587963052177408
    },
    {
      "type": "training",
      "description": "Training step 411",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:26",
      "total_flops_so_far": 589393619214336.0,
      "budget_used_percent": 0.589393619214336
    },
    {
      "type": "training",
      "description": "Training step 412",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:26",
      "total_flops_so_far": 590824186251264.0,
      "budget_used_percent": 0.590824186251264
    },
    {
      "type": "training",
      "description": "Training step 413",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:27",
      "total_flops_so_far": 592254753288192.0,
      "budget_used_percent": 0.592254753288192
    },
    {
      "type": "training",
      "description": "Training step 414",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:27",
      "total_flops_so_far": 593685320325120.0,
      "budget_used_percent": 0.59368532032512
    },
    {
      "type": "training",
      "description": "Training step 415",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:27",
      "total_flops_so_far": 595115887362048.0,
      "budget_used_percent": 0.5951158873620479
    },
    {
      "type": "training",
      "description": "Training step 416",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:27",
      "total_flops_so_far": 596546454398976.0,
      "budget_used_percent": 0.596546454398976
    },
    {
      "type": "training",
      "description": "Training step 417",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:27",
      "total_flops_so_far": 597977021435904.0,
      "budget_used_percent": 0.5979770214359039
    },
    {
      "type": "training",
      "description": "Training step 418",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:27",
      "total_flops_so_far": 599407588472832.0,
      "budget_used_percent": 0.599407588472832
    },
    {
      "type": "training",
      "description": "Training step 419",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:27",
      "total_flops_so_far": 600838155509760.0,
      "budget_used_percent": 0.6008381555097599
    },
    {
      "type": "training",
      "description": "Training step 420",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:27",
      "total_flops_so_far": 602268722546688.0,
      "budget_used_percent": 0.6022687225466881
    },
    {
      "type": "training",
      "description": "Training step 421",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:28",
      "total_flops_so_far": 603699289583616.0,
      "budget_used_percent": 0.603699289583616
    },
    {
      "type": "training",
      "description": "Training step 422",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:28",
      "total_flops_so_far": 605129856620544.0,
      "budget_used_percent": 0.6051298566205441
    },
    {
      "type": "training",
      "description": "Training step 423",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:28",
      "total_flops_so_far": 606560423657472.0,
      "budget_used_percent": 0.606560423657472
    },
    {
      "type": "training",
      "description": "Training step 424",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:28",
      "total_flops_so_far": 607990990694400.0,
      "budget_used_percent": 0.6079909906944
    },
    {
      "type": "training",
      "description": "Training step 425",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:28",
      "total_flops_so_far": 609421557731328.0,
      "budget_used_percent": 0.609421557731328
    },
    {
      "type": "training",
      "description": "Training step 426",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:28",
      "total_flops_so_far": 610852124768256.0,
      "budget_used_percent": 0.610852124768256
    },
    {
      "type": "training",
      "description": "Training step 427",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:28",
      "total_flops_so_far": 612282691805184.0,
      "budget_used_percent": 0.612282691805184
    },
    {
      "type": "training",
      "description": "Training step 428",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:28",
      "total_flops_so_far": 613713258842112.0,
      "budget_used_percent": 0.613713258842112
    },
    {
      "type": "training",
      "description": "Training step 429",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:29",
      "total_flops_so_far": 615143825879040.0,
      "budget_used_percent": 0.61514382587904
    },
    {
      "type": "training",
      "description": "Training step 430",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:29",
      "total_flops_so_far": 616574392915968.0,
      "budget_used_percent": 0.616574392915968
    },
    {
      "type": "training",
      "description": "Training step 431",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:29",
      "total_flops_so_far": 618004959952896.0,
      "budget_used_percent": 0.6180049599528961
    },
    {
      "type": "training",
      "description": "Training step 432",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:29",
      "total_flops_so_far": 619435526989824.0,
      "budget_used_percent": 0.6194355269898241
    },
    {
      "type": "training",
      "description": "Training step 433",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:29",
      "total_flops_so_far": 620866094026752.0,
      "budget_used_percent": 0.620866094026752
    },
    {
      "type": "training",
      "description": "Training step 434",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:29",
      "total_flops_so_far": 622296661063680.0,
      "budget_used_percent": 0.62229666106368
    },
    {
      "type": "training",
      "description": "Training step 435",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:29",
      "total_flops_so_far": 623727228100608.0,
      "budget_used_percent": 0.623727228100608
    },
    {
      "type": "training",
      "description": "Training step 436",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:29",
      "total_flops_so_far": 625157795137536.0,
      "budget_used_percent": 0.625157795137536
    },
    {
      "type": "training",
      "description": "Training step 437",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:30",
      "total_flops_so_far": 626588362174464.0,
      "budget_used_percent": 0.626588362174464
    },
    {
      "type": "training",
      "description": "Training step 438",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:30",
      "total_flops_so_far": 628018929211392.0,
      "budget_used_percent": 0.628018929211392
    },
    {
      "type": "training",
      "description": "Training step 439",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:30",
      "total_flops_so_far": 629449496248320.0,
      "budget_used_percent": 0.62944949624832
    },
    {
      "type": "training",
      "description": "Training step 440",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:30",
      "total_flops_so_far": 630880063285248.0,
      "budget_used_percent": 0.630880063285248
    },
    {
      "type": "training",
      "description": "Training step 441",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:30",
      "total_flops_so_far": 632310630322176.0,
      "budget_used_percent": 0.632310630322176
    },
    {
      "type": "training",
      "description": "Training step 442",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:30",
      "total_flops_so_far": 633741197359104.0,
      "budget_used_percent": 0.633741197359104
    },
    {
      "type": "training",
      "description": "Training step 443",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:30",
      "total_flops_so_far": 635171764396032.0,
      "budget_used_percent": 0.635171764396032
    },
    {
      "type": "training",
      "description": "Training step 444",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:31",
      "total_flops_so_far": 636602331432960.0,
      "budget_used_percent": 0.63660233143296
    },
    {
      "type": "training",
      "description": "Training step 445",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:31",
      "total_flops_so_far": 638032898469888.0,
      "budget_used_percent": 0.638032898469888
    },
    {
      "type": "training",
      "description": "Training step 446",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:31",
      "total_flops_so_far": 639463465506816.0,
      "budget_used_percent": 0.639463465506816
    },
    {
      "type": "training",
      "description": "Training step 447",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:31",
      "total_flops_so_far": 640894032543744.0,
      "budget_used_percent": 0.640894032543744
    },
    {
      "type": "training",
      "description": "Training step 448",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:31",
      "total_flops_so_far": 642324599580672.0,
      "budget_used_percent": 0.642324599580672
    },
    {
      "type": "training",
      "description": "Training step 449",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:31",
      "total_flops_so_far": 643755166617600.0,
      "budget_used_percent": 0.6437551666176
    },
    {
      "type": "training",
      "description": "Training step 450",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:31",
      "total_flops_so_far": 645185733654528.0,
      "budget_used_percent": 0.6451857336545279
    },
    {
      "type": "training",
      "description": "Training step 451",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:31",
      "total_flops_so_far": 646616300691456.0,
      "budget_used_percent": 0.6466163006914559
    },
    {
      "type": "training",
      "description": "Training step 452",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:32",
      "total_flops_so_far": 648046867728384.0,
      "budget_used_percent": 0.6480468677283839
    },
    {
      "type": "training",
      "description": "Training step 453",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:32",
      "total_flops_so_far": 649477434765312.0,
      "budget_used_percent": 0.649477434765312
    },
    {
      "type": "training",
      "description": "Training step 454",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:32",
      "total_flops_so_far": 650908001802240.0,
      "budget_used_percent": 0.65090800180224
    },
    {
      "type": "training",
      "description": "Training step 455",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:32",
      "total_flops_so_far": 652338568839168.0,
      "budget_used_percent": 0.652338568839168
    },
    {
      "type": "training",
      "description": "Training step 456",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:32",
      "total_flops_so_far": 653769135876096.0,
      "budget_used_percent": 0.653769135876096
    },
    {
      "type": "training",
      "description": "Training step 457",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:32",
      "total_flops_so_far": 655199702913024.0,
      "budget_used_percent": 0.655199702913024
    },
    {
      "type": "training",
      "description": "Training step 458",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:32",
      "total_flops_so_far": 656630269949952.0,
      "budget_used_percent": 0.656630269949952
    },
    {
      "type": "training",
      "description": "Training step 459",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:32",
      "total_flops_so_far": 658060836986880.0,
      "budget_used_percent": 0.65806083698688
    },
    {
      "type": "training",
      "description": "Training step 460",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:33",
      "total_flops_so_far": 659491404023808.0,
      "budget_used_percent": 0.659491404023808
    },
    {
      "type": "training",
      "description": "Training step 461",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:33",
      "total_flops_so_far": 660921971060736.0,
      "budget_used_percent": 0.660921971060736
    },
    {
      "type": "training",
      "description": "Training step 462",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:33",
      "total_flops_so_far": 662352538097664.0,
      "budget_used_percent": 0.662352538097664
    },
    {
      "type": "training",
      "description": "Training step 463",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:33",
      "total_flops_so_far": 663783105134592.0,
      "budget_used_percent": 0.663783105134592
    },
    {
      "type": "training",
      "description": "Training step 464",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:33",
      "total_flops_so_far": 665213672171520.0,
      "budget_used_percent": 0.66521367217152
    },
    {
      "type": "training",
      "description": "Training step 465",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:33",
      "total_flops_so_far": 666644239208448.0,
      "budget_used_percent": 0.6666442392084481
    },
    {
      "type": "training",
      "description": "Training step 466",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:33",
      "total_flops_so_far": 668074806245376.0,
      "budget_used_percent": 0.6680748062453761
    },
    {
      "type": "training",
      "description": "Training step 467",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:34",
      "total_flops_so_far": 669505373282304.0,
      "budget_used_percent": 0.6695053732823041
    },
    {
      "type": "training",
      "description": "Training step 468",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:34",
      "total_flops_so_far": 670935940319232.0,
      "budget_used_percent": 0.670935940319232
    },
    {
      "type": "training",
      "description": "Training step 469",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:34",
      "total_flops_so_far": 672366507356160.0,
      "budget_used_percent": 0.67236650735616
    },
    {
      "type": "training",
      "description": "Training step 470",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:34",
      "total_flops_so_far": 673797074393088.0,
      "budget_used_percent": 0.673797074393088
    },
    {
      "type": "training",
      "description": "Training step 471",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:34",
      "total_flops_so_far": 675227641430016.0,
      "budget_used_percent": 0.675227641430016
    },
    {
      "type": "training",
      "description": "Training step 472",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:34",
      "total_flops_so_far": 676658208466944.0,
      "budget_used_percent": 0.676658208466944
    },
    {
      "type": "training",
      "description": "Training step 473",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:34",
      "total_flops_so_far": 678088775503872.0,
      "budget_used_percent": 0.678088775503872
    },
    {
      "type": "training",
      "description": "Training step 474",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:34",
      "total_flops_so_far": 679519342540800.0,
      "budget_used_percent": 0.6795193425408
    },
    {
      "type": "training",
      "description": "Training step 475",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:35",
      "total_flops_so_far": 680949909577728.0,
      "budget_used_percent": 0.680949909577728
    },
    {
      "type": "training",
      "description": "Training step 476",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:35",
      "total_flops_so_far": 682380476614656.0,
      "budget_used_percent": 0.6823804766146561
    },
    {
      "type": "training",
      "description": "Training step 477",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:35",
      "total_flops_so_far": 683811043651584.0,
      "budget_used_percent": 0.683811043651584
    },
    {
      "type": "training",
      "description": "Training step 478",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:35",
      "total_flops_so_far": 685241610688512.0,
      "budget_used_percent": 0.685241610688512
    },
    {
      "type": "training",
      "description": "Training step 479",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:35",
      "total_flops_so_far": 686672177725440.0,
      "budget_used_percent": 0.68667217772544
    },
    {
      "type": "training",
      "description": "Training step 480",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:35",
      "total_flops_so_far": 688102744762368.0,
      "budget_used_percent": 0.688102744762368
    },
    {
      "type": "training",
      "description": "Training step 481",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:35",
      "total_flops_so_far": 689533311799296.0,
      "budget_used_percent": 0.689533311799296
    },
    {
      "type": "training",
      "description": "Training step 482",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:35",
      "total_flops_so_far": 690963878836224.0,
      "budget_used_percent": 0.690963878836224
    },
    {
      "type": "training",
      "description": "Training step 483",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:36",
      "total_flops_so_far": 692394445873152.0,
      "budget_used_percent": 0.692394445873152
    },
    {
      "type": "training",
      "description": "Training step 484",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:36",
      "total_flops_so_far": 693825012910080.0,
      "budget_used_percent": 0.69382501291008
    },
    {
      "type": "training",
      "description": "Training step 485",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:36",
      "total_flops_so_far": 695255579947008.0,
      "budget_used_percent": 0.6952555799470079
    },
    {
      "type": "training",
      "description": "Training step 486",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:36",
      "total_flops_so_far": 696686146983936.0,
      "budget_used_percent": 0.6966861469839359
    },
    {
      "type": "training",
      "description": "Training step 487",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:36",
      "total_flops_so_far": 698116714020864.0,
      "budget_used_percent": 0.698116714020864
    },
    {
      "type": "training",
      "description": "Training step 488",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:36",
      "total_flops_so_far": 699547281057792.0,
      "budget_used_percent": 0.699547281057792
    },
    {
      "type": "training",
      "description": "Training step 489",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:36",
      "total_flops_so_far": 700977848094720.0,
      "budget_used_percent": 0.70097784809472
    },
    {
      "type": "training",
      "description": "Training step 490",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:36",
      "total_flops_so_far": 702408415131648.0,
      "budget_used_percent": 0.702408415131648
    },
    {
      "type": "training",
      "description": "Training step 491",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:37",
      "total_flops_so_far": 703838982168576.0,
      "budget_used_percent": 0.703838982168576
    },
    {
      "type": "training",
      "description": "Training step 492",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:37",
      "total_flops_so_far": 705269549205504.0,
      "budget_used_percent": 0.705269549205504
    },
    {
      "type": "training",
      "description": "Training step 493",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:37",
      "total_flops_so_far": 706700116242432.0,
      "budget_used_percent": 0.706700116242432
    },
    {
      "type": "training",
      "description": "Training step 494",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:37",
      "total_flops_so_far": 708130683279360.0,
      "budget_used_percent": 0.7081306832793599
    },
    {
      "type": "training",
      "description": "Training step 495",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:37",
      "total_flops_so_far": 709561250316288.0,
      "budget_used_percent": 0.7095612503162879
    },
    {
      "type": "training",
      "description": "Training step 496",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:37",
      "total_flops_so_far": 710991817353216.0,
      "budget_used_percent": 0.7109918173532159
    },
    {
      "type": "training",
      "description": "Training step 497",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:37",
      "total_flops_so_far": 712422384390144.0,
      "budget_used_percent": 0.7124223843901439
    },
    {
      "type": "training",
      "description": "Training step 498",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:37",
      "total_flops_so_far": 713852951427072.0,
      "budget_used_percent": 0.713852951427072
    },
    {
      "type": "training",
      "description": "Training step 499",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:31:38",
      "total_flops_so_far": 715283518464000.0,
      "budget_used_percent": 0.715283518464
    },
    {
      "type": "training",
      "description": "Training step 500",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:01",
      "total_flops_so_far": 716714085500928.0,
      "budget_used_percent": 0.716714085500928
    },
    {
      "type": "training",
      "description": "Training step 501",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:02",
      "total_flops_so_far": 718144652537856.0,
      "budget_used_percent": 0.718144652537856
    },
    {
      "type": "training",
      "description": "Training step 502",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:02",
      "total_flops_so_far": 719575219574784.0,
      "budget_used_percent": 0.719575219574784
    },
    {
      "type": "training",
      "description": "Training step 503",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:02",
      "total_flops_so_far": 721005786611712.0,
      "budget_used_percent": 0.721005786611712
    },
    {
      "type": "training",
      "description": "Training step 504",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:02",
      "total_flops_so_far": 722436353648640.0,
      "budget_used_percent": 0.72243635364864
    },
    {
      "type": "training",
      "description": "Training step 505",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:02",
      "total_flops_so_far": 723866920685568.0,
      "budget_used_percent": 0.723866920685568
    },
    {
      "type": "training",
      "description": "Training step 506",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:02",
      "total_flops_so_far": 725297487722496.0,
      "budget_used_percent": 0.725297487722496
    },
    {
      "type": "training",
      "description": "Training step 507",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:02",
      "total_flops_so_far": 726728054759424.0,
      "budget_used_percent": 0.726728054759424
    },
    {
      "type": "training",
      "description": "Training step 508",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:02",
      "total_flops_so_far": 728158621796352.0,
      "budget_used_percent": 0.728158621796352
    },
    {
      "type": "training",
      "description": "Training step 509",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:03",
      "total_flops_so_far": 729589188833280.0,
      "budget_used_percent": 0.7295891888332801
    },
    {
      "type": "training",
      "description": "Training step 510",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:03",
      "total_flops_so_far": 731019755870208.0,
      "budget_used_percent": 0.7310197558702081
    },
    {
      "type": "training",
      "description": "Training step 511",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:03",
      "total_flops_so_far": 732450322907136.0,
      "budget_used_percent": 0.7324503229071361
    },
    {
      "type": "training",
      "description": "Training step 512",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:03",
      "total_flops_so_far": 733880889944064.0,
      "budget_used_percent": 0.733880889944064
    },
    {
      "type": "training",
      "description": "Training step 513",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:03",
      "total_flops_so_far": 735311456980992.0,
      "budget_used_percent": 0.735311456980992
    },
    {
      "type": "training",
      "description": "Training step 514",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:03",
      "total_flops_so_far": 736742024017920.0,
      "budget_used_percent": 0.73674202401792
    },
    {
      "type": "training",
      "description": "Training step 515",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:03",
      "total_flops_so_far": 738172591054848.0,
      "budget_used_percent": 0.738172591054848
    },
    {
      "type": "training",
      "description": "Training step 516",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:04",
      "total_flops_so_far": 739603158091776.0,
      "budget_used_percent": 0.739603158091776
    },
    {
      "type": "training",
      "description": "Training step 517",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:04",
      "total_flops_so_far": 741033725128704.0,
      "budget_used_percent": 0.741033725128704
    },
    {
      "type": "training",
      "description": "Training step 518",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:04",
      "total_flops_so_far": 742464292165632.0,
      "budget_used_percent": 0.742464292165632
    },
    {
      "type": "training",
      "description": "Training step 519",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:04",
      "total_flops_so_far": 743894859202560.0,
      "budget_used_percent": 0.74389485920256
    },
    {
      "type": "training",
      "description": "Training step 520",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:04",
      "total_flops_so_far": 745325426239488.0,
      "budget_used_percent": 0.745325426239488
    },
    {
      "type": "training",
      "description": "Training step 521",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:04",
      "total_flops_so_far": 746755993276416.0,
      "budget_used_percent": 0.746755993276416
    },
    {
      "type": "training",
      "description": "Training step 522",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:04",
      "total_flops_so_far": 748186560313344.0,
      "budget_used_percent": 0.748186560313344
    },
    {
      "type": "training",
      "description": "Training step 523",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:04",
      "total_flops_so_far": 749617127350272.0,
      "budget_used_percent": 0.749617127350272
    },
    {
      "type": "training",
      "description": "Training step 524",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:05",
      "total_flops_so_far": 751047694387200.0,
      "budget_used_percent": 0.7510476943872
    },
    {
      "type": "training",
      "description": "Training step 525",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:05",
      "total_flops_so_far": 752478261424128.0,
      "budget_used_percent": 0.752478261424128
    },
    {
      "type": "training",
      "description": "Training step 526",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:05",
      "total_flops_so_far": 753908828461056.0,
      "budget_used_percent": 0.753908828461056
    },
    {
      "type": "training",
      "description": "Training step 527",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:05",
      "total_flops_so_far": 755339395497984.0,
      "budget_used_percent": 0.755339395497984
    },
    {
      "type": "training",
      "description": "Training step 528",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:05",
      "total_flops_so_far": 756769962534912.0,
      "budget_used_percent": 0.756769962534912
    },
    {
      "type": "training",
      "description": "Training step 529",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:05",
      "total_flops_so_far": 758200529571840.0,
      "budget_used_percent": 0.7582005295718399
    },
    {
      "type": "training",
      "description": "Training step 530",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:05",
      "total_flops_so_far": 759631096608768.0,
      "budget_used_percent": 0.7596310966087679
    },
    {
      "type": "training",
      "description": "Training step 531",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:06",
      "total_flops_so_far": 761061663645696.0,
      "budget_used_percent": 0.7610616636456959
    },
    {
      "type": "training",
      "description": "Training step 532",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:06",
      "total_flops_so_far": 762492230682624.0,
      "budget_used_percent": 0.762492230682624
    },
    {
      "type": "training",
      "description": "Training step 533",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:06",
      "total_flops_so_far": 763922797719552.0,
      "budget_used_percent": 0.763922797719552
    },
    {
      "type": "training",
      "description": "Training step 534",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:06",
      "total_flops_so_far": 765353364756480.0,
      "budget_used_percent": 0.76535336475648
    },
    {
      "type": "training",
      "description": "Training step 535",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:06",
      "total_flops_so_far": 766783931793408.0,
      "budget_used_percent": 0.766783931793408
    },
    {
      "type": "training",
      "description": "Training step 536",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:06",
      "total_flops_so_far": 768214498830336.0,
      "budget_used_percent": 0.768214498830336
    },
    {
      "type": "training",
      "description": "Training step 537",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:06",
      "total_flops_so_far": 769645065867264.0,
      "budget_used_percent": 0.769645065867264
    },
    {
      "type": "training",
      "description": "Training step 538",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:06",
      "total_flops_so_far": 771075632904192.0,
      "budget_used_percent": 0.771075632904192
    },
    {
      "type": "training",
      "description": "Training step 539",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:07",
      "total_flops_so_far": 772506199941120.0,
      "budget_used_percent": 0.77250619994112
    },
    {
      "type": "training",
      "description": "Training step 540",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:07",
      "total_flops_so_far": 773936766978048.0,
      "budget_used_percent": 0.773936766978048
    },
    {
      "type": "training",
      "description": "Training step 541",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:07",
      "total_flops_so_far": 775367334014976.0,
      "budget_used_percent": 0.775367334014976
    },
    {
      "type": "training",
      "description": "Training step 542",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:07",
      "total_flops_so_far": 776797901051904.0,
      "budget_used_percent": 0.776797901051904
    },
    {
      "type": "training",
      "description": "Training step 543",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:07",
      "total_flops_so_far": 778228468088832.0,
      "budget_used_percent": 0.7782284680888321
    },
    {
      "type": "training",
      "description": "Training step 544",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:07",
      "total_flops_so_far": 779659035125760.0,
      "budget_used_percent": 0.7796590351257601
    },
    {
      "type": "training",
      "description": "Training step 545",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:07",
      "total_flops_so_far": 781089602162688.0,
      "budget_used_percent": 0.7810896021626881
    },
    {
      "type": "training",
      "description": "Training step 546",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:08",
      "total_flops_so_far": 782520169199616.0,
      "budget_used_percent": 0.7825201691996161
    },
    {
      "type": "training",
      "description": "Training step 547",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:08",
      "total_flops_so_far": 783950736236544.0,
      "budget_used_percent": 0.7839507362365441
    },
    {
      "type": "training",
      "description": "Training step 548",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:08",
      "total_flops_so_far": 785381303273472.0,
      "budget_used_percent": 0.7853813032734721
    },
    {
      "type": "training",
      "description": "Training step 549",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:08",
      "total_flops_so_far": 786811870310400.0,
      "budget_used_percent": 0.7868118703104001
    },
    {
      "type": "training",
      "description": "Training step 550",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:08",
      "total_flops_so_far": 788242437347328.0,
      "budget_used_percent": 0.7882424373473281
    },
    {
      "type": "training",
      "description": "Training step 551",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:08",
      "total_flops_so_far": 789673004384256.0,
      "budget_used_percent": 0.7896730043842559
    },
    {
      "type": "training",
      "description": "Training step 552",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:08",
      "total_flops_so_far": 791103571421184.0,
      "budget_used_percent": 0.7911035714211839
    },
    {
      "type": "training",
      "description": "Training step 553",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:08",
      "total_flops_so_far": 792534138458112.0,
      "budget_used_percent": 0.7925341384581119
    },
    {
      "type": "training",
      "description": "Training step 554",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:09",
      "total_flops_so_far": 793964705495040.0,
      "budget_used_percent": 0.79396470549504
    },
    {
      "type": "training",
      "description": "Training step 555",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:09",
      "total_flops_so_far": 795395272531968.0,
      "budget_used_percent": 0.795395272531968
    },
    {
      "type": "training",
      "description": "Training step 556",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:09",
      "total_flops_so_far": 796825839568896.0,
      "budget_used_percent": 0.796825839568896
    },
    {
      "type": "training",
      "description": "Training step 557",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:09",
      "total_flops_so_far": 798256406605824.0,
      "budget_used_percent": 0.798256406605824
    },
    {
      "type": "training",
      "description": "Training step 558",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:09",
      "total_flops_so_far": 799686973642752.0,
      "budget_used_percent": 0.799686973642752
    },
    {
      "type": "training",
      "description": "Training step 559",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:09",
      "total_flops_so_far": 801117540679680.0,
      "budget_used_percent": 0.80111754067968
    },
    {
      "type": "training",
      "description": "Training step 560",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:09",
      "total_flops_so_far": 802548107716608.0,
      "budget_used_percent": 0.802548107716608
    },
    {
      "type": "training",
      "description": "Training step 561",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:10",
      "total_flops_so_far": 803978674753536.0,
      "budget_used_percent": 0.803978674753536
    },
    {
      "type": "training",
      "description": "Training step 562",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:10",
      "total_flops_so_far": 805409241790464.0,
      "budget_used_percent": 0.805409241790464
    },
    {
      "type": "training",
      "description": "Training step 563",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:10",
      "total_flops_so_far": 806839808827392.0,
      "budget_used_percent": 0.806839808827392
    },
    {
      "type": "training",
      "description": "Training step 564",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:10",
      "total_flops_so_far": 808270375864320.0,
      "budget_used_percent": 0.80827037586432
    },
    {
      "type": "training",
      "description": "Training step 565",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:10",
      "total_flops_so_far": 809700942901248.0,
      "budget_used_percent": 0.809700942901248
    },
    {
      "type": "training",
      "description": "Training step 566",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:10",
      "total_flops_so_far": 811131509938176.0,
      "budget_used_percent": 0.8111315099381761
    },
    {
      "type": "training",
      "description": "Training step 567",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:10",
      "total_flops_so_far": 812562076975104.0,
      "budget_used_percent": 0.8125620769751041
    },
    {
      "type": "training",
      "description": "Training step 568",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:11",
      "total_flops_so_far": 813992644012032.0,
      "budget_used_percent": 0.8139926440120321
    },
    {
      "type": "training",
      "description": "Training step 569",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:11",
      "total_flops_so_far": 815423211048960.0,
      "budget_used_percent": 0.8154232110489599
    },
    {
      "type": "training",
      "description": "Training step 570",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:11",
      "total_flops_so_far": 816853778085888.0,
      "budget_used_percent": 0.8168537780858879
    },
    {
      "type": "training",
      "description": "Training step 571",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:11",
      "total_flops_so_far": 818284345122816.0,
      "budget_used_percent": 0.8182843451228159
    },
    {
      "type": "training",
      "description": "Training step 572",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:11",
      "total_flops_so_far": 819714912159744.0,
      "budget_used_percent": 0.8197149121597439
    },
    {
      "type": "training",
      "description": "Training step 573",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:11",
      "total_flops_so_far": 821145479196672.0,
      "budget_used_percent": 0.8211454791966719
    },
    {
      "type": "training",
      "description": "Training step 574",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:11",
      "total_flops_so_far": 822576046233600.0,
      "budget_used_percent": 0.8225760462335999
    },
    {
      "type": "training",
      "description": "Training step 575",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:11",
      "total_flops_so_far": 824006613270528.0,
      "budget_used_percent": 0.8240066132705279
    },
    {
      "type": "training",
      "description": "Training step 576",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:12",
      "total_flops_so_far": 825437180307456.0,
      "budget_used_percent": 0.8254371803074559
    },
    {
      "type": "training",
      "description": "Training step 577",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:12",
      "total_flops_so_far": 826867747344384.0,
      "budget_used_percent": 0.826867747344384
    },
    {
      "type": "training",
      "description": "Training step 578",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:12",
      "total_flops_so_far": 828298314381312.0,
      "budget_used_percent": 0.828298314381312
    },
    {
      "type": "training",
      "description": "Training step 579",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:12",
      "total_flops_so_far": 829728881418240.0,
      "budget_used_percent": 0.82972888141824
    },
    {
      "type": "training",
      "description": "Training step 580",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:12",
      "total_flops_so_far": 831159448455168.0,
      "budget_used_percent": 0.831159448455168
    },
    {
      "type": "training",
      "description": "Training step 581",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:12",
      "total_flops_so_far": 832590015492096.0,
      "budget_used_percent": 0.832590015492096
    },
    {
      "type": "training",
      "description": "Training step 582",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:12",
      "total_flops_so_far": 834020582529024.0,
      "budget_used_percent": 0.834020582529024
    },
    {
      "type": "training",
      "description": "Training step 583",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:12",
      "total_flops_so_far": 835451149565952.0,
      "budget_used_percent": 0.835451149565952
    },
    {
      "type": "training",
      "description": "Training step 584",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:13",
      "total_flops_so_far": 836881716602880.0,
      "budget_used_percent": 0.83688171660288
    },
    {
      "type": "training",
      "description": "Training step 585",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:13",
      "total_flops_so_far": 838312283639808.0,
      "budget_used_percent": 0.838312283639808
    },
    {
      "type": "training",
      "description": "Training step 586",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:13",
      "total_flops_so_far": 839742850676736.0,
      "budget_used_percent": 0.8397428506767359
    },
    {
      "type": "training",
      "description": "Training step 587",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:13",
      "total_flops_so_far": 841173417713664.0,
      "budget_used_percent": 0.8411734177136639
    },
    {
      "type": "training",
      "description": "Training step 588",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:13",
      "total_flops_so_far": 842603984750592.0,
      "budget_used_percent": 0.842603984750592
    },
    {
      "type": "training",
      "description": "Training step 589",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:13",
      "total_flops_so_far": 844034551787520.0,
      "budget_used_percent": 0.84403455178752
    },
    {
      "type": "training",
      "description": "Training step 590",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:13",
      "total_flops_so_far": 845465118824448.0,
      "budget_used_percent": 0.845465118824448
    },
    {
      "type": "training",
      "description": "Training step 591",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:14",
      "total_flops_so_far": 846895685861376.0,
      "budget_used_percent": 0.846895685861376
    },
    {
      "type": "training",
      "description": "Training step 592",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:14",
      "total_flops_so_far": 848326252898304.0,
      "budget_used_percent": 0.848326252898304
    },
    {
      "type": "training",
      "description": "Training step 593",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:14",
      "total_flops_so_far": 849756819935232.0,
      "budget_used_percent": 0.849756819935232
    },
    {
      "type": "training",
      "description": "Training step 594",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:14",
      "total_flops_so_far": 851187386972160.0,
      "budget_used_percent": 0.85118738697216
    },
    {
      "type": "training",
      "description": "Training step 595",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:14",
      "total_flops_so_far": 852617954009088.0,
      "budget_used_percent": 0.852617954009088
    },
    {
      "type": "training",
      "description": "Training step 596",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:14",
      "total_flops_so_far": 854048521046016.0,
      "budget_used_percent": 0.854048521046016
    },
    {
      "type": "training",
      "description": "Training step 597",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:14",
      "total_flops_so_far": 855479088082944.0,
      "budget_used_percent": 0.855479088082944
    },
    {
      "type": "training",
      "description": "Training step 598",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:14",
      "total_flops_so_far": 856909655119872.0,
      "budget_used_percent": 0.856909655119872
    },
    {
      "type": "training",
      "description": "Training step 599",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:15",
      "total_flops_so_far": 858340222156800.0,
      "budget_used_percent": 0.8583402221568001
    },
    {
      "type": "training",
      "description": "Training step 600",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:15",
      "total_flops_so_far": 859770789193728.0,
      "budget_used_percent": 0.8597707891937281
    },
    {
      "type": "training",
      "description": "Training step 601",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:15",
      "total_flops_so_far": 861201356230656.0,
      "budget_used_percent": 0.8612013562306561
    },
    {
      "type": "training",
      "description": "Training step 602",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:15",
      "total_flops_so_far": 862631923267584.0,
      "budget_used_percent": 0.8626319232675841
    },
    {
      "type": "training",
      "description": "Training step 603",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:15",
      "total_flops_so_far": 864062490304512.0,
      "budget_used_percent": 0.8640624903045121
    },
    {
      "type": "training",
      "description": "Training step 604",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:15",
      "total_flops_so_far": 865493057341440.0,
      "budget_used_percent": 0.8654930573414399
    },
    {
      "type": "training",
      "description": "Training step 605",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:15",
      "total_flops_so_far": 866923624378368.0,
      "budget_used_percent": 0.8669236243783679
    },
    {
      "type": "training",
      "description": "Training step 606",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:16",
      "total_flops_so_far": 868354191415296.0,
      "budget_used_percent": 0.8683541914152959
    },
    {
      "type": "training",
      "description": "Training step 607",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:16",
      "total_flops_so_far": 869784758452224.0,
      "budget_used_percent": 0.8697847584522239
    },
    {
      "type": "training",
      "description": "Training step 608",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:16",
      "total_flops_so_far": 871215325489152.0,
      "budget_used_percent": 0.8712153254891519
    },
    {
      "type": "training",
      "description": "Training step 609",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:16",
      "total_flops_so_far": 872645892526080.0,
      "budget_used_percent": 0.8726458925260799
    },
    {
      "type": "training",
      "description": "Training step 610",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:16",
      "total_flops_so_far": 874076459563008.0,
      "budget_used_percent": 0.874076459563008
    },
    {
      "type": "training",
      "description": "Training step 611",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:16",
      "total_flops_so_far": 875507026599936.0,
      "budget_used_percent": 0.875507026599936
    },
    {
      "type": "training",
      "description": "Training step 612",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:16",
      "total_flops_so_far": 876937593636864.0,
      "budget_used_percent": 0.876937593636864
    },
    {
      "type": "training",
      "description": "Training step 613",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:17",
      "total_flops_so_far": 878368160673792.0,
      "budget_used_percent": 0.878368160673792
    },
    {
      "type": "training",
      "description": "Training step 614",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:17",
      "total_flops_so_far": 879798727710720.0,
      "budget_used_percent": 0.87979872771072
    },
    {
      "type": "training",
      "description": "Training step 615",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:17",
      "total_flops_so_far": 881229294747648.0,
      "budget_used_percent": 0.881229294747648
    },
    {
      "type": "training",
      "description": "Training step 616",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:17",
      "total_flops_so_far": 882659861784576.0,
      "budget_used_percent": 0.882659861784576
    },
    {
      "type": "training",
      "description": "Training step 617",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:17",
      "total_flops_so_far": 884090428821504.0,
      "budget_used_percent": 0.884090428821504
    },
    {
      "type": "training",
      "description": "Training step 618",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:17",
      "total_flops_so_far": 885520995858432.0,
      "budget_used_percent": 0.885520995858432
    },
    {
      "type": "training",
      "description": "Training step 619",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:17",
      "total_flops_so_far": 886951562895360.0,
      "budget_used_percent": 0.88695156289536
    },
    {
      "type": "training",
      "description": "Training step 620",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:17",
      "total_flops_so_far": 888382129932288.0,
      "budget_used_percent": 0.888382129932288
    },
    {
      "type": "training",
      "description": "Training step 621",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:18",
      "total_flops_so_far": 889812696969216.0,
      "budget_used_percent": 0.8898126969692159
    },
    {
      "type": "training",
      "description": "Training step 622",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:18",
      "total_flops_so_far": 891243264006144.0,
      "budget_used_percent": 0.891243264006144
    },
    {
      "type": "training",
      "description": "Training step 623",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:18",
      "total_flops_so_far": 892673831043072.0,
      "budget_used_percent": 0.892673831043072
    },
    {
      "type": "training",
      "description": "Training step 624",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:18",
      "total_flops_so_far": 894104398080000.0,
      "budget_used_percent": 0.89410439808
    },
    {
      "type": "training",
      "description": "Training step 625",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:18",
      "total_flops_so_far": 895534965116928.0,
      "budget_used_percent": 0.895534965116928
    },
    {
      "type": "training",
      "description": "Training step 626",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:18",
      "total_flops_so_far": 896965532153856.0,
      "budget_used_percent": 0.896965532153856
    },
    {
      "type": "training",
      "description": "Training step 627",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:18",
      "total_flops_so_far": 898396099190784.0,
      "budget_used_percent": 0.898396099190784
    },
    {
      "type": "training",
      "description": "Training step 628",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:19",
      "total_flops_so_far": 899826666227712.0,
      "budget_used_percent": 0.899826666227712
    },
    {
      "type": "training",
      "description": "Training step 629",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:19",
      "total_flops_so_far": 901257233264640.0,
      "budget_used_percent": 0.90125723326464
    },
    {
      "type": "training",
      "description": "Training step 630",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:19",
      "total_flops_so_far": 902687800301568.0,
      "budget_used_percent": 0.902687800301568
    },
    {
      "type": "training",
      "description": "Training step 631",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:19",
      "total_flops_so_far": 904118367338496.0,
      "budget_used_percent": 0.904118367338496
    },
    {
      "type": "training",
      "description": "Training step 632",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:19",
      "total_flops_so_far": 905548934375424.0,
      "budget_used_percent": 0.905548934375424
    },
    {
      "type": "training",
      "description": "Training step 633",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:19",
      "total_flops_so_far": 906979501412352.0,
      "budget_used_percent": 0.9069795014123521
    },
    {
      "type": "training",
      "description": "Training step 634",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:19",
      "total_flops_so_far": 908410068449280.0,
      "budget_used_percent": 0.9084100684492801
    },
    {
      "type": "training",
      "description": "Training step 635",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:19",
      "total_flops_so_far": 909840635486208.0,
      "budget_used_percent": 0.9098406354862081
    },
    {
      "type": "training",
      "description": "Training step 636",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:20",
      "total_flops_so_far": 911271202523136.0,
      "budget_used_percent": 0.9112712025231361
    },
    {
      "type": "training",
      "description": "Training step 637",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:20",
      "total_flops_so_far": 912701769560064.0,
      "budget_used_percent": 0.9127017695600641
    },
    {
      "type": "training",
      "description": "Training step 638",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:20",
      "total_flops_so_far": 914132336596992.0,
      "budget_used_percent": 0.9141323365969921
    },
    {
      "type": "training",
      "description": "Training step 639",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:20",
      "total_flops_so_far": 915562903633920.0,
      "budget_used_percent": 0.9155629036339199
    },
    {
      "type": "training",
      "description": "Training step 640",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:20",
      "total_flops_so_far": 916993470670848.0,
      "budget_used_percent": 0.9169934706708479
    },
    {
      "type": "training",
      "description": "Training step 641",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:20",
      "total_flops_so_far": 918424037707776.0,
      "budget_used_percent": 0.9184240377077759
    },
    {
      "type": "training",
      "description": "Training step 642",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:20",
      "total_flops_so_far": 919854604744704.0,
      "budget_used_percent": 0.9198546047447039
    },
    {
      "type": "training",
      "description": "Training step 643",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:21",
      "total_flops_so_far": 921285171781632.0,
      "budget_used_percent": 0.9212851717816319
    },
    {
      "type": "training",
      "description": "Training step 644",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:21",
      "total_flops_so_far": 922715738818560.0,
      "budget_used_percent": 0.92271573881856
    },
    {
      "type": "training",
      "description": "Training step 645",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:21",
      "total_flops_so_far": 924146305855488.0,
      "budget_used_percent": 0.924146305855488
    },
    {
      "type": "training",
      "description": "Training step 646",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:21",
      "total_flops_so_far": 925576872892416.0,
      "budget_used_percent": 0.925576872892416
    },
    {
      "type": "training",
      "description": "Training step 647",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:21",
      "total_flops_so_far": 927007439929344.0,
      "budget_used_percent": 0.927007439929344
    },
    {
      "type": "training",
      "description": "Training step 648",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:21",
      "total_flops_so_far": 928438006966272.0,
      "budget_used_percent": 0.928438006966272
    },
    {
      "type": "training",
      "description": "Training step 649",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:21",
      "total_flops_so_far": 929868574003200.0,
      "budget_used_percent": 0.9298685740032
    },
    {
      "type": "training",
      "description": "Training step 650",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:22",
      "total_flops_so_far": 931299141040128.0,
      "budget_used_percent": 0.931299141040128
    },
    {
      "type": "training",
      "description": "Training step 651",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:22",
      "total_flops_so_far": 932729708077056.0,
      "budget_used_percent": 0.932729708077056
    },
    {
      "type": "training",
      "description": "Training step 652",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:22",
      "total_flops_so_far": 934160275113984.0,
      "budget_used_percent": 0.934160275113984
    },
    {
      "type": "training",
      "description": "Training step 653",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:22",
      "total_flops_so_far": 935590842150912.0,
      "budget_used_percent": 0.935590842150912
    },
    {
      "type": "training",
      "description": "Training step 654",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:22",
      "total_flops_so_far": 937021409187840.0,
      "budget_used_percent": 0.93702140918784
    },
    {
      "type": "training",
      "description": "Training step 655",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:22",
      "total_flops_so_far": 938451976224768.0,
      "budget_used_percent": 0.9384519762247681
    },
    {
      "type": "training",
      "description": "Training step 656",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:22",
      "total_flops_so_far": 939882543261696.0,
      "budget_used_percent": 0.939882543261696
    },
    {
      "type": "training",
      "description": "Training step 657",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:22",
      "total_flops_so_far": 941313110298624.0,
      "budget_used_percent": 0.941313110298624
    },
    {
      "type": "training",
      "description": "Training step 658",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:23",
      "total_flops_so_far": 942743677335552.0,
      "budget_used_percent": 0.942743677335552
    },
    {
      "type": "training",
      "description": "Training step 659",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:23",
      "total_flops_so_far": 944174244372480.0,
      "budget_used_percent": 0.94417424437248
    },
    {
      "type": "training",
      "description": "Training step 660",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:23",
      "total_flops_so_far": 945604811409408.0,
      "budget_used_percent": 0.945604811409408
    },
    {
      "type": "training",
      "description": "Training step 661",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:23",
      "total_flops_so_far": 947035378446336.0,
      "budget_used_percent": 0.947035378446336
    },
    {
      "type": "training",
      "description": "Training step 662",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:23",
      "total_flops_so_far": 948465945483264.0,
      "budget_used_percent": 0.948465945483264
    },
    {
      "type": "training",
      "description": "Training step 663",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:23",
      "total_flops_so_far": 949896512520192.0,
      "budget_used_percent": 0.949896512520192
    },
    {
      "type": "training",
      "description": "Training step 664",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:23",
      "total_flops_so_far": 951327079557120.0,
      "budget_used_percent": 0.95132707955712
    },
    {
      "type": "training",
      "description": "Training step 665",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:24",
      "total_flops_so_far": 952757646594048.0,
      "budget_used_percent": 0.952757646594048
    },
    {
      "type": "training",
      "description": "Training step 666",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:24",
      "total_flops_so_far": 954188213630976.0,
      "budget_used_percent": 0.9541882136309761
    },
    {
      "type": "training",
      "description": "Training step 667",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:24",
      "total_flops_so_far": 955618780667904.0,
      "budget_used_percent": 0.9556187806679041
    },
    {
      "type": "training",
      "description": "Training step 668",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:24",
      "total_flops_so_far": 957049347704832.0,
      "budget_used_percent": 0.9570493477048321
    },
    {
      "type": "training",
      "description": "Training step 669",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:24",
      "total_flops_so_far": 958479914741760.0,
      "budget_used_percent": 0.9584799147417601
    },
    {
      "type": "training",
      "description": "Training step 670",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:24",
      "total_flops_so_far": 959910481778688.0,
      "budget_used_percent": 0.9599104817786881
    },
    {
      "type": "training",
      "description": "Training step 671",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:24",
      "total_flops_so_far": 961341048815616.0,
      "budget_used_percent": 0.9613410488156161
    },
    {
      "type": "training",
      "description": "Training step 672",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:24",
      "total_flops_so_far": 962771615852544.0,
      "budget_used_percent": 0.9627716158525441
    },
    {
      "type": "training",
      "description": "Training step 673",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:25",
      "total_flops_so_far": 964202182889472.0,
      "budget_used_percent": 0.9642021828894721
    },
    {
      "type": "training",
      "description": "Training step 674",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:25",
      "total_flops_so_far": 965632749926400.0,
      "budget_used_percent": 0.9656327499263999
    },
    {
      "type": "training",
      "description": "Training step 675",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:25",
      "total_flops_so_far": 967063316963328.0,
      "budget_used_percent": 0.9670633169633279
    },
    {
      "type": "training",
      "description": "Training step 676",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:25",
      "total_flops_so_far": 968493884000256.0,
      "budget_used_percent": 0.9684938840002559
    },
    {
      "type": "training",
      "description": "Training step 677",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:25",
      "total_flops_so_far": 969924451037184.0,
      "budget_used_percent": 0.9699244510371839
    },
    {
      "type": "training",
      "description": "Training step 678",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:25",
      "total_flops_so_far": 971355018074112.0,
      "budget_used_percent": 0.971355018074112
    },
    {
      "type": "training",
      "description": "Training step 679",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:25",
      "total_flops_so_far": 972785585111040.0,
      "budget_used_percent": 0.97278558511104
    },
    {
      "type": "training",
      "description": "Training step 680",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:26",
      "total_flops_so_far": 974216152147968.0,
      "budget_used_percent": 0.974216152147968
    },
    {
      "type": "training",
      "description": "Training step 681",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:26",
      "total_flops_so_far": 975646719184896.0,
      "budget_used_percent": 0.975646719184896
    },
    {
      "type": "training",
      "description": "Training step 682",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:26",
      "total_flops_so_far": 977077286221824.0,
      "budget_used_percent": 0.977077286221824
    },
    {
      "type": "training",
      "description": "Training step 683",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:26",
      "total_flops_so_far": 978507853258752.0,
      "budget_used_percent": 0.978507853258752
    },
    {
      "type": "training",
      "description": "Training step 684",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:26",
      "total_flops_so_far": 979938420295680.0,
      "budget_used_percent": 0.97993842029568
    },
    {
      "type": "training",
      "description": "Training step 685",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:26",
      "total_flops_so_far": 981368987332608.0,
      "budget_used_percent": 0.981368987332608
    },
    {
      "type": "training",
      "description": "Training step 686",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:26",
      "total_flops_so_far": 982799554369536.0,
      "budget_used_percent": 0.982799554369536
    },
    {
      "type": "training",
      "description": "Training step 687",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:26",
      "total_flops_so_far": 984230121406464.0,
      "budget_used_percent": 0.984230121406464
    },
    {
      "type": "training",
      "description": "Training step 688",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:27",
      "total_flops_so_far": 985660688443392.0,
      "budget_used_percent": 0.985660688443392
    },
    {
      "type": "training",
      "description": "Training step 689",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:27",
      "total_flops_so_far": 987091255480320.0,
      "budget_used_percent": 0.9870912554803201
    },
    {
      "type": "training",
      "description": "Training step 690",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:27",
      "total_flops_so_far": 988521822517248.0,
      "budget_used_percent": 0.9885218225172481
    },
    {
      "type": "training",
      "description": "Training step 691",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:27",
      "total_flops_so_far": 989952389554176.0,
      "budget_used_percent": 0.989952389554176
    },
    {
      "type": "training",
      "description": "Training step 692",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:27",
      "total_flops_so_far": 991382956591104.0,
      "budget_used_percent": 0.9913829565911039
    },
    {
      "type": "training",
      "description": "Training step 693",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:27",
      "total_flops_so_far": 992813523628032.0,
      "budget_used_percent": 0.992813523628032
    },
    {
      "type": "training",
      "description": "Training step 694",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:27",
      "total_flops_so_far": 994244090664960.0,
      "budget_used_percent": 0.9942440906649599
    },
    {
      "type": "training",
      "description": "Training step 695",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:28",
      "total_flops_so_far": 995674657701888.0,
      "budget_used_percent": 0.995674657701888
    },
    {
      "type": "training",
      "description": "Training step 696",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:28",
      "total_flops_so_far": 997105224738816.0,
      "budget_used_percent": 0.9971052247388159
    },
    {
      "type": "training",
      "description": "Training step 697",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:28",
      "total_flops_so_far": 998535791775744.0,
      "budget_used_percent": 0.998535791775744
    },
    {
      "type": "training",
      "description": "Training step 698",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:28",
      "total_flops_so_far": 999966358812672.0,
      "budget_used_percent": 0.9999663588126719
    },
    {
      "type": "training",
      "description": "Training step 699",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:28",
      "total_flops_so_far": 1001396925849600.0,
      "budget_used_percent": 1.0013969258496
    },
    {
      "type": "training",
      "description": "Training step 700",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:28",
      "total_flops_so_far": 1002827492886528.0,
      "budget_used_percent": 1.002827492886528
    },
    {
      "type": "training",
      "description": "Training step 701",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:28",
      "total_flops_so_far": 1004258059923456.0,
      "budget_used_percent": 1.004258059923456
    },
    {
      "type": "training",
      "description": "Training step 702",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:29",
      "total_flops_so_far": 1005688626960384.0,
      "budget_used_percent": 1.005688626960384
    },
    {
      "type": "training",
      "description": "Training step 703",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:29",
      "total_flops_so_far": 1007119193997312.0,
      "budget_used_percent": 1.007119193997312
    },
    {
      "type": "training",
      "description": "Training step 704",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:29",
      "total_flops_so_far": 1008549761034240.0,
      "budget_used_percent": 1.00854976103424
    },
    {
      "type": "training",
      "description": "Training step 705",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:29",
      "total_flops_so_far": 1009980328071168.0,
      "budget_used_percent": 1.009980328071168
    },
    {
      "type": "training",
      "description": "Training step 706",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:29",
      "total_flops_so_far": 1011410895108096.0,
      "budget_used_percent": 1.011410895108096
    },
    {
      "type": "training",
      "description": "Training step 707",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:29",
      "total_flops_so_far": 1012841462145024.0,
      "budget_used_percent": 1.0128414621450241
    },
    {
      "type": "training",
      "description": "Training step 708",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:29",
      "total_flops_so_far": 1014272029181952.0,
      "budget_used_percent": 1.014272029181952
    },
    {
      "type": "training",
      "description": "Training step 709",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:30",
      "total_flops_so_far": 1015702596218880.0,
      "budget_used_percent": 1.01570259621888
    },
    {
      "type": "training",
      "description": "Training step 710",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:30",
      "total_flops_so_far": 1017133163255808.0,
      "budget_used_percent": 1.0171331632558078
    },
    {
      "type": "training",
      "description": "Training step 711",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:30",
      "total_flops_so_far": 1018563730292736.0,
      "budget_used_percent": 1.018563730292736
    },
    {
      "type": "training",
      "description": "Training step 712",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:30",
      "total_flops_so_far": 1019994297329664.0,
      "budget_used_percent": 1.0199942973296638
    },
    {
      "type": "training",
      "description": "Training step 713",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:30",
      "total_flops_so_far": 1021424864366592.0,
      "budget_used_percent": 1.021424864366592
    },
    {
      "type": "training",
      "description": "Training step 714",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:30",
      "total_flops_so_far": 1022855431403520.0,
      "budget_used_percent": 1.0228554314035199
    },
    {
      "type": "training",
      "description": "Training step 715",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:30",
      "total_flops_so_far": 1024285998440448.0,
      "budget_used_percent": 1.024285998440448
    },
    {
      "type": "training",
      "description": "Training step 716",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:30",
      "total_flops_so_far": 1025716565477376.0,
      "budget_used_percent": 1.0257165654773759
    },
    {
      "type": "training",
      "description": "Training step 717",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:31",
      "total_flops_so_far": 1027147132514304.0,
      "budget_used_percent": 1.027147132514304
    },
    {
      "type": "training",
      "description": "Training step 718",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:31",
      "total_flops_so_far": 1028577699551232.0,
      "budget_used_percent": 1.028577699551232
    },
    {
      "type": "training",
      "description": "Training step 719",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:31",
      "total_flops_so_far": 1030008266588160.0,
      "budget_used_percent": 1.03000826658816
    },
    {
      "type": "training",
      "description": "Training step 720",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:31",
      "total_flops_so_far": 1031438833625088.0,
      "budget_used_percent": 1.031438833625088
    },
    {
      "type": "training",
      "description": "Training step 721",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:31",
      "total_flops_so_far": 1032869400662016.0,
      "budget_used_percent": 1.032869400662016
    },
    {
      "type": "training",
      "description": "Training step 722",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:31",
      "total_flops_so_far": 1034299967698944.0,
      "budget_used_percent": 1.034299967698944
    },
    {
      "type": "training",
      "description": "Training step 723",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:31",
      "total_flops_so_far": 1035730534735872.0,
      "budget_used_percent": 1.035730534735872
    },
    {
      "type": "training",
      "description": "Training step 724",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:32",
      "total_flops_so_far": 1037161101772800.0,
      "budget_used_percent": 1.0371611017728
    },
    {
      "type": "training",
      "description": "Training step 725",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:32",
      "total_flops_so_far": 1038591668809728.0,
      "budget_used_percent": 1.038591668809728
    },
    {
      "type": "training",
      "description": "Training step 726",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:32",
      "total_flops_so_far": 1040022235846656.0,
      "budget_used_percent": 1.040022235846656
    },
    {
      "type": "training",
      "description": "Training step 727",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:32",
      "total_flops_so_far": 1041452802883584.0,
      "budget_used_percent": 1.0414528028835839
    },
    {
      "type": "training",
      "description": "Training step 728",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:32",
      "total_flops_so_far": 1042883369920512.0,
      "budget_used_percent": 1.042883369920512
    },
    {
      "type": "training",
      "description": "Training step 729",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:32",
      "total_flops_so_far": 1044313936957440.0,
      "budget_used_percent": 1.04431393695744
    },
    {
      "type": "training",
      "description": "Training step 730",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:32",
      "total_flops_so_far": 1045744503994368.0,
      "budget_used_percent": 1.045744503994368
    },
    {
      "type": "training",
      "description": "Training step 731",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:32",
      "total_flops_so_far": 1047175071031296.0,
      "budget_used_percent": 1.047175071031296
    },
    {
      "type": "training",
      "description": "Training step 732",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:33",
      "total_flops_so_far": 1048605638068224.0,
      "budget_used_percent": 1.048605638068224
    },
    {
      "type": "training",
      "description": "Training step 733",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:33",
      "total_flops_so_far": 1050036205105152.0,
      "budget_used_percent": 1.050036205105152
    },
    {
      "type": "training",
      "description": "Training step 734",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:33",
      "total_flops_so_far": 1051466772142080.0,
      "budget_used_percent": 1.05146677214208
    },
    {
      "type": "training",
      "description": "Training step 735",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:33",
      "total_flops_so_far": 1052897339179008.0,
      "budget_used_percent": 1.052897339179008
    },
    {
      "type": "training",
      "description": "Training step 736",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:33",
      "total_flops_so_far": 1054327906215936.0,
      "budget_used_percent": 1.054327906215936
    },
    {
      "type": "training",
      "description": "Training step 737",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:33",
      "total_flops_so_far": 1055758473252864.0,
      "budget_used_percent": 1.055758473252864
    },
    {
      "type": "training",
      "description": "Training step 738",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:33",
      "total_flops_so_far": 1057189040289792.0,
      "budget_used_percent": 1.057189040289792
    },
    {
      "type": "training",
      "description": "Training step 739",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:34",
      "total_flops_so_far": 1058619607326720.0,
      "budget_used_percent": 1.05861960732672
    },
    {
      "type": "training",
      "description": "Training step 740",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:34",
      "total_flops_so_far": 1060050174363648.0,
      "budget_used_percent": 1.0600501743636481
    },
    {
      "type": "training",
      "description": "Training step 741",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:34",
      "total_flops_so_far": 1061480741400576.0,
      "budget_used_percent": 1.061480741400576
    },
    {
      "type": "training",
      "description": "Training step 742",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:34",
      "total_flops_so_far": 1062911308437504.0,
      "budget_used_percent": 1.0629113084375041
    },
    {
      "type": "training",
      "description": "Training step 743",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:34",
      "total_flops_so_far": 1064341875474432.0,
      "budget_used_percent": 1.064341875474432
    },
    {
      "type": "training",
      "description": "Training step 744",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:34",
      "total_flops_so_far": 1065772442511360.0,
      "budget_used_percent": 1.06577244251136
    },
    {
      "type": "training",
      "description": "Training step 745",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:34",
      "total_flops_so_far": 1067203009548288.0,
      "budget_used_percent": 1.0672030095482878
    },
    {
      "type": "training",
      "description": "Training step 746",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:35",
      "total_flops_so_far": 1068633576585216.0,
      "budget_used_percent": 1.068633576585216
    },
    {
      "type": "training",
      "description": "Training step 747",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:35",
      "total_flops_so_far": 1070064143622144.0,
      "budget_used_percent": 1.0700641436221439
    },
    {
      "type": "training",
      "description": "Training step 748",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:35",
      "total_flops_so_far": 1071494710659072.0,
      "budget_used_percent": 1.071494710659072
    },
    {
      "type": "training",
      "description": "Training step 749",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:35",
      "total_flops_so_far": 1072925277696000.0,
      "budget_used_percent": 1.0729252776959999
    },
    {
      "type": "training",
      "description": "Training step 750",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:35",
      "total_flops_so_far": 1074355844732928.0,
      "budget_used_percent": 1.074355844732928
    },
    {
      "type": "training",
      "description": "Training step 751",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:35",
      "total_flops_so_far": 1075786411769856.0,
      "budget_used_percent": 1.075786411769856
    },
    {
      "type": "training",
      "description": "Training step 752",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:35",
      "total_flops_so_far": 1077216978806784.0,
      "budget_used_percent": 1.077216978806784
    },
    {
      "type": "training",
      "description": "Training step 753",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:35",
      "total_flops_so_far": 1078647545843712.0,
      "budget_used_percent": 1.078647545843712
    },
    {
      "type": "training",
      "description": "Training step 754",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:36",
      "total_flops_so_far": 1080078112880640.0,
      "budget_used_percent": 1.08007811288064
    },
    {
      "type": "training",
      "description": "Training step 755",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:36",
      "total_flops_so_far": 1081508679917568.0,
      "budget_used_percent": 1.081508679917568
    },
    {
      "type": "training",
      "description": "Training step 756",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:36",
      "total_flops_so_far": 1082939246954496.0,
      "budget_used_percent": 1.082939246954496
    },
    {
      "type": "training",
      "description": "Training step 757",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:36",
      "total_flops_so_far": 1084369813991424.0,
      "budget_used_percent": 1.084369813991424
    },
    {
      "type": "training",
      "description": "Training step 758",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:36",
      "total_flops_so_far": 1085800381028352.0,
      "budget_used_percent": 1.085800381028352
    },
    {
      "type": "training",
      "description": "Training step 759",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:36",
      "total_flops_so_far": 1087230948065280.0,
      "budget_used_percent": 1.08723094806528
    },
    {
      "type": "training",
      "description": "Training step 760",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:36",
      "total_flops_so_far": 1088661515102208.0,
      "budget_used_percent": 1.088661515102208
    },
    {
      "type": "training",
      "description": "Training step 761",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:37",
      "total_flops_so_far": 1090092082139136.0,
      "budget_used_percent": 1.090092082139136
    },
    {
      "type": "training",
      "description": "Training step 762",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:37",
      "total_flops_so_far": 1091522649176064.0,
      "budget_used_percent": 1.091522649176064
    },
    {
      "type": "training",
      "description": "Training step 763",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:37",
      "total_flops_so_far": 1092953216212992.0,
      "budget_used_percent": 1.092953216212992
    },
    {
      "type": "training",
      "description": "Training step 764",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:37",
      "total_flops_so_far": 1094383783249920.0,
      "budget_used_percent": 1.09438378324992
    },
    {
      "type": "training",
      "description": "Training step 765",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:37",
      "total_flops_so_far": 1095814350286848.0,
      "budget_used_percent": 1.095814350286848
    },
    {
      "type": "training",
      "description": "Training step 766",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:37",
      "total_flops_so_far": 1097244917323776.0,
      "budget_used_percent": 1.097244917323776
    },
    {
      "type": "training",
      "description": "Training step 767",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:37",
      "total_flops_so_far": 1098675484360704.0,
      "budget_used_percent": 1.098675484360704
    },
    {
      "type": "training",
      "description": "Training step 768",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:38",
      "total_flops_so_far": 1100106051397632.0,
      "budget_used_percent": 1.100106051397632
    },
    {
      "type": "training",
      "description": "Training step 769",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:38",
      "total_flops_so_far": 1101536618434560.0,
      "budget_used_percent": 1.10153661843456
    },
    {
      "type": "training",
      "description": "Training step 770",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:38",
      "total_flops_so_far": 1102967185471488.0,
      "budget_used_percent": 1.102967185471488
    },
    {
      "type": "training",
      "description": "Training step 771",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:38",
      "total_flops_so_far": 1104397752508416.0,
      "budget_used_percent": 1.104397752508416
    },
    {
      "type": "training",
      "description": "Training step 772",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:38",
      "total_flops_so_far": 1105828319545344.0,
      "budget_used_percent": 1.105828319545344
    },
    {
      "type": "training",
      "description": "Training step 773",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:38",
      "total_flops_so_far": 1107258886582272.0,
      "budget_used_percent": 1.1072588865822721
    },
    {
      "type": "training",
      "description": "Training step 774",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:38",
      "total_flops_so_far": 1108689453619200.0,
      "budget_used_percent": 1.1086894536192
    },
    {
      "type": "training",
      "description": "Training step 775",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:39",
      "total_flops_so_far": 1110120020656128.0,
      "budget_used_percent": 1.1101200206561281
    },
    {
      "type": "training",
      "description": "Training step 776",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:39",
      "total_flops_so_far": 1111550587693056.0,
      "budget_used_percent": 1.111550587693056
    },
    {
      "type": "training",
      "description": "Training step 777",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:39",
      "total_flops_so_far": 1112981154729984.0,
      "budget_used_percent": 1.1129811547299842
    },
    {
      "type": "training",
      "description": "Training step 778",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:39",
      "total_flops_so_far": 1114411721766912.0,
      "budget_used_percent": 1.114411721766912
    },
    {
      "type": "training",
      "description": "Training step 779",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:39",
      "total_flops_so_far": 1115842288803840.0,
      "budget_used_percent": 1.11584228880384
    },
    {
      "type": "training",
      "description": "Training step 780",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:39",
      "total_flops_so_far": 1117272855840768.0,
      "budget_used_percent": 1.1172728558407679
    },
    {
      "type": "training",
      "description": "Training step 781",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:39",
      "total_flops_so_far": 1118703422877696.0,
      "budget_used_percent": 1.118703422877696
    },
    {
      "type": "training",
      "description": "Training step 782",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:39",
      "total_flops_so_far": 1120133989914624.0,
      "budget_used_percent": 1.1201339899146239
    },
    {
      "type": "training",
      "description": "Training step 783",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:40",
      "total_flops_so_far": 1121564556951552.0,
      "budget_used_percent": 1.121564556951552
    },
    {
      "type": "training",
      "description": "Training step 784",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:40",
      "total_flops_so_far": 1122995123988480.0,
      "budget_used_percent": 1.12299512398848
    },
    {
      "type": "training",
      "description": "Training step 785",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:40",
      "total_flops_so_far": 1124425691025408.0,
      "budget_used_percent": 1.124425691025408
    },
    {
      "type": "training",
      "description": "Training step 786",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:40",
      "total_flops_so_far": 1125856258062336.0,
      "budget_used_percent": 1.125856258062336
    },
    {
      "type": "training",
      "description": "Training step 787",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:40",
      "total_flops_so_far": 1127286825099264.0,
      "budget_used_percent": 1.127286825099264
    },
    {
      "type": "training",
      "description": "Training step 788",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:40",
      "total_flops_so_far": 1128717392136192.0,
      "budget_used_percent": 1.128717392136192
    },
    {
      "type": "training",
      "description": "Training step 789",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:40",
      "total_flops_so_far": 1130147959173120.0,
      "budget_used_percent": 1.13014795917312
    },
    {
      "type": "training",
      "description": "Training step 790",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:41",
      "total_flops_so_far": 1131578526210048.0,
      "budget_used_percent": 1.131578526210048
    },
    {
      "type": "training",
      "description": "Training step 791",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:41",
      "total_flops_so_far": 1133009093246976.0,
      "budget_used_percent": 1.133009093246976
    },
    {
      "type": "training",
      "description": "Training step 792",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:41",
      "total_flops_so_far": 1134439660283904.0,
      "budget_used_percent": 1.134439660283904
    },
    {
      "type": "training",
      "description": "Training step 793",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:41",
      "total_flops_so_far": 1135870227320832.0,
      "budget_used_percent": 1.135870227320832
    },
    {
      "type": "training",
      "description": "Training step 794",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:41",
      "total_flops_so_far": 1137300794357760.0,
      "budget_used_percent": 1.13730079435776
    },
    {
      "type": "training",
      "description": "Training step 795",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:41",
      "total_flops_so_far": 1138731361394688.0,
      "budget_used_percent": 1.1387313613946881
    },
    {
      "type": "training",
      "description": "Training step 796",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:41",
      "total_flops_so_far": 1140161928431616.0,
      "budget_used_percent": 1.140161928431616
    },
    {
      "type": "training",
      "description": "Training step 797",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:42",
      "total_flops_so_far": 1141592495468544.0,
      "budget_used_percent": 1.141592495468544
    },
    {
      "type": "training",
      "description": "Training step 798",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:42",
      "total_flops_so_far": 1143023062505472.0,
      "budget_used_percent": 1.143023062505472
    },
    {
      "type": "training",
      "description": "Training step 799",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:42",
      "total_flops_so_far": 1144453629542400.0,
      "budget_used_percent": 1.1444536295424
    },
    {
      "type": "training",
      "description": "Training step 800",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:42",
      "total_flops_so_far": 1145884196579328.0,
      "budget_used_percent": 1.145884196579328
    },
    {
      "type": "training",
      "description": "Training step 801",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:42",
      "total_flops_so_far": 1147314763616256.0,
      "budget_used_percent": 1.147314763616256
    },
    {
      "type": "training",
      "description": "Training step 802",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:42",
      "total_flops_so_far": 1148745330653184.0,
      "budget_used_percent": 1.148745330653184
    },
    {
      "type": "training",
      "description": "Training step 803",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:42",
      "total_flops_so_far": 1150175897690112.0,
      "budget_used_percent": 1.150175897690112
    },
    {
      "type": "training",
      "description": "Training step 804",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:43",
      "total_flops_so_far": 1151606464727040.0,
      "budget_used_percent": 1.15160646472704
    },
    {
      "type": "training",
      "description": "Training step 805",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:43",
      "total_flops_so_far": 1153037031763968.0,
      "budget_used_percent": 1.153037031763968
    },
    {
      "type": "training",
      "description": "Training step 806",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:43",
      "total_flops_so_far": 1154467598800896.0,
      "budget_used_percent": 1.154467598800896
    },
    {
      "type": "training",
      "description": "Training step 807",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:43",
      "total_flops_so_far": 1155898165837824.0,
      "budget_used_percent": 1.155898165837824
    },
    {
      "type": "training",
      "description": "Training step 808",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:43",
      "total_flops_so_far": 1157328732874752.0,
      "budget_used_percent": 1.1573287328747521
    },
    {
      "type": "training",
      "description": "Training step 809",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:43",
      "total_flops_so_far": 1158759299911680.0,
      "budget_used_percent": 1.15875929991168
    },
    {
      "type": "training",
      "description": "Training step 810",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:43",
      "total_flops_so_far": 1160189866948608.0,
      "budget_used_percent": 1.1601898669486082
    },
    {
      "type": "training",
      "description": "Training step 811",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:43",
      "total_flops_so_far": 1161620433985536.0,
      "budget_used_percent": 1.161620433985536
    },
    {
      "type": "training",
      "description": "Training step 812",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:44",
      "total_flops_so_far": 1163051001022464.0,
      "budget_used_percent": 1.1630510010224642
    },
    {
      "type": "training",
      "description": "Training step 813",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:44",
      "total_flops_so_far": 1164481568059392.0,
      "budget_used_percent": 1.164481568059392
    },
    {
      "type": "training",
      "description": "Training step 814",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:44",
      "total_flops_so_far": 1165912135096320.0,
      "budget_used_percent": 1.16591213509632
    },
    {
      "type": "training",
      "description": "Training step 815",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:44",
      "total_flops_so_far": 1167342702133248.0,
      "budget_used_percent": 1.1673427021332479
    },
    {
      "type": "training",
      "description": "Training step 816",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:44",
      "total_flops_so_far": 1168773269170176.0,
      "budget_used_percent": 1.168773269170176
    },
    {
      "type": "training",
      "description": "Training step 817",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:44",
      "total_flops_so_far": 1170203836207104.0,
      "budget_used_percent": 1.1702038362071039
    },
    {
      "type": "training",
      "description": "Training step 818",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:44",
      "total_flops_so_far": 1171634403244032.0,
      "budget_used_percent": 1.171634403244032
    },
    {
      "type": "training",
      "description": "Training step 819",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:45",
      "total_flops_so_far": 1173064970280960.0,
      "budget_used_percent": 1.17306497028096
    },
    {
      "type": "training",
      "description": "Training step 820",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:45",
      "total_flops_so_far": 1174495537317888.0,
      "budget_used_percent": 1.174495537317888
    },
    {
      "type": "training",
      "description": "Training step 821",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:45",
      "total_flops_so_far": 1175926104354816.0,
      "budget_used_percent": 1.175926104354816
    },
    {
      "type": "training",
      "description": "Training step 822",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:45",
      "total_flops_so_far": 1177356671391744.0,
      "budget_used_percent": 1.177356671391744
    },
    {
      "type": "training",
      "description": "Training step 823",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:45",
      "total_flops_so_far": 1178787238428672.0,
      "budget_used_percent": 1.178787238428672
    },
    {
      "type": "training",
      "description": "Training step 824",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:45",
      "total_flops_so_far": 1180217805465600.0,
      "budget_used_percent": 1.1802178054656
    },
    {
      "type": "training",
      "description": "Training step 825",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:45",
      "total_flops_so_far": 1181648372502528.0,
      "budget_used_percent": 1.181648372502528
    },
    {
      "type": "training",
      "description": "Training step 826",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:46",
      "total_flops_so_far": 1183078939539456.0,
      "budget_used_percent": 1.183078939539456
    },
    {
      "type": "training",
      "description": "Training step 827",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:46",
      "total_flops_so_far": 1184509506576384.0,
      "budget_used_percent": 1.184509506576384
    },
    {
      "type": "training",
      "description": "Training step 828",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:46",
      "total_flops_so_far": 1185940073613312.0,
      "budget_used_percent": 1.185940073613312
    },
    {
      "type": "training",
      "description": "Training step 829",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:46",
      "total_flops_so_far": 1187370640650240.0,
      "budget_used_percent": 1.18737064065024
    },
    {
      "type": "training",
      "description": "Training step 830",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:46",
      "total_flops_so_far": 1188801207687168.0,
      "budget_used_percent": 1.1888012076871681
    },
    {
      "type": "training",
      "description": "Training step 831",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:46",
      "total_flops_so_far": 1190231774724096.0,
      "budget_used_percent": 1.1902317747240958
    },
    {
      "type": "training",
      "description": "Training step 832",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:46",
      "total_flops_so_far": 1191662341761024.0,
      "budget_used_percent": 1.191662341761024
    },
    {
      "type": "training",
      "description": "Training step 833",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:47",
      "total_flops_so_far": 1193092908797952.0,
      "budget_used_percent": 1.193092908797952
    },
    {
      "type": "training",
      "description": "Training step 834",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:47",
      "total_flops_so_far": 1194523475834880.0,
      "budget_used_percent": 1.19452347583488
    },
    {
      "type": "training",
      "description": "Training step 835",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:47",
      "total_flops_so_far": 1195954042871808.0,
      "budget_used_percent": 1.1959540428718078
    },
    {
      "type": "training",
      "description": "Training step 836",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:47",
      "total_flops_so_far": 1197384609908736.0,
      "budget_used_percent": 1.197384609908736
    },
    {
      "type": "training",
      "description": "Training step 837",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:47",
      "total_flops_so_far": 1198815176945664.0,
      "budget_used_percent": 1.198815176945664
    },
    {
      "type": "training",
      "description": "Training step 838",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:47",
      "total_flops_so_far": 1200245743982592.0,
      "budget_used_percent": 1.200245743982592
    },
    {
      "type": "training",
      "description": "Training step 839",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:47",
      "total_flops_so_far": 1201676311019520.0,
      "budget_used_percent": 1.2016763110195199
    },
    {
      "type": "training",
      "description": "Training step 840",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:48",
      "total_flops_so_far": 1203106878056448.0,
      "budget_used_percent": 1.203106878056448
    },
    {
      "type": "training",
      "description": "Training step 841",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:48",
      "total_flops_so_far": 1204537445093376.0,
      "budget_used_percent": 1.2045374450933761
    },
    {
      "type": "training",
      "description": "Training step 842",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:48",
      "total_flops_so_far": 1205968012130304.0,
      "budget_used_percent": 1.205968012130304
    },
    {
      "type": "training",
      "description": "Training step 843",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:48",
      "total_flops_so_far": 1207398579167232.0,
      "budget_used_percent": 1.207398579167232
    },
    {
      "type": "training",
      "description": "Training step 844",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:48",
      "total_flops_so_far": 1208829146204160.0,
      "budget_used_percent": 1.20882914620416
    },
    {
      "type": "training",
      "description": "Training step 845",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:48",
      "total_flops_so_far": 1210259713241088.0,
      "budget_used_percent": 1.2102597132410882
    },
    {
      "type": "training",
      "description": "Training step 846",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:48",
      "total_flops_so_far": 1211690280278016.0,
      "budget_used_percent": 1.211690280278016
    },
    {
      "type": "training",
      "description": "Training step 847",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:49",
      "total_flops_so_far": 1213120847314944.0,
      "budget_used_percent": 1.213120847314944
    },
    {
      "type": "training",
      "description": "Training step 848",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:49",
      "total_flops_so_far": 1214551414351872.0,
      "budget_used_percent": 1.214551414351872
    },
    {
      "type": "training",
      "description": "Training step 849",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:49",
      "total_flops_so_far": 1215981981388800.0,
      "budget_used_percent": 1.2159819813888
    },
    {
      "type": "training",
      "description": "Training step 850",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:49",
      "total_flops_so_far": 1217412548425728.0,
      "budget_used_percent": 1.2174125484257279
    },
    {
      "type": "training",
      "description": "Training step 851",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:49",
      "total_flops_so_far": 1218843115462656.0,
      "budget_used_percent": 1.218843115462656
    },
    {
      "type": "training",
      "description": "Training step 852",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:49",
      "total_flops_so_far": 1220273682499584.0,
      "budget_used_percent": 1.220273682499584
    },
    {
      "type": "training",
      "description": "Training step 853",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:49",
      "total_flops_so_far": 1221704249536512.0,
      "budget_used_percent": 1.221704249536512
    },
    {
      "type": "training",
      "description": "Training step 854",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:49",
      "total_flops_so_far": 1223134816573440.0,
      "budget_used_percent": 1.22313481657344
    },
    {
      "type": "training",
      "description": "Training step 855",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:50",
      "total_flops_so_far": 1224565383610368.0,
      "budget_used_percent": 1.224565383610368
    },
    {
      "type": "training",
      "description": "Training step 856",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:50",
      "total_flops_so_far": 1225995950647296.0,
      "budget_used_percent": 1.225995950647296
    },
    {
      "type": "training",
      "description": "Training step 857",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:50",
      "total_flops_so_far": 1227426517684224.0,
      "budget_used_percent": 1.227426517684224
    },
    {
      "type": "training",
      "description": "Training step 858",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:50",
      "total_flops_so_far": 1228857084721152.0,
      "budget_used_percent": 1.228857084721152
    },
    {
      "type": "training",
      "description": "Training step 859",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:50",
      "total_flops_so_far": 1230287651758080.0,
      "budget_used_percent": 1.23028765175808
    },
    {
      "type": "training",
      "description": "Training step 860",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:50",
      "total_flops_so_far": 1231718218795008.0,
      "budget_used_percent": 1.231718218795008
    },
    {
      "type": "training",
      "description": "Training step 861",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:50",
      "total_flops_so_far": 1233148785831936.0,
      "budget_used_percent": 1.233148785831936
    },
    {
      "type": "training",
      "description": "Training step 862",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:51",
      "total_flops_so_far": 1234579352868864.0,
      "budget_used_percent": 1.234579352868864
    },
    {
      "type": "training",
      "description": "Training step 863",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:51",
      "total_flops_so_far": 1236009919905792.0,
      "budget_used_percent": 1.2360099199057921
    },
    {
      "type": "training",
      "description": "Training step 864",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:51",
      "total_flops_so_far": 1237440486942720.0,
      "budget_used_percent": 1.23744048694272
    },
    {
      "type": "training",
      "description": "Training step 865",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:51",
      "total_flops_so_far": 1238871053979648.0,
      "budget_used_percent": 1.2388710539796481
    },
    {
      "type": "training",
      "description": "Training step 866",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:51",
      "total_flops_so_far": 1240301621016576.0,
      "budget_used_percent": 1.2403016210165758
    },
    {
      "type": "training",
      "description": "Training step 867",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:51",
      "total_flops_so_far": 1241732188053504.0,
      "budget_used_percent": 1.241732188053504
    },
    {
      "type": "training",
      "description": "Training step 868",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:51",
      "total_flops_so_far": 1243162755090432.0,
      "budget_used_percent": 1.2431627550904318
    },
    {
      "type": "training",
      "description": "Training step 869",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:52",
      "total_flops_so_far": 1244593322127360.0,
      "budget_used_percent": 1.24459332212736
    },
    {
      "type": "training",
      "description": "Training step 870",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:52",
      "total_flops_so_far": 1246023889164288.0,
      "budget_used_percent": 1.2460238891642879
    },
    {
      "type": "training",
      "description": "Training step 871",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:52",
      "total_flops_so_far": 1247454456201216.0,
      "budget_used_percent": 1.247454456201216
    },
    {
      "type": "training",
      "description": "Training step 872",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:52",
      "total_flops_so_far": 1248885023238144.0,
      "budget_used_percent": 1.2488850232381439
    },
    {
      "type": "training",
      "description": "Training step 873",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:52",
      "total_flops_so_far": 1250315590275072.0,
      "budget_used_percent": 1.250315590275072
    },
    {
      "type": "training",
      "description": "Training step 874",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:52",
      "total_flops_so_far": 1251746157312000.0,
      "budget_used_percent": 1.251746157312
    },
    {
      "type": "training",
      "description": "Training step 875",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:52",
      "total_flops_so_far": 1253176724348928.0,
      "budget_used_percent": 1.253176724348928
    },
    {
      "type": "training",
      "description": "Training step 876",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:53",
      "total_flops_so_far": 1254607291385856.0,
      "budget_used_percent": 1.254607291385856
    },
    {
      "type": "training",
      "description": "Training step 877",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:53",
      "total_flops_so_far": 1256037858422784.0,
      "budget_used_percent": 1.256037858422784
    },
    {
      "type": "training",
      "description": "Training step 878",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:53",
      "total_flops_so_far": 1257468425459712.0,
      "budget_used_percent": 1.257468425459712
    },
    {
      "type": "training",
      "description": "Training step 879",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:53",
      "total_flops_so_far": 1258898992496640.0,
      "budget_used_percent": 1.25889899249664
    },
    {
      "type": "training",
      "description": "Training step 880",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:53",
      "total_flops_so_far": 1260329559533568.0,
      "budget_used_percent": 1.260329559533568
    },
    {
      "type": "training",
      "description": "Training step 881",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:53",
      "total_flops_so_far": 1261760126570496.0,
      "budget_used_percent": 1.261760126570496
    },
    {
      "type": "training",
      "description": "Training step 882",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:53",
      "total_flops_so_far": 1263190693607424.0,
      "budget_used_percent": 1.263190693607424
    },
    {
      "type": "training",
      "description": "Training step 883",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:54",
      "total_flops_so_far": 1264621260644352.0,
      "budget_used_percent": 1.264621260644352
    },
    {
      "type": "training",
      "description": "Training step 884",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:54",
      "total_flops_so_far": 1266051827681280.0,
      "budget_used_percent": 1.26605182768128
    },
    {
      "type": "training",
      "description": "Training step 885",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:54",
      "total_flops_so_far": 1267482394718208.0,
      "budget_used_percent": 1.267482394718208
    },
    {
      "type": "training",
      "description": "Training step 886",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:54",
      "total_flops_so_far": 1268912961755136.0,
      "budget_used_percent": 1.268912961755136
    },
    {
      "type": "training",
      "description": "Training step 887",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:54",
      "total_flops_so_far": 1270343528792064.0,
      "budget_used_percent": 1.270343528792064
    },
    {
      "type": "training",
      "description": "Training step 888",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:54",
      "total_flops_so_far": 1271774095828992.0,
      "budget_used_percent": 1.271774095828992
    },
    {
      "type": "training",
      "description": "Training step 889",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:54",
      "total_flops_so_far": 1273204662865920.0,
      "budget_used_percent": 1.27320466286592
    },
    {
      "type": "training",
      "description": "Training step 890",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:54",
      "total_flops_so_far": 1274635229902848.0,
      "budget_used_percent": 1.274635229902848
    },
    {
      "type": "training",
      "description": "Training step 891",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:55",
      "total_flops_so_far": 1276065796939776.0,
      "budget_used_percent": 1.276065796939776
    },
    {
      "type": "training",
      "description": "Training step 892",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:55",
      "total_flops_so_far": 1277496363976704.0,
      "budget_used_percent": 1.277496363976704
    },
    {
      "type": "training",
      "description": "Training step 893",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:55",
      "total_flops_so_far": 1278926931013632.0,
      "budget_used_percent": 1.278926931013632
    },
    {
      "type": "training",
      "description": "Training step 894",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:55",
      "total_flops_so_far": 1280357498050560.0,
      "budget_used_percent": 1.28035749805056
    },
    {
      "type": "training",
      "description": "Training step 895",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:55",
      "total_flops_so_far": 1281788065087488.0,
      "budget_used_percent": 1.281788065087488
    },
    {
      "type": "training",
      "description": "Training step 896",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:55",
      "total_flops_so_far": 1283218632124416.0,
      "budget_used_percent": 1.2832186321244161
    },
    {
      "type": "training",
      "description": "Training step 897",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:55",
      "total_flops_so_far": 1284649199161344.0,
      "budget_used_percent": 1.284649199161344
    },
    {
      "type": "training",
      "description": "Training step 898",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:56",
      "total_flops_so_far": 1286079766198272.0,
      "budget_used_percent": 1.2860797661982721
    },
    {
      "type": "training",
      "description": "Training step 899",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:56",
      "total_flops_so_far": 1287510333235200.0,
      "budget_used_percent": 1.2875103332352
    },
    {
      "type": "training",
      "description": "Training step 900",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:56",
      "total_flops_so_far": 1288940900272128.0,
      "budget_used_percent": 1.2889409002721282
    },
    {
      "type": "training",
      "description": "Training step 901",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:56",
      "total_flops_so_far": 1290371467309056.0,
      "budget_used_percent": 1.2903714673090558
    },
    {
      "type": "training",
      "description": "Training step 902",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:56",
      "total_flops_so_far": 1291802034345984.0,
      "budget_used_percent": 1.291802034345984
    },
    {
      "type": "training",
      "description": "Training step 903",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:56",
      "total_flops_so_far": 1293232601382912.0,
      "budget_used_percent": 1.2932326013829119
    },
    {
      "type": "training",
      "description": "Training step 904",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:56",
      "total_flops_so_far": 1294663168419840.0,
      "budget_used_percent": 1.29466316841984
    },
    {
      "type": "training",
      "description": "Training step 905",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:57",
      "total_flops_so_far": 1296093735456768.0,
      "budget_used_percent": 1.2960937354567679
    },
    {
      "type": "training",
      "description": "Training step 906",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:57",
      "total_flops_so_far": 1297524302493696.0,
      "budget_used_percent": 1.297524302493696
    },
    {
      "type": "training",
      "description": "Training step 907",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:57",
      "total_flops_so_far": 1298954869530624.0,
      "budget_used_percent": 1.298954869530624
    },
    {
      "type": "training",
      "description": "Training step 908",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:57",
      "total_flops_so_far": 1300385436567552.0,
      "budget_used_percent": 1.300385436567552
    },
    {
      "type": "training",
      "description": "Training step 909",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:57",
      "total_flops_so_far": 1301816003604480.0,
      "budget_used_percent": 1.30181600360448
    },
    {
      "type": "training",
      "description": "Training step 910",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:57",
      "total_flops_so_far": 1303246570641408.0,
      "budget_used_percent": 1.303246570641408
    },
    {
      "type": "training",
      "description": "Training step 911",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:57",
      "total_flops_so_far": 1304677137678336.0,
      "budget_used_percent": 1.304677137678336
    },
    {
      "type": "training",
      "description": "Training step 912",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:58",
      "total_flops_so_far": 1306107704715264.0,
      "budget_used_percent": 1.306107704715264
    },
    {
      "type": "training",
      "description": "Training step 913",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:58",
      "total_flops_so_far": 1307538271752192.0,
      "budget_used_percent": 1.307538271752192
    },
    {
      "type": "training",
      "description": "Training step 914",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:58",
      "total_flops_so_far": 1308968838789120.0,
      "budget_used_percent": 1.30896883878912
    },
    {
      "type": "training",
      "description": "Training step 915",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:58",
      "total_flops_so_far": 1310399405826048.0,
      "budget_used_percent": 1.310399405826048
    },
    {
      "type": "training",
      "description": "Training step 916",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:58",
      "total_flops_so_far": 1311829972862976.0,
      "budget_used_percent": 1.311829972862976
    },
    {
      "type": "training",
      "description": "Training step 917",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:58",
      "total_flops_so_far": 1313260539899904.0,
      "budget_used_percent": 1.313260539899904
    },
    {
      "type": "training",
      "description": "Training step 918",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:58",
      "total_flops_so_far": 1314691106936832.0,
      "budget_used_percent": 1.314691106936832
    },
    {
      "type": "training",
      "description": "Training step 919",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:58",
      "total_flops_so_far": 1316121673973760.0,
      "budget_used_percent": 1.31612167397376
    },
    {
      "type": "training",
      "description": "Training step 920",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:59",
      "total_flops_so_far": 1317552241010688.0,
      "budget_used_percent": 1.317552241010688
    },
    {
      "type": "training",
      "description": "Training step 921",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:59",
      "total_flops_so_far": 1318982808047616.0,
      "budget_used_percent": 1.318982808047616
    },
    {
      "type": "training",
      "description": "Training step 922",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:59",
      "total_flops_so_far": 1320413375084544.0,
      "budget_used_percent": 1.320413375084544
    },
    {
      "type": "training",
      "description": "Training step 923",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:59",
      "total_flops_so_far": 1321843942121472.0,
      "budget_used_percent": 1.321843942121472
    },
    {
      "type": "training",
      "description": "Training step 924",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:59",
      "total_flops_so_far": 1323274509158400.0,
      "budget_used_percent": 1.3232745091584
    },
    {
      "type": "training",
      "description": "Training step 925",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:59",
      "total_flops_so_far": 1324705076195328.0,
      "budget_used_percent": 1.324705076195328
    },
    {
      "type": "training",
      "description": "Training step 926",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:34:59",
      "total_flops_so_far": 1326135643232256.0,
      "budget_used_percent": 1.326135643232256
    },
    {
      "type": "training",
      "description": "Training step 927",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:00",
      "total_flops_so_far": 1327566210269184.0,
      "budget_used_percent": 1.327566210269184
    },
    {
      "type": "training",
      "description": "Training step 928",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:00",
      "total_flops_so_far": 1328996777306112.0,
      "budget_used_percent": 1.328996777306112
    },
    {
      "type": "training",
      "description": "Training step 929",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:00",
      "total_flops_so_far": 1330427344343040.0,
      "budget_used_percent": 1.33042734434304
    },
    {
      "type": "training",
      "description": "Training step 930",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:00",
      "total_flops_so_far": 1331857911379968.0,
      "budget_used_percent": 1.331857911379968
    },
    {
      "type": "training",
      "description": "Training step 931",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:00",
      "total_flops_so_far": 1333288478416896.0,
      "budget_used_percent": 1.3332884784168961
    },
    {
      "type": "training",
      "description": "Training step 932",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:00",
      "total_flops_so_far": 1334719045453824.0,
      "budget_used_percent": 1.334719045453824
    },
    {
      "type": "training",
      "description": "Training step 933",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:00",
      "total_flops_so_far": 1336149612490752.0,
      "budget_used_percent": 1.3361496124907521
    },
    {
      "type": "training",
      "description": "Training step 934",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:01",
      "total_flops_so_far": 1337580179527680.0,
      "budget_used_percent": 1.33758017952768
    },
    {
      "type": "training",
      "description": "Training step 935",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:01",
      "total_flops_so_far": 1339010746564608.0,
      "budget_used_percent": 1.3390107465646082
    },
    {
      "type": "training",
      "description": "Training step 936",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:01",
      "total_flops_so_far": 1340441313601536.0,
      "budget_used_percent": 1.3404413136015358
    },
    {
      "type": "training",
      "description": "Training step 937",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:01",
      "total_flops_so_far": 1341871880638464.0,
      "budget_used_percent": 1.341871880638464
    },
    {
      "type": "training",
      "description": "Training step 938",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:01",
      "total_flops_so_far": 1343302447675392.0,
      "budget_used_percent": 1.3433024476753919
    },
    {
      "type": "training",
      "description": "Training step 939",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:01",
      "total_flops_so_far": 1344733014712320.0,
      "budget_used_percent": 1.34473301471232
    },
    {
      "type": "training",
      "description": "Training step 940",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:01",
      "total_flops_so_far": 1346163581749248.0,
      "budget_used_percent": 1.3461635817492479
    },
    {
      "type": "training",
      "description": "Training step 941",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:02",
      "total_flops_so_far": 1347594148786176.0,
      "budget_used_percent": 1.347594148786176
    },
    {
      "type": "training",
      "description": "Training step 942",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:02",
      "total_flops_so_far": 1349024715823104.0,
      "budget_used_percent": 1.349024715823104
    },
    {
      "type": "training",
      "description": "Training step 943",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:02",
      "total_flops_so_far": 1350455282860032.0,
      "budget_used_percent": 1.350455282860032
    },
    {
      "type": "training",
      "description": "Training step 944",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:02",
      "total_flops_so_far": 1351885849896960.0,
      "budget_used_percent": 1.35188584989696
    },
    {
      "type": "training",
      "description": "Training step 945",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:02",
      "total_flops_so_far": 1353316416933888.0,
      "budget_used_percent": 1.353316416933888
    },
    {
      "type": "training",
      "description": "Training step 946",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:02",
      "total_flops_so_far": 1354746983970816.0,
      "budget_used_percent": 1.354746983970816
    },
    {
      "type": "training",
      "description": "Training step 947",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:02",
      "total_flops_so_far": 1356177551007744.0,
      "budget_used_percent": 1.356177551007744
    },
    {
      "type": "training",
      "description": "Training step 948",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:03",
      "total_flops_so_far": 1357608118044672.0,
      "budget_used_percent": 1.357608118044672
    },
    {
      "type": "training",
      "description": "Training step 949",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:03",
      "total_flops_so_far": 1359038685081600.0,
      "budget_used_percent": 1.3590386850816
    },
    {
      "type": "training",
      "description": "Training step 950",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:03",
      "total_flops_so_far": 1360469252118528.0,
      "budget_used_percent": 1.360469252118528
    },
    {
      "type": "training",
      "description": "Training step 951",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:03",
      "total_flops_so_far": 1361899819155456.0,
      "budget_used_percent": 1.361899819155456
    },
    {
      "type": "training",
      "description": "Training step 952",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:03",
      "total_flops_so_far": 1363330386192384.0,
      "budget_used_percent": 1.363330386192384
    },
    {
      "type": "training",
      "description": "Training step 953",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:03",
      "total_flops_so_far": 1364760953229312.0,
      "budget_used_percent": 1.3647609532293121
    },
    {
      "type": "training",
      "description": "Training step 954",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:03",
      "total_flops_so_far": 1366191520266240.0,
      "budget_used_percent": 1.36619152026624
    },
    {
      "type": "training",
      "description": "Training step 955",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:04",
      "total_flops_so_far": 1367622087303168.0,
      "budget_used_percent": 1.367622087303168
    },
    {
      "type": "training",
      "description": "Training step 956",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:04",
      "total_flops_so_far": 1369052654340096.0,
      "budget_used_percent": 1.369052654340096
    },
    {
      "type": "training",
      "description": "Training step 957",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:04",
      "total_flops_so_far": 1370483221377024.0,
      "budget_used_percent": 1.370483221377024
    },
    {
      "type": "training",
      "description": "Training step 958",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:04",
      "total_flops_so_far": 1371913788413952.0,
      "budget_used_percent": 1.371913788413952
    },
    {
      "type": "training",
      "description": "Training step 959",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:04",
      "total_flops_so_far": 1373344355450880.0,
      "budget_used_percent": 1.37334435545088
    },
    {
      "type": "training",
      "description": "Training step 960",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:04",
      "total_flops_so_far": 1374774922487808.0,
      "budget_used_percent": 1.374774922487808
    },
    {
      "type": "training",
      "description": "Training step 961",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:04",
      "total_flops_so_far": 1376205489524736.0,
      "budget_used_percent": 1.376205489524736
    },
    {
      "type": "training",
      "description": "Training step 962",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:05",
      "total_flops_so_far": 1377636056561664.0,
      "budget_used_percent": 1.377636056561664
    },
    {
      "type": "training",
      "description": "Training step 963",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:05",
      "total_flops_so_far": 1379066623598592.0,
      "budget_used_percent": 1.379066623598592
    },
    {
      "type": "training",
      "description": "Training step 964",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:05",
      "total_flops_so_far": 1380497190635520.0,
      "budget_used_percent": 1.3804971906355201
    },
    {
      "type": "training",
      "description": "Training step 965",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:05",
      "total_flops_so_far": 1381927757672448.0,
      "budget_used_percent": 1.381927757672448
    },
    {
      "type": "training",
      "description": "Training step 966",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:05",
      "total_flops_so_far": 1383358324709376.0,
      "budget_used_percent": 1.3833583247093761
    },
    {
      "type": "training",
      "description": "Training step 967",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:05",
      "total_flops_so_far": 1384788891746304.0,
      "budget_used_percent": 1.384788891746304
    },
    {
      "type": "training",
      "description": "Training step 968",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:05",
      "total_flops_so_far": 1386219458783232.0,
      "budget_used_percent": 1.3862194587832322
    },
    {
      "type": "training",
      "description": "Training step 969",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:06",
      "total_flops_so_far": 1387650025820160.0,
      "budget_used_percent": 1.38765002582016
    },
    {
      "type": "training",
      "description": "Training step 970",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:06",
      "total_flops_so_far": 1389080592857088.0,
      "budget_used_percent": 1.3890805928570882
    },
    {
      "type": "training",
      "description": "Training step 971",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:06",
      "total_flops_so_far": 1390511159894016.0,
      "budget_used_percent": 1.3905111598940159
    },
    {
      "type": "training",
      "description": "Training step 972",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:06",
      "total_flops_so_far": 1391941726930944.0,
      "budget_used_percent": 1.391941726930944
    },
    {
      "type": "training",
      "description": "Training step 973",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:06",
      "total_flops_so_far": 1393372293967872.0,
      "budget_used_percent": 1.3933722939678719
    },
    {
      "type": "training",
      "description": "Training step 974",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:06",
      "total_flops_so_far": 1394802861004800.0,
      "budget_used_percent": 1.3948028610048
    },
    {
      "type": "training",
      "description": "Training step 975",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:06",
      "total_flops_so_far": 1396233428041728.0,
      "budget_used_percent": 1.396233428041728
    },
    {
      "type": "training",
      "description": "Training step 976",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:07",
      "total_flops_so_far": 1397663995078656.0,
      "budget_used_percent": 1.397663995078656
    },
    {
      "type": "training",
      "description": "Training step 977",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:07",
      "total_flops_so_far": 1399094562115584.0,
      "budget_used_percent": 1.399094562115584
    },
    {
      "type": "training",
      "description": "Training step 978",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:07",
      "total_flops_so_far": 1400525129152512.0,
      "budget_used_percent": 1.400525129152512
    },
    {
      "type": "training",
      "description": "Training step 979",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:07",
      "total_flops_so_far": 1401955696189440.0,
      "budget_used_percent": 1.40195569618944
    },
    {
      "type": "training",
      "description": "Training step 980",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:07",
      "total_flops_so_far": 1403386263226368.0,
      "budget_used_percent": 1.403386263226368
    },
    {
      "type": "training",
      "description": "Training step 981",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:07",
      "total_flops_so_far": 1404816830263296.0,
      "budget_used_percent": 1.404816830263296
    },
    {
      "type": "training",
      "description": "Training step 982",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:07",
      "total_flops_so_far": 1406247397300224.0,
      "budget_used_percent": 1.406247397300224
    },
    {
      "type": "training",
      "description": "Training step 983",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:08",
      "total_flops_so_far": 1407677964337152.0,
      "budget_used_percent": 1.407677964337152
    },
    {
      "type": "training",
      "description": "Training step 984",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:08",
      "total_flops_so_far": 1409108531374080.0,
      "budget_used_percent": 1.40910853137408
    },
    {
      "type": "training",
      "description": "Training step 985",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:08",
      "total_flops_so_far": 1410539098411008.0,
      "budget_used_percent": 1.410539098411008
    },
    {
      "type": "training",
      "description": "Training step 986",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:08",
      "total_flops_so_far": 1411969665447936.0,
      "budget_used_percent": 1.4119696654479361
    },
    {
      "type": "training",
      "description": "Training step 987",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:08",
      "total_flops_so_far": 1413400232484864.0,
      "budget_used_percent": 1.413400232484864
    },
    {
      "type": "training",
      "description": "Training step 988",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:09",
      "total_flops_so_far": 1414830799521792.0,
      "budget_used_percent": 1.4148307995217921
    },
    {
      "type": "training",
      "description": "Training step 989",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:09",
      "total_flops_so_far": 1416261366558720.0,
      "budget_used_percent": 1.4162613665587198
    },
    {
      "type": "training",
      "description": "Training step 990",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:09",
      "total_flops_so_far": 1417691933595648.0,
      "budget_used_percent": 1.417691933595648
    },
    {
      "type": "training",
      "description": "Training step 991",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:09",
      "total_flops_so_far": 1419122500632576.0,
      "budget_used_percent": 1.4191225006325758
    },
    {
      "type": "training",
      "description": "Training step 992",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:09",
      "total_flops_so_far": 1420553067669504.0,
      "budget_used_percent": 1.420553067669504
    },
    {
      "type": "training",
      "description": "Training step 993",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:09",
      "total_flops_so_far": 1421983634706432.0,
      "budget_used_percent": 1.4219836347064319
    },
    {
      "type": "training",
      "description": "Training step 994",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:09",
      "total_flops_so_far": 1423414201743360.0,
      "budget_used_percent": 1.42341420174336
    },
    {
      "type": "training",
      "description": "Training step 995",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:10",
      "total_flops_so_far": 1424844768780288.0,
      "budget_used_percent": 1.4248447687802879
    },
    {
      "type": "training",
      "description": "Training step 996",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:10",
      "total_flops_so_far": 1426275335817216.0,
      "budget_used_percent": 1.426275335817216
    },
    {
      "type": "training",
      "description": "Training step 997",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:10",
      "total_flops_so_far": 1427705902854144.0,
      "budget_used_percent": 1.427705902854144
    },
    {
      "type": "training",
      "description": "Training step 998",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:10",
      "total_flops_so_far": 1429136469891072.0,
      "budget_used_percent": 1.429136469891072
    },
    {
      "type": "training",
      "description": "Training step 999",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:35:10",
      "total_flops_so_far": 1430567036928000.0,
      "budget_used_percent": 1.430567036928
    },
    {
      "type": "training",
      "description": "Training step 1000",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:32",
      "total_flops_so_far": 1431997603964928.0,
      "budget_used_percent": 1.431997603964928
    },
    {
      "type": "training",
      "description": "Training step 1001",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:32",
      "total_flops_so_far": 1433428171001856.0,
      "budget_used_percent": 1.433428171001856
    },
    {
      "type": "training",
      "description": "Training step 1002",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:33",
      "total_flops_so_far": 1434858738038784.0,
      "budget_used_percent": 1.434858738038784
    },
    {
      "type": "training",
      "description": "Training step 1003",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:33",
      "total_flops_so_far": 1436289305075712.0,
      "budget_used_percent": 1.436289305075712
    },
    {
      "type": "training",
      "description": "Training step 1004",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:33",
      "total_flops_so_far": 1437719872112640.0,
      "budget_used_percent": 1.43771987211264
    },
    {
      "type": "training",
      "description": "Training step 1005",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:33",
      "total_flops_so_far": 1439150439149568.0,
      "budget_used_percent": 1.439150439149568
    },
    {
      "type": "training",
      "description": "Training step 1006",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:33",
      "total_flops_so_far": 1440581006186496.0,
      "budget_used_percent": 1.440581006186496
    },
    {
      "type": "training",
      "description": "Training step 1007",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:33",
      "total_flops_so_far": 1442011573223424.0,
      "budget_used_percent": 1.442011573223424
    },
    {
      "type": "training",
      "description": "Training step 1008",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:33",
      "total_flops_so_far": 1443442140260352.0,
      "budget_used_percent": 1.443442140260352
    },
    {
      "type": "training",
      "description": "Training step 1009",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:34",
      "total_flops_so_far": 1444872707297280.0,
      "budget_used_percent": 1.44487270729728
    },
    {
      "type": "training",
      "description": "Training step 1010",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:34",
      "total_flops_so_far": 1446303274334208.0,
      "budget_used_percent": 1.446303274334208
    },
    {
      "type": "training",
      "description": "Training step 1011",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:34",
      "total_flops_so_far": 1447733841371136.0,
      "budget_used_percent": 1.447733841371136
    },
    {
      "type": "training",
      "description": "Training step 1012",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:34",
      "total_flops_so_far": 1449164408408064.0,
      "budget_used_percent": 1.449164408408064
    },
    {
      "type": "training",
      "description": "Training step 1013",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:34",
      "total_flops_so_far": 1450594975444992.0,
      "budget_used_percent": 1.450594975444992
    },
    {
      "type": "training",
      "description": "Training step 1014",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:34",
      "total_flops_so_far": 1452025542481920.0,
      "budget_used_percent": 1.45202554248192
    },
    {
      "type": "training",
      "description": "Training step 1015",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:34",
      "total_flops_so_far": 1453456109518848.0,
      "budget_used_percent": 1.453456109518848
    },
    {
      "type": "training",
      "description": "Training step 1016",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:35",
      "total_flops_so_far": 1454886676555776.0,
      "budget_used_percent": 1.454886676555776
    },
    {
      "type": "training",
      "description": "Training step 1017",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:35",
      "total_flops_so_far": 1456317243592704.0,
      "budget_used_percent": 1.456317243592704
    },
    {
      "type": "training",
      "description": "Training step 1018",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:35",
      "total_flops_so_far": 1457747810629632.0,
      "budget_used_percent": 1.457747810629632
    },
    {
      "type": "training",
      "description": "Training step 1019",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:35",
      "total_flops_so_far": 1459178377666560.0,
      "budget_used_percent": 1.4591783776665601
    },
    {
      "type": "training",
      "description": "Training step 1020",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:35",
      "total_flops_so_far": 1460608944703488.0,
      "budget_used_percent": 1.460608944703488
    },
    {
      "type": "training",
      "description": "Training step 1021",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:35",
      "total_flops_so_far": 1462039511740416.0,
      "budget_used_percent": 1.4620395117404161
    },
    {
      "type": "training",
      "description": "Training step 1022",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:35",
      "total_flops_so_far": 1463470078777344.0,
      "budget_used_percent": 1.463470078777344
    },
    {
      "type": "training",
      "description": "Training step 1023",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:36",
      "total_flops_so_far": 1464900645814272.0,
      "budget_used_percent": 1.4649006458142722
    },
    {
      "type": "training",
      "description": "Training step 1024",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:36",
      "total_flops_so_far": 1466331212851200.0,
      "budget_used_percent": 1.4663312128511998
    },
    {
      "type": "training",
      "description": "Training step 1025",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:36",
      "total_flops_so_far": 1467761779888128.0,
      "budget_used_percent": 1.467761779888128
    },
    {
      "type": "training",
      "description": "Training step 1026",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:36",
      "total_flops_so_far": 1469192346925056.0,
      "budget_used_percent": 1.4691923469250558
    },
    {
      "type": "training",
      "description": "Training step 1027",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:36",
      "total_flops_so_far": 1470622913961984.0,
      "budget_used_percent": 1.470622913961984
    },
    {
      "type": "training",
      "description": "Training step 1028",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:36",
      "total_flops_so_far": 1472053480998912.0,
      "budget_used_percent": 1.4720534809989119
    },
    {
      "type": "training",
      "description": "Training step 1029",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:36",
      "total_flops_so_far": 1473484048035840.0,
      "budget_used_percent": 1.47348404803584
    },
    {
      "type": "training",
      "description": "Training step 1030",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:37",
      "total_flops_so_far": 1474914615072768.0,
      "budget_used_percent": 1.4749146150727679
    },
    {
      "type": "training",
      "description": "Training step 1031",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:37",
      "total_flops_so_far": 1476345182109696.0,
      "budget_used_percent": 1.476345182109696
    },
    {
      "type": "training",
      "description": "Training step 1032",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:37",
      "total_flops_so_far": 1477775749146624.0,
      "budget_used_percent": 1.477775749146624
    },
    {
      "type": "training",
      "description": "Training step 1033",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:37",
      "total_flops_so_far": 1479206316183552.0,
      "budget_used_percent": 1.479206316183552
    },
    {
      "type": "training",
      "description": "Training step 1034",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:37",
      "total_flops_so_far": 1480636883220480.0,
      "budget_used_percent": 1.48063688322048
    },
    {
      "type": "training",
      "description": "Training step 1035",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:37",
      "total_flops_so_far": 1482067450257408.0,
      "budget_used_percent": 1.482067450257408
    },
    {
      "type": "training",
      "description": "Training step 1036",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:37",
      "total_flops_so_far": 1483498017294336.0,
      "budget_used_percent": 1.483498017294336
    },
    {
      "type": "training",
      "description": "Training step 1037",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:38",
      "total_flops_so_far": 1484928584331264.0,
      "budget_used_percent": 1.484928584331264
    },
    {
      "type": "training",
      "description": "Training step 1038",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:38",
      "total_flops_so_far": 1486359151368192.0,
      "budget_used_percent": 1.486359151368192
    },
    {
      "type": "training",
      "description": "Training step 1039",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:38",
      "total_flops_so_far": 1487789718405120.0,
      "budget_used_percent": 1.48778971840512
    },
    {
      "type": "training",
      "description": "Training step 1040",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:38",
      "total_flops_so_far": 1489220285442048.0,
      "budget_used_percent": 1.489220285442048
    },
    {
      "type": "training",
      "description": "Training step 1041",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:38",
      "total_flops_so_far": 1490650852478976.0,
      "budget_used_percent": 1.490650852478976
    },
    {
      "type": "training",
      "description": "Training step 1042",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:38",
      "total_flops_so_far": 1492081419515904.0,
      "budget_used_percent": 1.492081419515904
    },
    {
      "type": "training",
      "description": "Training step 1043",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:38",
      "total_flops_so_far": 1493511986552832.0,
      "budget_used_percent": 1.493511986552832
    },
    {
      "type": "training",
      "description": "Training step 1044",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:39",
      "total_flops_so_far": 1494942553589760.0,
      "budget_used_percent": 1.49494255358976
    },
    {
      "type": "training",
      "description": "Training step 1045",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:39",
      "total_flops_so_far": 1496373120626688.0,
      "budget_used_percent": 1.496373120626688
    },
    {
      "type": "training",
      "description": "Training step 1046",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:39",
      "total_flops_so_far": 1497803687663616.0,
      "budget_used_percent": 1.497803687663616
    },
    {
      "type": "training",
      "description": "Training step 1047",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:39",
      "total_flops_so_far": 1499234254700544.0,
      "budget_used_percent": 1.499234254700544
    },
    {
      "type": "training",
      "description": "Training step 1048",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:39",
      "total_flops_so_far": 1500664821737472.0,
      "budget_used_percent": 1.500664821737472
    },
    {
      "type": "training",
      "description": "Training step 1049",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:39",
      "total_flops_so_far": 1502095388774400.0,
      "budget_used_percent": 1.5020953887744
    },
    {
      "type": "training",
      "description": "Training step 1050",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:39",
      "total_flops_so_far": 1503525955811328.0,
      "budget_used_percent": 1.503525955811328
    },
    {
      "type": "training",
      "description": "Training step 1051",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:40",
      "total_flops_so_far": 1504956522848256.0,
      "budget_used_percent": 1.504956522848256
    },
    {
      "type": "training",
      "description": "Training step 1052",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:40",
      "total_flops_so_far": 1506387089885184.0,
      "budget_used_percent": 1.506387089885184
    },
    {
      "type": "training",
      "description": "Training step 1053",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:40",
      "total_flops_so_far": 1507817656922112.0,
      "budget_used_percent": 1.507817656922112
    },
    {
      "type": "training",
      "description": "Training step 1054",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:40",
      "total_flops_so_far": 1509248223959040.0,
      "budget_used_percent": 1.5092482239590401
    },
    {
      "type": "training",
      "description": "Training step 1055",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:40",
      "total_flops_so_far": 1510678790995968.0,
      "budget_used_percent": 1.510678790995968
    },
    {
      "type": "training",
      "description": "Training step 1056",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:40",
      "total_flops_so_far": 1512109358032896.0,
      "budget_used_percent": 1.5121093580328961
    },
    {
      "type": "training",
      "description": "Training step 1057",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:40",
      "total_flops_so_far": 1513539925069824.0,
      "budget_used_percent": 1.513539925069824
    },
    {
      "type": "training",
      "description": "Training step 1058",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:41",
      "total_flops_so_far": 1514970492106752.0,
      "budget_used_percent": 1.5149704921067522
    },
    {
      "type": "training",
      "description": "Training step 1059",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:41",
      "total_flops_so_far": 1516401059143680.0,
      "budget_used_percent": 1.5164010591436798
    },
    {
      "type": "training",
      "description": "Training step 1060",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:41",
      "total_flops_so_far": 1517831626180608.0,
      "budget_used_percent": 1.517831626180608
    },
    {
      "type": "training",
      "description": "Training step 1061",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:41",
      "total_flops_so_far": 1519262193217536.0,
      "budget_used_percent": 1.5192621932175359
    },
    {
      "type": "training",
      "description": "Training step 1062",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:41",
      "total_flops_so_far": 1520692760254464.0,
      "budget_used_percent": 1.520692760254464
    },
    {
      "type": "training",
      "description": "Training step 1063",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:41",
      "total_flops_so_far": 1522123327291392.0,
      "budget_used_percent": 1.5221233272913919
    },
    {
      "type": "training",
      "description": "Training step 1064",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:41",
      "total_flops_so_far": 1523553894328320.0,
      "budget_used_percent": 1.52355389432832
    },
    {
      "type": "training",
      "description": "Training step 1065",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:42",
      "total_flops_so_far": 1524984461365248.0,
      "budget_used_percent": 1.524984461365248
    },
    {
      "type": "training",
      "description": "Training step 1066",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:42",
      "total_flops_so_far": 1526415028402176.0,
      "budget_used_percent": 1.526415028402176
    },
    {
      "type": "training",
      "description": "Training step 1067",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:42",
      "total_flops_so_far": 1527845595439104.0,
      "budget_used_percent": 1.527845595439104
    },
    {
      "type": "training",
      "description": "Training step 1068",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:42",
      "total_flops_so_far": 1529276162476032.0,
      "budget_used_percent": 1.529276162476032
    },
    {
      "type": "training",
      "description": "Training step 1069",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:42",
      "total_flops_so_far": 1530706729512960.0,
      "budget_used_percent": 1.53070672951296
    },
    {
      "type": "training",
      "description": "Training step 1070",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:42",
      "total_flops_so_far": 1532137296549888.0,
      "budget_used_percent": 1.532137296549888
    },
    {
      "type": "training",
      "description": "Training step 1071",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:42",
      "total_flops_so_far": 1533567863586816.0,
      "budget_used_percent": 1.533567863586816
    },
    {
      "type": "training",
      "description": "Training step 1072",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:43",
      "total_flops_so_far": 1534998430623744.0,
      "budget_used_percent": 1.534998430623744
    },
    {
      "type": "training",
      "description": "Training step 1073",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:43",
      "total_flops_so_far": 1536428997660672.0,
      "budget_used_percent": 1.536428997660672
    },
    {
      "type": "training",
      "description": "Training step 1074",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:43",
      "total_flops_so_far": 1537859564697600.0,
      "budget_used_percent": 1.5378595646976
    },
    {
      "type": "training",
      "description": "Training step 1075",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:43",
      "total_flops_so_far": 1539290131734528.0,
      "budget_used_percent": 1.539290131734528
    },
    {
      "type": "training",
      "description": "Training step 1076",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:43",
      "total_flops_so_far": 1540720698771456.0,
      "budget_used_percent": 1.5407206987714561
    },
    {
      "type": "training",
      "description": "Training step 1077",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:43",
      "total_flops_so_far": 1542151265808384.0,
      "budget_used_percent": 1.542151265808384
    },
    {
      "type": "training",
      "description": "Training step 1078",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:43",
      "total_flops_so_far": 1543581832845312.0,
      "budget_used_percent": 1.543581832845312
    },
    {
      "type": "training",
      "description": "Training step 1079",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:44",
      "total_flops_so_far": 1545012399882240.0,
      "budget_used_percent": 1.54501239988224
    },
    {
      "type": "training",
      "description": "Training step 1080",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:44",
      "total_flops_so_far": 1546442966919168.0,
      "budget_used_percent": 1.546442966919168
    },
    {
      "type": "training",
      "description": "Training step 1081",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:44",
      "total_flops_so_far": 1547873533956096.0,
      "budget_used_percent": 1.547873533956096
    },
    {
      "type": "training",
      "description": "Training step 1082",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:44",
      "total_flops_so_far": 1549304100993024.0,
      "budget_used_percent": 1.549304100993024
    },
    {
      "type": "training",
      "description": "Training step 1083",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:44",
      "total_flops_so_far": 1550734668029952.0,
      "budget_used_percent": 1.550734668029952
    },
    {
      "type": "training",
      "description": "Training step 1084",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:44",
      "total_flops_so_far": 1552165235066880.0,
      "budget_used_percent": 1.55216523506688
    },
    {
      "type": "training",
      "description": "Training step 1085",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:44",
      "total_flops_so_far": 1553595802103808.0,
      "budget_used_percent": 1.553595802103808
    },
    {
      "type": "training",
      "description": "Training step 1086",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:45",
      "total_flops_so_far": 1555026369140736.0,
      "budget_used_percent": 1.555026369140736
    },
    {
      "type": "training",
      "description": "Training step 1087",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:45",
      "total_flops_so_far": 1556456936177664.0,
      "budget_used_percent": 1.5564569361776641
    },
    {
      "type": "training",
      "description": "Training step 1088",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:45",
      "total_flops_so_far": 1557887503214592.0,
      "budget_used_percent": 1.557887503214592
    },
    {
      "type": "training",
      "description": "Training step 1089",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:45",
      "total_flops_so_far": 1559318070251520.0,
      "budget_used_percent": 1.5593180702515201
    },
    {
      "type": "training",
      "description": "Training step 1090",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:45",
      "total_flops_so_far": 1560748637288448.0,
      "budget_used_percent": 1.560748637288448
    },
    {
      "type": "training",
      "description": "Training step 1091",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:45",
      "total_flops_so_far": 1562179204325376.0,
      "budget_used_percent": 1.5621792043253762
    },
    {
      "type": "training",
      "description": "Training step 1092",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:45",
      "total_flops_so_far": 1563609771362304.0,
      "budget_used_percent": 1.563609771362304
    },
    {
      "type": "training",
      "description": "Training step 1093",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:46",
      "total_flops_so_far": 1565040338399232.0,
      "budget_used_percent": 1.5650403383992322
    },
    {
      "type": "training",
      "description": "Training step 1094",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:46",
      "total_flops_so_far": 1566470905436160.0,
      "budget_used_percent": 1.56647090543616
    },
    {
      "type": "training",
      "description": "Training step 1095",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:46",
      "total_flops_so_far": 1567901472473088.0,
      "budget_used_percent": 1.5679014724730882
    },
    {
      "type": "training",
      "description": "Training step 1096",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:46",
      "total_flops_so_far": 1569332039510016.0,
      "budget_used_percent": 1.569332039510016
    },
    {
      "type": "training",
      "description": "Training step 1097",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:46",
      "total_flops_so_far": 1570762606546944.0,
      "budget_used_percent": 1.5707626065469442
    },
    {
      "type": "training",
      "description": "Training step 1098",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:46",
      "total_flops_so_far": 1572193173583872.0,
      "budget_used_percent": 1.5721931735838721
    },
    {
      "type": "training",
      "description": "Training step 1099",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:46",
      "total_flops_so_far": 1573623740620800.0,
      "budget_used_percent": 1.5736237406208002
    },
    {
      "type": "training",
      "description": "Training step 1100",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:47",
      "total_flops_so_far": 1575054307657728.0,
      "budget_used_percent": 1.5750543076577281
    },
    {
      "type": "training",
      "description": "Training step 1101",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:47",
      "total_flops_so_far": 1576484874694656.0,
      "budget_used_percent": 1.5764848746946563
    },
    {
      "type": "training",
      "description": "Training step 1102",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:47",
      "total_flops_so_far": 1577915441731584.0,
      "budget_used_percent": 1.5779154417315842
    },
    {
      "type": "training",
      "description": "Training step 1103",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:47",
      "total_flops_so_far": 1579346008768512.0,
      "budget_used_percent": 1.5793460087685118
    },
    {
      "type": "training",
      "description": "Training step 1104",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:47",
      "total_flops_so_far": 1580776575805440.0,
      "budget_used_percent": 1.58077657580544
    },
    {
      "type": "training",
      "description": "Training step 1105",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:47",
      "total_flops_so_far": 1582207142842368.0,
      "budget_used_percent": 1.5822071428423679
    },
    {
      "type": "training",
      "description": "Training step 1106",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:47",
      "total_flops_so_far": 1583637709879296.0,
      "budget_used_percent": 1.5836377098792958
    },
    {
      "type": "training",
      "description": "Training step 1107",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:48",
      "total_flops_so_far": 1585068276916224.0,
      "budget_used_percent": 1.5850682769162239
    },
    {
      "type": "training",
      "description": "Training step 1108",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:48",
      "total_flops_so_far": 1586498843953152.0,
      "budget_used_percent": 1.586498843953152
    },
    {
      "type": "training",
      "description": "Training step 1109",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:48",
      "total_flops_so_far": 1587929410990080.0,
      "budget_used_percent": 1.58792941099008
    },
    {
      "type": "training",
      "description": "Training step 1110",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:48",
      "total_flops_so_far": 1589359978027008.0,
      "budget_used_percent": 1.5893599780270078
    },
    {
      "type": "training",
      "description": "Training step 1111",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:48",
      "total_flops_so_far": 1590790545063936.0,
      "budget_used_percent": 1.590790545063936
    },
    {
      "type": "training",
      "description": "Training step 1112",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:48",
      "total_flops_so_far": 1592221112100864.0,
      "budget_used_percent": 1.592221112100864
    },
    {
      "type": "training",
      "description": "Training step 1113",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:48",
      "total_flops_so_far": 1593651679137792.0,
      "budget_used_percent": 1.593651679137792
    },
    {
      "type": "training",
      "description": "Training step 1114",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:49",
      "total_flops_so_far": 1595082246174720.0,
      "budget_used_percent": 1.5950822461747198
    },
    {
      "type": "training",
      "description": "Training step 1115",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:49",
      "total_flops_so_far": 1596512813211648.0,
      "budget_used_percent": 1.596512813211648
    },
    {
      "type": "training",
      "description": "Training step 1116",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:49",
      "total_flops_so_far": 1597943380248576.0,
      "budget_used_percent": 1.597943380248576
    },
    {
      "type": "training",
      "description": "Training step 1117",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:49",
      "total_flops_so_far": 1599373947285504.0,
      "budget_used_percent": 1.599373947285504
    },
    {
      "type": "training",
      "description": "Training step 1118",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:49",
      "total_flops_so_far": 1600804514322432.0,
      "budget_used_percent": 1.6008045143224319
    },
    {
      "type": "training",
      "description": "Training step 1119",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:49",
      "total_flops_so_far": 1602235081359360.0,
      "budget_used_percent": 1.60223508135936
    },
    {
      "type": "training",
      "description": "Training step 1120",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:49",
      "total_flops_so_far": 1603665648396288.0,
      "budget_used_percent": 1.6036656483962881
    },
    {
      "type": "training",
      "description": "Training step 1121",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:50",
      "total_flops_so_far": 1605096215433216.0,
      "budget_used_percent": 1.605096215433216
    },
    {
      "type": "training",
      "description": "Training step 1122",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:50",
      "total_flops_so_far": 1606526782470144.0,
      "budget_used_percent": 1.606526782470144
    },
    {
      "type": "training",
      "description": "Training step 1123",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:50",
      "total_flops_so_far": 1607957349507072.0,
      "budget_used_percent": 1.607957349507072
    },
    {
      "type": "training",
      "description": "Training step 1124",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:50",
      "total_flops_so_far": 1609387916544000.0,
      "budget_used_percent": 1.6093879165440002
    },
    {
      "type": "training",
      "description": "Training step 1125",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:50",
      "total_flops_so_far": 1610818483580928.0,
      "budget_used_percent": 1.610818483580928
    },
    {
      "type": "training",
      "description": "Training step 1126",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:50",
      "total_flops_so_far": 1612249050617856.0,
      "budget_used_percent": 1.612249050617856
    },
    {
      "type": "training",
      "description": "Training step 1127",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:51",
      "total_flops_so_far": 1613679617654784.0,
      "budget_used_percent": 1.613679617654784
    },
    {
      "type": "training",
      "description": "Training step 1128",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:51",
      "total_flops_so_far": 1615110184691712.0,
      "budget_used_percent": 1.6151101846917122
    },
    {
      "type": "training",
      "description": "Training step 1129",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:51",
      "total_flops_so_far": 1616540751728640.0,
      "budget_used_percent": 1.61654075172864
    },
    {
      "type": "training",
      "description": "Training step 1130",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:51",
      "total_flops_so_far": 1617971318765568.0,
      "budget_used_percent": 1.617971318765568
    },
    {
      "type": "training",
      "description": "Training step 1131",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:51",
      "total_flops_so_far": 1619401885802496.0,
      "budget_used_percent": 1.619401885802496
    },
    {
      "type": "training",
      "description": "Training step 1132",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:51",
      "total_flops_so_far": 1620832452839424.0,
      "budget_used_percent": 1.6208324528394242
    },
    {
      "type": "training",
      "description": "Training step 1133",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:51",
      "total_flops_so_far": 1622263019876352.0,
      "budget_used_percent": 1.6222630198763521
    },
    {
      "type": "training",
      "description": "Training step 1134",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:52",
      "total_flops_so_far": 1623693586913280.0,
      "budget_used_percent": 1.62369358691328
    },
    {
      "type": "training",
      "description": "Training step 1135",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:52",
      "total_flops_so_far": 1625124153950208.0,
      "budget_used_percent": 1.6251241539502082
    },
    {
      "type": "training",
      "description": "Training step 1136",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:52",
      "total_flops_so_far": 1626554720987136.0,
      "budget_used_percent": 1.6265547209871363
    },
    {
      "type": "training",
      "description": "Training step 1137",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:52",
      "total_flops_so_far": 1627985288024064.0,
      "budget_used_percent": 1.6279852880240642
    },
    {
      "type": "training",
      "description": "Training step 1138",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:52",
      "total_flops_so_far": 1629415855060992.0,
      "budget_used_percent": 1.6294158550609918
    },
    {
      "type": "training",
      "description": "Training step 1139",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:52",
      "total_flops_so_far": 1630846422097920.0,
      "budget_used_percent": 1.6308464220979197
    },
    {
      "type": "training",
      "description": "Training step 1140",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:52",
      "total_flops_so_far": 1632276989134848.0,
      "budget_used_percent": 1.6322769891348479
    },
    {
      "type": "training",
      "description": "Training step 1141",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:53",
      "total_flops_so_far": 1633707556171776.0,
      "budget_used_percent": 1.6337075561717758
    },
    {
      "type": "training",
      "description": "Training step 1142",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:53",
      "total_flops_so_far": 1635138123208704.0,
      "budget_used_percent": 1.6351381232087039
    },
    {
      "type": "training",
      "description": "Training step 1143",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:53",
      "total_flops_so_far": 1636568690245632.0,
      "budget_used_percent": 1.6365686902456318
    },
    {
      "type": "training",
      "description": "Training step 1144",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:53",
      "total_flops_so_far": 1637999257282560.0,
      "budget_used_percent": 1.63799925728256
    },
    {
      "type": "training",
      "description": "Training step 1145",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:53",
      "total_flops_so_far": 1639429824319488.0,
      "budget_used_percent": 1.6394298243194878
    },
    {
      "type": "training",
      "description": "Training step 1146",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:53",
      "total_flops_so_far": 1640860391356416.0,
      "budget_used_percent": 1.640860391356416
    },
    {
      "type": "training",
      "description": "Training step 1147",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:53",
      "total_flops_so_far": 1642290958393344.0,
      "budget_used_percent": 1.6422909583933438
    },
    {
      "type": "training",
      "description": "Training step 1148",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:54",
      "total_flops_so_far": 1643721525430272.0,
      "budget_used_percent": 1.643721525430272
    },
    {
      "type": "training",
      "description": "Training step 1149",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:54",
      "total_flops_so_far": 1645152092467200.0,
      "budget_used_percent": 1.6451520924671998
    },
    {
      "type": "training",
      "description": "Training step 1150",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:54",
      "total_flops_so_far": 1646582659504128.0,
      "budget_used_percent": 1.646582659504128
    },
    {
      "type": "training",
      "description": "Training step 1151",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:54",
      "total_flops_so_far": 1648013226541056.0,
      "budget_used_percent": 1.6480132265410559
    },
    {
      "type": "training",
      "description": "Training step 1152",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:54",
      "total_flops_so_far": 1649443793577984.0,
      "budget_used_percent": 1.649443793577984
    },
    {
      "type": "training",
      "description": "Training step 1153",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:54",
      "total_flops_so_far": 1650874360614912.0,
      "budget_used_percent": 1.6508743606149119
    },
    {
      "type": "training",
      "description": "Training step 1154",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:54",
      "total_flops_so_far": 1652304927651840.0,
      "budget_used_percent": 1.65230492765184
    },
    {
      "type": "training",
      "description": "Training step 1155",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:55",
      "total_flops_so_far": 1653735494688768.0,
      "budget_used_percent": 1.653735494688768
    },
    {
      "type": "training",
      "description": "Training step 1156",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:55",
      "total_flops_so_far": 1655166061725696.0,
      "budget_used_percent": 1.655166061725696
    },
    {
      "type": "training",
      "description": "Training step 1157",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:55",
      "total_flops_so_far": 1656596628762624.0,
      "budget_used_percent": 1.656596628762624
    },
    {
      "type": "training",
      "description": "Training step 1158",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:55",
      "total_flops_so_far": 1658027195799552.0,
      "budget_used_percent": 1.658027195799552
    },
    {
      "type": "training",
      "description": "Training step 1159",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:55",
      "total_flops_so_far": 1659457762836480.0,
      "budget_used_percent": 1.65945776283648
    },
    {
      "type": "training",
      "description": "Training step 1160",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:55",
      "total_flops_so_far": 1660888329873408.0,
      "budget_used_percent": 1.660888329873408
    },
    {
      "type": "training",
      "description": "Training step 1161",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:55",
      "total_flops_so_far": 1662318896910336.0,
      "budget_used_percent": 1.662318896910336
    },
    {
      "type": "training",
      "description": "Training step 1162",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:56",
      "total_flops_so_far": 1663749463947264.0,
      "budget_used_percent": 1.663749463947264
    },
    {
      "type": "training",
      "description": "Training step 1163",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:56",
      "total_flops_so_far": 1665180030984192.0,
      "budget_used_percent": 1.665180030984192
    },
    {
      "type": "training",
      "description": "Training step 1164",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:56",
      "total_flops_so_far": 1666610598021120.0,
      "budget_used_percent": 1.66661059802112
    },
    {
      "type": "training",
      "description": "Training step 1165",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:56",
      "total_flops_so_far": 1668041165058048.0,
      "budget_used_percent": 1.668041165058048
    },
    {
      "type": "training",
      "description": "Training step 1166",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:56",
      "total_flops_so_far": 1669471732094976.0,
      "budget_used_percent": 1.6694717320949761
    },
    {
      "type": "training",
      "description": "Training step 1167",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:56",
      "total_flops_so_far": 1670902299131904.0,
      "budget_used_percent": 1.670902299131904
    },
    {
      "type": "training",
      "description": "Training step 1168",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:56",
      "total_flops_so_far": 1672332866168832.0,
      "budget_used_percent": 1.6723328661688321
    },
    {
      "type": "training",
      "description": "Training step 1169",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:57",
      "total_flops_so_far": 1673763433205760.0,
      "budget_used_percent": 1.67376343320576
    },
    {
      "type": "training",
      "description": "Training step 1170",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:57",
      "total_flops_so_far": 1675194000242688.0,
      "budget_used_percent": 1.6751940002426882
    },
    {
      "type": "training",
      "description": "Training step 1171",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:57",
      "total_flops_so_far": 1676624567279616.0,
      "budget_used_percent": 1.676624567279616
    },
    {
      "type": "training",
      "description": "Training step 1172",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:57",
      "total_flops_so_far": 1678055134316544.0,
      "budget_used_percent": 1.6780551343165442
    },
    {
      "type": "training",
      "description": "Training step 1173",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:57",
      "total_flops_so_far": 1679485701353472.0,
      "budget_used_percent": 1.6794857013534719
    },
    {
      "type": "training",
      "description": "Training step 1174",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:57",
      "total_flops_so_far": 1680916268390400.0,
      "budget_used_percent": 1.6809162683903998
    },
    {
      "type": "training",
      "description": "Training step 1175",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:57",
      "total_flops_so_far": 1682346835427328.0,
      "budget_used_percent": 1.6823468354273279
    },
    {
      "type": "training",
      "description": "Training step 1176",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:58",
      "total_flops_so_far": 1683777402464256.0,
      "budget_used_percent": 1.6837774024642558
    },
    {
      "type": "training",
      "description": "Training step 1177",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:58",
      "total_flops_so_far": 1685207969501184.0,
      "budget_used_percent": 1.685207969501184
    },
    {
      "type": "training",
      "description": "Training step 1178",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:58",
      "total_flops_so_far": 1686638536538112.0,
      "budget_used_percent": 1.6866385365381118
    },
    {
      "type": "training",
      "description": "Training step 1179",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:58",
      "total_flops_so_far": 1688069103575040.0,
      "budget_used_percent": 1.68806910357504
    },
    {
      "type": "training",
      "description": "Training step 1180",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:58",
      "total_flops_so_far": 1689499670611968.0,
      "budget_used_percent": 1.6894996706119678
    },
    {
      "type": "training",
      "description": "Training step 1181",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:58",
      "total_flops_so_far": 1690930237648896.0,
      "budget_used_percent": 1.690930237648896
    },
    {
      "type": "training",
      "description": "Training step 1182",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:59",
      "total_flops_so_far": 1692360804685824.0,
      "budget_used_percent": 1.6923608046858238
    },
    {
      "type": "training",
      "description": "Training step 1183",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:59",
      "total_flops_so_far": 1693791371722752.0,
      "budget_used_percent": 1.693791371722752
    },
    {
      "type": "training",
      "description": "Training step 1184",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:59",
      "total_flops_so_far": 1695221938759680.0,
      "budget_used_percent": 1.6952219387596799
    },
    {
      "type": "training",
      "description": "Training step 1185",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:59",
      "total_flops_so_far": 1696652505796608.0,
      "budget_used_percent": 1.696652505796608
    },
    {
      "type": "training",
      "description": "Training step 1186",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:59",
      "total_flops_so_far": 1698083072833536.0,
      "budget_used_percent": 1.6980830728335359
    },
    {
      "type": "training",
      "description": "Training step 1187",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:59",
      "total_flops_so_far": 1699513639870464.0,
      "budget_used_percent": 1.699513639870464
    },
    {
      "type": "training",
      "description": "Training step 1188",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:37:59",
      "total_flops_so_far": 1700944206907392.0,
      "budget_used_percent": 1.700944206907392
    },
    {
      "type": "training",
      "description": "Training step 1189",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:00",
      "total_flops_so_far": 1702374773944320.0,
      "budget_used_percent": 1.70237477394432
    },
    {
      "type": "training",
      "description": "Training step 1190",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:00",
      "total_flops_so_far": 1703805340981248.0,
      "budget_used_percent": 1.703805340981248
    },
    {
      "type": "training",
      "description": "Training step 1191",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:00",
      "total_flops_so_far": 1705235908018176.0,
      "budget_used_percent": 1.705235908018176
    },
    {
      "type": "training",
      "description": "Training step 1192",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:00",
      "total_flops_so_far": 1706666475055104.0,
      "budget_used_percent": 1.706666475055104
    },
    {
      "type": "training",
      "description": "Training step 1193",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:00",
      "total_flops_so_far": 1708097042092032.0,
      "budget_used_percent": 1.708097042092032
    },
    {
      "type": "training",
      "description": "Training step 1194",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:00",
      "total_flops_so_far": 1709527609128960.0,
      "budget_used_percent": 1.70952760912896
    },
    {
      "type": "training",
      "description": "Training step 1195",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:00",
      "total_flops_so_far": 1710958176165888.0,
      "budget_used_percent": 1.710958176165888
    },
    {
      "type": "training",
      "description": "Training step 1196",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:01",
      "total_flops_so_far": 1712388743202816.0,
      "budget_used_percent": 1.712388743202816
    },
    {
      "type": "training",
      "description": "Training step 1197",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:01",
      "total_flops_so_far": 1713819310239744.0,
      "budget_used_percent": 1.713819310239744
    },
    {
      "type": "training",
      "description": "Training step 1198",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:01",
      "total_flops_so_far": 1715249877276672.0,
      "budget_used_percent": 1.715249877276672
    },
    {
      "type": "training",
      "description": "Training step 1199",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:01",
      "total_flops_so_far": 1716680444313600.0,
      "budget_used_percent": 1.7166804443136001
    },
    {
      "type": "training",
      "description": "Training step 1200",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:01",
      "total_flops_so_far": 1718111011350528.0,
      "budget_used_percent": 1.718111011350528
    },
    {
      "type": "training",
      "description": "Training step 1201",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:01",
      "total_flops_so_far": 1719541578387456.0,
      "budget_used_percent": 1.7195415783874561
    },
    {
      "type": "training",
      "description": "Training step 1202",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:01",
      "total_flops_so_far": 1720972145424384.0,
      "budget_used_percent": 1.720972145424384
    },
    {
      "type": "training",
      "description": "Training step 1203",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:02",
      "total_flops_so_far": 1722402712461312.0,
      "budget_used_percent": 1.7224027124613122
    },
    {
      "type": "training",
      "description": "Training step 1204",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:02",
      "total_flops_so_far": 1723833279498240.0,
      "budget_used_percent": 1.72383327949824
    },
    {
      "type": "training",
      "description": "Training step 1205",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:02",
      "total_flops_so_far": 1725263846535168.0,
      "budget_used_percent": 1.7252638465351682
    },
    {
      "type": "training",
      "description": "Training step 1206",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:02",
      "total_flops_so_far": 1726694413572096.0,
      "budget_used_percent": 1.726694413572096
    },
    {
      "type": "training",
      "description": "Training step 1207",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:02",
      "total_flops_so_far": 1728124980609024.0,
      "budget_used_percent": 1.7281249806090242
    },
    {
      "type": "training",
      "description": "Training step 1208",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:02",
      "total_flops_so_far": 1729555547645952.0,
      "budget_used_percent": 1.7295555476459519
    },
    {
      "type": "training",
      "description": "Training step 1209",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:03",
      "total_flops_so_far": 1730986114682880.0,
      "budget_used_percent": 1.7309861146828798
    },
    {
      "type": "training",
      "description": "Training step 1210",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:03",
      "total_flops_so_far": 1732416681719808.0,
      "budget_used_percent": 1.732416681719808
    },
    {
      "type": "training",
      "description": "Training step 1211",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:03",
      "total_flops_so_far": 1733847248756736.0,
      "budget_used_percent": 1.7338472487567358
    },
    {
      "type": "training",
      "description": "Training step 1212",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:03",
      "total_flops_so_far": 1735277815793664.0,
      "budget_used_percent": 1.735277815793664
    },
    {
      "type": "training",
      "description": "Training step 1213",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:03",
      "total_flops_so_far": 1736708382830592.0,
      "budget_used_percent": 1.7367083828305918
    },
    {
      "type": "training",
      "description": "Training step 1214",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:03",
      "total_flops_so_far": 1738138949867520.0,
      "budget_used_percent": 1.73813894986752
    },
    {
      "type": "training",
      "description": "Training step 1215",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:03",
      "total_flops_so_far": 1739569516904448.0,
      "budget_used_percent": 1.7395695169044478
    },
    {
      "type": "training",
      "description": "Training step 1216",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:04",
      "total_flops_so_far": 1741000083941376.0,
      "budget_used_percent": 1.741000083941376
    },
    {
      "type": "training",
      "description": "Training step 1217",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:04",
      "total_flops_so_far": 1742430650978304.0,
      "budget_used_percent": 1.7424306509783039
    },
    {
      "type": "training",
      "description": "Training step 1218",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:04",
      "total_flops_so_far": 1743861218015232.0,
      "budget_used_percent": 1.743861218015232
    },
    {
      "type": "training",
      "description": "Training step 1219",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:04",
      "total_flops_so_far": 1745291785052160.0,
      "budget_used_percent": 1.7452917850521599
    },
    {
      "type": "training",
      "description": "Training step 1220",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:04",
      "total_flops_so_far": 1746722352089088.0,
      "budget_used_percent": 1.746722352089088
    },
    {
      "type": "training",
      "description": "Training step 1221",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:04",
      "total_flops_so_far": 1748152919126016.0,
      "budget_used_percent": 1.748152919126016
    },
    {
      "type": "training",
      "description": "Training step 1222",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:04",
      "total_flops_so_far": 1749583486162944.0,
      "budget_used_percent": 1.749583486162944
    },
    {
      "type": "training",
      "description": "Training step 1223",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:05",
      "total_flops_so_far": 1751014053199872.0,
      "budget_used_percent": 1.751014053199872
    },
    {
      "type": "training",
      "description": "Training step 1224",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:05",
      "total_flops_so_far": 1752444620236800.0,
      "budget_used_percent": 1.7524446202368
    },
    {
      "type": "training",
      "description": "Training step 1225",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:05",
      "total_flops_so_far": 1753875187273728.0,
      "budget_used_percent": 1.753875187273728
    },
    {
      "type": "training",
      "description": "Training step 1226",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:05",
      "total_flops_so_far": 1755305754310656.0,
      "budget_used_percent": 1.755305754310656
    },
    {
      "type": "training",
      "description": "Training step 1227",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:05",
      "total_flops_so_far": 1756736321347584.0,
      "budget_used_percent": 1.756736321347584
    },
    {
      "type": "training",
      "description": "Training step 1228",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:05",
      "total_flops_so_far": 1758166888384512.0,
      "budget_used_percent": 1.758166888384512
    },
    {
      "type": "training",
      "description": "Training step 1229",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:06",
      "total_flops_so_far": 1759597455421440.0,
      "budget_used_percent": 1.75959745542144
    },
    {
      "type": "training",
      "description": "Training step 1230",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:06",
      "total_flops_so_far": 1761028022458368.0,
      "budget_used_percent": 1.761028022458368
    },
    {
      "type": "training",
      "description": "Training step 1231",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:06",
      "total_flops_so_far": 1762458589495296.0,
      "budget_used_percent": 1.762458589495296
    },
    {
      "type": "training",
      "description": "Training step 1232",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:06",
      "total_flops_so_far": 1763889156532224.0,
      "budget_used_percent": 1.7638891565322241
    },
    {
      "type": "training",
      "description": "Training step 1233",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:06",
      "total_flops_so_far": 1765319723569152.0,
      "budget_used_percent": 1.765319723569152
    },
    {
      "type": "training",
      "description": "Training step 1234",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:06",
      "total_flops_so_far": 1766750290606080.0,
      "budget_used_percent": 1.7667502906060801
    },
    {
      "type": "training",
      "description": "Training step 1235",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:06",
      "total_flops_so_far": 1768180857643008.0,
      "budget_used_percent": 1.768180857643008
    },
    {
      "type": "training",
      "description": "Training step 1236",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:07",
      "total_flops_so_far": 1769611424679936.0,
      "budget_used_percent": 1.7696114246799362
    },
    {
      "type": "training",
      "description": "Training step 1237",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:07",
      "total_flops_so_far": 1771041991716864.0,
      "budget_used_percent": 1.771041991716864
    },
    {
      "type": "training",
      "description": "Training step 1238",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:07",
      "total_flops_so_far": 1772472558753792.0,
      "budget_used_percent": 1.7724725587537922
    },
    {
      "type": "training",
      "description": "Training step 1239",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:07",
      "total_flops_so_far": 1773903125790720.0,
      "budget_used_percent": 1.77390312579072
    },
    {
      "type": "training",
      "description": "Training step 1240",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:07",
      "total_flops_so_far": 1775333692827648.0,
      "budget_used_percent": 1.7753336928276482
    },
    {
      "type": "training",
      "description": "Training step 1241",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:07",
      "total_flops_so_far": 1776764259864576.0,
      "budget_used_percent": 1.776764259864576
    },
    {
      "type": "training",
      "description": "Training step 1242",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:07",
      "total_flops_so_far": 1778194826901504.0,
      "budget_used_percent": 1.7781948269015042
    },
    {
      "type": "training",
      "description": "Training step 1243",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:08",
      "total_flops_so_far": 1779625393938432.0,
      "budget_used_percent": 1.7796253939384319
    },
    {
      "type": "training",
      "description": "Training step 1244",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:08",
      "total_flops_so_far": 1781055960975360.0,
      "budget_used_percent": 1.7810559609753598
    },
    {
      "type": "training",
      "description": "Training step 1245",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:08",
      "total_flops_so_far": 1782486528012288.0,
      "budget_used_percent": 1.782486528012288
    },
    {
      "type": "training",
      "description": "Training step 1246",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:08",
      "total_flops_so_far": 1783917095049216.0,
      "budget_used_percent": 1.7839170950492158
    },
    {
      "type": "training",
      "description": "Training step 1247",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:08",
      "total_flops_so_far": 1785347662086144.0,
      "budget_used_percent": 1.785347662086144
    },
    {
      "type": "training",
      "description": "Training step 1248",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:08",
      "total_flops_so_far": 1786778229123072.0,
      "budget_used_percent": 1.7867782291230718
    },
    {
      "type": "training",
      "description": "Training step 1249",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:08",
      "total_flops_so_far": 1788208796160000.0,
      "budget_used_percent": 1.78820879616
    },
    {
      "type": "training",
      "description": "Training step 1250",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:09",
      "total_flops_so_far": 1789639363196928.0,
      "budget_used_percent": 1.7896393631969278
    },
    {
      "type": "training",
      "description": "Training step 1251",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:09",
      "total_flops_so_far": 1791069930233856.0,
      "budget_used_percent": 1.791069930233856
    },
    {
      "type": "training",
      "description": "Training step 1252",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:09",
      "total_flops_so_far": 1792500497270784.0,
      "budget_used_percent": 1.7925004972707839
    },
    {
      "type": "training",
      "description": "Training step 1253",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:09",
      "total_flops_so_far": 1793931064307712.0,
      "budget_used_percent": 1.793931064307712
    },
    {
      "type": "training",
      "description": "Training step 1254",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:09",
      "total_flops_so_far": 1795361631344640.0,
      "budget_used_percent": 1.7953616313446399
    },
    {
      "type": "training",
      "description": "Training step 1255",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:09",
      "total_flops_so_far": 1796792198381568.0,
      "budget_used_percent": 1.796792198381568
    },
    {
      "type": "training",
      "description": "Training step 1256",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:09",
      "total_flops_so_far": 1798222765418496.0,
      "budget_used_percent": 1.798222765418496
    },
    {
      "type": "training",
      "description": "Training step 1257",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:10",
      "total_flops_so_far": 1799653332455424.0,
      "budget_used_percent": 1.799653332455424
    },
    {
      "type": "training",
      "description": "Training step 1258",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:10",
      "total_flops_so_far": 1801083899492352.0,
      "budget_used_percent": 1.801083899492352
    },
    {
      "type": "training",
      "description": "Training step 1259",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:10",
      "total_flops_so_far": 1802514466529280.0,
      "budget_used_percent": 1.80251446652928
    },
    {
      "type": "training",
      "description": "Training step 1260",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:10",
      "total_flops_so_far": 1803945033566208.0,
      "budget_used_percent": 1.803945033566208
    },
    {
      "type": "training",
      "description": "Training step 1261",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:10",
      "total_flops_so_far": 1805375600603136.0,
      "budget_used_percent": 1.805375600603136
    },
    {
      "type": "training",
      "description": "Training step 1262",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:10",
      "total_flops_so_far": 1806806167640064.0,
      "budget_used_percent": 1.806806167640064
    },
    {
      "type": "training",
      "description": "Training step 1263",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:11",
      "total_flops_so_far": 1808236734676992.0,
      "budget_used_percent": 1.808236734676992
    },
    {
      "type": "training",
      "description": "Training step 1264",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:11",
      "total_flops_so_far": 1809667301713920.0,
      "budget_used_percent": 1.80966730171392
    },
    {
      "type": "training",
      "description": "Training step 1265",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:11",
      "total_flops_so_far": 1811097868750848.0,
      "budget_used_percent": 1.811097868750848
    },
    {
      "type": "training",
      "description": "Training step 1266",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:11",
      "total_flops_so_far": 1812528435787776.0,
      "budget_used_percent": 1.812528435787776
    },
    {
      "type": "training",
      "description": "Training step 1267",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:11",
      "total_flops_so_far": 1813959002824704.0,
      "budget_used_percent": 1.8139590028247041
    },
    {
      "type": "training",
      "description": "Training step 1268",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:11",
      "total_flops_so_far": 1815389569861632.0,
      "budget_used_percent": 1.815389569861632
    },
    {
      "type": "training",
      "description": "Training step 1269",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:11",
      "total_flops_so_far": 1816820136898560.0,
      "budget_used_percent": 1.8168201368985601
    },
    {
      "type": "training",
      "description": "Training step 1270",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:12",
      "total_flops_so_far": 1818250703935488.0,
      "budget_used_percent": 1.818250703935488
    },
    {
      "type": "training",
      "description": "Training step 1271",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:12",
      "total_flops_so_far": 1819681270972416.0,
      "budget_used_percent": 1.8196812709724162
    },
    {
      "type": "training",
      "description": "Training step 1272",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:12",
      "total_flops_so_far": 1821111838009344.0,
      "budget_used_percent": 1.821111838009344
    },
    {
      "type": "training",
      "description": "Training step 1273",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:12",
      "total_flops_so_far": 1822542405046272.0,
      "budget_used_percent": 1.8225424050462722
    },
    {
      "type": "training",
      "description": "Training step 1274",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:12",
      "total_flops_so_far": 1823972972083200.0,
      "budget_used_percent": 1.8239729720832
    },
    {
      "type": "training",
      "description": "Training step 1275",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:12",
      "total_flops_so_far": 1825403539120128.0,
      "budget_used_percent": 1.8254035391201282
    },
    {
      "type": "training",
      "description": "Training step 1276",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:12",
      "total_flops_so_far": 1826834106157056.0,
      "budget_used_percent": 1.826834106157056
    },
    {
      "type": "training",
      "description": "Training step 1277",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:13",
      "total_flops_so_far": 1828264673193984.0,
      "budget_used_percent": 1.8282646731939842
    },
    {
      "type": "training",
      "description": "Training step 1278",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:13",
      "total_flops_so_far": 1829695240230912.0,
      "budget_used_percent": 1.829695240230912
    },
    {
      "type": "training",
      "description": "Training step 1279",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:13",
      "total_flops_so_far": 1831125807267840.0,
      "budget_used_percent": 1.8311258072678398
    },
    {
      "type": "training",
      "description": "Training step 1280",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:13",
      "total_flops_so_far": 1832556374304768.0,
      "budget_used_percent": 1.832556374304768
    },
    {
      "type": "training",
      "description": "Training step 1281",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:13",
      "total_flops_so_far": 1833986941341696.0,
      "budget_used_percent": 1.8339869413416958
    },
    {
      "type": "training",
      "description": "Training step 1282",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:13",
      "total_flops_so_far": 1835417508378624.0,
      "budget_used_percent": 1.835417508378624
    },
    {
      "type": "training",
      "description": "Training step 1283",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:14",
      "total_flops_so_far": 1836848075415552.0,
      "budget_used_percent": 1.8368480754155518
    },
    {
      "type": "training",
      "description": "Training step 1284",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:14",
      "total_flops_so_far": 1838278642452480.0,
      "budget_used_percent": 1.83827864245248
    },
    {
      "type": "training",
      "description": "Training step 1285",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:14",
      "total_flops_so_far": 1839709209489408.0,
      "budget_used_percent": 1.8397092094894079
    },
    {
      "type": "training",
      "description": "Training step 1286",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:14",
      "total_flops_so_far": 1841139776526336.0,
      "budget_used_percent": 1.841139776526336
    },
    {
      "type": "training",
      "description": "Training step 1287",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:14",
      "total_flops_so_far": 1842570343563264.0,
      "budget_used_percent": 1.8425703435632639
    },
    {
      "type": "training",
      "description": "Training step 1288",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:14",
      "total_flops_so_far": 1844000910600192.0,
      "budget_used_percent": 1.844000910600192
    },
    {
      "type": "training",
      "description": "Training step 1289",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:14",
      "total_flops_so_far": 1845431477637120.0,
      "budget_used_percent": 1.84543147763712
    },
    {
      "type": "training",
      "description": "Training step 1290",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:15",
      "total_flops_so_far": 1846862044674048.0,
      "budget_used_percent": 1.846862044674048
    },
    {
      "type": "training",
      "description": "Training step 1291",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:15",
      "total_flops_so_far": 1848292611710976.0,
      "budget_used_percent": 1.848292611710976
    },
    {
      "type": "training",
      "description": "Training step 1292",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:15",
      "total_flops_so_far": 1849723178747904.0,
      "budget_used_percent": 1.849723178747904
    },
    {
      "type": "training",
      "description": "Training step 1293",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:15",
      "total_flops_so_far": 1851153745784832.0,
      "budget_used_percent": 1.851153745784832
    },
    {
      "type": "training",
      "description": "Training step 1294",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:15",
      "total_flops_so_far": 1852584312821760.0,
      "budget_used_percent": 1.85258431282176
    },
    {
      "type": "training",
      "description": "Training step 1295",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:15",
      "total_flops_so_far": 1854014879858688.0,
      "budget_used_percent": 1.854014879858688
    },
    {
      "type": "training",
      "description": "Training step 1296",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:15",
      "total_flops_so_far": 1855445446895616.0,
      "budget_used_percent": 1.855445446895616
    },
    {
      "type": "training",
      "description": "Training step 1297",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:16",
      "total_flops_so_far": 1856876013932544.0,
      "budget_used_percent": 1.856876013932544
    },
    {
      "type": "training",
      "description": "Training step 1298",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:16",
      "total_flops_so_far": 1858306580969472.0,
      "budget_used_percent": 1.858306580969472
    },
    {
      "type": "training",
      "description": "Training step 1299",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:16",
      "total_flops_so_far": 1859737148006400.0,
      "budget_used_percent": 1.8597371480064
    },
    {
      "type": "training",
      "description": "Training step 1300",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:16",
      "total_flops_so_far": 1861167715043328.0,
      "budget_used_percent": 1.8611677150433281
    },
    {
      "type": "training",
      "description": "Training step 1301",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:16",
      "total_flops_so_far": 1862598282080256.0,
      "budget_used_percent": 1.862598282080256
    },
    {
      "type": "training",
      "description": "Training step 1302",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:16",
      "total_flops_so_far": 1864028849117184.0,
      "budget_used_percent": 1.8640288491171841
    },
    {
      "type": "training",
      "description": "Training step 1303",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:17",
      "total_flops_so_far": 1865459416154112.0,
      "budget_used_percent": 1.865459416154112
    },
    {
      "type": "training",
      "description": "Training step 1304",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:17",
      "total_flops_so_far": 1866889983191040.0,
      "budget_used_percent": 1.8668899831910402
    },
    {
      "type": "training",
      "description": "Training step 1305",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:17",
      "total_flops_so_far": 1868320550227968.0,
      "budget_used_percent": 1.868320550227968
    },
    {
      "type": "training",
      "description": "Training step 1306",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:17",
      "total_flops_so_far": 1869751117264896.0,
      "budget_used_percent": 1.8697511172648962
    },
    {
      "type": "training",
      "description": "Training step 1307",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:17",
      "total_flops_so_far": 1871181684301824.0,
      "budget_used_percent": 1.871181684301824
    },
    {
      "type": "training",
      "description": "Training step 1308",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:17",
      "total_flops_so_far": 1872612251338752.0,
      "budget_used_percent": 1.8726122513387522
    },
    {
      "type": "training",
      "description": "Training step 1309",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:17",
      "total_flops_so_far": 1874042818375680.0,
      "budget_used_percent": 1.87404281837568
    },
    {
      "type": "training",
      "description": "Training step 1310",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:18",
      "total_flops_so_far": 1875473385412608.0,
      "budget_used_percent": 1.8754733854126082
    },
    {
      "type": "training",
      "description": "Training step 1311",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:18",
      "total_flops_so_far": 1876903952449536.0,
      "budget_used_percent": 1.8769039524495361
    },
    {
      "type": "training",
      "description": "Training step 1312",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:18",
      "total_flops_so_far": 1878334519486464.0,
      "budget_used_percent": 1.8783345194864642
    },
    {
      "type": "training",
      "description": "Training step 1313",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:18",
      "total_flops_so_far": 1879765086523392.0,
      "budget_used_percent": 1.879765086523392
    },
    {
      "type": "training",
      "description": "Training step 1314",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:18",
      "total_flops_so_far": 1881195653560320.0,
      "budget_used_percent": 1.8811956535603198
    },
    {
      "type": "training",
      "description": "Training step 1315",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:18",
      "total_flops_so_far": 1882626220597248.0,
      "budget_used_percent": 1.882626220597248
    },
    {
      "type": "training",
      "description": "Training step 1316",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:18",
      "total_flops_so_far": 1884056787634176.0,
      "budget_used_percent": 1.8840567876341758
    },
    {
      "type": "training",
      "description": "Training step 1317",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:19",
      "total_flops_so_far": 1885487354671104.0,
      "budget_used_percent": 1.885487354671104
    },
    {
      "type": "training",
      "description": "Training step 1318",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:19",
      "total_flops_so_far": 1886917921708032.0,
      "budget_used_percent": 1.8869179217080319
    },
    {
      "type": "training",
      "description": "Training step 1319",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:19",
      "total_flops_so_far": 1888348488744960.0,
      "budget_used_percent": 1.88834848874496
    },
    {
      "type": "training",
      "description": "Training step 1320",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:19",
      "total_flops_so_far": 1889779055781888.0,
      "budget_used_percent": 1.8897790557818879
    },
    {
      "type": "training",
      "description": "Training step 1321",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:19",
      "total_flops_so_far": 1891209622818816.0,
      "budget_used_percent": 1.891209622818816
    },
    {
      "type": "training",
      "description": "Training step 1322",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:19",
      "total_flops_so_far": 1892640189855744.0,
      "budget_used_percent": 1.892640189855744
    },
    {
      "type": "training",
      "description": "Training step 1323",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:20",
      "total_flops_so_far": 1894070756892672.0,
      "budget_used_percent": 1.894070756892672
    },
    {
      "type": "training",
      "description": "Training step 1324",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:20",
      "total_flops_so_far": 1895501323929600.0,
      "budget_used_percent": 1.8955013239296
    },
    {
      "type": "training",
      "description": "Training step 1325",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:20",
      "total_flops_so_far": 1896931890966528.0,
      "budget_used_percent": 1.896931890966528
    },
    {
      "type": "training",
      "description": "Training step 1326",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:20",
      "total_flops_so_far": 1898362458003456.0,
      "budget_used_percent": 1.898362458003456
    },
    {
      "type": "training",
      "description": "Training step 1327",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:20",
      "total_flops_so_far": 1899793025040384.0,
      "budget_used_percent": 1.899793025040384
    },
    {
      "type": "training",
      "description": "Training step 1328",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:20",
      "total_flops_so_far": 1901223592077312.0,
      "budget_used_percent": 1.901223592077312
    },
    {
      "type": "training",
      "description": "Training step 1329",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:20",
      "total_flops_so_far": 1902654159114240.0,
      "budget_used_percent": 1.90265415911424
    },
    {
      "type": "training",
      "description": "Training step 1330",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:21",
      "total_flops_so_far": 1904084726151168.0,
      "budget_used_percent": 1.904084726151168
    },
    {
      "type": "training",
      "description": "Training step 1331",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:21",
      "total_flops_so_far": 1905515293188096.0,
      "budget_used_percent": 1.905515293188096
    },
    {
      "type": "training",
      "description": "Training step 1332",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:21",
      "total_flops_so_far": 1906945860225024.0,
      "budget_used_percent": 1.906945860225024
    },
    {
      "type": "training",
      "description": "Training step 1333",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:21",
      "total_flops_so_far": 1908376427261952.0,
      "budget_used_percent": 1.9083764272619521
    },
    {
      "type": "training",
      "description": "Training step 1334",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:21",
      "total_flops_so_far": 1909806994298880.0,
      "budget_used_percent": 1.90980699429888
    },
    {
      "type": "training",
      "description": "Training step 1335",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:21",
      "total_flops_so_far": 1911237561335808.0,
      "budget_used_percent": 1.9112375613358081
    },
    {
      "type": "training",
      "description": "Training step 1336",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:21",
      "total_flops_so_far": 1912668128372736.0,
      "budget_used_percent": 1.912668128372736
    },
    {
      "type": "training",
      "description": "Training step 1337",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:22",
      "total_flops_so_far": 1914098695409664.0,
      "budget_used_percent": 1.9140986954096642
    },
    {
      "type": "training",
      "description": "Training step 1338",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:22",
      "total_flops_so_far": 1915529262446592.0,
      "budget_used_percent": 1.915529262446592
    },
    {
      "type": "training",
      "description": "Training step 1339",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:22",
      "total_flops_so_far": 1916959829483520.0,
      "budget_used_percent": 1.9169598294835202
    },
    {
      "type": "training",
      "description": "Training step 1340",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:22",
      "total_flops_so_far": 1918390396520448.0,
      "budget_used_percent": 1.918390396520448
    },
    {
      "type": "training",
      "description": "Training step 1341",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:22",
      "total_flops_so_far": 1919820963557376.0,
      "budget_used_percent": 1.9198209635573762
    },
    {
      "type": "training",
      "description": "Training step 1342",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:22",
      "total_flops_so_far": 1921251530594304.0,
      "budget_used_percent": 1.921251530594304
    },
    {
      "type": "training",
      "description": "Training step 1343",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:23",
      "total_flops_so_far": 1922682097631232.0,
      "budget_used_percent": 1.9226820976312322
    },
    {
      "type": "training",
      "description": "Training step 1344",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:23",
      "total_flops_so_far": 1924112664668160.0,
      "budget_used_percent": 1.92411266466816
    },
    {
      "type": "training",
      "description": "Training step 1345",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:23",
      "total_flops_so_far": 1925543231705088.0,
      "budget_used_percent": 1.9255432317050882
    },
    {
      "type": "training",
      "description": "Training step 1346",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:23",
      "total_flops_so_far": 1926973798742016.0,
      "budget_used_percent": 1.9269737987420161
    },
    {
      "type": "training",
      "description": "Training step 1347",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:23",
      "total_flops_so_far": 1928404365778944.0,
      "budget_used_percent": 1.9284043657789443
    },
    {
      "type": "training",
      "description": "Training step 1348",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:23",
      "total_flops_so_far": 1929834932815872.0,
      "budget_used_percent": 1.929834932815872
    },
    {
      "type": "training",
      "description": "Training step 1349",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:23",
      "total_flops_so_far": 1931265499852800.0,
      "budget_used_percent": 1.9312654998527998
    },
    {
      "type": "training",
      "description": "Training step 1350",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:24",
      "total_flops_so_far": 1932696066889728.0,
      "budget_used_percent": 1.932696066889728
    },
    {
      "type": "training",
      "description": "Training step 1351",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:24",
      "total_flops_so_far": 1934126633926656.0,
      "budget_used_percent": 1.9341266339266558
    },
    {
      "type": "training",
      "description": "Training step 1352",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:24",
      "total_flops_so_far": 1935557200963584.0,
      "budget_used_percent": 1.935557200963584
    },
    {
      "type": "training",
      "description": "Training step 1353",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:24",
      "total_flops_so_far": 1936987768000512.0,
      "budget_used_percent": 1.9369877680005119
    },
    {
      "type": "training",
      "description": "Training step 1354",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:24",
      "total_flops_so_far": 1938418335037440.0,
      "budget_used_percent": 1.93841833503744
    },
    {
      "type": "training",
      "description": "Training step 1355",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:24",
      "total_flops_so_far": 1939848902074368.0,
      "budget_used_percent": 1.9398489020743679
    },
    {
      "type": "training",
      "description": "Training step 1356",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:25",
      "total_flops_so_far": 1941279469111296.0,
      "budget_used_percent": 1.941279469111296
    },
    {
      "type": "training",
      "description": "Training step 1357",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:25",
      "total_flops_so_far": 1942710036148224.0,
      "budget_used_percent": 1.942710036148224
    },
    {
      "type": "training",
      "description": "Training step 1358",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:25",
      "total_flops_so_far": 1944140603185152.0,
      "budget_used_percent": 1.944140603185152
    },
    {
      "type": "training",
      "description": "Training step 1359",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:25",
      "total_flops_so_far": 1945571170222080.0,
      "budget_used_percent": 1.94557117022208
    },
    {
      "type": "training",
      "description": "Training step 1360",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:25",
      "total_flops_so_far": 1947001737259008.0,
      "budget_used_percent": 1.947001737259008
    },
    {
      "type": "training",
      "description": "Training step 1361",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:25",
      "total_flops_so_far": 1948432304295936.0,
      "budget_used_percent": 1.948432304295936
    },
    {
      "type": "training",
      "description": "Training step 1362",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:25",
      "total_flops_so_far": 1949862871332864.0,
      "budget_used_percent": 1.949862871332864
    },
    {
      "type": "training",
      "description": "Training step 1363",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:26",
      "total_flops_so_far": 1951293438369792.0,
      "budget_used_percent": 1.951293438369792
    },
    {
      "type": "training",
      "description": "Training step 1364",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:26",
      "total_flops_so_far": 1952724005406720.0,
      "budget_used_percent": 1.95272400540672
    },
    {
      "type": "training",
      "description": "Training step 1365",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:26",
      "total_flops_so_far": 1954154572443648.0,
      "budget_used_percent": 1.954154572443648
    },
    {
      "type": "training",
      "description": "Training step 1366",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:26",
      "total_flops_so_far": 1955585139480576.0,
      "budget_used_percent": 1.955585139480576
    },
    {
      "type": "training",
      "description": "Training step 1367",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:26",
      "total_flops_so_far": 1957015706517504.0,
      "budget_used_percent": 1.957015706517504
    },
    {
      "type": "training",
      "description": "Training step 1368",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:26",
      "total_flops_so_far": 1958446273554432.0,
      "budget_used_percent": 1.9584462735544321
    },
    {
      "type": "training",
      "description": "Training step 1369",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:26",
      "total_flops_so_far": 1959876840591360.0,
      "budget_used_percent": 1.95987684059136
    },
    {
      "type": "training",
      "description": "Training step 1370",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:27",
      "total_flops_so_far": 1961307407628288.0,
      "budget_used_percent": 1.9613074076282881
    },
    {
      "type": "training",
      "description": "Training step 1371",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:27",
      "total_flops_so_far": 1962737974665216.0,
      "budget_used_percent": 1.962737974665216
    },
    {
      "type": "training",
      "description": "Training step 1372",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:27",
      "total_flops_so_far": 1964168541702144.0,
      "budget_used_percent": 1.9641685417021442
    },
    {
      "type": "training",
      "description": "Training step 1373",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:27",
      "total_flops_so_far": 1965599108739072.0,
      "budget_used_percent": 1.965599108739072
    },
    {
      "type": "training",
      "description": "Training step 1374",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:27",
      "total_flops_so_far": 1967029675776000.0,
      "budget_used_percent": 1.9670296757760002
    },
    {
      "type": "training",
      "description": "Training step 1375",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:27",
      "total_flops_so_far": 1968460242812928.0,
      "budget_used_percent": 1.968460242812928
    },
    {
      "type": "training",
      "description": "Training step 1376",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:27",
      "total_flops_so_far": 1969890809849856.0,
      "budget_used_percent": 1.9698908098498562
    },
    {
      "type": "training",
      "description": "Training step 1377",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:28",
      "total_flops_so_far": 1971321376886784.0,
      "budget_used_percent": 1.971321376886784
    },
    {
      "type": "training",
      "description": "Training step 1378",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:28",
      "total_flops_so_far": 1972751943923712.0,
      "budget_used_percent": 1.9727519439237122
    },
    {
      "type": "training",
      "description": "Training step 1379",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:28",
      "total_flops_so_far": 1974182510960640.0,
      "budget_used_percent": 1.9741825109606401
    },
    {
      "type": "training",
      "description": "Training step 1380",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:28",
      "total_flops_so_far": 1975613077997568.0,
      "budget_used_percent": 1.9756130779975682
    },
    {
      "type": "training",
      "description": "Training step 1381",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:28",
      "total_flops_so_far": 1977043645034496.0,
      "budget_used_percent": 1.9770436450344961
    },
    {
      "type": "training",
      "description": "Training step 1382",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:28",
      "total_flops_so_far": 1978474212071424.0,
      "budget_used_percent": 1.9784742120714243
    },
    {
      "type": "training",
      "description": "Training step 1383",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:29",
      "total_flops_so_far": 1979904779108352.0,
      "budget_used_percent": 1.979904779108352
    },
    {
      "type": "training",
      "description": "Training step 1384",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:29",
      "total_flops_so_far": 1981335346145280.0,
      "budget_used_percent": 1.9813353461452798
    },
    {
      "type": "training",
      "description": "Training step 1385",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:29",
      "total_flops_so_far": 1982765913182208.0,
      "budget_used_percent": 1.9827659131822077
    },
    {
      "type": "training",
      "description": "Training step 1386",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:29",
      "total_flops_so_far": 1984196480219136.0,
      "budget_used_percent": 1.9841964802191359
    },
    {
      "type": "training",
      "description": "Training step 1387",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:29",
      "total_flops_so_far": 1985627047256064.0,
      "budget_used_percent": 1.985627047256064
    },
    {
      "type": "training",
      "description": "Training step 1388",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:29",
      "total_flops_so_far": 1987057614292992.0,
      "budget_used_percent": 1.9870576142929919
    },
    {
      "type": "training",
      "description": "Training step 1389",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:29",
      "total_flops_so_far": 1988488181329920.0,
      "budget_used_percent": 1.9884881813299198
    },
    {
      "type": "training",
      "description": "Training step 1390",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:30",
      "total_flops_so_far": 1989918748366848.0,
      "budget_used_percent": 1.989918748366848
    },
    {
      "type": "training",
      "description": "Training step 1391",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:30",
      "total_flops_so_far": 1991349315403776.0,
      "budget_used_percent": 1.991349315403776
    },
    {
      "type": "training",
      "description": "Training step 1392",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:30",
      "total_flops_so_far": 1992779882440704.0,
      "budget_used_percent": 1.992779882440704
    },
    {
      "type": "training",
      "description": "Training step 1393",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:30",
      "total_flops_so_far": 1994210449477632.0,
      "budget_used_percent": 1.9942104494776318
    },
    {
      "type": "training",
      "description": "Training step 1394",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:30",
      "total_flops_so_far": 1995641016514560.0,
      "budget_used_percent": 1.99564101651456
    },
    {
      "type": "training",
      "description": "Training step 1395",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:30",
      "total_flops_so_far": 1997071583551488.0,
      "budget_used_percent": 1.997071583551488
    },
    {
      "type": "training",
      "description": "Training step 1396",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:31",
      "total_flops_so_far": 1998502150588416.0,
      "budget_used_percent": 1.998502150588416
    },
    {
      "type": "training",
      "description": "Training step 1397",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:31",
      "total_flops_so_far": 1999932717625344.0,
      "budget_used_percent": 1.9999327176253439
    },
    {
      "type": "training",
      "description": "Training step 1398",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:31",
      "total_flops_so_far": 2001363284662272.0,
      "budget_used_percent": 2.001363284662272
    },
    {
      "type": "training",
      "description": "Training step 1399",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:31",
      "total_flops_so_far": 2002793851699200.0,
      "budget_used_percent": 2.0027938516992
    },
    {
      "type": "training",
      "description": "Training step 1400",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:31",
      "total_flops_so_far": 2004224418736128.0,
      "budget_used_percent": 2.004224418736128
    },
    {
      "type": "training",
      "description": "Training step 1401",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:31",
      "total_flops_so_far": 2005654985773056.0,
      "budget_used_percent": 2.005654985773056
    },
    {
      "type": "training",
      "description": "Training step 1402",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:31",
      "total_flops_so_far": 2007085552809984.0,
      "budget_used_percent": 2.007085552809984
    },
    {
      "type": "training",
      "description": "Training step 1403",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:32",
      "total_flops_so_far": 2008516119846912.0,
      "budget_used_percent": 2.008516119846912
    },
    {
      "type": "training",
      "description": "Training step 1404",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:32",
      "total_flops_so_far": 2009946686883840.0,
      "budget_used_percent": 2.00994668688384
    },
    {
      "type": "training",
      "description": "Training step 1405",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:32",
      "total_flops_so_far": 2011377253920768.0,
      "budget_used_percent": 2.011377253920768
    },
    {
      "type": "training",
      "description": "Training step 1406",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:32",
      "total_flops_so_far": 2012807820957696.0,
      "budget_used_percent": 2.012807820957696
    },
    {
      "type": "training",
      "description": "Training step 1407",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:32",
      "total_flops_so_far": 2014238387994624.0,
      "budget_used_percent": 2.014238387994624
    },
    {
      "type": "training",
      "description": "Training step 1408",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:32",
      "total_flops_so_far": 2015668955031552.0,
      "budget_used_percent": 2.0156689550315523
    },
    {
      "type": "training",
      "description": "Training step 1409",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:32",
      "total_flops_so_far": 2017099522068480.0,
      "budget_used_percent": 2.01709952206848
    },
    {
      "type": "training",
      "description": "Training step 1410",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:33",
      "total_flops_so_far": 2018530089105408.0,
      "budget_used_percent": 2.018530089105408
    },
    {
      "type": "training",
      "description": "Training step 1411",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:33",
      "total_flops_so_far": 2019960656142336.0,
      "budget_used_percent": 2.019960656142336
    },
    {
      "type": "training",
      "description": "Training step 1412",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:33",
      "total_flops_so_far": 2021391223179264.0,
      "budget_used_percent": 2.021391223179264
    },
    {
      "type": "training",
      "description": "Training step 1413",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:33",
      "total_flops_so_far": 2022821790216192.0,
      "budget_used_percent": 2.022821790216192
    },
    {
      "type": "training",
      "description": "Training step 1414",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:33",
      "total_flops_so_far": 2024252357253120.0,
      "budget_used_percent": 2.02425235725312
    },
    {
      "type": "training",
      "description": "Training step 1415",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:33",
      "total_flops_so_far": 2025682924290048.0,
      "budget_used_percent": 2.0256829242900483
    },
    {
      "type": "training",
      "description": "Training step 1416",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:34",
      "total_flops_so_far": 2027113491326976.0,
      "budget_used_percent": 2.0271134913269764
    },
    {
      "type": "training",
      "description": "Training step 1417",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:34",
      "total_flops_so_far": 2028544058363904.0,
      "budget_used_percent": 2.028544058363904
    },
    {
      "type": "training",
      "description": "Training step 1418",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:34",
      "total_flops_so_far": 2029974625400832.0,
      "budget_used_percent": 2.0299746254008317
    },
    {
      "type": "training",
      "description": "Training step 1419",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:34",
      "total_flops_so_far": 2031405192437760.0,
      "budget_used_percent": 2.03140519243776
    },
    {
      "type": "training",
      "description": "Training step 1420",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:34",
      "total_flops_so_far": 2032835759474688.0,
      "budget_used_percent": 2.032835759474688
    },
    {
      "type": "training",
      "description": "Training step 1421",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:34",
      "total_flops_so_far": 2034266326511616.0,
      "budget_used_percent": 2.0342663265116157
    },
    {
      "type": "training",
      "description": "Training step 1422",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:34",
      "total_flops_so_far": 2035696893548544.0,
      "budget_used_percent": 2.0356968935485438
    },
    {
      "type": "training",
      "description": "Training step 1423",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:35",
      "total_flops_so_far": 2037127460585472.0,
      "budget_used_percent": 2.037127460585472
    },
    {
      "type": "training",
      "description": "Training step 1424",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:35",
      "total_flops_so_far": 2038558027622400.0,
      "budget_used_percent": 2.0385580276224
    },
    {
      "type": "training",
      "description": "Training step 1425",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:35",
      "total_flops_so_far": 2039988594659328.0,
      "budget_used_percent": 2.0399885946593277
    },
    {
      "type": "training",
      "description": "Training step 1426",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:35",
      "total_flops_so_far": 2041419161696256.0,
      "budget_used_percent": 2.041419161696256
    },
    {
      "type": "training",
      "description": "Training step 1427",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:35",
      "total_flops_so_far": 2042849728733184.0,
      "budget_used_percent": 2.042849728733184
    },
    {
      "type": "training",
      "description": "Training step 1428",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:35",
      "total_flops_so_far": 2044280295770112.0,
      "budget_used_percent": 2.044280295770112
    },
    {
      "type": "training",
      "description": "Training step 1429",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:36",
      "total_flops_so_far": 2045710862807040.0,
      "budget_used_percent": 2.0457108628070397
    },
    {
      "type": "training",
      "description": "Training step 1430",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:36",
      "total_flops_so_far": 2047141429843968.0,
      "budget_used_percent": 2.047141429843968
    },
    {
      "type": "training",
      "description": "Training step 1431",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:36",
      "total_flops_so_far": 2048571996880896.0,
      "budget_used_percent": 2.048571996880896
    },
    {
      "type": "training",
      "description": "Training step 1432",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:36",
      "total_flops_so_far": 2050002563917824.0,
      "budget_used_percent": 2.050002563917824
    },
    {
      "type": "training",
      "description": "Training step 1433",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:36",
      "total_flops_so_far": 2051433130954752.0,
      "budget_used_percent": 2.0514331309547518
    },
    {
      "type": "training",
      "description": "Training step 1434",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:36",
      "total_flops_so_far": 2052863697991680.0,
      "budget_used_percent": 2.05286369799168
    },
    {
      "type": "training",
      "description": "Training step 1435",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:36",
      "total_flops_so_far": 2054294265028608.0,
      "budget_used_percent": 2.054294265028608
    },
    {
      "type": "training",
      "description": "Training step 1436",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:37",
      "total_flops_so_far": 2055724832065536.0,
      "budget_used_percent": 2.055724832065536
    },
    {
      "type": "training",
      "description": "Training step 1437",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:37",
      "total_flops_so_far": 2057155399102464.0,
      "budget_used_percent": 2.057155399102464
    },
    {
      "type": "training",
      "description": "Training step 1438",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:37",
      "total_flops_so_far": 2058585966139392.0,
      "budget_used_percent": 2.058585966139392
    },
    {
      "type": "training",
      "description": "Training step 1439",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:37",
      "total_flops_so_far": 2060016533176320.0,
      "budget_used_percent": 2.06001653317632
    },
    {
      "type": "training",
      "description": "Training step 1440",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:37",
      "total_flops_so_far": 2061447100213248.0,
      "budget_used_percent": 2.061447100213248
    },
    {
      "type": "training",
      "description": "Training step 1441",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:37",
      "total_flops_so_far": 2062877667250176.0,
      "budget_used_percent": 2.062877667250176
    },
    {
      "type": "training",
      "description": "Training step 1442",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:38",
      "total_flops_so_far": 2064308234287104.0,
      "budget_used_percent": 2.064308234287104
    },
    {
      "type": "training",
      "description": "Training step 1443",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:38",
      "total_flops_so_far": 2065738801324032.0,
      "budget_used_percent": 2.065738801324032
    },
    {
      "type": "training",
      "description": "Training step 1444",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:38",
      "total_flops_so_far": 2067169368360960.0,
      "budget_used_percent": 2.06716936836096
    },
    {
      "type": "training",
      "description": "Training step 1445",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:38",
      "total_flops_so_far": 2068599935397888.0,
      "budget_used_percent": 2.068599935397888
    },
    {
      "type": "training",
      "description": "Training step 1446",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:38",
      "total_flops_so_far": 2070030502434816.0,
      "budget_used_percent": 2.070030502434816
    },
    {
      "type": "training",
      "description": "Training step 1447",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:39",
      "total_flops_so_far": 2071461069471744.0,
      "budget_used_percent": 2.071461069471744
    },
    {
      "type": "training",
      "description": "Training step 1448",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:39",
      "total_flops_so_far": 2072891636508672.0,
      "budget_used_percent": 2.0728916365086723
    },
    {
      "type": "training",
      "description": "Training step 1449",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:39",
      "total_flops_so_far": 2074322203545600.0,
      "budget_used_percent": 2.0743222035456
    },
    {
      "type": "training",
      "description": "Training step 1450",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:39",
      "total_flops_so_far": 2075752770582528.0,
      "budget_used_percent": 2.075752770582528
    },
    {
      "type": "training",
      "description": "Training step 1451",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:39",
      "total_flops_so_far": 2077183337619456.0,
      "budget_used_percent": 2.077183337619456
    },
    {
      "type": "training",
      "description": "Training step 1452",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:39",
      "total_flops_so_far": 2078613904656384.0,
      "budget_used_percent": 2.0786139046563843
    },
    {
      "type": "training",
      "description": "Training step 1453",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:40",
      "total_flops_so_far": 2080044471693312.0,
      "budget_used_percent": 2.080044471693312
    },
    {
      "type": "training",
      "description": "Training step 1454",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:40",
      "total_flops_so_far": 2081475038730240.0,
      "budget_used_percent": 2.0814750387302396
    },
    {
      "type": "training",
      "description": "Training step 1455",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:40",
      "total_flops_so_far": 2082905605767168.0,
      "budget_used_percent": 2.0829056057671678
    },
    {
      "type": "training",
      "description": "Training step 1456",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:40",
      "total_flops_so_far": 2084336172804096.0,
      "budget_used_percent": 2.084336172804096
    },
    {
      "type": "training",
      "description": "Training step 1457",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:40",
      "total_flops_so_far": 2085766739841024.0,
      "budget_used_percent": 2.085766739841024
    },
    {
      "type": "training",
      "description": "Training step 1458",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:40",
      "total_flops_so_far": 2087197306877952.0,
      "budget_used_percent": 2.0871973068779517
    },
    {
      "type": "training",
      "description": "Training step 1459",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:40",
      "total_flops_so_far": 2088627873914880.0,
      "budget_used_percent": 2.08862787391488
    },
    {
      "type": "training",
      "description": "Training step 1460",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:41",
      "total_flops_so_far": 2090058440951808.0,
      "budget_used_percent": 2.090058440951808
    },
    {
      "type": "training",
      "description": "Training step 1461",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:41",
      "total_flops_so_far": 2091489007988736.0,
      "budget_used_percent": 2.091489007988736
    },
    {
      "type": "training",
      "description": "Training step 1462",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:41",
      "total_flops_so_far": 2092919575025664.0,
      "budget_used_percent": 2.0929195750256637
    },
    {
      "type": "training",
      "description": "Training step 1463",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:41",
      "total_flops_so_far": 2094350142062592.0,
      "budget_used_percent": 2.094350142062592
    },
    {
      "type": "training",
      "description": "Training step 1464",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:41",
      "total_flops_so_far": 2095780709099520.0,
      "budget_used_percent": 2.09578070909952
    },
    {
      "type": "training",
      "description": "Training step 1465",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:41",
      "total_flops_so_far": 2097211276136448.0,
      "budget_used_percent": 2.097211276136448
    },
    {
      "type": "training",
      "description": "Training step 1466",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:42",
      "total_flops_so_far": 2098641843173376.0,
      "budget_used_percent": 2.0986418431733758
    },
    {
      "type": "training",
      "description": "Training step 1467",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:42",
      "total_flops_so_far": 2100072410210304.0,
      "budget_used_percent": 2.100072410210304
    },
    {
      "type": "training",
      "description": "Training step 1468",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:42",
      "total_flops_so_far": 2101502977247232.0,
      "budget_used_percent": 2.101502977247232
    },
    {
      "type": "training",
      "description": "Training step 1469",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:42",
      "total_flops_so_far": 2102933544284160.0,
      "budget_used_percent": 2.10293354428416
    },
    {
      "type": "training",
      "description": "Training step 1470",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:42",
      "total_flops_so_far": 2104364111321088.0,
      "budget_used_percent": 2.104364111321088
    },
    {
      "type": "training",
      "description": "Training step 1471",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:42",
      "total_flops_so_far": 2105794678358016.0,
      "budget_used_percent": 2.105794678358016
    },
    {
      "type": "training",
      "description": "Training step 1472",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:42",
      "total_flops_so_far": 2107225245394944.0,
      "budget_used_percent": 2.107225245394944
    },
    {
      "type": "training",
      "description": "Training step 1473",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:43",
      "total_flops_so_far": 2108655812431872.0,
      "budget_used_percent": 2.108655812431872
    },
    {
      "type": "training",
      "description": "Training step 1474",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:43",
      "total_flops_so_far": 2110086379468800.0,
      "budget_used_percent": 2.1100863794688
    },
    {
      "type": "training",
      "description": "Training step 1475",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:43",
      "total_flops_so_far": 2111516946505728.0,
      "budget_used_percent": 2.111516946505728
    },
    {
      "type": "training",
      "description": "Training step 1476",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:43",
      "total_flops_so_far": 2112947513542656.0,
      "budget_used_percent": 2.112947513542656
    },
    {
      "type": "training",
      "description": "Training step 1477",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:43",
      "total_flops_so_far": 2114378080579584.0,
      "budget_used_percent": 2.114378080579584
    },
    {
      "type": "training",
      "description": "Training step 1478",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:43",
      "total_flops_so_far": 2115808647616512.0,
      "budget_used_percent": 2.115808647616512
    },
    {
      "type": "training",
      "description": "Training step 1479",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:44",
      "total_flops_so_far": 2117239214653440.0,
      "budget_used_percent": 2.11723921465344
    },
    {
      "type": "training",
      "description": "Training step 1480",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:44",
      "total_flops_so_far": 2118669781690368.0,
      "budget_used_percent": 2.118669781690368
    },
    {
      "type": "training",
      "description": "Training step 1481",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:44",
      "total_flops_so_far": 2120100348727296.0,
      "budget_used_percent": 2.1201003487272962
    },
    {
      "type": "training",
      "description": "Training step 1482",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:44",
      "total_flops_so_far": 2121530915764224.0,
      "budget_used_percent": 2.121530915764224
    },
    {
      "type": "training",
      "description": "Training step 1483",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:44",
      "total_flops_so_far": 2122961482801152.0,
      "budget_used_percent": 2.122961482801152
    },
    {
      "type": "training",
      "description": "Training step 1484",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:44",
      "total_flops_so_far": 2124392049838080.0,
      "budget_used_percent": 2.12439204983808
    },
    {
      "type": "training",
      "description": "Training step 1485",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:44",
      "total_flops_so_far": 2125822616875008.0,
      "budget_used_percent": 2.1258226168750083
    },
    {
      "type": "training",
      "description": "Training step 1486",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:45",
      "total_flops_so_far": 2127253183911936.0,
      "budget_used_percent": 2.127253183911936
    },
    {
      "type": "training",
      "description": "Training step 1487",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:45",
      "total_flops_so_far": 2128683750948864.0,
      "budget_used_percent": 2.128683750948864
    },
    {
      "type": "training",
      "description": "Training step 1488",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:45",
      "total_flops_so_far": 2130114317985792.0,
      "budget_used_percent": 2.1301143179857918
    },
    {
      "type": "training",
      "description": "Training step 1489",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:45",
      "total_flops_so_far": 2131544885022720.0,
      "budget_used_percent": 2.13154488502272
    },
    {
      "type": "training",
      "description": "Training step 1490",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:45",
      "total_flops_so_far": 2132975452059648.0,
      "budget_used_percent": 2.132975452059648
    },
    {
      "type": "training",
      "description": "Training step 1491",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:45",
      "total_flops_so_far": 2134406019096576.0,
      "budget_used_percent": 2.1344060190965757
    },
    {
      "type": "training",
      "description": "Training step 1492",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:46",
      "total_flops_so_far": 2135836586133504.0,
      "budget_used_percent": 2.135836586133504
    },
    {
      "type": "training",
      "description": "Training step 1493",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:46",
      "total_flops_so_far": 2137267153170432.0,
      "budget_used_percent": 2.137267153170432
    },
    {
      "type": "training",
      "description": "Training step 1494",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:46",
      "total_flops_so_far": 2138697720207360.0,
      "budget_used_percent": 2.13869772020736
    },
    {
      "type": "training",
      "description": "Training step 1495",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:46",
      "total_flops_so_far": 2140128287244288.0,
      "budget_used_percent": 2.1401282872442877
    },
    {
      "type": "training",
      "description": "Training step 1496",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:46",
      "total_flops_so_far": 2141558854281216.0,
      "budget_used_percent": 2.141558854281216
    },
    {
      "type": "training",
      "description": "Training step 1497",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:46",
      "total_flops_so_far": 2142989421318144.0,
      "budget_used_percent": 2.142989421318144
    },
    {
      "type": "training",
      "description": "Training step 1498",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:46",
      "total_flops_so_far": 2144419988355072.0,
      "budget_used_percent": 2.144419988355072
    },
    {
      "type": "training",
      "description": "Training step 1499",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:38:47",
      "total_flops_so_far": 2145850555392000.0,
      "budget_used_percent": 2.1458505553919998
    },
    {
      "type": "training",
      "description": "Training step 1500",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:09",
      "total_flops_so_far": 2147281122428928.0,
      "budget_used_percent": 2.147281122428928
    },
    {
      "type": "training",
      "description": "Training step 1501",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:10",
      "total_flops_so_far": 2148711689465856.0,
      "budget_used_percent": 2.148711689465856
    },
    {
      "type": "training",
      "description": "Training step 1502",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:10",
      "total_flops_so_far": 2150142256502784.0,
      "budget_used_percent": 2.150142256502784
    },
    {
      "type": "training",
      "description": "Training step 1503",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:10",
      "total_flops_so_far": 2151572823539712.0,
      "budget_used_percent": 2.151572823539712
    },
    {
      "type": "training",
      "description": "Training step 1504",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:10",
      "total_flops_so_far": 2153003390576640.0,
      "budget_used_percent": 2.15300339057664
    },
    {
      "type": "training",
      "description": "Training step 1505",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:10",
      "total_flops_so_far": 2154433957613568.0,
      "budget_used_percent": 2.154433957613568
    },
    {
      "type": "training",
      "description": "Training step 1506",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:10",
      "total_flops_so_far": 2155864524650496.0,
      "budget_used_percent": 2.155864524650496
    },
    {
      "type": "training",
      "description": "Training step 1507",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:11",
      "total_flops_so_far": 2157295091687424.0,
      "budget_used_percent": 2.157295091687424
    },
    {
      "type": "training",
      "description": "Training step 1508",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:11",
      "total_flops_so_far": 2158725658724352.0,
      "budget_used_percent": 2.158725658724352
    },
    {
      "type": "training",
      "description": "Training step 1509",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:11",
      "total_flops_so_far": 2160156225761280.0,
      "budget_used_percent": 2.16015622576128
    },
    {
      "type": "training",
      "description": "Training step 1510",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:11",
      "total_flops_so_far": 2161586792798208.0,
      "budget_used_percent": 2.161586792798208
    },
    {
      "type": "training",
      "description": "Training step 1511",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:11",
      "total_flops_so_far": 2163017359835136.0,
      "budget_used_percent": 2.163017359835136
    },
    {
      "type": "training",
      "description": "Training step 1512",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:11",
      "total_flops_so_far": 2164447926872064.0,
      "budget_used_percent": 2.164447926872064
    },
    {
      "type": "training",
      "description": "Training step 1513",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:11",
      "total_flops_so_far": 2165878493908992.0,
      "budget_used_percent": 2.165878493908992
    },
    {
      "type": "training",
      "description": "Training step 1514",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:12",
      "total_flops_so_far": 2167309060945920.0,
      "budget_used_percent": 2.1673090609459202
    },
    {
      "type": "training",
      "description": "Training step 1515",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:12",
      "total_flops_so_far": 2168739627982848.0,
      "budget_used_percent": 2.168739627982848
    },
    {
      "type": "training",
      "description": "Training step 1516",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:12",
      "total_flops_so_far": 2170170195019776.0,
      "budget_used_percent": 2.170170195019776
    },
    {
      "type": "training",
      "description": "Training step 1517",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:12",
      "total_flops_so_far": 2171600762056704.0,
      "budget_used_percent": 2.171600762056704
    },
    {
      "type": "training",
      "description": "Training step 1518",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:12",
      "total_flops_so_far": 2173031329093632.0,
      "budget_used_percent": 2.1730313290936323
    },
    {
      "type": "training",
      "description": "Training step 1519",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:12",
      "total_flops_so_far": 2174461896130560.0,
      "budget_used_percent": 2.17446189613056
    },
    {
      "type": "training",
      "description": "Training step 1520",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:13",
      "total_flops_so_far": 2175892463167488.0,
      "budget_used_percent": 2.175892463167488
    },
    {
      "type": "training",
      "description": "Training step 1521",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:13",
      "total_flops_so_far": 2177323030204416.0,
      "budget_used_percent": 2.177323030204416
    },
    {
      "type": "training",
      "description": "Training step 1522",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:13",
      "total_flops_so_far": 2178753597241344.0,
      "budget_used_percent": 2.1787535972413443
    },
    {
      "type": "training",
      "description": "Training step 1523",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:13",
      "total_flops_so_far": 2180184164278272.0,
      "budget_used_percent": 2.180184164278272
    },
    {
      "type": "training",
      "description": "Training step 1524",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:13",
      "total_flops_so_far": 2181614731315200.0,
      "budget_used_percent": 2.1816147313151997
    },
    {
      "type": "training",
      "description": "Training step 1525",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:13",
      "total_flops_so_far": 2183045298352128.0,
      "budget_used_percent": 2.183045298352128
    },
    {
      "type": "training",
      "description": "Training step 1526",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:14",
      "total_flops_so_far": 2184475865389056.0,
      "budget_used_percent": 2.184475865389056
    },
    {
      "type": "training",
      "description": "Training step 1527",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:14",
      "total_flops_so_far": 2185906432425984.0,
      "budget_used_percent": 2.185906432425984
    },
    {
      "type": "training",
      "description": "Training step 1528",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:14",
      "total_flops_so_far": 2187336999462912.0,
      "budget_used_percent": 2.1873369994629117
    },
    {
      "type": "training",
      "description": "Training step 1529",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:14",
      "total_flops_so_far": 2188767566499840.0,
      "budget_used_percent": 2.18876756649984
    },
    {
      "type": "training",
      "description": "Training step 1530",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:14",
      "total_flops_so_far": 2190198133536768.0,
      "budget_used_percent": 2.190198133536768
    },
    {
      "type": "training",
      "description": "Training step 1531",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:14",
      "total_flops_so_far": 2191628700573696.0,
      "budget_used_percent": 2.191628700573696
    },
    {
      "type": "training",
      "description": "Training step 1532",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:14",
      "total_flops_so_far": 2193059267610624.0,
      "budget_used_percent": 2.1930592676106238
    },
    {
      "type": "training",
      "description": "Training step 1533",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:15",
      "total_flops_so_far": 2194489834647552.0,
      "budget_used_percent": 2.194489834647552
    },
    {
      "type": "training",
      "description": "Training step 1534",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:15",
      "total_flops_so_far": 2195920401684480.0,
      "budget_used_percent": 2.19592040168448
    },
    {
      "type": "training",
      "description": "Training step 1535",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:15",
      "total_flops_so_far": 2197350968721408.0,
      "budget_used_percent": 2.197350968721408
    },
    {
      "type": "training",
      "description": "Training step 1536",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:15",
      "total_flops_so_far": 2198781535758336.0,
      "budget_used_percent": 2.198781535758336
    },
    {
      "type": "training",
      "description": "Training step 1537",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:15",
      "total_flops_so_far": 2200212102795264.0,
      "budget_used_percent": 2.200212102795264
    },
    {
      "type": "training",
      "description": "Training step 1538",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:15",
      "total_flops_so_far": 2201642669832192.0,
      "budget_used_percent": 2.201642669832192
    },
    {
      "type": "training",
      "description": "Training step 1539",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:16",
      "total_flops_so_far": 2203073236869120.0,
      "budget_used_percent": 2.20307323686912
    },
    {
      "type": "training",
      "description": "Training step 1540",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:16",
      "total_flops_so_far": 2204503803906048.0,
      "budget_used_percent": 2.204503803906048
    },
    {
      "type": "training",
      "description": "Training step 1541",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:16",
      "total_flops_so_far": 2205934370942976.0,
      "budget_used_percent": 2.205934370942976
    },
    {
      "type": "training",
      "description": "Training step 1542",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:16",
      "total_flops_so_far": 2207364937979904.0,
      "budget_used_percent": 2.207364937979904
    },
    {
      "type": "training",
      "description": "Training step 1543",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:16",
      "total_flops_so_far": 2208795505016832.0,
      "budget_used_percent": 2.208795505016832
    },
    {
      "type": "training",
      "description": "Training step 1544",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:16",
      "total_flops_so_far": 2210226072053760.0,
      "budget_used_percent": 2.21022607205376
    },
    {
      "type": "training",
      "description": "Training step 1545",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:16",
      "total_flops_so_far": 2211656639090688.0,
      "budget_used_percent": 2.211656639090688
    },
    {
      "type": "training",
      "description": "Training step 1546",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:17",
      "total_flops_so_far": 2213087206127616.0,
      "budget_used_percent": 2.213087206127616
    },
    {
      "type": "training",
      "description": "Training step 1547",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:17",
      "total_flops_so_far": 2214517773164544.0,
      "budget_used_percent": 2.2145177731645442
    },
    {
      "type": "training",
      "description": "Training step 1548",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:17",
      "total_flops_so_far": 2215948340201472.0,
      "budget_used_percent": 2.215948340201472
    },
    {
      "type": "training",
      "description": "Training step 1549",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:17",
      "total_flops_so_far": 2217378907238400.0,
      "budget_used_percent": 2.2173789072384
    },
    {
      "type": "training",
      "description": "Training step 1550",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:17",
      "total_flops_so_far": 2218809474275328.0,
      "budget_used_percent": 2.218809474275328
    },
    {
      "type": "training",
      "description": "Training step 1551",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:17",
      "total_flops_so_far": 2220240041312256.0,
      "budget_used_percent": 2.2202400413122563
    },
    {
      "type": "training",
      "description": "Training step 1552",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:18",
      "total_flops_so_far": 2221670608349184.0,
      "budget_used_percent": 2.221670608349184
    },
    {
      "type": "training",
      "description": "Training step 1553",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:18",
      "total_flops_so_far": 2223101175386112.0,
      "budget_used_percent": 2.223101175386112
    },
    {
      "type": "training",
      "description": "Training step 1554",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:18",
      "total_flops_so_far": 2224531742423040.0,
      "budget_used_percent": 2.22453174242304
    },
    {
      "type": "training",
      "description": "Training step 1555",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:18",
      "total_flops_so_far": 2225962309459968.0,
      "budget_used_percent": 2.2259623094599683
    },
    {
      "type": "training",
      "description": "Training step 1556",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:18",
      "total_flops_so_far": 2227392876496896.0,
      "budget_used_percent": 2.227392876496896
    },
    {
      "type": "training",
      "description": "Training step 1557",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:18",
      "total_flops_so_far": 2228823443533824.0,
      "budget_used_percent": 2.228823443533824
    },
    {
      "type": "training",
      "description": "Training step 1558",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:18",
      "total_flops_so_far": 2230254010570752.0,
      "budget_used_percent": 2.230254010570752
    },
    {
      "type": "training",
      "description": "Training step 1559",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:19",
      "total_flops_so_far": 2231684577607680.0,
      "budget_used_percent": 2.23168457760768
    },
    {
      "type": "training",
      "description": "Training step 1560",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:19",
      "total_flops_so_far": 2233115144644608.0,
      "budget_used_percent": 2.233115144644608
    },
    {
      "type": "training",
      "description": "Training step 1561",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:19",
      "total_flops_so_far": 2234545711681536.0,
      "budget_used_percent": 2.2345457116815357
    },
    {
      "type": "training",
      "description": "Training step 1562",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:19",
      "total_flops_so_far": 2235976278718464.0,
      "budget_used_percent": 2.235976278718464
    },
    {
      "type": "training",
      "description": "Training step 1563",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:19",
      "total_flops_so_far": 2237406845755392.0,
      "budget_used_percent": 2.237406845755392
    },
    {
      "type": "training",
      "description": "Training step 1564",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:19",
      "total_flops_so_far": 2238837412792320.0,
      "budget_used_percent": 2.23883741279232
    },
    {
      "type": "training",
      "description": "Training step 1565",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:20",
      "total_flops_so_far": 2240267979829248.0,
      "budget_used_percent": 2.2402679798292477
    },
    {
      "type": "training",
      "description": "Training step 1566",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:20",
      "total_flops_so_far": 2241698546866176.0,
      "budget_used_percent": 2.241698546866176
    },
    {
      "type": "training",
      "description": "Training step 1567",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:20",
      "total_flops_so_far": 2243129113903104.0,
      "budget_used_percent": 2.243129113903104
    },
    {
      "type": "training",
      "description": "Training step 1568",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:20",
      "total_flops_so_far": 2244559680940032.0,
      "budget_used_percent": 2.244559680940032
    },
    {
      "type": "training",
      "description": "Training step 1569",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:20",
      "total_flops_so_far": 2245990247976960.0,
      "budget_used_percent": 2.24599024797696
    },
    {
      "type": "training",
      "description": "Training step 1570",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:20",
      "total_flops_so_far": 2247420815013888.0,
      "budget_used_percent": 2.247420815013888
    },
    {
      "type": "training",
      "description": "Training step 1571",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:21",
      "total_flops_so_far": 2248851382050816.0,
      "budget_used_percent": 2.248851382050816
    },
    {
      "type": "training",
      "description": "Training step 1572",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:21",
      "total_flops_so_far": 2250281949087744.0,
      "budget_used_percent": 2.250281949087744
    },
    {
      "type": "training",
      "description": "Training step 1573",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:21",
      "total_flops_so_far": 2251712516124672.0,
      "budget_used_percent": 2.251712516124672
    },
    {
      "type": "training",
      "description": "Training step 1574",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:21",
      "total_flops_so_far": 2253143083161600.0,
      "budget_used_percent": 2.2531430831616
    },
    {
      "type": "training",
      "description": "Training step 1575",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:21",
      "total_flops_so_far": 2254573650198528.0,
      "budget_used_percent": 2.254573650198528
    },
    {
      "type": "training",
      "description": "Training step 1576",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:21",
      "total_flops_so_far": 2256004217235456.0,
      "budget_used_percent": 2.256004217235456
    },
    {
      "type": "training",
      "description": "Training step 1577",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:22",
      "total_flops_so_far": 2257434784272384.0,
      "budget_used_percent": 2.257434784272384
    },
    {
      "type": "training",
      "description": "Training step 1578",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:22",
      "total_flops_so_far": 2258865351309312.0,
      "budget_used_percent": 2.258865351309312
    },
    {
      "type": "training",
      "description": "Training step 1579",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:22",
      "total_flops_so_far": 2260295918346240.0,
      "budget_used_percent": 2.26029591834624
    },
    {
      "type": "training",
      "description": "Training step 1580",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:22",
      "total_flops_so_far": 2261726485383168.0,
      "budget_used_percent": 2.2617264853831682
    },
    {
      "type": "training",
      "description": "Training step 1581",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:22",
      "total_flops_so_far": 2263157052420096.0,
      "budget_used_percent": 2.263157052420096
    },
    {
      "type": "training",
      "description": "Training step 1582",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:22",
      "total_flops_so_far": 2264587619457024.0,
      "budget_used_percent": 2.264587619457024
    },
    {
      "type": "training",
      "description": "Training step 1583",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:22",
      "total_flops_so_far": 2266018186493952.0,
      "budget_used_percent": 2.266018186493952
    },
    {
      "type": "training",
      "description": "Training step 1584",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:23",
      "total_flops_so_far": 2267448753530880.0,
      "budget_used_percent": 2.2674487535308803
    },
    {
      "type": "training",
      "description": "Training step 1585",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:23",
      "total_flops_so_far": 2268879320567808.0,
      "budget_used_percent": 2.268879320567808
    },
    {
      "type": "training",
      "description": "Training step 1586",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:23",
      "total_flops_so_far": 2270309887604736.0,
      "budget_used_percent": 2.270309887604736
    },
    {
      "type": "training",
      "description": "Training step 1587",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:23",
      "total_flops_so_far": 2271740454641664.0,
      "budget_used_percent": 2.271740454641664
    },
    {
      "type": "training",
      "description": "Training step 1588",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:23",
      "total_flops_so_far": 2273171021678592.0,
      "budget_used_percent": 2.2731710216785923
    },
    {
      "type": "training",
      "description": "Training step 1589",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:23",
      "total_flops_so_far": 2274601588715520.0,
      "budget_used_percent": 2.27460158871552
    },
    {
      "type": "training",
      "description": "Training step 1590",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:24",
      "total_flops_so_far": 2276032155752448.0,
      "budget_used_percent": 2.276032155752448
    },
    {
      "type": "training",
      "description": "Training step 1591",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:24",
      "total_flops_so_far": 2277462722789376.0,
      "budget_used_percent": 2.2774627227893762
    },
    {
      "type": "training",
      "description": "Training step 1592",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:24",
      "total_flops_so_far": 2278893289826304.0,
      "budget_used_percent": 2.2788932898263043
    },
    {
      "type": "training",
      "description": "Training step 1593",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:24",
      "total_flops_so_far": 2280323856863232.0,
      "budget_used_percent": 2.280323856863232
    },
    {
      "type": "training",
      "description": "Training step 1594",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:24",
      "total_flops_so_far": 2281754423900160.0,
      "budget_used_percent": 2.2817544239001597
    },
    {
      "type": "training",
      "description": "Training step 1595",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:24",
      "total_flops_so_far": 2283184990937088.0,
      "budget_used_percent": 2.283184990937088
    },
    {
      "type": "training",
      "description": "Training step 1596",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:24",
      "total_flops_so_far": 2284615557974016.0,
      "budget_used_percent": 2.284615557974016
    },
    {
      "type": "training",
      "description": "Training step 1597",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:25",
      "total_flops_so_far": 2286046125010944.0,
      "budget_used_percent": 2.286046125010944
    },
    {
      "type": "training",
      "description": "Training step 1598",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:25",
      "total_flops_so_far": 2287476692047872.0,
      "budget_used_percent": 2.2874766920478717
    },
    {
      "type": "training",
      "description": "Training step 1599",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:25",
      "total_flops_so_far": 2288907259084800.0,
      "budget_used_percent": 2.2889072590848
    },
    {
      "type": "training",
      "description": "Training step 1600",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:25",
      "total_flops_so_far": 2290337826121728.0,
      "budget_used_percent": 2.290337826121728
    },
    {
      "type": "training",
      "description": "Training step 1601",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:25",
      "total_flops_so_far": 2291768393158656.0,
      "budget_used_percent": 2.291768393158656
    },
    {
      "type": "training",
      "description": "Training step 1602",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:25",
      "total_flops_so_far": 2293198960195584.0,
      "budget_used_percent": 2.293198960195584
    },
    {
      "type": "training",
      "description": "Training step 1603",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:26",
      "total_flops_so_far": 2294629527232512.0,
      "budget_used_percent": 2.294629527232512
    },
    {
      "type": "training",
      "description": "Training step 1604",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:26",
      "total_flops_so_far": 2296060094269440.0,
      "budget_used_percent": 2.29606009426944
    },
    {
      "type": "training",
      "description": "Training step 1605",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:26",
      "total_flops_so_far": 2297490661306368.0,
      "budget_used_percent": 2.297490661306368
    },
    {
      "type": "training",
      "description": "Training step 1606",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:26",
      "total_flops_so_far": 2298921228343296.0,
      "budget_used_percent": 2.298921228343296
    },
    {
      "type": "training",
      "description": "Training step 1607",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:26",
      "total_flops_so_far": 2300351795380224.0,
      "budget_used_percent": 2.300351795380224
    },
    {
      "type": "training",
      "description": "Training step 1608",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:26",
      "total_flops_so_far": 2301782362417152.0,
      "budget_used_percent": 2.301782362417152
    },
    {
      "type": "training",
      "description": "Training step 1609",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:26",
      "total_flops_so_far": 2303212929454080.0,
      "budget_used_percent": 2.30321292945408
    },
    {
      "type": "training",
      "description": "Training step 1610",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:27",
      "total_flops_so_far": 2304643496491008.0,
      "budget_used_percent": 2.304643496491008
    },
    {
      "type": "training",
      "description": "Training step 1611",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:27",
      "total_flops_so_far": 2306074063527936.0,
      "budget_used_percent": 2.306074063527936
    },
    {
      "type": "training",
      "description": "Training step 1612",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:27",
      "total_flops_so_far": 2307504630564864.0,
      "budget_used_percent": 2.307504630564864
    },
    {
      "type": "training",
      "description": "Training step 1613",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:27",
      "total_flops_so_far": 2308935197601792.0,
      "budget_used_percent": 2.308935197601792
    },
    {
      "type": "training",
      "description": "Training step 1614",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:27",
      "total_flops_so_far": 2310365764638720.0,
      "budget_used_percent": 2.31036576463872
    },
    {
      "type": "training",
      "description": "Training step 1615",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:27",
      "total_flops_so_far": 2311796331675648.0,
      "budget_used_percent": 2.311796331675648
    },
    {
      "type": "training",
      "description": "Training step 1616",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:28",
      "total_flops_so_far": 2313226898712576.0,
      "budget_used_percent": 2.313226898712576
    },
    {
      "type": "training",
      "description": "Training step 1617",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:28",
      "total_flops_so_far": 2314657465749504.0,
      "budget_used_percent": 2.3146574657495043
    },
    {
      "type": "training",
      "description": "Training step 1618",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:28",
      "total_flops_so_far": 2316088032786432.0,
      "budget_used_percent": 2.316088032786432
    },
    {
      "type": "training",
      "description": "Training step 1619",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:28",
      "total_flops_so_far": 2317518599823360.0,
      "budget_used_percent": 2.31751859982336
    },
    {
      "type": "training",
      "description": "Training step 1620",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:28",
      "total_flops_so_far": 2318949166860288.0,
      "budget_used_percent": 2.318949166860288
    },
    {
      "type": "training",
      "description": "Training step 1621",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:28",
      "total_flops_so_far": 2320379733897216.0,
      "budget_used_percent": 2.3203797338972163
    },
    {
      "type": "training",
      "description": "Training step 1622",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:29",
      "total_flops_so_far": 2321810300934144.0,
      "budget_used_percent": 2.321810300934144
    },
    {
      "type": "training",
      "description": "Training step 1623",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:29",
      "total_flops_so_far": 2323240867971072.0,
      "budget_used_percent": 2.323240867971072
    },
    {
      "type": "training",
      "description": "Training step 1624",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:29",
      "total_flops_so_far": 2324671435008000.0,
      "budget_used_percent": 2.324671435008
    },
    {
      "type": "training",
      "description": "Training step 1625",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:29",
      "total_flops_so_far": 2326102002044928.0,
      "budget_used_percent": 2.3261020020449283
    },
    {
      "type": "training",
      "description": "Training step 1626",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:29",
      "total_flops_so_far": 2327532569081856.0,
      "budget_used_percent": 2.327532569081856
    },
    {
      "type": "training",
      "description": "Training step 1627",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:29",
      "total_flops_so_far": 2328963136118784.0,
      "budget_used_percent": 2.328963136118784
    },
    {
      "type": "training",
      "description": "Training step 1628",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:29",
      "total_flops_so_far": 2330393703155712.0,
      "budget_used_percent": 2.330393703155712
    },
    {
      "type": "training",
      "description": "Training step 1629",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:30",
      "total_flops_so_far": 2331824270192640.0,
      "budget_used_percent": 2.33182427019264
    },
    {
      "type": "training",
      "description": "Training step 1630",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:30",
      "total_flops_so_far": 2333254837229568.0,
      "budget_used_percent": 2.333254837229568
    },
    {
      "type": "training",
      "description": "Training step 1631",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:30",
      "total_flops_so_far": 2334685404266496.0,
      "budget_used_percent": 2.3346854042664957
    },
    {
      "type": "training",
      "description": "Training step 1632",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:30",
      "total_flops_so_far": 2336115971303424.0,
      "budget_used_percent": 2.336115971303424
    },
    {
      "type": "training",
      "description": "Training step 1633",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:30",
      "total_flops_so_far": 2337546538340352.0,
      "budget_used_percent": 2.337546538340352
    },
    {
      "type": "training",
      "description": "Training step 1634",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:30",
      "total_flops_so_far": 2338977105377280.0,
      "budget_used_percent": 2.33897710537728
    },
    {
      "type": "training",
      "description": "Training step 1635",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:31",
      "total_flops_so_far": 2340407672414208.0,
      "budget_used_percent": 2.3404076724142078
    },
    {
      "type": "training",
      "description": "Training step 1636",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:31",
      "total_flops_so_far": 2341838239451136.0,
      "budget_used_percent": 2.341838239451136
    },
    {
      "type": "training",
      "description": "Training step 1637",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:31",
      "total_flops_so_far": 2343268806488064.0,
      "budget_used_percent": 2.343268806488064
    },
    {
      "type": "training",
      "description": "Training step 1638",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:31",
      "total_flops_so_far": 2344699373524992.0,
      "budget_used_percent": 2.344699373524992
    },
    {
      "type": "training",
      "description": "Training step 1639",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:31",
      "total_flops_so_far": 2346129940561920.0,
      "budget_used_percent": 2.34612994056192
    },
    {
      "type": "training",
      "description": "Training step 1640",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:31",
      "total_flops_so_far": 2347560507598848.0,
      "budget_used_percent": 2.347560507598848
    },
    {
      "type": "training",
      "description": "Training step 1641",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:32",
      "total_flops_so_far": 2348991074635776.0,
      "budget_used_percent": 2.348991074635776
    },
    {
      "type": "training",
      "description": "Training step 1642",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:32",
      "total_flops_so_far": 2350421641672704.0,
      "budget_used_percent": 2.350421641672704
    },
    {
      "type": "training",
      "description": "Training step 1643",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:32",
      "total_flops_so_far": 2351852208709632.0,
      "budget_used_percent": 2.351852208709632
    },
    {
      "type": "training",
      "description": "Training step 1644",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:32",
      "total_flops_so_far": 2353282775746560.0,
      "budget_used_percent": 2.35328277574656
    },
    {
      "type": "training",
      "description": "Training step 1645",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:32",
      "total_flops_so_far": 2354713342783488.0,
      "budget_used_percent": 2.354713342783488
    },
    {
      "type": "training",
      "description": "Training step 1646",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:32",
      "total_flops_so_far": 2356143909820416.0,
      "budget_used_percent": 2.356143909820416
    },
    {
      "type": "training",
      "description": "Training step 1647",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:33",
      "total_flops_so_far": 2357574476857344.0,
      "budget_used_percent": 2.357574476857344
    },
    {
      "type": "training",
      "description": "Training step 1648",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:33",
      "total_flops_so_far": 2359005043894272.0,
      "budget_used_percent": 2.359005043894272
    },
    {
      "type": "training",
      "description": "Training step 1649",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:33",
      "total_flops_so_far": 2360435610931200.0,
      "budget_used_percent": 2.3604356109312
    },
    {
      "type": "training",
      "description": "Training step 1650",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:33",
      "total_flops_so_far": 2361866177968128.0,
      "budget_used_percent": 2.3618661779681283
    },
    {
      "type": "training",
      "description": "Training step 1651",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:33",
      "total_flops_so_far": 2363296745005056.0,
      "budget_used_percent": 2.363296745005056
    },
    {
      "type": "training",
      "description": "Training step 1652",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:33",
      "total_flops_so_far": 2364727312041984.0,
      "budget_used_percent": 2.364727312041984
    },
    {
      "type": "training",
      "description": "Training step 1653",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:33",
      "total_flops_so_far": 2366157879078912.0,
      "budget_used_percent": 2.366157879078912
    },
    {
      "type": "training",
      "description": "Training step 1654",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:34",
      "total_flops_so_far": 2367588446115840.0,
      "budget_used_percent": 2.3675884461158403
    },
    {
      "type": "training",
      "description": "Training step 1655",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:34",
      "total_flops_so_far": 2369019013152768.0,
      "budget_used_percent": 2.369019013152768
    },
    {
      "type": "training",
      "description": "Training step 1656",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:34",
      "total_flops_so_far": 2370449580189696.0,
      "budget_used_percent": 2.370449580189696
    },
    {
      "type": "training",
      "description": "Training step 1657",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:34",
      "total_flops_so_far": 2371880147226624.0,
      "budget_used_percent": 2.371880147226624
    },
    {
      "type": "training",
      "description": "Training step 1658",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:34",
      "total_flops_so_far": 2373310714263552.0,
      "budget_used_percent": 2.3733107142635523
    },
    {
      "type": "training",
      "description": "Training step 1659",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:34",
      "total_flops_so_far": 2374741281300480.0,
      "budget_used_percent": 2.37474128130048
    },
    {
      "type": "training",
      "description": "Training step 1660",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:35",
      "total_flops_so_far": 2376171848337408.0,
      "budget_used_percent": 2.376171848337408
    },
    {
      "type": "training",
      "description": "Training step 1661",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:35",
      "total_flops_so_far": 2377602415374336.0,
      "budget_used_percent": 2.3776024153743363
    },
    {
      "type": "training",
      "description": "Training step 1662",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:35",
      "total_flops_so_far": 2379032982411264.0,
      "budget_used_percent": 2.3790329824112644
    },
    {
      "type": "training",
      "description": "Training step 1663",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:35",
      "total_flops_so_far": 2380463549448192.0,
      "budget_used_percent": 2.3804635494481916
    },
    {
      "type": "training",
      "description": "Training step 1664",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:35",
      "total_flops_so_far": 2381894116485120.0,
      "budget_used_percent": 2.3818941164851197
    },
    {
      "type": "training",
      "description": "Training step 1665",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:35",
      "total_flops_so_far": 2383324683522048.0,
      "budget_used_percent": 2.383324683522048
    },
    {
      "type": "training",
      "description": "Training step 1666",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:36",
      "total_flops_so_far": 2384755250558976.0,
      "budget_used_percent": 2.384755250558976
    },
    {
      "type": "training",
      "description": "Training step 1667",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:36",
      "total_flops_so_far": 2386185817595904.0,
      "budget_used_percent": 2.386185817595904
    },
    {
      "type": "training",
      "description": "Training step 1668",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:36",
      "total_flops_so_far": 2387616384632832.0,
      "budget_used_percent": 2.3876163846328318
    },
    {
      "type": "training",
      "description": "Training step 1669",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:36",
      "total_flops_so_far": 2389046951669760.0,
      "budget_used_percent": 2.38904695166976
    },
    {
      "type": "training",
      "description": "Training step 1670",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:36",
      "total_flops_so_far": 2390477518706688.0,
      "budget_used_percent": 2.390477518706688
    },
    {
      "type": "training",
      "description": "Training step 1671",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:36",
      "total_flops_so_far": 2391908085743616.0,
      "budget_used_percent": 2.3919080857436157
    },
    {
      "type": "training",
      "description": "Training step 1672",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:36",
      "total_flops_so_far": 2393338652780544.0,
      "budget_used_percent": 2.393338652780544
    },
    {
      "type": "training",
      "description": "Training step 1673",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:37",
      "total_flops_so_far": 2394769219817472.0,
      "budget_used_percent": 2.394769219817472
    },
    {
      "type": "training",
      "description": "Training step 1674",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:37",
      "total_flops_so_far": 2396199786854400.0,
      "budget_used_percent": 2.3961997868544
    },
    {
      "type": "training",
      "description": "Training step 1675",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:37",
      "total_flops_so_far": 2397630353891328.0,
      "budget_used_percent": 2.397630353891328
    },
    {
      "type": "training",
      "description": "Training step 1676",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:37",
      "total_flops_so_far": 2399060920928256.0,
      "budget_used_percent": 2.399060920928256
    },
    {
      "type": "training",
      "description": "Training step 1677",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:37",
      "total_flops_so_far": 2400491487965184.0,
      "budget_used_percent": 2.400491487965184
    },
    {
      "type": "training",
      "description": "Training step 1678",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:37",
      "total_flops_so_far": 2401922055002112.0,
      "budget_used_percent": 2.401922055002112
    },
    {
      "type": "training",
      "description": "Training step 1679",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:38",
      "total_flops_so_far": 2403352622039040.0,
      "budget_used_percent": 2.4033526220390398
    },
    {
      "type": "training",
      "description": "Training step 1680",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:38",
      "total_flops_so_far": 2404783189075968.0,
      "budget_used_percent": 2.404783189075968
    },
    {
      "type": "training",
      "description": "Training step 1681",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:38",
      "total_flops_so_far": 2406213756112896.0,
      "budget_used_percent": 2.406213756112896
    },
    {
      "type": "training",
      "description": "Training step 1682",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:38",
      "total_flops_so_far": 2407644323149824.0,
      "budget_used_percent": 2.407644323149824
    },
    {
      "type": "training",
      "description": "Training step 1683",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:38",
      "total_flops_so_far": 2409074890186752.0,
      "budget_used_percent": 2.4090748901867522
    },
    {
      "type": "training",
      "description": "Training step 1684",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:39",
      "total_flops_so_far": 2410505457223680.0,
      "budget_used_percent": 2.41050545722368
    },
    {
      "type": "training",
      "description": "Training step 1685",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:39",
      "total_flops_so_far": 2411936024260608.0,
      "budget_used_percent": 2.411936024260608
    },
    {
      "type": "training",
      "description": "Training step 1686",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:39",
      "total_flops_so_far": 2413366591297536.0,
      "budget_used_percent": 2.413366591297536
    },
    {
      "type": "training",
      "description": "Training step 1687",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:39",
      "total_flops_so_far": 2414797158334464.0,
      "budget_used_percent": 2.414797158334464
    },
    {
      "type": "training",
      "description": "Training step 1688",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:39",
      "total_flops_so_far": 2416227725371392.0,
      "budget_used_percent": 2.416227725371392
    },
    {
      "type": "training",
      "description": "Training step 1689",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:39",
      "total_flops_so_far": 2417658292408320.0,
      "budget_used_percent": 2.41765829240832
    },
    {
      "type": "training",
      "description": "Training step 1690",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:40",
      "total_flops_so_far": 2419088859445248.0,
      "budget_used_percent": 2.419088859445248
    },
    {
      "type": "training",
      "description": "Training step 1691",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:40",
      "total_flops_so_far": 2420519426482176.0,
      "budget_used_percent": 2.4205194264821763
    },
    {
      "type": "training",
      "description": "Training step 1692",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:40",
      "total_flops_so_far": 2421949993519104.0,
      "budget_used_percent": 2.421949993519104
    },
    {
      "type": "training",
      "description": "Training step 1693",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:40",
      "total_flops_so_far": 2423380560556032.0,
      "budget_used_percent": 2.423380560556032
    },
    {
      "type": "training",
      "description": "Training step 1694",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:40",
      "total_flops_so_far": 2424811127592960.0,
      "budget_used_percent": 2.4248111275929602
    },
    {
      "type": "training",
      "description": "Training step 1695",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:40",
      "total_flops_so_far": 2426241694629888.0,
      "budget_used_percent": 2.426241694629888
    },
    {
      "type": "training",
      "description": "Training step 1696",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:41",
      "total_flops_so_far": 2427672261666816.0,
      "budget_used_percent": 2.427672261666816
    },
    {
      "type": "training",
      "description": "Training step 1697",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:41",
      "total_flops_so_far": 2429102828703744.0,
      "budget_used_percent": 2.429102828703744
    },
    {
      "type": "training",
      "description": "Training step 1698",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:41",
      "total_flops_so_far": 2430533395740672.0,
      "budget_used_percent": 2.430533395740672
    },
    {
      "type": "training",
      "description": "Training step 1699",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:41",
      "total_flops_so_far": 2431963962777600.0,
      "budget_used_percent": 2.4319639627776
    },
    {
      "type": "training",
      "description": "Training step 1700",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:41",
      "total_flops_so_far": 2433394529814528.0,
      "budget_used_percent": 2.4333945298145276
    },
    {
      "type": "training",
      "description": "Training step 1701",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:41",
      "total_flops_so_far": 2434825096851456.0,
      "budget_used_percent": 2.4348250968514558
    },
    {
      "type": "training",
      "description": "Training step 1702",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:42",
      "total_flops_so_far": 2436255663888384.0,
      "budget_used_percent": 2.436255663888384
    },
    {
      "type": "training",
      "description": "Training step 1703",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:42",
      "total_flops_so_far": 2437686230925312.0,
      "budget_used_percent": 2.437686230925312
    },
    {
      "type": "training",
      "description": "Training step 1704",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:42",
      "total_flops_so_far": 2439116797962240.0,
      "budget_used_percent": 2.4391167979622397
    },
    {
      "type": "training",
      "description": "Training step 1705",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:42",
      "total_flops_so_far": 2440547364999168.0,
      "budget_used_percent": 2.440547364999168
    },
    {
      "type": "training",
      "description": "Training step 1706",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:42",
      "total_flops_so_far": 2441977932036096.0,
      "budget_used_percent": 2.441977932036096
    },
    {
      "type": "training",
      "description": "Training step 1707",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:42",
      "total_flops_so_far": 2443408499073024.0,
      "budget_used_percent": 2.443408499073024
    },
    {
      "type": "training",
      "description": "Training step 1708",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:42",
      "total_flops_so_far": 2444839066109952.0,
      "budget_used_percent": 2.4448390661099517
    },
    {
      "type": "training",
      "description": "Training step 1709",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:43",
      "total_flops_so_far": 2446269633146880.0,
      "budget_used_percent": 2.44626963314688
    },
    {
      "type": "training",
      "description": "Training step 1710",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:43",
      "total_flops_so_far": 2447700200183808.0,
      "budget_used_percent": 2.447700200183808
    },
    {
      "type": "training",
      "description": "Training step 1711",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:43",
      "total_flops_so_far": 2449130767220736.0,
      "budget_used_percent": 2.449130767220736
    },
    {
      "type": "training",
      "description": "Training step 1712",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:43",
      "total_flops_so_far": 2450561334257664.0,
      "budget_used_percent": 2.4505613342576638
    },
    {
      "type": "training",
      "description": "Training step 1713",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:43",
      "total_flops_so_far": 2451991901294592.0,
      "budget_used_percent": 2.451991901294592
    },
    {
      "type": "training",
      "description": "Training step 1714",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:43",
      "total_flops_so_far": 2453422468331520.0,
      "budget_used_percent": 2.45342246833152
    },
    {
      "type": "training",
      "description": "Training step 1715",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:44",
      "total_flops_so_far": 2454853035368448.0,
      "budget_used_percent": 2.454853035368448
    },
    {
      "type": "training",
      "description": "Training step 1716",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:44",
      "total_flops_so_far": 2456283602405376.0,
      "budget_used_percent": 2.456283602405376
    },
    {
      "type": "training",
      "description": "Training step 1717",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:44",
      "total_flops_so_far": 2457714169442304.0,
      "budget_used_percent": 2.457714169442304
    },
    {
      "type": "training",
      "description": "Training step 1718",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:44",
      "total_flops_so_far": 2459144736479232.0,
      "budget_used_percent": 2.459144736479232
    },
    {
      "type": "training",
      "description": "Training step 1719",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:44",
      "total_flops_so_far": 2460575303516160.0,
      "budget_used_percent": 2.46057530351616
    },
    {
      "type": "training",
      "description": "Training step 1720",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:44",
      "total_flops_so_far": 2462005870553088.0,
      "budget_used_percent": 2.462005870553088
    },
    {
      "type": "training",
      "description": "Training step 1721",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:45",
      "total_flops_so_far": 2463436437590016.0,
      "budget_used_percent": 2.463436437590016
    },
    {
      "type": "training",
      "description": "Training step 1722",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:45",
      "total_flops_so_far": 2464867004626944.0,
      "budget_used_percent": 2.464867004626944
    },
    {
      "type": "training",
      "description": "Training step 1723",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:45",
      "total_flops_so_far": 2466297571663872.0,
      "budget_used_percent": 2.466297571663872
    },
    {
      "type": "training",
      "description": "Training step 1724",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:45",
      "total_flops_so_far": 2467728138700800.0,
      "budget_used_percent": 2.4677281387008
    },
    {
      "type": "training",
      "description": "Training step 1725",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:45",
      "total_flops_so_far": 2469158705737728.0,
      "budget_used_percent": 2.469158705737728
    },
    {
      "type": "training",
      "description": "Training step 1726",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:45",
      "total_flops_so_far": 2470589272774656.0,
      "budget_used_percent": 2.470589272774656
    },
    {
      "type": "training",
      "description": "Training step 1727",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:46",
      "total_flops_so_far": 2472019839811584.0,
      "budget_used_percent": 2.4720198398115842
    },
    {
      "type": "training",
      "description": "Training step 1728",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:46",
      "total_flops_so_far": 2473450406848512.0,
      "budget_used_percent": 2.473450406848512
    },
    {
      "type": "training",
      "description": "Training step 1729",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:46",
      "total_flops_so_far": 2474880973885440.0,
      "budget_used_percent": 2.47488097388544
    },
    {
      "type": "training",
      "description": "Training step 1730",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:46",
      "total_flops_so_far": 2476311540922368.0,
      "budget_used_percent": 2.476311540922368
    },
    {
      "type": "training",
      "description": "Training step 1731",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:46",
      "total_flops_so_far": 2477742107959296.0,
      "budget_used_percent": 2.4777421079592963
    },
    {
      "type": "training",
      "description": "Training step 1732",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:46",
      "total_flops_so_far": 2479172674996224.0,
      "budget_used_percent": 2.479172674996224
    },
    {
      "type": "training",
      "description": "Training step 1733",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:47",
      "total_flops_so_far": 2480603242033152.0,
      "budget_used_percent": 2.4806032420331516
    },
    {
      "type": "training",
      "description": "Training step 1734",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:47",
      "total_flops_so_far": 2482033809070080.0,
      "budget_used_percent": 2.4820338090700798
    },
    {
      "type": "training",
      "description": "Training step 1735",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:47",
      "total_flops_so_far": 2483464376107008.0,
      "budget_used_percent": 2.483464376107008
    },
    {
      "type": "training",
      "description": "Training step 1736",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:47",
      "total_flops_so_far": 2484894943143936.0,
      "budget_used_percent": 2.484894943143936
    },
    {
      "type": "training",
      "description": "Training step 1737",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:47",
      "total_flops_so_far": 2486325510180864.0,
      "budget_used_percent": 2.4863255101808637
    },
    {
      "type": "training",
      "description": "Training step 1738",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:47",
      "total_flops_so_far": 2487756077217792.0,
      "budget_used_percent": 2.487756077217792
    },
    {
      "type": "training",
      "description": "Training step 1739",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:48",
      "total_flops_so_far": 2489186644254720.0,
      "budget_used_percent": 2.48918664425472
    },
    {
      "type": "training",
      "description": "Training step 1740",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:48",
      "total_flops_so_far": 2490617211291648.0,
      "budget_used_percent": 2.490617211291648
    },
    {
      "type": "training",
      "description": "Training step 1741",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:48",
      "total_flops_so_far": 2492047778328576.0,
      "budget_used_percent": 2.4920477783285757
    },
    {
      "type": "training",
      "description": "Training step 1742",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:48",
      "total_flops_so_far": 2493478345365504.0,
      "budget_used_percent": 2.493478345365504
    },
    {
      "type": "training",
      "description": "Training step 1743",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:48",
      "total_flops_so_far": 2494908912402432.0,
      "budget_used_percent": 2.494908912402432
    },
    {
      "type": "training",
      "description": "Training step 1744",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:48",
      "total_flops_so_far": 2496339479439360.0,
      "budget_used_percent": 2.49633947943936
    },
    {
      "type": "training",
      "description": "Training step 1745",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:48",
      "total_flops_so_far": 2497770046476288.0,
      "budget_used_percent": 2.4977700464762878
    },
    {
      "type": "training",
      "description": "Training step 1746",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:49",
      "total_flops_so_far": 2499200613513216.0,
      "budget_used_percent": 2.499200613513216
    },
    {
      "type": "training",
      "description": "Training step 1747",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:49",
      "total_flops_so_far": 2500631180550144.0,
      "budget_used_percent": 2.500631180550144
    },
    {
      "type": "training",
      "description": "Training step 1748",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:49",
      "total_flops_so_far": 2502061747587072.0,
      "budget_used_percent": 2.502061747587072
    },
    {
      "type": "training",
      "description": "Training step 1749",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:49",
      "total_flops_so_far": 2503492314624000.0,
      "budget_used_percent": 2.503492314624
    },
    {
      "type": "training",
      "description": "Training step 1750",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:49",
      "total_flops_so_far": 2504922881660928.0,
      "budget_used_percent": 2.504922881660928
    },
    {
      "type": "training",
      "description": "Training step 1751",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:49",
      "total_flops_so_far": 2506353448697856.0,
      "budget_used_percent": 2.506353448697856
    },
    {
      "type": "training",
      "description": "Training step 1752",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:50",
      "total_flops_so_far": 2507784015734784.0,
      "budget_used_percent": 2.507784015734784
    },
    {
      "type": "training",
      "description": "Training step 1753",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:50",
      "total_flops_so_far": 2509214582771712.0,
      "budget_used_percent": 2.509214582771712
    },
    {
      "type": "training",
      "description": "Training step 1754",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:50",
      "total_flops_so_far": 2510645149808640.0,
      "budget_used_percent": 2.51064514980864
    },
    {
      "type": "training",
      "description": "Training step 1755",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:50",
      "total_flops_so_far": 2512075716845568.0,
      "budget_used_percent": 2.512075716845568
    },
    {
      "type": "training",
      "description": "Training step 1756",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:50",
      "total_flops_so_far": 2513506283882496.0,
      "budget_used_percent": 2.513506283882496
    },
    {
      "type": "training",
      "description": "Training step 1757",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:50",
      "total_flops_so_far": 2514936850919424.0,
      "budget_used_percent": 2.514936850919424
    },
    {
      "type": "training",
      "description": "Training step 1758",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:51",
      "total_flops_so_far": 2516367417956352.0,
      "budget_used_percent": 2.516367417956352
    },
    {
      "type": "training",
      "description": "Training step 1759",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:51",
      "total_flops_so_far": 2517797984993280.0,
      "budget_used_percent": 2.51779798499328
    },
    {
      "type": "training",
      "description": "Training step 1760",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:51",
      "total_flops_so_far": 2519228552030208.0,
      "budget_used_percent": 2.5192285520302082
    },
    {
      "type": "training",
      "description": "Training step 1761",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:51",
      "total_flops_so_far": 2520659119067136.0,
      "budget_used_percent": 2.520659119067136
    },
    {
      "type": "training",
      "description": "Training step 1762",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:51",
      "total_flops_so_far": 2522089686104064.0,
      "budget_used_percent": 2.522089686104064
    },
    {
      "type": "training",
      "description": "Training step 1763",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:51",
      "total_flops_so_far": 2523520253140992.0,
      "budget_used_percent": 2.523520253140992
    },
    {
      "type": "training",
      "description": "Training step 1764",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:52",
      "total_flops_so_far": 2524950820177920.0,
      "budget_used_percent": 2.5249508201779203
    },
    {
      "type": "training",
      "description": "Training step 1765",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:52",
      "total_flops_so_far": 2526381387214848.0,
      "budget_used_percent": 2.526381387214848
    },
    {
      "type": "training",
      "description": "Training step 1766",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:52",
      "total_flops_so_far": 2527811954251776.0,
      "budget_used_percent": 2.527811954251776
    },
    {
      "type": "training",
      "description": "Training step 1767",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:52",
      "total_flops_so_far": 2529242521288704.0,
      "budget_used_percent": 2.529242521288704
    },
    {
      "type": "training",
      "description": "Training step 1768",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:52",
      "total_flops_so_far": 2530673088325632.0,
      "budget_used_percent": 2.530673088325632
    },
    {
      "type": "training",
      "description": "Training step 1769",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:52",
      "total_flops_so_far": 2532103655362560.0,
      "budget_used_percent": 2.53210365536256
    },
    {
      "type": "training",
      "description": "Training step 1770",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:52",
      "total_flops_so_far": 2533534222399488.0,
      "budget_used_percent": 2.5335342223994877
    },
    {
      "type": "training",
      "description": "Training step 1771",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:53",
      "total_flops_so_far": 2534964789436416.0,
      "budget_used_percent": 2.534964789436416
    },
    {
      "type": "training",
      "description": "Training step 1772",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:53",
      "total_flops_so_far": 2536395356473344.0,
      "budget_used_percent": 2.536395356473344
    },
    {
      "type": "training",
      "description": "Training step 1773",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:53",
      "total_flops_so_far": 2537825923510272.0,
      "budget_used_percent": 2.537825923510272
    },
    {
      "type": "training",
      "description": "Training step 1774",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:53",
      "total_flops_so_far": 2539256490547200.0,
      "budget_used_percent": 2.5392564905471997
    },
    {
      "type": "training",
      "description": "Training step 1775",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:53",
      "total_flops_so_far": 2540687057584128.0,
      "budget_used_percent": 2.540687057584128
    },
    {
      "type": "training",
      "description": "Training step 1776",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:53",
      "total_flops_so_far": 2542117624621056.0,
      "budget_used_percent": 2.542117624621056
    },
    {
      "type": "training",
      "description": "Training step 1777",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:54",
      "total_flops_so_far": 2543548191657984.0,
      "budget_used_percent": 2.543548191657984
    },
    {
      "type": "training",
      "description": "Training step 1778",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:54",
      "total_flops_so_far": 2544978758694912.0,
      "budget_used_percent": 2.5449787586949117
    },
    {
      "type": "training",
      "description": "Training step 1779",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:54",
      "total_flops_so_far": 2546409325731840.0,
      "budget_used_percent": 2.54640932573184
    },
    {
      "type": "training",
      "description": "Training step 1780",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:54",
      "total_flops_so_far": 2547839892768768.0,
      "budget_used_percent": 2.547839892768768
    },
    {
      "type": "training",
      "description": "Training step 1781",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:54",
      "total_flops_so_far": 2549270459805696.0,
      "budget_used_percent": 2.549270459805696
    },
    {
      "type": "training",
      "description": "Training step 1782",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:54",
      "total_flops_so_far": 2550701026842624.0,
      "budget_used_percent": 2.550701026842624
    },
    {
      "type": "training",
      "description": "Training step 1783",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:55",
      "total_flops_so_far": 2552131593879552.0,
      "budget_used_percent": 2.552131593879552
    },
    {
      "type": "training",
      "description": "Training step 1784",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:55",
      "total_flops_so_far": 2553562160916480.0,
      "budget_used_percent": 2.55356216091648
    },
    {
      "type": "training",
      "description": "Training step 1785",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:55",
      "total_flops_so_far": 2554992727953408.0,
      "budget_used_percent": 2.554992727953408
    },
    {
      "type": "training",
      "description": "Training step 1786",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:55",
      "total_flops_so_far": 2556423294990336.0,
      "budget_used_percent": 2.556423294990336
    },
    {
      "type": "training",
      "description": "Training step 1787",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:55",
      "total_flops_so_far": 2557853862027264.0,
      "budget_used_percent": 2.557853862027264
    },
    {
      "type": "training",
      "description": "Training step 1788",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:55",
      "total_flops_so_far": 2559284429064192.0,
      "budget_used_percent": 2.559284429064192
    },
    {
      "type": "training",
      "description": "Training step 1789",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:56",
      "total_flops_so_far": 2560714996101120.0,
      "budget_used_percent": 2.56071499610112
    },
    {
      "type": "training",
      "description": "Training step 1790",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:56",
      "total_flops_so_far": 2562145563138048.0,
      "budget_used_percent": 2.562145563138048
    },
    {
      "type": "training",
      "description": "Training step 1791",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:56",
      "total_flops_so_far": 2563576130174976.0,
      "budget_used_percent": 2.563576130174976
    },
    {
      "type": "training",
      "description": "Training step 1792",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:56",
      "total_flops_so_far": 2565006697211904.0,
      "budget_used_percent": 2.565006697211904
    },
    {
      "type": "training",
      "description": "Training step 1793",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:56",
      "total_flops_so_far": 2566437264248832.0,
      "budget_used_percent": 2.5664372642488322
    },
    {
      "type": "training",
      "description": "Training step 1794",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:56",
      "total_flops_so_far": 2567867831285760.0,
      "budget_used_percent": 2.56786783128576
    },
    {
      "type": "training",
      "description": "Training step 1795",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:57",
      "total_flops_so_far": 2569298398322688.0,
      "budget_used_percent": 2.569298398322688
    },
    {
      "type": "training",
      "description": "Training step 1796",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:57",
      "total_flops_so_far": 2570728965359616.0,
      "budget_used_percent": 2.570728965359616
    },
    {
      "type": "training",
      "description": "Training step 1797",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:57",
      "total_flops_so_far": 2572159532396544.0,
      "budget_used_percent": 2.5721595323965443
    },
    {
      "type": "training",
      "description": "Training step 1798",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:57",
      "total_flops_so_far": 2573590099433472.0,
      "budget_used_percent": 2.573590099433472
    },
    {
      "type": "training",
      "description": "Training step 1799",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:57",
      "total_flops_so_far": 2575020666470400.0,
      "budget_used_percent": 2.5750206664704
    },
    {
      "type": "training",
      "description": "Training step 1800",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:57",
      "total_flops_so_far": 2576451233507328.0,
      "budget_used_percent": 2.576451233507328
    },
    {
      "type": "training",
      "description": "Training step 1801",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:58",
      "total_flops_so_far": 2577881800544256.0,
      "budget_used_percent": 2.5778818005442563
    },
    {
      "type": "training",
      "description": "Training step 1802",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:58",
      "total_flops_so_far": 2579312367581184.0,
      "budget_used_percent": 2.579312367581184
    },
    {
      "type": "training",
      "description": "Training step 1803",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:58",
      "total_flops_so_far": 2580742934618112.0,
      "budget_used_percent": 2.5807429346181117
    },
    {
      "type": "training",
      "description": "Training step 1804",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:58",
      "total_flops_so_far": 2582173501655040.0,
      "budget_used_percent": 2.58217350165504
    },
    {
      "type": "training",
      "description": "Training step 1805",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:58",
      "total_flops_so_far": 2583604068691968.0,
      "budget_used_percent": 2.583604068691968
    },
    {
      "type": "training",
      "description": "Training step 1806",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:58",
      "total_flops_so_far": 2585034635728896.0,
      "budget_used_percent": 2.585034635728896
    },
    {
      "type": "training",
      "description": "Training step 1807",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:59",
      "total_flops_so_far": 2586465202765824.0,
      "budget_used_percent": 2.5864652027658237
    },
    {
      "type": "training",
      "description": "Training step 1808",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:59",
      "total_flops_so_far": 2587895769802752.0,
      "budget_used_percent": 2.587895769802752
    },
    {
      "type": "training",
      "description": "Training step 1809",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:59",
      "total_flops_so_far": 2589326336839680.0,
      "budget_used_percent": 2.58932633683968
    },
    {
      "type": "training",
      "description": "Training step 1810",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:59",
      "total_flops_so_far": 2590756903876608.0,
      "budget_used_percent": 2.590756903876608
    },
    {
      "type": "training",
      "description": "Training step 1811",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:59",
      "total_flops_so_far": 2592187470913536.0,
      "budget_used_percent": 2.5921874709135357
    },
    {
      "type": "training",
      "description": "Training step 1812",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:59",
      "total_flops_so_far": 2593618037950464.0,
      "budget_used_percent": 2.593618037950464
    },
    {
      "type": "training",
      "description": "Training step 1813",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:41:59",
      "total_flops_so_far": 2595048604987392.0,
      "budget_used_percent": 2.595048604987392
    },
    {
      "type": "training",
      "description": "Training step 1814",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:00",
      "total_flops_so_far": 2596479172024320.0,
      "budget_used_percent": 2.59647917202432
    },
    {
      "type": "training",
      "description": "Training step 1815",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:00",
      "total_flops_so_far": 2597909739061248.0,
      "budget_used_percent": 2.597909739061248
    },
    {
      "type": "training",
      "description": "Training step 1816",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:00",
      "total_flops_so_far": 2599340306098176.0,
      "budget_used_percent": 2.599340306098176
    },
    {
      "type": "training",
      "description": "Training step 1817",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:00",
      "total_flops_so_far": 2600770873135104.0,
      "budget_used_percent": 2.600770873135104
    },
    {
      "type": "training",
      "description": "Training step 1818",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:00",
      "total_flops_so_far": 2602201440172032.0,
      "budget_used_percent": 2.602201440172032
    },
    {
      "type": "training",
      "description": "Training step 1819",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:00",
      "total_flops_so_far": 2603632007208960.0,
      "budget_used_percent": 2.60363200720896
    },
    {
      "type": "training",
      "description": "Training step 1820",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:01",
      "total_flops_so_far": 2605062574245888.0,
      "budget_used_percent": 2.605062574245888
    },
    {
      "type": "training",
      "description": "Training step 1821",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:01",
      "total_flops_so_far": 2606493141282816.0,
      "budget_used_percent": 2.606493141282816
    },
    {
      "type": "training",
      "description": "Training step 1822",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:01",
      "total_flops_so_far": 2607923708319744.0,
      "budget_used_percent": 2.607923708319744
    },
    {
      "type": "training",
      "description": "Training step 1823",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:01",
      "total_flops_so_far": 2609354275356672.0,
      "budget_used_percent": 2.609354275356672
    },
    {
      "type": "training",
      "description": "Training step 1824",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:01",
      "total_flops_so_far": 2610784842393600.0,
      "budget_used_percent": 2.6107848423936
    },
    {
      "type": "training",
      "description": "Training step 1825",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:01",
      "total_flops_so_far": 2612215409430528.0,
      "budget_used_percent": 2.612215409430528
    },
    {
      "type": "training",
      "description": "Training step 1826",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:02",
      "total_flops_so_far": 2613645976467456.0,
      "budget_used_percent": 2.6136459764674562
    },
    {
      "type": "training",
      "description": "Training step 1827",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:02",
      "total_flops_so_far": 2615076543504384.0,
      "budget_used_percent": 2.615076543504384
    },
    {
      "type": "training",
      "description": "Training step 1828",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:02",
      "total_flops_so_far": 2616507110541312.0,
      "budget_used_percent": 2.616507110541312
    },
    {
      "type": "training",
      "description": "Training step 1829",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:02",
      "total_flops_so_far": 2617937677578240.0,
      "budget_used_percent": 2.61793767757824
    },
    {
      "type": "training",
      "description": "Training step 1830",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:02",
      "total_flops_so_far": 2619368244615168.0,
      "budget_used_percent": 2.6193682446151683
    },
    {
      "type": "training",
      "description": "Training step 1831",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:02",
      "total_flops_so_far": 2620798811652096.0,
      "budget_used_percent": 2.620798811652096
    },
    {
      "type": "training",
      "description": "Training step 1832",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:03",
      "total_flops_so_far": 2622229378689024.0,
      "budget_used_percent": 2.622229378689024
    },
    {
      "type": "training",
      "description": "Training step 1833",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:03",
      "total_flops_so_far": 2623659945725952.0,
      "budget_used_percent": 2.623659945725952
    },
    {
      "type": "training",
      "description": "Training step 1834",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:03",
      "total_flops_so_far": 2625090512762880.0,
      "budget_used_percent": 2.6250905127628803
    },
    {
      "type": "training",
      "description": "Training step 1835",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:03",
      "total_flops_so_far": 2626521079799808.0,
      "budget_used_percent": 2.626521079799808
    },
    {
      "type": "training",
      "description": "Training step 1836",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:03",
      "total_flops_so_far": 2627951646836736.0,
      "budget_used_percent": 2.627951646836736
    },
    {
      "type": "training",
      "description": "Training step 1837",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:03",
      "total_flops_so_far": 2629382213873664.0,
      "budget_used_percent": 2.629382213873664
    },
    {
      "type": "training",
      "description": "Training step 1838",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:04",
      "total_flops_so_far": 2630812780910592.0,
      "budget_used_percent": 2.630812780910592
    },
    {
      "type": "training",
      "description": "Training step 1839",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:04",
      "total_flops_so_far": 2632243347947520.0,
      "budget_used_percent": 2.63224334794752
    },
    {
      "type": "training",
      "description": "Training step 1840",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:04",
      "total_flops_so_far": 2633673914984448.0,
      "budget_used_percent": 2.6336739149844477
    },
    {
      "type": "training",
      "description": "Training step 1841",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:04",
      "total_flops_so_far": 2635104482021376.0,
      "budget_used_percent": 2.635104482021376
    },
    {
      "type": "training",
      "description": "Training step 1842",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:04",
      "total_flops_so_far": 2636535049058304.0,
      "budget_used_percent": 2.636535049058304
    },
    {
      "type": "training",
      "description": "Training step 1843",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:04",
      "total_flops_so_far": 2637965616095232.0,
      "budget_used_percent": 2.637965616095232
    },
    {
      "type": "training",
      "description": "Training step 1844",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:05",
      "total_flops_so_far": 2639396183132160.0,
      "budget_used_percent": 2.6393961831321597
    },
    {
      "type": "training",
      "description": "Training step 1845",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:05",
      "total_flops_so_far": 2640826750169088.0,
      "budget_used_percent": 2.640826750169088
    },
    {
      "type": "training",
      "description": "Training step 1846",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:05",
      "total_flops_so_far": 2642257317206016.0,
      "budget_used_percent": 2.642257317206016
    },
    {
      "type": "training",
      "description": "Training step 1847",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:05",
      "total_flops_so_far": 2643687884242944.0,
      "budget_used_percent": 2.643687884242944
    },
    {
      "type": "training",
      "description": "Training step 1848",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:05",
      "total_flops_so_far": 2645118451279872.0,
      "budget_used_percent": 2.6451184512798718
    },
    {
      "type": "training",
      "description": "Training step 1849",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:05",
      "total_flops_so_far": 2646549018316800.0,
      "budget_used_percent": 2.6465490183168
    },
    {
      "type": "training",
      "description": "Training step 1850",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:05",
      "total_flops_so_far": 2647979585353728.0,
      "budget_used_percent": 2.647979585353728
    },
    {
      "type": "training",
      "description": "Training step 1851",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:06",
      "total_flops_so_far": 2649410152390656.0,
      "budget_used_percent": 2.649410152390656
    },
    {
      "type": "training",
      "description": "Training step 1852",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:06",
      "total_flops_so_far": 2650840719427584.0,
      "budget_used_percent": 2.650840719427584
    },
    {
      "type": "training",
      "description": "Training step 1853",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:06",
      "total_flops_so_far": 2652271286464512.0,
      "budget_used_percent": 2.652271286464512
    },
    {
      "type": "training",
      "description": "Training step 1854",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:06",
      "total_flops_so_far": 2653701853501440.0,
      "budget_used_percent": 2.65370185350144
    },
    {
      "type": "training",
      "description": "Training step 1855",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:06",
      "total_flops_so_far": 2655132420538368.0,
      "budget_used_percent": 2.655132420538368
    },
    {
      "type": "training",
      "description": "Training step 1856",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:06",
      "total_flops_so_far": 2656562987575296.0,
      "budget_used_percent": 2.656562987575296
    },
    {
      "type": "training",
      "description": "Training step 1857",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:07",
      "total_flops_so_far": 2657993554612224.0,
      "budget_used_percent": 2.657993554612224
    },
    {
      "type": "training",
      "description": "Training step 1858",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:07",
      "total_flops_so_far": 2659424121649152.0,
      "budget_used_percent": 2.659424121649152
    },
    {
      "type": "training",
      "description": "Training step 1859",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:07",
      "total_flops_so_far": 2660854688686080.0,
      "budget_used_percent": 2.66085468868608
    },
    {
      "type": "training",
      "description": "Training step 1860",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:07",
      "total_flops_so_far": 2662285255723008.0,
      "budget_used_percent": 2.662285255723008
    },
    {
      "type": "training",
      "description": "Training step 1861",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:07",
      "total_flops_so_far": 2663715822759936.0,
      "budget_used_percent": 2.663715822759936
    },
    {
      "type": "training",
      "description": "Training step 1862",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:07",
      "total_flops_so_far": 2665146389796864.0,
      "budget_used_percent": 2.665146389796864
    },
    {
      "type": "training",
      "description": "Training step 1863",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:08",
      "total_flops_so_far": 2666576956833792.0,
      "budget_used_percent": 2.6665769568337923
    },
    {
      "type": "training",
      "description": "Training step 1864",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:08",
      "total_flops_so_far": 2668007523870720.0,
      "budget_used_percent": 2.66800752387072
    },
    {
      "type": "training",
      "description": "Training step 1865",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:08",
      "total_flops_so_far": 2669438090907648.0,
      "budget_used_percent": 2.669438090907648
    },
    {
      "type": "training",
      "description": "Training step 1866",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:08",
      "total_flops_so_far": 2670868657944576.0,
      "budget_used_percent": 2.670868657944576
    },
    {
      "type": "training",
      "description": "Training step 1867",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:08",
      "total_flops_so_far": 2672299224981504.0,
      "budget_used_percent": 2.6722992249815043
    },
    {
      "type": "training",
      "description": "Training step 1868",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:08",
      "total_flops_so_far": 2673729792018432.0,
      "budget_used_percent": 2.673729792018432
    },
    {
      "type": "training",
      "description": "Training step 1869",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:09",
      "total_flops_so_far": 2675160359055360.0,
      "budget_used_percent": 2.67516035905536
    },
    {
      "type": "training",
      "description": "Training step 1870",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:09",
      "total_flops_so_far": 2676590926092288.0,
      "budget_used_percent": 2.676590926092288
    },
    {
      "type": "training",
      "description": "Training step 1871",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:09",
      "total_flops_so_far": 2678021493129216.0,
      "budget_used_percent": 2.6780214931292163
    },
    {
      "type": "training",
      "description": "Training step 1872",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:09",
      "total_flops_so_far": 2679452060166144.0,
      "budget_used_percent": 2.679452060166144
    },
    {
      "type": "training",
      "description": "Training step 1873",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:09",
      "total_flops_so_far": 2680882627203072.0,
      "budget_used_percent": 2.6808826272030717
    },
    {
      "type": "training",
      "description": "Training step 1874",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:09",
      "total_flops_so_far": 2682313194240000.0,
      "budget_used_percent": 2.68231319424
    },
    {
      "type": "training",
      "description": "Training step 1875",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:10",
      "total_flops_so_far": 2683743761276928.0,
      "budget_used_percent": 2.683743761276928
    },
    {
      "type": "training",
      "description": "Training step 1876",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:10",
      "total_flops_so_far": 2685174328313856.0,
      "budget_used_percent": 2.685174328313856
    },
    {
      "type": "training",
      "description": "Training step 1877",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:10",
      "total_flops_so_far": 2686604895350784.0,
      "budget_used_percent": 2.6866048953507837
    },
    {
      "type": "training",
      "description": "Training step 1878",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:10",
      "total_flops_so_far": 2688035462387712.0,
      "budget_used_percent": 2.688035462387712
    },
    {
      "type": "training",
      "description": "Training step 1879",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:10",
      "total_flops_so_far": 2689466029424640.0,
      "budget_used_percent": 2.68946602942464
    },
    {
      "type": "training",
      "description": "Training step 1880",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:10",
      "total_flops_so_far": 2690896596461568.0,
      "budget_used_percent": 2.690896596461568
    },
    {
      "type": "training",
      "description": "Training step 1881",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:11",
      "total_flops_so_far": 2692327163498496.0,
      "budget_used_percent": 2.6923271634984958
    },
    {
      "type": "training",
      "description": "Training step 1882",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:11",
      "total_flops_so_far": 2693757730535424.0,
      "budget_used_percent": 2.693757730535424
    },
    {
      "type": "training",
      "description": "Training step 1883",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:11",
      "total_flops_so_far": 2695188297572352.0,
      "budget_used_percent": 2.695188297572352
    },
    {
      "type": "training",
      "description": "Training step 1884",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:11",
      "total_flops_so_far": 2696618864609280.0,
      "budget_used_percent": 2.69661886460928
    },
    {
      "type": "training",
      "description": "Training step 1885",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:11",
      "total_flops_so_far": 2698049431646208.0,
      "budget_used_percent": 2.698049431646208
    },
    {
      "type": "training",
      "description": "Training step 1886",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:11",
      "total_flops_so_far": 2699479998683136.0,
      "budget_used_percent": 2.699479998683136
    },
    {
      "type": "training",
      "description": "Training step 1887",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:12",
      "total_flops_so_far": 2700910565720064.0,
      "budget_used_percent": 2.700910565720064
    },
    {
      "type": "training",
      "description": "Training step 1888",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:12",
      "total_flops_so_far": 2702341132756992.0,
      "budget_used_percent": 2.702341132756992
    },
    {
      "type": "training",
      "description": "Training step 1889",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:12",
      "total_flops_so_far": 2703771699793920.0,
      "budget_used_percent": 2.70377169979392
    },
    {
      "type": "training",
      "description": "Training step 1890",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:12",
      "total_flops_so_far": 2705202266830848.0,
      "budget_used_percent": 2.705202266830848
    },
    {
      "type": "training",
      "description": "Training step 1891",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:12",
      "total_flops_so_far": 2706632833867776.0,
      "budget_used_percent": 2.706632833867776
    },
    {
      "type": "training",
      "description": "Training step 1892",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:12",
      "total_flops_so_far": 2708063400904704.0,
      "budget_used_percent": 2.708063400904704
    },
    {
      "type": "training",
      "description": "Training step 1893",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:13",
      "total_flops_so_far": 2709493967941632.0,
      "budget_used_percent": 2.709493967941632
    },
    {
      "type": "training",
      "description": "Training step 1894",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:13",
      "total_flops_so_far": 2710924534978560.0,
      "budget_used_percent": 2.71092453497856
    },
    {
      "type": "training",
      "description": "Training step 1895",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:13",
      "total_flops_so_far": 2712355102015488.0,
      "budget_used_percent": 2.712355102015488
    },
    {
      "type": "training",
      "description": "Training step 1896",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:13",
      "total_flops_so_far": 2713785669052416.0,
      "budget_used_percent": 2.7137856690524162
    },
    {
      "type": "training",
      "description": "Training step 1897",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:13",
      "total_flops_so_far": 2715216236089344.0,
      "budget_used_percent": 2.715216236089344
    },
    {
      "type": "training",
      "description": "Training step 1898",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:13",
      "total_flops_so_far": 2716646803126272.0,
      "budget_used_percent": 2.716646803126272
    },
    {
      "type": "training",
      "description": "Training step 1899",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:14",
      "total_flops_so_far": 2718077370163200.0,
      "budget_used_percent": 2.7180773701632
    },
    {
      "type": "training",
      "description": "Training step 1900",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:14",
      "total_flops_so_far": 2719507937200128.0,
      "budget_used_percent": 2.7195079372001283
    },
    {
      "type": "training",
      "description": "Training step 1901",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:14",
      "total_flops_so_far": 2720938504237056.0,
      "budget_used_percent": 2.720938504237056
    },
    {
      "type": "training",
      "description": "Training step 1902",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:14",
      "total_flops_so_far": 2722369071273984.0,
      "budget_used_percent": 2.722369071273984
    },
    {
      "type": "training",
      "description": "Training step 1903",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:14",
      "total_flops_so_far": 2723799638310912.0,
      "budget_used_percent": 2.723799638310912
    },
    {
      "type": "training",
      "description": "Training step 1904",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:14",
      "total_flops_so_far": 2725230205347840.0,
      "budget_used_percent": 2.7252302053478403
    },
    {
      "type": "training",
      "description": "Training step 1905",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:14",
      "total_flops_so_far": 2726660772384768.0,
      "budget_used_percent": 2.726660772384768
    },
    {
      "type": "training",
      "description": "Training step 1906",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:15",
      "total_flops_so_far": 2728091339421696.0,
      "budget_used_percent": 2.728091339421696
    },
    {
      "type": "training",
      "description": "Training step 1907",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:15",
      "total_flops_so_far": 2729521906458624.0,
      "budget_used_percent": 2.7295219064586242
    },
    {
      "type": "training",
      "description": "Training step 1908",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:15",
      "total_flops_so_far": 2730952473495552.0,
      "budget_used_percent": 2.730952473495552
    },
    {
      "type": "training",
      "description": "Training step 1909",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:15",
      "total_flops_so_far": 2732383040532480.0,
      "budget_used_percent": 2.73238304053248
    },
    {
      "type": "training",
      "description": "Training step 1910",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:15",
      "total_flops_so_far": 2733813607569408.0,
      "budget_used_percent": 2.7338136075694077
    },
    {
      "type": "training",
      "description": "Training step 1911",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:15",
      "total_flops_so_far": 2735244174606336.0,
      "budget_used_percent": 2.735244174606336
    },
    {
      "type": "training",
      "description": "Training step 1912",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:16",
      "total_flops_so_far": 2736674741643264.0,
      "budget_used_percent": 2.736674741643264
    },
    {
      "type": "training",
      "description": "Training step 1913",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:16",
      "total_flops_so_far": 2738105308680192.0,
      "budget_used_percent": 2.738105308680192
    },
    {
      "type": "training",
      "description": "Training step 1914",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:16",
      "total_flops_so_far": 2739535875717120.0,
      "budget_used_percent": 2.7395358757171198
    },
    {
      "type": "training",
      "description": "Training step 1915",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:16",
      "total_flops_so_far": 2740966442754048.0,
      "budget_used_percent": 2.740966442754048
    },
    {
      "type": "training",
      "description": "Training step 1916",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:16",
      "total_flops_so_far": 2742397009790976.0,
      "budget_used_percent": 2.742397009790976
    },
    {
      "type": "training",
      "description": "Training step 1917",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:16",
      "total_flops_so_far": 2743827576827904.0,
      "budget_used_percent": 2.743827576827904
    },
    {
      "type": "training",
      "description": "Training step 1918",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:17",
      "total_flops_so_far": 2745258143864832.0,
      "budget_used_percent": 2.745258143864832
    },
    {
      "type": "training",
      "description": "Training step 1919",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:17",
      "total_flops_so_far": 2746688710901760.0,
      "budget_used_percent": 2.74668871090176
    },
    {
      "type": "training",
      "description": "Training step 1920",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:17",
      "total_flops_so_far": 2748119277938688.0,
      "budget_used_percent": 2.748119277938688
    },
    {
      "type": "training",
      "description": "Training step 1921",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:17",
      "total_flops_so_far": 2749549844975616.0,
      "budget_used_percent": 2.749549844975616
    },
    {
      "type": "training",
      "description": "Training step 1922",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:17",
      "total_flops_so_far": 2750980412012544.0,
      "budget_used_percent": 2.750980412012544
    },
    {
      "type": "training",
      "description": "Training step 1923",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:17",
      "total_flops_so_far": 2752410979049472.0,
      "budget_used_percent": 2.752410979049472
    },
    {
      "type": "training",
      "description": "Training step 1924",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:18",
      "total_flops_so_far": 2753841546086400.0,
      "budget_used_percent": 2.7538415460864
    },
    {
      "type": "training",
      "description": "Training step 1925",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:18",
      "total_flops_so_far": 2755272113123328.0,
      "budget_used_percent": 2.755272113123328
    },
    {
      "type": "training",
      "description": "Training step 1926",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:18",
      "total_flops_so_far": 2756702680160256.0,
      "budget_used_percent": 2.756702680160256
    },
    {
      "type": "training",
      "description": "Training step 1927",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:18",
      "total_flops_so_far": 2758133247197184.0,
      "budget_used_percent": 2.758133247197184
    },
    {
      "type": "training",
      "description": "Training step 1928",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:18",
      "total_flops_so_far": 2759563814234112.0,
      "budget_used_percent": 2.759563814234112
    },
    {
      "type": "training",
      "description": "Training step 1929",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:18",
      "total_flops_so_far": 2760994381271040.0,
      "budget_used_percent": 2.7609943812710402
    },
    {
      "type": "training",
      "description": "Training step 1930",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:19",
      "total_flops_so_far": 2762424948307968.0,
      "budget_used_percent": 2.762424948307968
    },
    {
      "type": "training",
      "description": "Training step 1931",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:19",
      "total_flops_so_far": 2763855515344896.0,
      "budget_used_percent": 2.763855515344896
    },
    {
      "type": "training",
      "description": "Training step 1932",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:19",
      "total_flops_so_far": 2765286082381824.0,
      "budget_used_percent": 2.765286082381824
    },
    {
      "type": "training",
      "description": "Training step 1933",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:19",
      "total_flops_so_far": 2766716649418752.0,
      "budget_used_percent": 2.7667166494187523
    },
    {
      "type": "training",
      "description": "Training step 1934",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:19",
      "total_flops_so_far": 2768147216455680.0,
      "budget_used_percent": 2.76814721645568
    },
    {
      "type": "training",
      "description": "Training step 1935",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:19",
      "total_flops_so_far": 2769577783492608.0,
      "budget_used_percent": 2.769577783492608
    },
    {
      "type": "training",
      "description": "Training step 1936",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:20",
      "total_flops_so_far": 2771008350529536.0,
      "budget_used_percent": 2.771008350529536
    },
    {
      "type": "training",
      "description": "Training step 1937",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:20",
      "total_flops_so_far": 2772438917566464.0,
      "budget_used_percent": 2.7724389175664643
    },
    {
      "type": "training",
      "description": "Training step 1938",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:20",
      "total_flops_so_far": 2773869484603392.0,
      "budget_used_percent": 2.773869484603392
    },
    {
      "type": "training",
      "description": "Training step 1939",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:20",
      "total_flops_so_far": 2775300051640320.0,
      "budget_used_percent": 2.77530005164032
    },
    {
      "type": "training",
      "description": "Training step 1940",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:21",
      "total_flops_so_far": 2776730618677248.0,
      "budget_used_percent": 2.7767306186772482
    },
    {
      "type": "training",
      "description": "Training step 1941",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:21",
      "total_flops_so_far": 2778161185714176.0,
      "budget_used_percent": 2.7781611857141764
    },
    {
      "type": "training",
      "description": "Training step 1942",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:21",
      "total_flops_so_far": 2779591752751104.0,
      "budget_used_percent": 2.779591752751104
    },
    {
      "type": "training",
      "description": "Training step 1943",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:21",
      "total_flops_so_far": 2781022319788032.0,
      "budget_used_percent": 2.7810223197880317
    },
    {
      "type": "training",
      "description": "Training step 1944",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:21",
      "total_flops_so_far": 2782452886824960.0,
      "budget_used_percent": 2.78245288682496
    },
    {
      "type": "training",
      "description": "Training step 1945",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:21",
      "total_flops_so_far": 2783883453861888.0,
      "budget_used_percent": 2.783883453861888
    },
    {
      "type": "training",
      "description": "Training step 1946",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:22",
      "total_flops_so_far": 2785314020898816.0,
      "budget_used_percent": 2.7853140208988156
    },
    {
      "type": "training",
      "description": "Training step 1947",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:22",
      "total_flops_so_far": 2786744587935744.0,
      "budget_used_percent": 2.7867445879357438
    },
    {
      "type": "training",
      "description": "Training step 1948",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:22",
      "total_flops_so_far": 2788175154972672.0,
      "budget_used_percent": 2.788175154972672
    },
    {
      "type": "training",
      "description": "Training step 1949",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:22",
      "total_flops_so_far": 2789605722009600.0,
      "budget_used_percent": 2.7896057220096
    },
    {
      "type": "training",
      "description": "Training step 1950",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:22",
      "total_flops_so_far": 2791036289046528.0,
      "budget_used_percent": 2.791036289046528
    },
    {
      "type": "training",
      "description": "Training step 1951",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:23",
      "total_flops_so_far": 2792466856083456.0,
      "budget_used_percent": 2.792466856083456
    },
    {
      "type": "training",
      "description": "Training step 1952",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:23",
      "total_flops_so_far": 2793897423120384.0,
      "budget_used_percent": 2.793897423120384
    },
    {
      "type": "training",
      "description": "Training step 1953",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:23",
      "total_flops_so_far": 2795327990157312.0,
      "budget_used_percent": 2.795327990157312
    },
    {
      "type": "training",
      "description": "Training step 1954",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:23",
      "total_flops_so_far": 2796758557194240.0,
      "budget_used_percent": 2.7967585571942397
    },
    {
      "type": "training",
      "description": "Training step 1955",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:23",
      "total_flops_so_far": 2798189124231168.0,
      "budget_used_percent": 2.798189124231168
    },
    {
      "type": "training",
      "description": "Training step 1956",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:23",
      "total_flops_so_far": 2799619691268096.0,
      "budget_used_percent": 2.799619691268096
    },
    {
      "type": "training",
      "description": "Training step 1957",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:23",
      "total_flops_so_far": 2801050258305024.0,
      "budget_used_percent": 2.801050258305024
    },
    {
      "type": "training",
      "description": "Training step 1958",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:24",
      "total_flops_so_far": 2802480825341952.0,
      "budget_used_percent": 2.802480825341952
    },
    {
      "type": "training",
      "description": "Training step 1959",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:24",
      "total_flops_so_far": 2803911392378880.0,
      "budget_used_percent": 2.80391139237888
    },
    {
      "type": "training",
      "description": "Training step 1960",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:24",
      "total_flops_so_far": 2805341959415808.0,
      "budget_used_percent": 2.805341959415808
    },
    {
      "type": "training",
      "description": "Training step 1961",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:24",
      "total_flops_so_far": 2806772526452736.0,
      "budget_used_percent": 2.806772526452736
    },
    {
      "type": "training",
      "description": "Training step 1962",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:24",
      "total_flops_so_far": 2808203093489664.0,
      "budget_used_percent": 2.808203093489664
    },
    {
      "type": "training",
      "description": "Training step 1963",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:24",
      "total_flops_so_far": 2809633660526592.0,
      "budget_used_percent": 2.809633660526592
    },
    {
      "type": "training",
      "description": "Training step 1964",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:25",
      "total_flops_so_far": 2811064227563520.0,
      "budget_used_percent": 2.81106422756352
    },
    {
      "type": "training",
      "description": "Training step 1965",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:25",
      "total_flops_so_far": 2812494794600448.0,
      "budget_used_percent": 2.812494794600448
    },
    {
      "type": "training",
      "description": "Training step 1966",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:25",
      "total_flops_so_far": 2813925361637376.0,
      "budget_used_percent": 2.8139253616373763
    },
    {
      "type": "training",
      "description": "Training step 1967",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:25",
      "total_flops_so_far": 2815355928674304.0,
      "budget_used_percent": 2.815355928674304
    },
    {
      "type": "training",
      "description": "Training step 1968",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:25",
      "total_flops_so_far": 2816786495711232.0,
      "budget_used_percent": 2.816786495711232
    },
    {
      "type": "training",
      "description": "Training step 1969",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:25",
      "total_flops_so_far": 2818217062748160.0,
      "budget_used_percent": 2.81821706274816
    },
    {
      "type": "training",
      "description": "Training step 1970",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:26",
      "total_flops_so_far": 2819647629785088.0,
      "budget_used_percent": 2.819647629785088
    },
    {
      "type": "training",
      "description": "Training step 1971",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:26",
      "total_flops_so_far": 2821078196822016.0,
      "budget_used_percent": 2.821078196822016
    },
    {
      "type": "training",
      "description": "Training step 1972",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:26",
      "total_flops_so_far": 2822508763858944.0,
      "budget_used_percent": 2.822508763858944
    },
    {
      "type": "training",
      "description": "Training step 1973",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:26",
      "total_flops_so_far": 2823939330895872.0,
      "budget_used_percent": 2.8239393308958722
    },
    {
      "type": "training",
      "description": "Training step 1974",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:26",
      "total_flops_so_far": 2825369897932800.0,
      "budget_used_percent": 2.8253698979328004
    },
    {
      "type": "training",
      "description": "Training step 1975",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:26",
      "total_flops_so_far": 2826800464969728.0,
      "budget_used_percent": 2.826800464969728
    },
    {
      "type": "training",
      "description": "Training step 1976",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:27",
      "total_flops_so_far": 2828231032006656.0,
      "budget_used_percent": 2.828231032006656
    },
    {
      "type": "training",
      "description": "Training step 1977",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:27",
      "total_flops_so_far": 2829661599043584.0,
      "budget_used_percent": 2.8296615990435843
    },
    {
      "type": "training",
      "description": "Training step 1978",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:27",
      "total_flops_so_far": 2831092166080512.0,
      "budget_used_percent": 2.831092166080512
    },
    {
      "type": "training",
      "description": "Training step 1979",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:27",
      "total_flops_so_far": 2832522733117440.0,
      "budget_used_percent": 2.8325227331174396
    },
    {
      "type": "training",
      "description": "Training step 1980",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:27",
      "total_flops_so_far": 2833953300154368.0,
      "budget_used_percent": 2.8339533001543677
    },
    {
      "type": "training",
      "description": "Training step 1981",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:27",
      "total_flops_so_far": 2835383867191296.0,
      "budget_used_percent": 2.835383867191296
    },
    {
      "type": "training",
      "description": "Training step 1982",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:28",
      "total_flops_so_far": 2836814434228224.0,
      "budget_used_percent": 2.836814434228224
    },
    {
      "type": "training",
      "description": "Training step 1983",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:28",
      "total_flops_so_far": 2838245001265152.0,
      "budget_used_percent": 2.8382450012651517
    },
    {
      "type": "training",
      "description": "Training step 1984",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:28",
      "total_flops_so_far": 2839675568302080.0,
      "budget_used_percent": 2.83967556830208
    },
    {
      "type": "training",
      "description": "Training step 1985",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:28",
      "total_flops_so_far": 2841106135339008.0,
      "budget_used_percent": 2.841106135339008
    },
    {
      "type": "training",
      "description": "Training step 1986",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:28",
      "total_flops_so_far": 2842536702375936.0,
      "budget_used_percent": 2.842536702375936
    },
    {
      "type": "training",
      "description": "Training step 1987",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:28",
      "total_flops_so_far": 2843967269412864.0,
      "budget_used_percent": 2.8439672694128637
    },
    {
      "type": "training",
      "description": "Training step 1988",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:29",
      "total_flops_so_far": 2845397836449792.0,
      "budget_used_percent": 2.845397836449792
    },
    {
      "type": "training",
      "description": "Training step 1989",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:29",
      "total_flops_so_far": 2846828403486720.0,
      "budget_used_percent": 2.84682840348672
    },
    {
      "type": "training",
      "description": "Training step 1990",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:29",
      "total_flops_so_far": 2848258970523648.0,
      "budget_used_percent": 2.848258970523648
    },
    {
      "type": "training",
      "description": "Training step 1991",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:29",
      "total_flops_so_far": 2849689537560576.0,
      "budget_used_percent": 2.8496895375605757
    },
    {
      "type": "training",
      "description": "Training step 1992",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:29",
      "total_flops_so_far": 2851120104597504.0,
      "budget_used_percent": 2.851120104597504
    },
    {
      "type": "training",
      "description": "Training step 1993",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:29",
      "total_flops_so_far": 2852550671634432.0,
      "budget_used_percent": 2.852550671634432
    },
    {
      "type": "training",
      "description": "Training step 1994",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:30",
      "total_flops_so_far": 2853981238671360.0,
      "budget_used_percent": 2.85398123867136
    },
    {
      "type": "training",
      "description": "Training step 1995",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:30",
      "total_flops_so_far": 2855411805708288.0,
      "budget_used_percent": 2.855411805708288
    },
    {
      "type": "training",
      "description": "Training step 1996",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:30",
      "total_flops_so_far": 2856842372745216.0,
      "budget_used_percent": 2.856842372745216
    },
    {
      "type": "training",
      "description": "Training step 1997",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:30",
      "total_flops_so_far": 2858272939782144.0,
      "budget_used_percent": 2.858272939782144
    },
    {
      "type": "training",
      "description": "Training step 1998",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:30",
      "total_flops_so_far": 2859703506819072.0,
      "budget_used_percent": 2.859703506819072
    },
    {
      "type": "training",
      "description": "Training step 1999",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 476855678976.0,
      "backward_flops": 953711357952.0,
      "flops": 1430567036928.0,
      "lora_r": 2,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:42:30",
      "total_flops_so_far": 2861134073856000.0,
      "budget_used_percent": 2.861134073856
    }
  ],
  "total_flops": 2861134073856000.0,
  "budget_used_percent": 2.861134073856
}