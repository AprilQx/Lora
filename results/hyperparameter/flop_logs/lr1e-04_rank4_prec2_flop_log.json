{
  "experiment_name": "lr1e-04_rank4_prec2",
  "model_config": {
    "hidden_size": 896,
    "num_attention_heads": 14,
    "num_hidden_layers": 24,
    "intermediate_size": 4864,
    "head_dim": 64,
    "vocab_size": 151936,
    "lora_r": 4,
    "lora_target_modules": [
      "q_proj",
      "v_proj"
    ]
  },
  "max_budget": 1e+17,
  "start_time": "2025-03-31 15:47:18",
  "operations": [
    {
      "type": "training",
      "description": "Training step 0",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:22",
      "total_flops_so_far": 1431095371776.0,
      "budget_used_percent": 0.001431095371776
    },
    {
      "type": "training",
      "description": "Training step 1",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:22",
      "total_flops_so_far": 2862190743552.0,
      "budget_used_percent": 0.002862190743552
    },
    {
      "type": "training",
      "description": "Training step 2",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:22",
      "total_flops_so_far": 4293286115328.0,
      "budget_used_percent": 0.004293286115328
    },
    {
      "type": "training",
      "description": "Training step 3",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:22",
      "total_flops_so_far": 5724381487104.0,
      "budget_used_percent": 0.005724381487104
    },
    {
      "type": "training",
      "description": "Training step 4",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:22",
      "total_flops_so_far": 7155476858880.0,
      "budget_used_percent": 0.00715547685888
    },
    {
      "type": "training",
      "description": "Training step 5",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:22",
      "total_flops_so_far": 8586572230656.0,
      "budget_used_percent": 0.008586572230656
    },
    {
      "type": "training",
      "description": "Training step 6",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:22",
      "total_flops_so_far": 10017667602432.0,
      "budget_used_percent": 0.010017667602432001
    },
    {
      "type": "training",
      "description": "Training step 7",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:23",
      "total_flops_so_far": 11448762974208.0,
      "budget_used_percent": 0.011448762974208
    },
    {
      "type": "training",
      "description": "Training step 8",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:23",
      "total_flops_so_far": 12879858345984.0,
      "budget_used_percent": 0.012879858345984
    },
    {
      "type": "training",
      "description": "Training step 9",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:23",
      "total_flops_so_far": 14310953717760.0,
      "budget_used_percent": 0.01431095371776
    },
    {
      "type": "training",
      "description": "Training step 10",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:23",
      "total_flops_so_far": 15742049089536.0,
      "budget_used_percent": 0.015742049089536
    },
    {
      "type": "training",
      "description": "Training step 11",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:23",
      "total_flops_so_far": 17173144461312.0,
      "budget_used_percent": 0.017173144461312
    },
    {
      "type": "training",
      "description": "Training step 12",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:23",
      "total_flops_so_far": 18604239833088.0,
      "budget_used_percent": 0.018604239833088
    },
    {
      "type": "training",
      "description": "Training step 13",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:23",
      "total_flops_so_far": 20035335204864.0,
      "budget_used_percent": 0.020035335204864002
    },
    {
      "type": "training",
      "description": "Training step 14",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:23",
      "total_flops_so_far": 21466430576640.0,
      "budget_used_percent": 0.02146643057664
    },
    {
      "type": "training",
      "description": "Training step 15",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:23",
      "total_flops_so_far": 22897525948416.0,
      "budget_used_percent": 0.022897525948416
    },
    {
      "type": "training",
      "description": "Training step 16",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:24",
      "total_flops_so_far": 24328621320192.0,
      "budget_used_percent": 0.024328621320192
    },
    {
      "type": "training",
      "description": "Training step 17",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:24",
      "total_flops_so_far": 25759716691968.0,
      "budget_used_percent": 0.025759716691968
    },
    {
      "type": "training",
      "description": "Training step 18",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:24",
      "total_flops_so_far": 27190812063744.0,
      "budget_used_percent": 0.027190812063743998
    },
    {
      "type": "training",
      "description": "Training step 19",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:24",
      "total_flops_so_far": 28621907435520.0,
      "budget_used_percent": 0.02862190743552
    },
    {
      "type": "training",
      "description": "Training step 20",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:24",
      "total_flops_so_far": 30053002807296.0,
      "budget_used_percent": 0.030053002807296
    },
    {
      "type": "training",
      "description": "Training step 21",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:24",
      "total_flops_so_far": 31484098179072.0,
      "budget_used_percent": 0.031484098179072
    },
    {
      "type": "training",
      "description": "Training step 22",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:24",
      "total_flops_so_far": 32915193550848.0,
      "budget_used_percent": 0.032915193550848
    },
    {
      "type": "training",
      "description": "Training step 23",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:24",
      "total_flops_so_far": 34346288922624.0,
      "budget_used_percent": 0.034346288922624
    },
    {
      "type": "training",
      "description": "Training step 24",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:25",
      "total_flops_so_far": 35777384294400.0,
      "budget_used_percent": 0.0357773842944
    },
    {
      "type": "training",
      "description": "Training step 25",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:25",
      "total_flops_so_far": 37208479666176.0,
      "budget_used_percent": 0.037208479666176
    },
    {
      "type": "training",
      "description": "Training step 26",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:25",
      "total_flops_so_far": 38639575037952.0,
      "budget_used_percent": 0.038639575037952
    },
    {
      "type": "training",
      "description": "Training step 27",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:25",
      "total_flops_so_far": 40070670409728.0,
      "budget_used_percent": 0.040070670409728004
    },
    {
      "type": "training",
      "description": "Training step 28",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:25",
      "total_flops_so_far": 41501765781504.0,
      "budget_used_percent": 0.041501765781504
    },
    {
      "type": "training",
      "description": "Training step 29",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:25",
      "total_flops_so_far": 42932861153280.0,
      "budget_used_percent": 0.04293286115328
    },
    {
      "type": "training",
      "description": "Training step 30",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:25",
      "total_flops_so_far": 44363956525056.0,
      "budget_used_percent": 0.044363956525056
    },
    {
      "type": "training",
      "description": "Training step 31",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:25",
      "total_flops_so_far": 45795051896832.0,
      "budget_used_percent": 0.045795051896832
    },
    {
      "type": "training",
      "description": "Training step 32",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:25",
      "total_flops_so_far": 47226147268608.0,
      "budget_used_percent": 0.047226147268608
    },
    {
      "type": "training",
      "description": "Training step 33",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:26",
      "total_flops_so_far": 48657242640384.0,
      "budget_used_percent": 0.048657242640384
    },
    {
      "type": "training",
      "description": "Training step 34",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:26",
      "total_flops_so_far": 50088338012160.0,
      "budget_used_percent": 0.050088338012160005
    },
    {
      "type": "training",
      "description": "Training step 35",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:26",
      "total_flops_so_far": 51519433383936.0,
      "budget_used_percent": 0.051519433383936
    },
    {
      "type": "training",
      "description": "Training step 36",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:26",
      "total_flops_so_far": 52950528755712.0,
      "budget_used_percent": 0.052950528755712004
    },
    {
      "type": "training",
      "description": "Training step 37",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:26",
      "total_flops_so_far": 54381624127488.0,
      "budget_used_percent": 0.054381624127487996
    },
    {
      "type": "training",
      "description": "Training step 38",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:26",
      "total_flops_so_far": 55812719499264.0,
      "budget_used_percent": 0.055812719499264
    },
    {
      "type": "training",
      "description": "Training step 39",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:26",
      "total_flops_so_far": 57243814871040.0,
      "budget_used_percent": 0.05724381487104
    },
    {
      "type": "training",
      "description": "Training step 40",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:26",
      "total_flops_so_far": 58674910242816.0,
      "budget_used_percent": 0.05867491024281601
    },
    {
      "type": "training",
      "description": "Training step 41",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:27",
      "total_flops_so_far": 60106005614592.0,
      "budget_used_percent": 0.060106005614592
    },
    {
      "type": "training",
      "description": "Training step 42",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:27",
      "total_flops_so_far": 61537100986368.0,
      "budget_used_percent": 0.061537100986368005
    },
    {
      "type": "training",
      "description": "Training step 43",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:27",
      "total_flops_so_far": 62968196358144.0,
      "budget_used_percent": 0.062968196358144
    },
    {
      "type": "training",
      "description": "Training step 44",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:27",
      "total_flops_so_far": 64399291729920.0,
      "budget_used_percent": 0.06439929172992
    },
    {
      "type": "training",
      "description": "Training step 45",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:27",
      "total_flops_so_far": 65830387101696.0,
      "budget_used_percent": 0.065830387101696
    },
    {
      "type": "training",
      "description": "Training step 46",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:27",
      "total_flops_so_far": 67261482473472.0,
      "budget_used_percent": 0.067261482473472
    },
    {
      "type": "training",
      "description": "Training step 47",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:27",
      "total_flops_so_far": 68692577845248.0,
      "budget_used_percent": 0.068692577845248
    },
    {
      "type": "training",
      "description": "Training step 48",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:27",
      "total_flops_so_far": 70123673217024.0,
      "budget_used_percent": 0.070123673217024
    },
    {
      "type": "training",
      "description": "Training step 49",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:27",
      "total_flops_so_far": 71554768588800.0,
      "budget_used_percent": 0.0715547685888
    },
    {
      "type": "training",
      "description": "Training step 50",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:28",
      "total_flops_so_far": 72985863960576.0,
      "budget_used_percent": 0.07298586396057599
    },
    {
      "type": "training",
      "description": "Training step 51",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:28",
      "total_flops_so_far": 74416959332352.0,
      "budget_used_percent": 0.074416959332352
    },
    {
      "type": "training",
      "description": "Training step 52",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:28",
      "total_flops_so_far": 75848054704128.0,
      "budget_used_percent": 0.07584805470412799
    },
    {
      "type": "training",
      "description": "Training step 53",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:28",
      "total_flops_so_far": 77279150075904.0,
      "budget_used_percent": 0.077279150075904
    },
    {
      "type": "training",
      "description": "Training step 54",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:28",
      "total_flops_so_far": 78710245447680.0,
      "budget_used_percent": 0.07871024544768
    },
    {
      "type": "training",
      "description": "Training step 55",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:28",
      "total_flops_so_far": 80141340819456.0,
      "budget_used_percent": 0.08014134081945601
    },
    {
      "type": "training",
      "description": "Training step 56",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:28",
      "total_flops_so_far": 81572436191232.0,
      "budget_used_percent": 0.081572436191232
    },
    {
      "type": "training",
      "description": "Training step 57",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:28",
      "total_flops_so_far": 83003531563008.0,
      "budget_used_percent": 0.083003531563008
    },
    {
      "type": "training",
      "description": "Training step 58",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:29",
      "total_flops_so_far": 84434626934784.0,
      "budget_used_percent": 0.084434626934784
    },
    {
      "type": "training",
      "description": "Training step 59",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:29",
      "total_flops_so_far": 85865722306560.0,
      "budget_used_percent": 0.08586572230656
    },
    {
      "type": "training",
      "description": "Training step 60",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:29",
      "total_flops_so_far": 87296817678336.0,
      "budget_used_percent": 0.087296817678336
    },
    {
      "type": "training",
      "description": "Training step 61",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:29",
      "total_flops_so_far": 88727913050112.0,
      "budget_used_percent": 0.088727913050112
    },
    {
      "type": "training",
      "description": "Training step 62",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:29",
      "total_flops_so_far": 90159008421888.0,
      "budget_used_percent": 0.090159008421888
    },
    {
      "type": "training",
      "description": "Training step 63",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:29",
      "total_flops_so_far": 91590103793664.0,
      "budget_used_percent": 0.091590103793664
    },
    {
      "type": "training",
      "description": "Training step 64",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:29",
      "total_flops_so_far": 93021199165440.0,
      "budget_used_percent": 0.09302119916544
    },
    {
      "type": "training",
      "description": "Training step 65",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:29",
      "total_flops_so_far": 94452294537216.0,
      "budget_used_percent": 0.094452294537216
    },
    {
      "type": "training",
      "description": "Training step 66",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:30",
      "total_flops_so_far": 95883389908992.0,
      "budget_used_percent": 0.095883389908992
    },
    {
      "type": "training",
      "description": "Training step 67",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:30",
      "total_flops_so_far": 97314485280768.0,
      "budget_used_percent": 0.097314485280768
    },
    {
      "type": "training",
      "description": "Training step 68",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:30",
      "total_flops_so_far": 98745580652544.0,
      "budget_used_percent": 0.09874558065254399
    },
    {
      "type": "training",
      "description": "Training step 69",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:30",
      "total_flops_so_far": 100176676024320.0,
      "budget_used_percent": 0.10017667602432001
    },
    {
      "type": "training",
      "description": "Training step 70",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:30",
      "total_flops_so_far": 101607771396096.0,
      "budget_used_percent": 0.101607771396096
    },
    {
      "type": "training",
      "description": "Training step 71",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:30",
      "total_flops_so_far": 103038866767872.0,
      "budget_used_percent": 0.103038866767872
    },
    {
      "type": "training",
      "description": "Training step 72",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:30",
      "total_flops_so_far": 104469962139648.0,
      "budget_used_percent": 0.10446996213964799
    },
    {
      "type": "training",
      "description": "Training step 73",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:30",
      "total_flops_so_far": 105901057511424.0,
      "budget_used_percent": 0.10590105751142401
    },
    {
      "type": "training",
      "description": "Training step 74",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:31",
      "total_flops_so_far": 107332152883200.0,
      "budget_used_percent": 0.1073321528832
    },
    {
      "type": "training",
      "description": "Training step 75",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:31",
      "total_flops_so_far": 108763248254976.0,
      "budget_used_percent": 0.10876324825497599
    },
    {
      "type": "training",
      "description": "Training step 76",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:31",
      "total_flops_so_far": 110194343626752.0,
      "budget_used_percent": 0.110194343626752
    },
    {
      "type": "training",
      "description": "Training step 77",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:31",
      "total_flops_so_far": 111625438998528.0,
      "budget_used_percent": 0.111625438998528
    },
    {
      "type": "training",
      "description": "Training step 78",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:31",
      "total_flops_so_far": 113056534370304.0,
      "budget_used_percent": 0.113056534370304
    },
    {
      "type": "training",
      "description": "Training step 79",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:31",
      "total_flops_so_far": 114487629742080.0,
      "budget_used_percent": 0.11448762974208
    },
    {
      "type": "training",
      "description": "Training step 80",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:31",
      "total_flops_so_far": 115918725113856.0,
      "budget_used_percent": 0.115918725113856
    },
    {
      "type": "training",
      "description": "Training step 81",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:31",
      "total_flops_so_far": 117349820485632.0,
      "budget_used_percent": 0.11734982048563201
    },
    {
      "type": "training",
      "description": "Training step 82",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:32",
      "total_flops_so_far": 118780915857408.0,
      "budget_used_percent": 0.118780915857408
    },
    {
      "type": "training",
      "description": "Training step 83",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:32",
      "total_flops_so_far": 120212011229184.0,
      "budget_used_percent": 0.120212011229184
    },
    {
      "type": "training",
      "description": "Training step 84",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:32",
      "total_flops_so_far": 121643106600960.0,
      "budget_used_percent": 0.12164310660095999
    },
    {
      "type": "training",
      "description": "Training step 85",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:32",
      "total_flops_so_far": 123074201972736.0,
      "budget_used_percent": 0.12307420197273601
    },
    {
      "type": "training",
      "description": "Training step 86",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:32",
      "total_flops_so_far": 124505297344512.0,
      "budget_used_percent": 0.124505297344512
    },
    {
      "type": "training",
      "description": "Training step 87",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:32",
      "total_flops_so_far": 125936392716288.0,
      "budget_used_percent": 0.125936392716288
    },
    {
      "type": "training",
      "description": "Training step 88",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:32",
      "total_flops_so_far": 127367488088064.0,
      "budget_used_percent": 0.127367488088064
    },
    {
      "type": "training",
      "description": "Training step 89",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:32",
      "total_flops_so_far": 128798583459840.0,
      "budget_used_percent": 0.12879858345984
    },
    {
      "type": "training",
      "description": "Training step 90",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:32",
      "total_flops_so_far": 130229678831616.0,
      "budget_used_percent": 0.130229678831616
    },
    {
      "type": "training",
      "description": "Training step 91",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:33",
      "total_flops_so_far": 131660774203392.0,
      "budget_used_percent": 0.131660774203392
    },
    {
      "type": "training",
      "description": "Training step 92",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:33",
      "total_flops_so_far": 133091869575168.0,
      "budget_used_percent": 0.133091869575168
    },
    {
      "type": "training",
      "description": "Training step 93",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:33",
      "total_flops_so_far": 134522964946944.0,
      "budget_used_percent": 0.134522964946944
    },
    {
      "type": "training",
      "description": "Training step 94",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:33",
      "total_flops_so_far": 135954060318720.0,
      "budget_used_percent": 0.13595406031872
    },
    {
      "type": "training",
      "description": "Training step 95",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:33",
      "total_flops_so_far": 137385155690496.0,
      "budget_used_percent": 0.137385155690496
    },
    {
      "type": "training",
      "description": "Training step 96",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:33",
      "total_flops_so_far": 138816251062272.0,
      "budget_used_percent": 0.138816251062272
    },
    {
      "type": "training",
      "description": "Training step 97",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:33",
      "total_flops_so_far": 140247346434048.0,
      "budget_used_percent": 0.140247346434048
    },
    {
      "type": "training",
      "description": "Training step 98",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:33",
      "total_flops_so_far": 141678441805824.0,
      "budget_used_percent": 0.141678441805824
    },
    {
      "type": "training",
      "description": "Training step 99",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:34",
      "total_flops_so_far": 143109537177600.0,
      "budget_used_percent": 0.1431095371776
    },
    {
      "type": "training",
      "description": "Training step 100",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:34",
      "total_flops_so_far": 144540632549376.0,
      "budget_used_percent": 0.144540632549376
    },
    {
      "type": "training",
      "description": "Training step 101",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:34",
      "total_flops_so_far": 145971727921152.0,
      "budget_used_percent": 0.14597172792115198
    },
    {
      "type": "training",
      "description": "Training step 102",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:34",
      "total_flops_so_far": 147402823292928.0,
      "budget_used_percent": 0.147402823292928
    },
    {
      "type": "training",
      "description": "Training step 103",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:34",
      "total_flops_so_far": 148833918664704.0,
      "budget_used_percent": 0.148833918664704
    },
    {
      "type": "training",
      "description": "Training step 104",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:34",
      "total_flops_so_far": 150265014036480.0,
      "budget_used_percent": 0.15026501403648
    },
    {
      "type": "training",
      "description": "Training step 105",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:34",
      "total_flops_so_far": 151696109408256.0,
      "budget_used_percent": 0.15169610940825598
    },
    {
      "type": "training",
      "description": "Training step 106",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:35",
      "total_flops_so_far": 153127204780032.0,
      "budget_used_percent": 0.153127204780032
    },
    {
      "type": "training",
      "description": "Training step 107",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:35",
      "total_flops_so_far": 154558300151808.0,
      "budget_used_percent": 0.154558300151808
    },
    {
      "type": "training",
      "description": "Training step 108",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:35",
      "total_flops_so_far": 155989395523584.0,
      "budget_used_percent": 0.155989395523584
    },
    {
      "type": "training",
      "description": "Training step 109",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:35",
      "total_flops_so_far": 157420490895360.0,
      "budget_used_percent": 0.15742049089536
    },
    {
      "type": "training",
      "description": "Training step 110",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:35",
      "total_flops_so_far": 158851586267136.0,
      "budget_used_percent": 0.15885158626713602
    },
    {
      "type": "training",
      "description": "Training step 111",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:35",
      "total_flops_so_far": 160282681638912.0,
      "budget_used_percent": 0.16028268163891202
    },
    {
      "type": "training",
      "description": "Training step 112",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:35",
      "total_flops_so_far": 161713777010688.0,
      "budget_used_percent": 0.161713777010688
    },
    {
      "type": "training",
      "description": "Training step 113",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:35",
      "total_flops_so_far": 163144872382464.0,
      "budget_used_percent": 0.163144872382464
    },
    {
      "type": "training",
      "description": "Training step 114",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:35",
      "total_flops_so_far": 164575967754240.0,
      "budget_used_percent": 0.16457596775424
    },
    {
      "type": "training",
      "description": "Training step 115",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:36",
      "total_flops_so_far": 166007063126016.0,
      "budget_used_percent": 0.166007063126016
    },
    {
      "type": "training",
      "description": "Training step 116",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:36",
      "total_flops_so_far": 167438158497792.0,
      "budget_used_percent": 0.167438158497792
    },
    {
      "type": "training",
      "description": "Training step 117",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:36",
      "total_flops_so_far": 168869253869568.0,
      "budget_used_percent": 0.168869253869568
    },
    {
      "type": "training",
      "description": "Training step 118",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:36",
      "total_flops_so_far": 170300349241344.0,
      "budget_used_percent": 0.170300349241344
    },
    {
      "type": "training",
      "description": "Training step 119",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:36",
      "total_flops_so_far": 171731444613120.0,
      "budget_used_percent": 0.17173144461312
    },
    {
      "type": "training",
      "description": "Training step 120",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:36",
      "total_flops_so_far": 173162539984896.0,
      "budget_used_percent": 0.173162539984896
    },
    {
      "type": "training",
      "description": "Training step 121",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:36",
      "total_flops_so_far": 174593635356672.0,
      "budget_used_percent": 0.174593635356672
    },
    {
      "type": "training",
      "description": "Training step 122",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:36",
      "total_flops_so_far": 176024730728448.0,
      "budget_used_percent": 0.176024730728448
    },
    {
      "type": "training",
      "description": "Training step 123",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:37",
      "total_flops_so_far": 177455826100224.0,
      "budget_used_percent": 0.177455826100224
    },
    {
      "type": "training",
      "description": "Training step 124",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:37",
      "total_flops_so_far": 178886921472000.0,
      "budget_used_percent": 0.178886921472
    },
    {
      "type": "training",
      "description": "Training step 125",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:37",
      "total_flops_so_far": 180318016843776.0,
      "budget_used_percent": 0.180318016843776
    },
    {
      "type": "training",
      "description": "Training step 126",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:37",
      "total_flops_so_far": 181749112215552.0,
      "budget_used_percent": 0.18174911221555198
    },
    {
      "type": "training",
      "description": "Training step 127",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:37",
      "total_flops_so_far": 183180207587328.0,
      "budget_used_percent": 0.183180207587328
    },
    {
      "type": "training",
      "description": "Training step 128",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:37",
      "total_flops_so_far": 184611302959104.0,
      "budget_used_percent": 0.184611302959104
    },
    {
      "type": "training",
      "description": "Training step 129",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:37",
      "total_flops_so_far": 186042398330880.0,
      "budget_used_percent": 0.18604239833088
    },
    {
      "type": "training",
      "description": "Training step 130",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:37",
      "total_flops_so_far": 187473493702656.0,
      "budget_used_percent": 0.18747349370265598
    },
    {
      "type": "training",
      "description": "Training step 131",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:38",
      "total_flops_so_far": 188904589074432.0,
      "budget_used_percent": 0.188904589074432
    },
    {
      "type": "training",
      "description": "Training step 132",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:38",
      "total_flops_so_far": 190335684446208.0,
      "budget_used_percent": 0.190335684446208
    },
    {
      "type": "training",
      "description": "Training step 133",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:38",
      "total_flops_so_far": 191766779817984.0,
      "budget_used_percent": 0.191766779817984
    },
    {
      "type": "training",
      "description": "Training step 134",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:38",
      "total_flops_so_far": 193197875189760.0,
      "budget_used_percent": 0.19319787518976
    },
    {
      "type": "training",
      "description": "Training step 135",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:38",
      "total_flops_so_far": 194628970561536.0,
      "budget_used_percent": 0.194628970561536
    },
    {
      "type": "training",
      "description": "Training step 136",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:38",
      "total_flops_so_far": 196060065933312.0,
      "budget_used_percent": 0.19606006593331202
    },
    {
      "type": "training",
      "description": "Training step 137",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:38",
      "total_flops_so_far": 197491161305088.0,
      "budget_used_percent": 0.19749116130508798
    },
    {
      "type": "training",
      "description": "Training step 138",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:38",
      "total_flops_so_far": 198922256676864.0,
      "budget_used_percent": 0.198922256676864
    },
    {
      "type": "training",
      "description": "Training step 139",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:38",
      "total_flops_so_far": 200353352048640.0,
      "budget_used_percent": 0.20035335204864002
    },
    {
      "type": "training",
      "description": "Training step 140",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:39",
      "total_flops_so_far": 201784447420416.0,
      "budget_used_percent": 0.20178444742041599
    },
    {
      "type": "training",
      "description": "Training step 141",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:39",
      "total_flops_so_far": 203215542792192.0,
      "budget_used_percent": 0.203215542792192
    },
    {
      "type": "training",
      "description": "Training step 142",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:39",
      "total_flops_so_far": 204646638163968.0,
      "budget_used_percent": 0.20464663816396803
    },
    {
      "type": "training",
      "description": "Training step 143",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:39",
      "total_flops_so_far": 206077733535744.0,
      "budget_used_percent": 0.206077733535744
    },
    {
      "type": "training",
      "description": "Training step 144",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:39",
      "total_flops_so_far": 207508828907520.0,
      "budget_used_percent": 0.20750882890752
    },
    {
      "type": "training",
      "description": "Training step 145",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:39",
      "total_flops_so_far": 208939924279296.0,
      "budget_used_percent": 0.20893992427929597
    },
    {
      "type": "training",
      "description": "Training step 146",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:39",
      "total_flops_so_far": 210371019651072.0,
      "budget_used_percent": 0.210371019651072
    },
    {
      "type": "training",
      "description": "Training step 147",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:39",
      "total_flops_so_far": 211802115022848.0,
      "budget_used_percent": 0.21180211502284801
    },
    {
      "type": "training",
      "description": "Training step 148",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:40",
      "total_flops_so_far": 213233210394624.0,
      "budget_used_percent": 0.21323321039462398
    },
    {
      "type": "training",
      "description": "Training step 149",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:40",
      "total_flops_so_far": 214664305766400.0,
      "budget_used_percent": 0.2146643057664
    },
    {
      "type": "training",
      "description": "Training step 150",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:40",
      "total_flops_so_far": 216095401138176.0,
      "budget_used_percent": 0.21609540113817602
    },
    {
      "type": "training",
      "description": "Training step 151",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:40",
      "total_flops_so_far": 217526496509952.0,
      "budget_used_percent": 0.21752649650995198
    },
    {
      "type": "training",
      "description": "Training step 152",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:40",
      "total_flops_so_far": 218957591881728.0,
      "budget_used_percent": 0.218957591881728
    },
    {
      "type": "training",
      "description": "Training step 153",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:40",
      "total_flops_so_far": 220388687253504.0,
      "budget_used_percent": 0.220388687253504
    },
    {
      "type": "training",
      "description": "Training step 154",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:40",
      "total_flops_so_far": 221819782625280.0,
      "budget_used_percent": 0.22181978262528
    },
    {
      "type": "training",
      "description": "Training step 155",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:40",
      "total_flops_so_far": 223250877997056.0,
      "budget_used_percent": 0.223250877997056
    },
    {
      "type": "training",
      "description": "Training step 156",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:41",
      "total_flops_so_far": 224681973368832.0,
      "budget_used_percent": 0.224681973368832
    },
    {
      "type": "training",
      "description": "Training step 157",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:41",
      "total_flops_so_far": 226113068740608.0,
      "budget_used_percent": 0.226113068740608
    },
    {
      "type": "training",
      "description": "Training step 158",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:41",
      "total_flops_so_far": 227544164112384.0,
      "budget_used_percent": 0.22754416411238398
    },
    {
      "type": "training",
      "description": "Training step 159",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:41",
      "total_flops_so_far": 228975259484160.0,
      "budget_used_percent": 0.22897525948416
    },
    {
      "type": "training",
      "description": "Training step 160",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:41",
      "total_flops_so_far": 230406354855936.0,
      "budget_used_percent": 0.23040635485593602
    },
    {
      "type": "training",
      "description": "Training step 161",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:41",
      "total_flops_so_far": 231837450227712.0,
      "budget_used_percent": 0.231837450227712
    },
    {
      "type": "training",
      "description": "Training step 162",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:41",
      "total_flops_so_far": 233268545599488.0,
      "budget_used_percent": 0.233268545599488
    },
    {
      "type": "training",
      "description": "Training step 163",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:41",
      "total_flops_so_far": 234699640971264.0,
      "budget_used_percent": 0.23469964097126403
    },
    {
      "type": "training",
      "description": "Training step 164",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:41",
      "total_flops_so_far": 236130736343040.0,
      "budget_used_percent": 0.23613073634304
    },
    {
      "type": "training",
      "description": "Training step 165",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:42",
      "total_flops_so_far": 237561831714816.0,
      "budget_used_percent": 0.237561831714816
    },
    {
      "type": "training",
      "description": "Training step 166",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:42",
      "total_flops_so_far": 238992927086592.0,
      "budget_used_percent": 0.23899292708659198
    },
    {
      "type": "training",
      "description": "Training step 167",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:42",
      "total_flops_so_far": 240424022458368.0,
      "budget_used_percent": 0.240424022458368
    },
    {
      "type": "training",
      "description": "Training step 168",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:42",
      "total_flops_so_far": 241855117830144.0,
      "budget_used_percent": 0.24185511783014402
    },
    {
      "type": "training",
      "description": "Training step 169",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:42",
      "total_flops_so_far": 243286213201920.0,
      "budget_used_percent": 0.24328621320191998
    },
    {
      "type": "training",
      "description": "Training step 170",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:42",
      "total_flops_so_far": 244717308573696.0,
      "budget_used_percent": 0.244717308573696
    },
    {
      "type": "training",
      "description": "Training step 171",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:42",
      "total_flops_so_far": 246148403945472.0,
      "budget_used_percent": 0.24614840394547202
    },
    {
      "type": "training",
      "description": "Training step 172",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:42",
      "total_flops_so_far": 247579499317248.0,
      "budget_used_percent": 0.247579499317248
    },
    {
      "type": "training",
      "description": "Training step 173",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:43",
      "total_flops_so_far": 249010594689024.0,
      "budget_used_percent": 0.249010594689024
    },
    {
      "type": "training",
      "description": "Training step 174",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:43",
      "total_flops_so_far": 250441690060800.0,
      "budget_used_percent": 0.25044169006079997
    },
    {
      "type": "training",
      "description": "Training step 175",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:43",
      "total_flops_so_far": 251872785432576.0,
      "budget_used_percent": 0.251872785432576
    },
    {
      "type": "training",
      "description": "Training step 176",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:43",
      "total_flops_so_far": 253303880804352.0,
      "budget_used_percent": 0.253303880804352
    },
    {
      "type": "training",
      "description": "Training step 177",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:43",
      "total_flops_so_far": 254734976176128.0,
      "budget_used_percent": 0.254734976176128
    },
    {
      "type": "training",
      "description": "Training step 178",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:43",
      "total_flops_so_far": 256166071547904.0,
      "budget_used_percent": 0.256166071547904
    },
    {
      "type": "training",
      "description": "Training step 179",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:43",
      "total_flops_so_far": 257597166919680.0,
      "budget_used_percent": 0.25759716691968
    },
    {
      "type": "training",
      "description": "Training step 180",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:43",
      "total_flops_so_far": 259028262291456.0,
      "budget_used_percent": 0.259028262291456
    },
    {
      "type": "training",
      "description": "Training step 181",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:44",
      "total_flops_so_far": 260459357663232.0,
      "budget_used_percent": 0.260459357663232
    },
    {
      "type": "training",
      "description": "Training step 182",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:44",
      "total_flops_so_far": 261890453035008.0,
      "budget_used_percent": 0.26189045303500796
    },
    {
      "type": "training",
      "description": "Training step 183",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:44",
      "total_flops_so_far": 263321548406784.0,
      "budget_used_percent": 0.263321548406784
    },
    {
      "type": "training",
      "description": "Training step 184",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:44",
      "total_flops_so_far": 264752643778560.0,
      "budget_used_percent": 0.26475264377856
    },
    {
      "type": "training",
      "description": "Training step 185",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:44",
      "total_flops_so_far": 266183739150336.0,
      "budget_used_percent": 0.266183739150336
    },
    {
      "type": "training",
      "description": "Training step 186",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:44",
      "total_flops_so_far": 267614834522112.0,
      "budget_used_percent": 0.267614834522112
    },
    {
      "type": "training",
      "description": "Training step 187",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:44",
      "total_flops_so_far": 269045929893888.0,
      "budget_used_percent": 0.269045929893888
    },
    {
      "type": "training",
      "description": "Training step 188",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:44",
      "total_flops_so_far": 270477025265664.0,
      "budget_used_percent": 0.270477025265664
    },
    {
      "type": "training",
      "description": "Training step 189",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:45",
      "total_flops_so_far": 271908120637440.0,
      "budget_used_percent": 0.27190812063744
    },
    {
      "type": "training",
      "description": "Training step 190",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:45",
      "total_flops_so_far": 273339216009216.0,
      "budget_used_percent": 0.273339216009216
    },
    {
      "type": "training",
      "description": "Training step 191",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:45",
      "total_flops_so_far": 274770311380992.0,
      "budget_used_percent": 0.274770311380992
    },
    {
      "type": "training",
      "description": "Training step 192",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:45",
      "total_flops_so_far": 276201406752768.0,
      "budget_used_percent": 0.276201406752768
    },
    {
      "type": "training",
      "description": "Training step 193",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:45",
      "total_flops_so_far": 277632502124544.0,
      "budget_used_percent": 0.277632502124544
    },
    {
      "type": "training",
      "description": "Training step 194",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:45",
      "total_flops_so_far": 279063597496320.0,
      "budget_used_percent": 0.27906359749632004
    },
    {
      "type": "training",
      "description": "Training step 195",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:45",
      "total_flops_so_far": 280494692868096.0,
      "budget_used_percent": 0.280494692868096
    },
    {
      "type": "training",
      "description": "Training step 196",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:45",
      "total_flops_so_far": 281925788239872.0,
      "budget_used_percent": 0.281925788239872
    },
    {
      "type": "training",
      "description": "Training step 197",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:45",
      "total_flops_so_far": 283356883611648.0,
      "budget_used_percent": 0.283356883611648
    },
    {
      "type": "training",
      "description": "Training step 198",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:46",
      "total_flops_so_far": 284787978983424.0,
      "budget_used_percent": 0.284787978983424
    },
    {
      "type": "training",
      "description": "Training step 199",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:46",
      "total_flops_so_far": 286219074355200.0,
      "budget_used_percent": 0.2862190743552
    },
    {
      "type": "training",
      "description": "Training step 200",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:46",
      "total_flops_so_far": 287650169726976.0,
      "budget_used_percent": 0.287650169726976
    },
    {
      "type": "training",
      "description": "Training step 201",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:46",
      "total_flops_so_far": 289081265098752.0,
      "budget_used_percent": 0.289081265098752
    },
    {
      "type": "training",
      "description": "Training step 202",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:46",
      "total_flops_so_far": 290512360470528.0,
      "budget_used_percent": 0.29051236047052803
    },
    {
      "type": "training",
      "description": "Training step 203",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:46",
      "total_flops_so_far": 291943455842304.0,
      "budget_used_percent": 0.29194345584230397
    },
    {
      "type": "training",
      "description": "Training step 204",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:46",
      "total_flops_so_far": 293374551214080.0,
      "budget_used_percent": 0.29337455121408
    },
    {
      "type": "training",
      "description": "Training step 205",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:46",
      "total_flops_so_far": 294805646585856.0,
      "budget_used_percent": 0.294805646585856
    },
    {
      "type": "training",
      "description": "Training step 206",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:47",
      "total_flops_so_far": 296236741957632.0,
      "budget_used_percent": 0.296236741957632
    },
    {
      "type": "training",
      "description": "Training step 207",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:47",
      "total_flops_so_far": 297667837329408.0,
      "budget_used_percent": 0.297667837329408
    },
    {
      "type": "training",
      "description": "Training step 208",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:47",
      "total_flops_so_far": 299098932701184.0,
      "budget_used_percent": 0.299098932701184
    },
    {
      "type": "training",
      "description": "Training step 209",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:47",
      "total_flops_so_far": 300530028072960.0,
      "budget_used_percent": 0.30053002807296
    },
    {
      "type": "training",
      "description": "Training step 210",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:47",
      "total_flops_so_far": 301961123444736.0,
      "budget_used_percent": 0.301961123444736
    },
    {
      "type": "training",
      "description": "Training step 211",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:47",
      "total_flops_so_far": 303392218816512.0,
      "budget_used_percent": 0.30339221881651196
    },
    {
      "type": "training",
      "description": "Training step 212",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:47",
      "total_flops_so_far": 304823314188288.0,
      "budget_used_percent": 0.304823314188288
    },
    {
      "type": "training",
      "description": "Training step 213",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:47",
      "total_flops_so_far": 306254409560064.0,
      "budget_used_percent": 0.306254409560064
    },
    {
      "type": "training",
      "description": "Training step 214",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:48",
      "total_flops_so_far": 307685504931840.0,
      "budget_used_percent": 0.30768550493184
    },
    {
      "type": "training",
      "description": "Training step 215",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:48",
      "total_flops_so_far": 309116600303616.0,
      "budget_used_percent": 0.309116600303616
    },
    {
      "type": "training",
      "description": "Training step 216",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:48",
      "total_flops_so_far": 310547695675392.0,
      "budget_used_percent": 0.310547695675392
    },
    {
      "type": "training",
      "description": "Training step 217",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:48",
      "total_flops_so_far": 311978791047168.0,
      "budget_used_percent": 0.311978791047168
    },
    {
      "type": "training",
      "description": "Training step 218",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:48",
      "total_flops_so_far": 313409886418944.0,
      "budget_used_percent": 0.313409886418944
    },
    {
      "type": "training",
      "description": "Training step 219",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:48",
      "total_flops_so_far": 314840981790720.0,
      "budget_used_percent": 0.31484098179072
    },
    {
      "type": "training",
      "description": "Training step 220",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:48",
      "total_flops_so_far": 316272077162496.0,
      "budget_used_percent": 0.316272077162496
    },
    {
      "type": "training",
      "description": "Training step 221",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:48",
      "total_flops_so_far": 317703172534272.0,
      "budget_used_percent": 0.31770317253427205
    },
    {
      "type": "training",
      "description": "Training step 222",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:49",
      "total_flops_so_far": 319134267906048.0,
      "budget_used_percent": 0.319134267906048
    },
    {
      "type": "training",
      "description": "Training step 223",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:49",
      "total_flops_so_far": 320565363277824.0,
      "budget_used_percent": 0.32056536327782403
    },
    {
      "type": "training",
      "description": "Training step 224",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:49",
      "total_flops_so_far": 321996458649600.0,
      "budget_used_percent": 0.32199645864959997
    },
    {
      "type": "training",
      "description": "Training step 225",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:49",
      "total_flops_so_far": 323427554021376.0,
      "budget_used_percent": 0.323427554021376
    },
    {
      "type": "training",
      "description": "Training step 226",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:49",
      "total_flops_so_far": 324858649393152.0,
      "budget_used_percent": 0.324858649393152
    },
    {
      "type": "training",
      "description": "Training step 227",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:49",
      "total_flops_so_far": 326289744764928.0,
      "budget_used_percent": 0.326289744764928
    },
    {
      "type": "training",
      "description": "Training step 228",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:49",
      "total_flops_so_far": 327720840136704.0,
      "budget_used_percent": 0.327720840136704
    },
    {
      "type": "training",
      "description": "Training step 229",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:49",
      "total_flops_so_far": 329151935508480.0,
      "budget_used_percent": 0.32915193550848
    },
    {
      "type": "training",
      "description": "Training step 230",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:50",
      "total_flops_so_far": 330583030880256.0,
      "budget_used_percent": 0.330583030880256
    },
    {
      "type": "training",
      "description": "Training step 231",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:50",
      "total_flops_so_far": 332014126252032.0,
      "budget_used_percent": 0.332014126252032
    },
    {
      "type": "training",
      "description": "Training step 232",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:50",
      "total_flops_so_far": 333445221623808.0,
      "budget_used_percent": 0.33344522162380796
    },
    {
      "type": "training",
      "description": "Training step 233",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:50",
      "total_flops_so_far": 334876316995584.0,
      "budget_used_percent": 0.334876316995584
    },
    {
      "type": "training",
      "description": "Training step 234",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:50",
      "total_flops_so_far": 336307412367360.0,
      "budget_used_percent": 0.33630741236736
    },
    {
      "type": "training",
      "description": "Training step 235",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:50",
      "total_flops_so_far": 337738507739136.0,
      "budget_used_percent": 0.337738507739136
    },
    {
      "type": "training",
      "description": "Training step 236",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:50",
      "total_flops_so_far": 339169603110912.0,
      "budget_used_percent": 0.339169603110912
    },
    {
      "type": "training",
      "description": "Training step 237",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:50",
      "total_flops_so_far": 340600698482688.0,
      "budget_used_percent": 0.340600698482688
    },
    {
      "type": "training",
      "description": "Training step 238",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:51",
      "total_flops_so_far": 342031793854464.0,
      "budget_used_percent": 0.342031793854464
    },
    {
      "type": "training",
      "description": "Training step 239",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:51",
      "total_flops_so_far": 343462889226240.0,
      "budget_used_percent": 0.34346288922624
    },
    {
      "type": "training",
      "description": "Training step 240",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:51",
      "total_flops_so_far": 344893984598016.0,
      "budget_used_percent": 0.344893984598016
    },
    {
      "type": "training",
      "description": "Training step 241",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:51",
      "total_flops_so_far": 346325079969792.0,
      "budget_used_percent": 0.346325079969792
    },
    {
      "type": "training",
      "description": "Training step 242",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:51",
      "total_flops_so_far": 347756175341568.0,
      "budget_used_percent": 0.347756175341568
    },
    {
      "type": "training",
      "description": "Training step 243",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:51",
      "total_flops_so_far": 349187270713344.0,
      "budget_used_percent": 0.349187270713344
    },
    {
      "type": "training",
      "description": "Training step 244",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:51",
      "total_flops_so_far": 350618366085120.0,
      "budget_used_percent": 0.35061836608512004
    },
    {
      "type": "training",
      "description": "Training step 245",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:51",
      "total_flops_so_far": 352049461456896.0,
      "budget_used_percent": 0.352049461456896
    },
    {
      "type": "training",
      "description": "Training step 246",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:52",
      "total_flops_so_far": 353480556828672.0,
      "budget_used_percent": 0.353480556828672
    },
    {
      "type": "training",
      "description": "Training step 247",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:52",
      "total_flops_so_far": 354911652200448.0,
      "budget_used_percent": 0.354911652200448
    },
    {
      "type": "training",
      "description": "Training step 248",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:52",
      "total_flops_so_far": 356342747572224.0,
      "budget_used_percent": 0.356342747572224
    },
    {
      "type": "training",
      "description": "Training step 249",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:52",
      "total_flops_so_far": 357773842944000.0,
      "budget_used_percent": 0.357773842944
    },
    {
      "type": "training",
      "description": "Training step 250",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:52",
      "total_flops_so_far": 359204938315776.0,
      "budget_used_percent": 0.359204938315776
    },
    {
      "type": "training",
      "description": "Training step 251",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:52",
      "total_flops_so_far": 360636033687552.0,
      "budget_used_percent": 0.360636033687552
    },
    {
      "type": "training",
      "description": "Training step 252",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:52",
      "total_flops_so_far": 362067129059328.0,
      "budget_used_percent": 0.36206712905932803
    },
    {
      "type": "training",
      "description": "Training step 253",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:52",
      "total_flops_so_far": 363498224431104.0,
      "budget_used_percent": 0.36349822443110397
    },
    {
      "type": "training",
      "description": "Training step 254",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:52",
      "total_flops_so_far": 364929319802880.0,
      "budget_used_percent": 0.36492931980288
    },
    {
      "type": "training",
      "description": "Training step 255",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:53",
      "total_flops_so_far": 366360415174656.0,
      "budget_used_percent": 0.366360415174656
    },
    {
      "type": "training",
      "description": "Training step 256",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:53",
      "total_flops_so_far": 367791510546432.0,
      "budget_used_percent": 0.367791510546432
    },
    {
      "type": "training",
      "description": "Training step 257",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:53",
      "total_flops_so_far": 369222605918208.0,
      "budget_used_percent": 0.369222605918208
    },
    {
      "type": "training",
      "description": "Training step 258",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:53",
      "total_flops_so_far": 370653701289984.0,
      "budget_used_percent": 0.370653701289984
    },
    {
      "type": "training",
      "description": "Training step 259",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:53",
      "total_flops_so_far": 372084796661760.0,
      "budget_used_percent": 0.37208479666176
    },
    {
      "type": "training",
      "description": "Training step 260",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:53",
      "total_flops_so_far": 373515892033536.0,
      "budget_used_percent": 0.373515892033536
    },
    {
      "type": "training",
      "description": "Training step 261",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:53",
      "total_flops_so_far": 374946987405312.0,
      "budget_used_percent": 0.37494698740531196
    },
    {
      "type": "training",
      "description": "Training step 262",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:53",
      "total_flops_so_far": 376378082777088.0,
      "budget_used_percent": 0.376378082777088
    },
    {
      "type": "training",
      "description": "Training step 263",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:54",
      "total_flops_so_far": 377809178148864.0,
      "budget_used_percent": 0.377809178148864
    },
    {
      "type": "training",
      "description": "Training step 264",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:54",
      "total_flops_so_far": 379240273520640.0,
      "budget_used_percent": 0.37924027352064
    },
    {
      "type": "training",
      "description": "Training step 265",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:54",
      "total_flops_so_far": 380671368892416.0,
      "budget_used_percent": 0.380671368892416
    },
    {
      "type": "training",
      "description": "Training step 266",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:54",
      "total_flops_so_far": 382102464264192.0,
      "budget_used_percent": 0.382102464264192
    },
    {
      "type": "training",
      "description": "Training step 267",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:54",
      "total_flops_so_far": 383533559635968.0,
      "budget_used_percent": 0.383533559635968
    },
    {
      "type": "training",
      "description": "Training step 268",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:54",
      "total_flops_so_far": 384964655007744.0,
      "budget_used_percent": 0.384964655007744
    },
    {
      "type": "training",
      "description": "Training step 269",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:54",
      "total_flops_so_far": 386395750379520.0,
      "budget_used_percent": 0.38639575037952
    },
    {
      "type": "training",
      "description": "Training step 270",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:54",
      "total_flops_so_far": 387826845751296.0,
      "budget_used_percent": 0.387826845751296
    },
    {
      "type": "training",
      "description": "Training step 271",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:55",
      "total_flops_so_far": 389257941123072.0,
      "budget_used_percent": 0.389257941123072
    },
    {
      "type": "training",
      "description": "Training step 272",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:55",
      "total_flops_so_far": 390689036494848.0,
      "budget_used_percent": 0.390689036494848
    },
    {
      "type": "training",
      "description": "Training step 273",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:55",
      "total_flops_so_far": 392120131866624.0,
      "budget_used_percent": 0.39212013186662403
    },
    {
      "type": "training",
      "description": "Training step 274",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:55",
      "total_flops_so_far": 393551227238400.0,
      "budget_used_percent": 0.3935512272384
    },
    {
      "type": "training",
      "description": "Training step 275",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:55",
      "total_flops_so_far": 394982322610176.0,
      "budget_used_percent": 0.39498232261017596
    },
    {
      "type": "training",
      "description": "Training step 276",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:55",
      "total_flops_so_far": 396413417981952.0,
      "budget_used_percent": 0.39641341798195195
    },
    {
      "type": "training",
      "description": "Training step 277",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:55",
      "total_flops_so_far": 397844513353728.0,
      "budget_used_percent": 0.397844513353728
    },
    {
      "type": "training",
      "description": "Training step 278",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:56",
      "total_flops_so_far": 399275608725504.0,
      "budget_used_percent": 0.399275608725504
    },
    {
      "type": "training",
      "description": "Training step 279",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:56",
      "total_flops_so_far": 400706704097280.0,
      "budget_used_percent": 0.40070670409728004
    },
    {
      "type": "training",
      "description": "Training step 280",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:56",
      "total_flops_so_far": 402137799469056.0,
      "budget_used_percent": 0.40213779946905603
    },
    {
      "type": "training",
      "description": "Training step 281",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:56",
      "total_flops_so_far": 403568894840832.0,
      "budget_used_percent": 0.40356889484083197
    },
    {
      "type": "training",
      "description": "Training step 282",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:56",
      "total_flops_so_far": 404999990212608.0,
      "budget_used_percent": 0.40499999021260796
    },
    {
      "type": "training",
      "description": "Training step 283",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:56",
      "total_flops_so_far": 406431085584384.0,
      "budget_used_percent": 0.406431085584384
    },
    {
      "type": "training",
      "description": "Training step 284",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:56",
      "total_flops_so_far": 407862180956160.0,
      "budget_used_percent": 0.40786218095616
    },
    {
      "type": "training",
      "description": "Training step 285",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:56",
      "total_flops_so_far": 409293276327936.0,
      "budget_used_percent": 0.40929327632793605
    },
    {
      "type": "training",
      "description": "Training step 286",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:56",
      "total_flops_so_far": 410724371699712.0,
      "budget_used_percent": 0.410724371699712
    },
    {
      "type": "training",
      "description": "Training step 287",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:57",
      "total_flops_so_far": 412155467071488.0,
      "budget_used_percent": 0.412155467071488
    },
    {
      "type": "training",
      "description": "Training step 288",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:57",
      "total_flops_so_far": 413586562443264.0,
      "budget_used_percent": 0.41358656244326397
    },
    {
      "type": "training",
      "description": "Training step 289",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:57",
      "total_flops_so_far": 415017657815040.0,
      "budget_used_percent": 0.41501765781504
    },
    {
      "type": "training",
      "description": "Training step 290",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:57",
      "total_flops_so_far": 416448753186816.0,
      "budget_used_percent": 0.416448753186816
    },
    {
      "type": "training",
      "description": "Training step 291",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:57",
      "total_flops_so_far": 417879848558592.0,
      "budget_used_percent": 0.41787984855859195
    },
    {
      "type": "training",
      "description": "Training step 292",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:57",
      "total_flops_so_far": 419310943930368.0,
      "budget_used_percent": 0.419310943930368
    },
    {
      "type": "training",
      "description": "Training step 293",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:57",
      "total_flops_so_far": 420742039302144.0,
      "budget_used_percent": 0.420742039302144
    },
    {
      "type": "training",
      "description": "Training step 294",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:57",
      "total_flops_so_far": 422173134673920.0,
      "budget_used_percent": 0.42217313467392004
    },
    {
      "type": "training",
      "description": "Training step 295",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:58",
      "total_flops_so_far": 423604230045696.0,
      "budget_used_percent": 0.42360423004569603
    },
    {
      "type": "training",
      "description": "Training step 296",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:58",
      "total_flops_so_far": 425035325417472.0,
      "budget_used_percent": 0.42503532541747197
    },
    {
      "type": "training",
      "description": "Training step 297",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:58",
      "total_flops_so_far": 426466420789248.0,
      "budget_used_percent": 0.42646642078924796
    },
    {
      "type": "training",
      "description": "Training step 298",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:58",
      "total_flops_so_far": 427897516161024.0,
      "budget_used_percent": 0.427897516161024
    },
    {
      "type": "training",
      "description": "Training step 299",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:58",
      "total_flops_so_far": 429328611532800.0,
      "budget_used_percent": 0.4293286115328
    },
    {
      "type": "training",
      "description": "Training step 300",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:58",
      "total_flops_so_far": 430759706904576.0,
      "budget_used_percent": 0.43075970690457605
    },
    {
      "type": "training",
      "description": "Training step 301",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:58",
      "total_flops_so_far": 432190802276352.0,
      "budget_used_percent": 0.43219080227635204
    },
    {
      "type": "training",
      "description": "Training step 302",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:58",
      "total_flops_so_far": 433621897648128.0,
      "budget_used_percent": 0.433621897648128
    },
    {
      "type": "training",
      "description": "Training step 303",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:59",
      "total_flops_so_far": 435052993019904.0,
      "budget_used_percent": 0.43505299301990397
    },
    {
      "type": "training",
      "description": "Training step 304",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:59",
      "total_flops_so_far": 436484088391680.0,
      "budget_used_percent": 0.43648408839168
    },
    {
      "type": "training",
      "description": "Training step 305",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:59",
      "total_flops_so_far": 437915183763456.0,
      "budget_used_percent": 0.437915183763456
    },
    {
      "type": "training",
      "description": "Training step 306",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:59",
      "total_flops_so_far": 439346279135232.0,
      "budget_used_percent": 0.43934627913523205
    },
    {
      "type": "training",
      "description": "Training step 307",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:59",
      "total_flops_so_far": 440777374507008.0,
      "budget_used_percent": 0.440777374507008
    },
    {
      "type": "training",
      "description": "Training step 308",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:59",
      "total_flops_so_far": 442208469878784.0,
      "budget_used_percent": 0.442208469878784
    },
    {
      "type": "training",
      "description": "Training step 309",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:59",
      "total_flops_so_far": 443639565250560.0,
      "budget_used_percent": 0.44363956525056
    },
    {
      "type": "training",
      "description": "Training step 310",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:47:59",
      "total_flops_so_far": 445070660622336.0,
      "budget_used_percent": 0.445070660622336
    },
    {
      "type": "training",
      "description": "Training step 311",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:00",
      "total_flops_so_far": 446501755994112.0,
      "budget_used_percent": 0.446501755994112
    },
    {
      "type": "training",
      "description": "Training step 312",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:00",
      "total_flops_so_far": 447932851365888.0,
      "budget_used_percent": 0.44793285136588795
    },
    {
      "type": "training",
      "description": "Training step 313",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:00",
      "total_flops_so_far": 449363946737664.0,
      "budget_used_percent": 0.449363946737664
    },
    {
      "type": "training",
      "description": "Training step 314",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:00",
      "total_flops_so_far": 450795042109440.0,
      "budget_used_percent": 0.45079504210944
    },
    {
      "type": "training",
      "description": "Training step 315",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:00",
      "total_flops_so_far": 452226137481216.0,
      "budget_used_percent": 0.452226137481216
    },
    {
      "type": "training",
      "description": "Training step 316",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:00",
      "total_flops_so_far": 453657232852992.0,
      "budget_used_percent": 0.45365723285299203
    },
    {
      "type": "training",
      "description": "Training step 317",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:00",
      "total_flops_so_far": 455088328224768.0,
      "budget_used_percent": 0.45508832822476797
    },
    {
      "type": "training",
      "description": "Training step 318",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:00",
      "total_flops_so_far": 456519423596544.0,
      "budget_used_percent": 0.45651942359654396
    },
    {
      "type": "training",
      "description": "Training step 319",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:01",
      "total_flops_so_far": 457950518968320.0,
      "budget_used_percent": 0.45795051896832
    },
    {
      "type": "training",
      "description": "Training step 320",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:01",
      "total_flops_so_far": 459381614340096.0,
      "budget_used_percent": 0.459381614340096
    },
    {
      "type": "training",
      "description": "Training step 321",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:01",
      "total_flops_so_far": 460812709711872.0,
      "budget_used_percent": 0.46081270971187205
    },
    {
      "type": "training",
      "description": "Training step 322",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:01",
      "total_flops_so_far": 462243805083648.0,
      "budget_used_percent": 0.46224380508364804
    },
    {
      "type": "training",
      "description": "Training step 323",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:01",
      "total_flops_so_far": 463674900455424.0,
      "budget_used_percent": 0.463674900455424
    },
    {
      "type": "training",
      "description": "Training step 324",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:01",
      "total_flops_so_far": 465105995827200.0,
      "budget_used_percent": 0.46510599582719997
    },
    {
      "type": "training",
      "description": "Training step 325",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:01",
      "total_flops_so_far": 466537091198976.0,
      "budget_used_percent": 0.466537091198976
    },
    {
      "type": "training",
      "description": "Training step 326",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:01",
      "total_flops_so_far": 467968186570752.0,
      "budget_used_percent": 0.467968186570752
    },
    {
      "type": "training",
      "description": "Training step 327",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:02",
      "total_flops_so_far": 469399281942528.0,
      "budget_used_percent": 0.46939928194252806
    },
    {
      "type": "training",
      "description": "Training step 328",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:02",
      "total_flops_so_far": 470830377314304.0,
      "budget_used_percent": 0.470830377314304
    },
    {
      "type": "training",
      "description": "Training step 329",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:02",
      "total_flops_so_far": 472261472686080.0,
      "budget_used_percent": 0.47226147268608
    },
    {
      "type": "training",
      "description": "Training step 330",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:02",
      "total_flops_so_far": 473692568057856.0,
      "budget_used_percent": 0.473692568057856
    },
    {
      "type": "training",
      "description": "Training step 331",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:02",
      "total_flops_so_far": 475123663429632.0,
      "budget_used_percent": 0.475123663429632
    },
    {
      "type": "training",
      "description": "Training step 332",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:02",
      "total_flops_so_far": 476554758801408.0,
      "budget_used_percent": 0.476554758801408
    },
    {
      "type": "training",
      "description": "Training step 333",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:02",
      "total_flops_so_far": 477985854173184.0,
      "budget_used_percent": 0.47798585417318395
    },
    {
      "type": "training",
      "description": "Training step 334",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:03",
      "total_flops_so_far": 479416949544960.0,
      "budget_used_percent": 0.47941694954496
    },
    {
      "type": "training",
      "description": "Training step 335",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:03",
      "total_flops_so_far": 480848044916736.0,
      "budget_used_percent": 0.480848044916736
    },
    {
      "type": "training",
      "description": "Training step 336",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:03",
      "total_flops_so_far": 482279140288512.0,
      "budget_used_percent": 0.482279140288512
    },
    {
      "type": "training",
      "description": "Training step 337",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:03",
      "total_flops_so_far": 483710235660288.0,
      "budget_used_percent": 0.48371023566028803
    },
    {
      "type": "training",
      "description": "Training step 338",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:03",
      "total_flops_so_far": 485141331032064.0,
      "budget_used_percent": 0.48514133103206397
    },
    {
      "type": "training",
      "description": "Training step 339",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:03",
      "total_flops_so_far": 486572426403840.0,
      "budget_used_percent": 0.48657242640383996
    },
    {
      "type": "training",
      "description": "Training step 340",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:03",
      "total_flops_so_far": 488003521775616.0,
      "budget_used_percent": 0.488003521775616
    },
    {
      "type": "training",
      "description": "Training step 341",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:03",
      "total_flops_so_far": 489434617147392.0,
      "budget_used_percent": 0.489434617147392
    },
    {
      "type": "training",
      "description": "Training step 342",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:04",
      "total_flops_so_far": 490865712519168.0,
      "budget_used_percent": 0.490865712519168
    },
    {
      "type": "training",
      "description": "Training step 343",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:04",
      "total_flops_so_far": 492296807890944.0,
      "budget_used_percent": 0.49229680789094404
    },
    {
      "type": "training",
      "description": "Training step 344",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:04",
      "total_flops_so_far": 493727903262720.0,
      "budget_used_percent": 0.49372790326272
    },
    {
      "type": "training",
      "description": "Training step 345",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:04",
      "total_flops_so_far": 495158998634496.0,
      "budget_used_percent": 0.495158998634496
    },
    {
      "type": "training",
      "description": "Training step 346",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:04",
      "total_flops_so_far": 496590094006272.0,
      "budget_used_percent": 0.496590094006272
    },
    {
      "type": "training",
      "description": "Training step 347",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:04",
      "total_flops_so_far": 498021189378048.0,
      "budget_used_percent": 0.498021189378048
    },
    {
      "type": "training",
      "description": "Training step 348",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:04",
      "total_flops_so_far": 499452284749824.0,
      "budget_used_percent": 0.49945228474982406
    },
    {
      "type": "training",
      "description": "Training step 349",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:04",
      "total_flops_so_far": 500883380121600.0,
      "budget_used_percent": 0.5008833801215999
    },
    {
      "type": "training",
      "description": "Training step 350",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:05",
      "total_flops_so_far": 502314475493376.0,
      "budget_used_percent": 0.5023144754933759
    },
    {
      "type": "training",
      "description": "Training step 351",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:05",
      "total_flops_so_far": 503745570865152.0,
      "budget_used_percent": 0.503745570865152
    },
    {
      "type": "training",
      "description": "Training step 352",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:05",
      "total_flops_so_far": 505176666236928.0,
      "budget_used_percent": 0.505176666236928
    },
    {
      "type": "training",
      "description": "Training step 353",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:05",
      "total_flops_so_far": 506607761608704.0,
      "budget_used_percent": 0.506607761608704
    },
    {
      "type": "training",
      "description": "Training step 354",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:05",
      "total_flops_so_far": 508038856980480.0,
      "budget_used_percent": 0.50803885698048
    },
    {
      "type": "training",
      "description": "Training step 355",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:05",
      "total_flops_so_far": 509469952352256.0,
      "budget_used_percent": 0.509469952352256
    },
    {
      "type": "training",
      "description": "Training step 356",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:05",
      "total_flops_so_far": 510901047724032.0,
      "budget_used_percent": 0.510901047724032
    },
    {
      "type": "training",
      "description": "Training step 357",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:05",
      "total_flops_so_far": 512332143095808.0,
      "budget_used_percent": 0.512332143095808
    },
    {
      "type": "training",
      "description": "Training step 358",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:06",
      "total_flops_so_far": 513763238467584.0,
      "budget_used_percent": 0.513763238467584
    },
    {
      "type": "training",
      "description": "Training step 359",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:06",
      "total_flops_so_far": 515194333839360.0,
      "budget_used_percent": 0.51519433383936
    },
    {
      "type": "training",
      "description": "Training step 360",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:06",
      "total_flops_so_far": 516625429211136.0,
      "budget_used_percent": 0.516625429211136
    },
    {
      "type": "training",
      "description": "Training step 361",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:06",
      "total_flops_so_far": 518056524582912.0,
      "budget_used_percent": 0.518056524582912
    },
    {
      "type": "training",
      "description": "Training step 362",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:06",
      "total_flops_so_far": 519487619954688.0,
      "budget_used_percent": 0.5194876199546881
    },
    {
      "type": "training",
      "description": "Training step 363",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:06",
      "total_flops_so_far": 520918715326464.0,
      "budget_used_percent": 0.520918715326464
    },
    {
      "type": "training",
      "description": "Training step 364",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:06",
      "total_flops_so_far": 522349810698240.0,
      "budget_used_percent": 0.52234981069824
    },
    {
      "type": "training",
      "description": "Training step 365",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:06",
      "total_flops_so_far": 523780906070016.0,
      "budget_used_percent": 0.5237809060700159
    },
    {
      "type": "training",
      "description": "Training step 366",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:07",
      "total_flops_so_far": 525212001441792.0,
      "budget_used_percent": 0.525212001441792
    },
    {
      "type": "training",
      "description": "Training step 367",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:07",
      "total_flops_so_far": 526643096813568.0,
      "budget_used_percent": 0.526643096813568
    },
    {
      "type": "training",
      "description": "Training step 368",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:07",
      "total_flops_so_far": 528074192185344.0,
      "budget_used_percent": 0.528074192185344
    },
    {
      "type": "training",
      "description": "Training step 369",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:07",
      "total_flops_so_far": 529505287557120.0,
      "budget_used_percent": 0.52950528755712
    },
    {
      "type": "training",
      "description": "Training step 370",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:07",
      "total_flops_so_far": 530936382928896.0,
      "budget_used_percent": 0.530936382928896
    },
    {
      "type": "training",
      "description": "Training step 371",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:07",
      "total_flops_so_far": 532367478300672.0,
      "budget_used_percent": 0.532367478300672
    },
    {
      "type": "training",
      "description": "Training step 372",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:07",
      "total_flops_so_far": 533798573672448.0,
      "budget_used_percent": 0.533798573672448
    },
    {
      "type": "training",
      "description": "Training step 373",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:07",
      "total_flops_so_far": 535229669044224.0,
      "budget_used_percent": 0.535229669044224
    },
    {
      "type": "training",
      "description": "Training step 374",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:08",
      "total_flops_so_far": 536660764416000.0,
      "budget_used_percent": 0.5366607644160001
    },
    {
      "type": "training",
      "description": "Training step 375",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:08",
      "total_flops_so_far": 538091859787776.0,
      "budget_used_percent": 0.538091859787776
    },
    {
      "type": "training",
      "description": "Training step 376",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:08",
      "total_flops_so_far": 539522955159552.0,
      "budget_used_percent": 0.539522955159552
    },
    {
      "type": "training",
      "description": "Training step 377",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:08",
      "total_flops_so_far": 540954050531328.0,
      "budget_used_percent": 0.540954050531328
    },
    {
      "type": "training",
      "description": "Training step 378",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:08",
      "total_flops_so_far": 542385145903104.0,
      "budget_used_percent": 0.542385145903104
    },
    {
      "type": "training",
      "description": "Training step 379",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:08",
      "total_flops_so_far": 543816241274880.0,
      "budget_used_percent": 0.54381624127488
    },
    {
      "type": "training",
      "description": "Training step 380",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:08",
      "total_flops_so_far": 545247336646656.0,
      "budget_used_percent": 0.5452473366466559
    },
    {
      "type": "training",
      "description": "Training step 381",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:08",
      "total_flops_so_far": 546678432018432.0,
      "budget_used_percent": 0.546678432018432
    },
    {
      "type": "training",
      "description": "Training step 382",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:09",
      "total_flops_so_far": 548109527390208.0,
      "budget_used_percent": 0.548109527390208
    },
    {
      "type": "training",
      "description": "Training step 383",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:09",
      "total_flops_so_far": 549540622761984.0,
      "budget_used_percent": 0.549540622761984
    },
    {
      "type": "training",
      "description": "Training step 384",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:09",
      "total_flops_so_far": 550971718133760.0,
      "budget_used_percent": 0.55097171813376
    },
    {
      "type": "training",
      "description": "Training step 385",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:09",
      "total_flops_so_far": 552402813505536.0,
      "budget_used_percent": 0.552402813505536
    },
    {
      "type": "training",
      "description": "Training step 386",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:09",
      "total_flops_so_far": 553833908877312.0,
      "budget_used_percent": 0.553833908877312
    },
    {
      "type": "training",
      "description": "Training step 387",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:09",
      "total_flops_so_far": 555265004249088.0,
      "budget_used_percent": 0.555265004249088
    },
    {
      "type": "training",
      "description": "Training step 388",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:09",
      "total_flops_so_far": 556696099620864.0,
      "budget_used_percent": 0.556696099620864
    },
    {
      "type": "training",
      "description": "Training step 389",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:09",
      "total_flops_so_far": 558127194992640.0,
      "budget_used_percent": 0.5581271949926401
    },
    {
      "type": "training",
      "description": "Training step 390",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:10",
      "total_flops_so_far": 559558290364416.0,
      "budget_used_percent": 0.5595582903644161
    },
    {
      "type": "training",
      "description": "Training step 391",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:10",
      "total_flops_so_far": 560989385736192.0,
      "budget_used_percent": 0.560989385736192
    },
    {
      "type": "training",
      "description": "Training step 392",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:10",
      "total_flops_so_far": 562420481107968.0,
      "budget_used_percent": 0.5624204811079679
    },
    {
      "type": "training",
      "description": "Training step 393",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:10",
      "total_flops_so_far": 563851576479744.0,
      "budget_used_percent": 0.563851576479744
    },
    {
      "type": "training",
      "description": "Training step 394",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:10",
      "total_flops_so_far": 565282671851520.0,
      "budget_used_percent": 0.56528267185152
    },
    {
      "type": "training",
      "description": "Training step 395",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:10",
      "total_flops_so_far": 566713767223296.0,
      "budget_used_percent": 0.566713767223296
    },
    {
      "type": "training",
      "description": "Training step 396",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:10",
      "total_flops_so_far": 568144862595072.0,
      "budget_used_percent": 0.5681448625950719
    },
    {
      "type": "training",
      "description": "Training step 397",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:10",
      "total_flops_so_far": 569575957966848.0,
      "budget_used_percent": 0.569575957966848
    },
    {
      "type": "training",
      "description": "Training step 398",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:11",
      "total_flops_so_far": 571007053338624.0,
      "budget_used_percent": 0.571007053338624
    },
    {
      "type": "training",
      "description": "Training step 399",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:11",
      "total_flops_so_far": 572438148710400.0,
      "budget_used_percent": 0.5724381487104
    },
    {
      "type": "training",
      "description": "Training step 400",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:11",
      "total_flops_so_far": 573869244082176.0,
      "budget_used_percent": 0.573869244082176
    },
    {
      "type": "training",
      "description": "Training step 401",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:11",
      "total_flops_so_far": 575300339453952.0,
      "budget_used_percent": 0.575300339453952
    },
    {
      "type": "training",
      "description": "Training step 402",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:11",
      "total_flops_so_far": 576731434825728.0,
      "budget_used_percent": 0.576731434825728
    },
    {
      "type": "training",
      "description": "Training step 403",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:11",
      "total_flops_so_far": 578162530197504.0,
      "budget_used_percent": 0.578162530197504
    },
    {
      "type": "training",
      "description": "Training step 404",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:11",
      "total_flops_so_far": 579593625569280.0,
      "budget_used_percent": 0.57959362556928
    },
    {
      "type": "training",
      "description": "Training step 405",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:11",
      "total_flops_so_far": 581024720941056.0,
      "budget_used_percent": 0.5810247209410561
    },
    {
      "type": "training",
      "description": "Training step 406",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:12",
      "total_flops_so_far": 582455816312832.0,
      "budget_used_percent": 0.582455816312832
    },
    {
      "type": "training",
      "description": "Training step 407",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:12",
      "total_flops_so_far": 583886911684608.0,
      "budget_used_percent": 0.5838869116846079
    },
    {
      "type": "training",
      "description": "Training step 408",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:12",
      "total_flops_so_far": 585318007056384.0,
      "budget_used_percent": 0.585318007056384
    },
    {
      "type": "training",
      "description": "Training step 409",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:12",
      "total_flops_so_far": 586749102428160.0,
      "budget_used_percent": 0.58674910242816
    },
    {
      "type": "training",
      "description": "Training step 410",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:12",
      "total_flops_so_far": 588180197799936.0,
      "budget_used_percent": 0.588180197799936
    },
    {
      "type": "training",
      "description": "Training step 411",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:12",
      "total_flops_so_far": 589611293171712.0,
      "budget_used_percent": 0.589611293171712
    },
    {
      "type": "training",
      "description": "Training step 412",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:12",
      "total_flops_so_far": 591042388543488.0,
      "budget_used_percent": 0.591042388543488
    },
    {
      "type": "training",
      "description": "Training step 413",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:13",
      "total_flops_so_far": 592473483915264.0,
      "budget_used_percent": 0.592473483915264
    },
    {
      "type": "training",
      "description": "Training step 414",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:13",
      "total_flops_so_far": 593904579287040.0,
      "budget_used_percent": 0.59390457928704
    },
    {
      "type": "training",
      "description": "Training step 415",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:13",
      "total_flops_so_far": 595335674658816.0,
      "budget_used_percent": 0.595335674658816
    },
    {
      "type": "training",
      "description": "Training step 416",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:13",
      "total_flops_so_far": 596766770030592.0,
      "budget_used_percent": 0.5967667700305921
    },
    {
      "type": "training",
      "description": "Training step 417",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:13",
      "total_flops_so_far": 598197865402368.0,
      "budget_used_percent": 0.598197865402368
    },
    {
      "type": "training",
      "description": "Training step 418",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:13",
      "total_flops_so_far": 599628960774144.0,
      "budget_used_percent": 0.599628960774144
    },
    {
      "type": "training",
      "description": "Training step 419",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:13",
      "total_flops_so_far": 601060056145920.0,
      "budget_used_percent": 0.60106005614592
    },
    {
      "type": "training",
      "description": "Training step 420",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:13",
      "total_flops_so_far": 602491151517696.0,
      "budget_used_percent": 0.602491151517696
    },
    {
      "type": "training",
      "description": "Training step 421",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:14",
      "total_flops_so_far": 603922246889472.0,
      "budget_used_percent": 0.603922246889472
    },
    {
      "type": "training",
      "description": "Training step 422",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:14",
      "total_flops_so_far": 605353342261248.0,
      "budget_used_percent": 0.605353342261248
    },
    {
      "type": "training",
      "description": "Training step 423",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:14",
      "total_flops_so_far": 606784437633024.0,
      "budget_used_percent": 0.6067844376330239
    },
    {
      "type": "training",
      "description": "Training step 424",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:14",
      "total_flops_so_far": 608215533004800.0,
      "budget_used_percent": 0.6082155330048
    },
    {
      "type": "training",
      "description": "Training step 425",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:14",
      "total_flops_so_far": 609646628376576.0,
      "budget_used_percent": 0.609646628376576
    },
    {
      "type": "training",
      "description": "Training step 426",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:14",
      "total_flops_so_far": 611077723748352.0,
      "budget_used_percent": 0.611077723748352
    },
    {
      "type": "training",
      "description": "Training step 427",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:14",
      "total_flops_so_far": 612508819120128.0,
      "budget_used_percent": 0.612508819120128
    },
    {
      "type": "training",
      "description": "Training step 428",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:14",
      "total_flops_so_far": 613939914491904.0,
      "budget_used_percent": 0.613939914491904
    },
    {
      "type": "training",
      "description": "Training step 429",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:15",
      "total_flops_so_far": 615371009863680.0,
      "budget_used_percent": 0.61537100986368
    },
    {
      "type": "training",
      "description": "Training step 430",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:15",
      "total_flops_so_far": 616802105235456.0,
      "budget_used_percent": 0.616802105235456
    },
    {
      "type": "training",
      "description": "Training step 431",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:15",
      "total_flops_so_far": 618233200607232.0,
      "budget_used_percent": 0.618233200607232
    },
    {
      "type": "training",
      "description": "Training step 432",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:15",
      "total_flops_so_far": 619664295979008.0,
      "budget_used_percent": 0.6196642959790081
    },
    {
      "type": "training",
      "description": "Training step 433",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:15",
      "total_flops_so_far": 621095391350784.0,
      "budget_used_percent": 0.621095391350784
    },
    {
      "type": "training",
      "description": "Training step 434",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:15",
      "total_flops_so_far": 622526486722560.0,
      "budget_used_percent": 0.62252648672256
    },
    {
      "type": "training",
      "description": "Training step 435",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:15",
      "total_flops_so_far": 623957582094336.0,
      "budget_used_percent": 0.623957582094336
    },
    {
      "type": "training",
      "description": "Training step 436",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:15",
      "total_flops_so_far": 625388677466112.0,
      "budget_used_percent": 0.625388677466112
    },
    {
      "type": "training",
      "description": "Training step 437",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:16",
      "total_flops_so_far": 626819772837888.0,
      "budget_used_percent": 0.626819772837888
    },
    {
      "type": "training",
      "description": "Training step 438",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:16",
      "total_flops_so_far": 628250868209664.0,
      "budget_used_percent": 0.6282508682096639
    },
    {
      "type": "training",
      "description": "Training step 439",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:16",
      "total_flops_so_far": 629681963581440.0,
      "budget_used_percent": 0.62968196358144
    },
    {
      "type": "training",
      "description": "Training step 440",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:16",
      "total_flops_so_far": 631113058953216.0,
      "budget_used_percent": 0.631113058953216
    },
    {
      "type": "training",
      "description": "Training step 441",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:16",
      "total_flops_so_far": 632544154324992.0,
      "budget_used_percent": 0.632544154324992
    },
    {
      "type": "training",
      "description": "Training step 442",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:16",
      "total_flops_so_far": 633975249696768.0,
      "budget_used_percent": 0.633975249696768
    },
    {
      "type": "training",
      "description": "Training step 443",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:16",
      "total_flops_so_far": 635406345068544.0,
      "budget_used_percent": 0.6354063450685441
    },
    {
      "type": "training",
      "description": "Training step 444",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:16",
      "total_flops_so_far": 636837440440320.0,
      "budget_used_percent": 0.63683744044032
    },
    {
      "type": "training",
      "description": "Training step 445",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:17",
      "total_flops_so_far": 638268535812096.0,
      "budget_used_percent": 0.638268535812096
    },
    {
      "type": "training",
      "description": "Training step 446",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:17",
      "total_flops_so_far": 639699631183872.0,
      "budget_used_percent": 0.639699631183872
    },
    {
      "type": "training",
      "description": "Training step 447",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:17",
      "total_flops_so_far": 641130726555648.0,
      "budget_used_percent": 0.6411307265556481
    },
    {
      "type": "training",
      "description": "Training step 448",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:17",
      "total_flops_so_far": 642561821927424.0,
      "budget_used_percent": 0.6425618219274241
    },
    {
      "type": "training",
      "description": "Training step 449",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:17",
      "total_flops_so_far": 643992917299200.0,
      "budget_used_percent": 0.6439929172991999
    },
    {
      "type": "training",
      "description": "Training step 450",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:17",
      "total_flops_so_far": 645424012670976.0,
      "budget_used_percent": 0.6454240126709759
    },
    {
      "type": "training",
      "description": "Training step 451",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:17",
      "total_flops_so_far": 646855108042752.0,
      "budget_used_percent": 0.646855108042752
    },
    {
      "type": "training",
      "description": "Training step 452",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:17",
      "total_flops_so_far": 648286203414528.0,
      "budget_used_percent": 0.648286203414528
    },
    {
      "type": "training",
      "description": "Training step 453",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:18",
      "total_flops_so_far": 649717298786304.0,
      "budget_used_percent": 0.649717298786304
    },
    {
      "type": "training",
      "description": "Training step 454",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:18",
      "total_flops_so_far": 651148394158080.0,
      "budget_used_percent": 0.65114839415808
    },
    {
      "type": "training",
      "description": "Training step 455",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:18",
      "total_flops_so_far": 652579489529856.0,
      "budget_used_percent": 0.652579489529856
    },
    {
      "type": "training",
      "description": "Training step 456",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:18",
      "total_flops_so_far": 654010584901632.0,
      "budget_used_percent": 0.654010584901632
    },
    {
      "type": "training",
      "description": "Training step 457",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:18",
      "total_flops_so_far": 655441680273408.0,
      "budget_used_percent": 0.655441680273408
    },
    {
      "type": "training",
      "description": "Training step 458",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:18",
      "total_flops_so_far": 656872775645184.0,
      "budget_used_percent": 0.656872775645184
    },
    {
      "type": "training",
      "description": "Training step 459",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:18",
      "total_flops_so_far": 658303871016960.0,
      "budget_used_percent": 0.65830387101696
    },
    {
      "type": "training",
      "description": "Training step 460",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:18",
      "total_flops_so_far": 659734966388736.0,
      "budget_used_percent": 0.659734966388736
    },
    {
      "type": "training",
      "description": "Training step 461",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:19",
      "total_flops_so_far": 661166061760512.0,
      "budget_used_percent": 0.661166061760512
    },
    {
      "type": "training",
      "description": "Training step 462",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:19",
      "total_flops_so_far": 662597157132288.0,
      "budget_used_percent": 0.6625971571322881
    },
    {
      "type": "training",
      "description": "Training step 463",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:19",
      "total_flops_so_far": 664028252504064.0,
      "budget_used_percent": 0.664028252504064
    },
    {
      "type": "training",
      "description": "Training step 464",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:19",
      "total_flops_so_far": 665459347875840.0,
      "budget_used_percent": 0.66545934787584
    },
    {
      "type": "training",
      "description": "Training step 465",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:19",
      "total_flops_so_far": 666890443247616.0,
      "budget_used_percent": 0.6668904432476159
    },
    {
      "type": "training",
      "description": "Training step 466",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:19",
      "total_flops_so_far": 668321538619392.0,
      "budget_used_percent": 0.668321538619392
    },
    {
      "type": "training",
      "description": "Training step 467",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:19",
      "total_flops_so_far": 669752633991168.0,
      "budget_used_percent": 0.669752633991168
    },
    {
      "type": "training",
      "description": "Training step 468",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:20",
      "total_flops_so_far": 671183729362944.0,
      "budget_used_percent": 0.671183729362944
    },
    {
      "type": "training",
      "description": "Training step 469",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:20",
      "total_flops_so_far": 672614824734720.0,
      "budget_used_percent": 0.67261482473472
    },
    {
      "type": "training",
      "description": "Training step 470",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:20",
      "total_flops_so_far": 674045920106496.0,
      "budget_used_percent": 0.674045920106496
    },
    {
      "type": "training",
      "description": "Training step 471",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:20",
      "total_flops_so_far": 675477015478272.0,
      "budget_used_percent": 0.675477015478272
    },
    {
      "type": "training",
      "description": "Training step 472",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:20",
      "total_flops_so_far": 676908110850048.0,
      "budget_used_percent": 0.676908110850048
    },
    {
      "type": "training",
      "description": "Training step 473",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:20",
      "total_flops_so_far": 678339206221824.0,
      "budget_used_percent": 0.678339206221824
    },
    {
      "type": "training",
      "description": "Training step 474",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:20",
      "total_flops_so_far": 679770301593600.0,
      "budget_used_percent": 0.6797703015936001
    },
    {
      "type": "training",
      "description": "Training step 475",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:20",
      "total_flops_so_far": 681201396965376.0,
      "budget_used_percent": 0.681201396965376
    },
    {
      "type": "training",
      "description": "Training step 476",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:21",
      "total_flops_so_far": 682632492337152.0,
      "budget_used_percent": 0.682632492337152
    },
    {
      "type": "training",
      "description": "Training step 477",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:21",
      "total_flops_so_far": 684063587708928.0,
      "budget_used_percent": 0.684063587708928
    },
    {
      "type": "training",
      "description": "Training step 478",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:21",
      "total_flops_so_far": 685494683080704.0,
      "budget_used_percent": 0.685494683080704
    },
    {
      "type": "training",
      "description": "Training step 479",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:21",
      "total_flops_so_far": 686925778452480.0,
      "budget_used_percent": 0.68692577845248
    },
    {
      "type": "training",
      "description": "Training step 480",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:21",
      "total_flops_so_far": 688356873824256.0,
      "budget_used_percent": 0.6883568738242559
    },
    {
      "type": "training",
      "description": "Training step 481",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:21",
      "total_flops_so_far": 689787969196032.0,
      "budget_used_percent": 0.689787969196032
    },
    {
      "type": "training",
      "description": "Training step 482",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:21",
      "total_flops_so_far": 691219064567808.0,
      "budget_used_percent": 0.691219064567808
    },
    {
      "type": "training",
      "description": "Training step 483",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:21",
      "total_flops_so_far": 692650159939584.0,
      "budget_used_percent": 0.692650159939584
    },
    {
      "type": "training",
      "description": "Training step 484",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:22",
      "total_flops_so_far": 694081255311360.0,
      "budget_used_percent": 0.69408125531136
    },
    {
      "type": "training",
      "description": "Training step 485",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:22",
      "total_flops_so_far": 695512350683136.0,
      "budget_used_percent": 0.695512350683136
    },
    {
      "type": "training",
      "description": "Training step 486",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:22",
      "total_flops_so_far": 696943446054912.0,
      "budget_used_percent": 0.696943446054912
    },
    {
      "type": "training",
      "description": "Training step 487",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:22",
      "total_flops_so_far": 698374541426688.0,
      "budget_used_percent": 0.698374541426688
    },
    {
      "type": "training",
      "description": "Training step 488",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:22",
      "total_flops_so_far": 699805636798464.0,
      "budget_used_percent": 0.699805636798464
    },
    {
      "type": "training",
      "description": "Training step 489",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:22",
      "total_flops_so_far": 701236732170240.0,
      "budget_used_percent": 0.7012367321702401
    },
    {
      "type": "training",
      "description": "Training step 490",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:22",
      "total_flops_so_far": 702667827542016.0,
      "budget_used_percent": 0.7026678275420161
    },
    {
      "type": "training",
      "description": "Training step 491",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:22",
      "total_flops_so_far": 704098922913792.0,
      "budget_used_percent": 0.704098922913792
    },
    {
      "type": "training",
      "description": "Training step 492",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:23",
      "total_flops_so_far": 705530018285568.0,
      "budget_used_percent": 0.7055300182855679
    },
    {
      "type": "training",
      "description": "Training step 493",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:23",
      "total_flops_so_far": 706961113657344.0,
      "budget_used_percent": 0.706961113657344
    },
    {
      "type": "training",
      "description": "Training step 494",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:23",
      "total_flops_so_far": 708392209029120.0,
      "budget_used_percent": 0.70839220902912
    },
    {
      "type": "training",
      "description": "Training step 495",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:23",
      "total_flops_so_far": 709823304400896.0,
      "budget_used_percent": 0.709823304400896
    },
    {
      "type": "training",
      "description": "Training step 496",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:23",
      "total_flops_so_far": 711254399772672.0,
      "budget_used_percent": 0.7112543997726719
    },
    {
      "type": "training",
      "description": "Training step 497",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:23",
      "total_flops_so_far": 712685495144448.0,
      "budget_used_percent": 0.712685495144448
    },
    {
      "type": "training",
      "description": "Training step 498",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:23",
      "total_flops_so_far": 714116590516224.0,
      "budget_used_percent": 0.714116590516224
    },
    {
      "type": "training",
      "description": "Training step 499",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:48:24",
      "total_flops_so_far": 715547685888000.0,
      "budget_used_percent": 0.715547685888
    },
    {
      "type": "training",
      "description": "Training step 500",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:46",
      "total_flops_so_far": 716978781259776.0,
      "budget_used_percent": 0.716978781259776
    },
    {
      "type": "training",
      "description": "Training step 501",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:46",
      "total_flops_so_far": 718409876631552.0,
      "budget_used_percent": 0.718409876631552
    },
    {
      "type": "training",
      "description": "Training step 502",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:46",
      "total_flops_so_far": 719840972003328.0,
      "budget_used_percent": 0.719840972003328
    },
    {
      "type": "training",
      "description": "Training step 503",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:47",
      "total_flops_so_far": 721272067375104.0,
      "budget_used_percent": 0.721272067375104
    },
    {
      "type": "training",
      "description": "Training step 504",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:47",
      "total_flops_so_far": 722703162746880.0,
      "budget_used_percent": 0.72270316274688
    },
    {
      "type": "training",
      "description": "Training step 505",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:47",
      "total_flops_so_far": 724134258118656.0,
      "budget_used_percent": 0.7241342581186561
    },
    {
      "type": "training",
      "description": "Training step 506",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:47",
      "total_flops_so_far": 725565353490432.0,
      "budget_used_percent": 0.725565353490432
    },
    {
      "type": "training",
      "description": "Training step 507",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:47",
      "total_flops_so_far": 726996448862208.0,
      "budget_used_percent": 0.7269964488622079
    },
    {
      "type": "training",
      "description": "Training step 508",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:47",
      "total_flops_so_far": 728427544233984.0,
      "budget_used_percent": 0.728427544233984
    },
    {
      "type": "training",
      "description": "Training step 509",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:47",
      "total_flops_so_far": 729858639605760.0,
      "budget_used_percent": 0.72985863960576
    },
    {
      "type": "training",
      "description": "Training step 510",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:47",
      "total_flops_so_far": 731289734977536.0,
      "budget_used_percent": 0.731289734977536
    },
    {
      "type": "training",
      "description": "Training step 511",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:48",
      "total_flops_so_far": 732720830349312.0,
      "budget_used_percent": 0.732720830349312
    },
    {
      "type": "training",
      "description": "Training step 512",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:48",
      "total_flops_so_far": 734151925721088.0,
      "budget_used_percent": 0.734151925721088
    },
    {
      "type": "training",
      "description": "Training step 513",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:48",
      "total_flops_so_far": 735583021092864.0,
      "budget_used_percent": 0.735583021092864
    },
    {
      "type": "training",
      "description": "Training step 514",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:48",
      "total_flops_so_far": 737014116464640.0,
      "budget_used_percent": 0.73701411646464
    },
    {
      "type": "training",
      "description": "Training step 515",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:48",
      "total_flops_so_far": 738445211836416.0,
      "budget_used_percent": 0.738445211836416
    },
    {
      "type": "training",
      "description": "Training step 516",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:48",
      "total_flops_so_far": 739876307208192.0,
      "budget_used_percent": 0.7398763072081921
    },
    {
      "type": "training",
      "description": "Training step 517",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:48",
      "total_flops_so_far": 741307402579968.0,
      "budget_used_percent": 0.741307402579968
    },
    {
      "type": "training",
      "description": "Training step 518",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:48",
      "total_flops_so_far": 742738497951744.0,
      "budget_used_percent": 0.742738497951744
    },
    {
      "type": "training",
      "description": "Training step 519",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:49",
      "total_flops_so_far": 744169593323520.0,
      "budget_used_percent": 0.74416959332352
    },
    {
      "type": "training",
      "description": "Training step 520",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:49",
      "total_flops_so_far": 745600688695296.0,
      "budget_used_percent": 0.745600688695296
    },
    {
      "type": "training",
      "description": "Training step 521",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:49",
      "total_flops_so_far": 747031784067072.0,
      "budget_used_percent": 0.747031784067072
    },
    {
      "type": "training",
      "description": "Training step 522",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:49",
      "total_flops_so_far": 748462879438848.0,
      "budget_used_percent": 0.7484628794388479
    },
    {
      "type": "training",
      "description": "Training step 523",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:49",
      "total_flops_so_far": 749893974810624.0,
      "budget_used_percent": 0.7498939748106239
    },
    {
      "type": "training",
      "description": "Training step 524",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:49",
      "total_flops_so_far": 751325070182400.0,
      "budget_used_percent": 0.7513250701824
    },
    {
      "type": "training",
      "description": "Training step 525",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:49",
      "total_flops_so_far": 752756165554176.0,
      "budget_used_percent": 0.752756165554176
    },
    {
      "type": "training",
      "description": "Training step 526",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:50",
      "total_flops_so_far": 754187260925952.0,
      "budget_used_percent": 0.754187260925952
    },
    {
      "type": "training",
      "description": "Training step 527",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:50",
      "total_flops_so_far": 755618356297728.0,
      "budget_used_percent": 0.755618356297728
    },
    {
      "type": "training",
      "description": "Training step 528",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:50",
      "total_flops_so_far": 757049451669504.0,
      "budget_used_percent": 0.757049451669504
    },
    {
      "type": "training",
      "description": "Training step 529",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:50",
      "total_flops_so_far": 758480547041280.0,
      "budget_used_percent": 0.75848054704128
    },
    {
      "type": "training",
      "description": "Training step 530",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:50",
      "total_flops_so_far": 759911642413056.0,
      "budget_used_percent": 0.759911642413056
    },
    {
      "type": "training",
      "description": "Training step 531",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:50",
      "total_flops_so_far": 761342737784832.0,
      "budget_used_percent": 0.761342737784832
    },
    {
      "type": "training",
      "description": "Training step 532",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:50",
      "total_flops_so_far": 762773833156608.0,
      "budget_used_percent": 0.7627738331566081
    },
    {
      "type": "training",
      "description": "Training step 533",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:50",
      "total_flops_so_far": 764204928528384.0,
      "budget_used_percent": 0.764204928528384
    },
    {
      "type": "training",
      "description": "Training step 534",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:51",
      "total_flops_so_far": 765636023900160.0,
      "budget_used_percent": 0.76563602390016
    },
    {
      "type": "training",
      "description": "Training step 535",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:51",
      "total_flops_so_far": 767067119271936.0,
      "budget_used_percent": 0.767067119271936
    },
    {
      "type": "training",
      "description": "Training step 536",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:51",
      "total_flops_so_far": 768498214643712.0,
      "budget_used_percent": 0.768498214643712
    },
    {
      "type": "training",
      "description": "Training step 537",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:51",
      "total_flops_so_far": 769929310015488.0,
      "budget_used_percent": 0.769929310015488
    },
    {
      "type": "training",
      "description": "Training step 538",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:51",
      "total_flops_so_far": 771360405387264.0,
      "budget_used_percent": 0.7713604053872639
    },
    {
      "type": "training",
      "description": "Training step 539",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:51",
      "total_flops_so_far": 772791500759040.0,
      "budget_used_percent": 0.77279150075904
    },
    {
      "type": "training",
      "description": "Training step 540",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:51",
      "total_flops_so_far": 774222596130816.0,
      "budget_used_percent": 0.774222596130816
    },
    {
      "type": "training",
      "description": "Training step 541",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:51",
      "total_flops_so_far": 775653691502592.0,
      "budget_used_percent": 0.775653691502592
    },
    {
      "type": "training",
      "description": "Training step 542",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:52",
      "total_flops_so_far": 777084786874368.0,
      "budget_used_percent": 0.777084786874368
    },
    {
      "type": "training",
      "description": "Training step 543",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:52",
      "total_flops_so_far": 778515882246144.0,
      "budget_used_percent": 0.778515882246144
    },
    {
      "type": "training",
      "description": "Training step 544",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:52",
      "total_flops_so_far": 779946977617920.0,
      "budget_used_percent": 0.77994697761792
    },
    {
      "type": "training",
      "description": "Training step 545",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:52",
      "total_flops_so_far": 781378072989696.0,
      "budget_used_percent": 0.781378072989696
    },
    {
      "type": "training",
      "description": "Training step 546",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:52",
      "total_flops_so_far": 782809168361472.0,
      "budget_used_percent": 0.782809168361472
    },
    {
      "type": "training",
      "description": "Training step 547",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:52",
      "total_flops_so_far": 784240263733248.0,
      "budget_used_percent": 0.7842402637332481
    },
    {
      "type": "training",
      "description": "Training step 548",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:52",
      "total_flops_so_far": 785671359105024.0,
      "budget_used_percent": 0.785671359105024
    },
    {
      "type": "training",
      "description": "Training step 549",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:53",
      "total_flops_so_far": 787102454476800.0,
      "budget_used_percent": 0.7871024544768
    },
    {
      "type": "training",
      "description": "Training step 550",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:53",
      "total_flops_so_far": 788533549848576.0,
      "budget_used_percent": 0.7885335498485759
    },
    {
      "type": "training",
      "description": "Training step 551",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:53",
      "total_flops_so_far": 789964645220352.0,
      "budget_used_percent": 0.7899646452203519
    },
    {
      "type": "training",
      "description": "Training step 552",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:53",
      "total_flops_so_far": 791395740592128.0,
      "budget_used_percent": 0.791395740592128
    },
    {
      "type": "training",
      "description": "Training step 553",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:53",
      "total_flops_so_far": 792826835963904.0,
      "budget_used_percent": 0.7928268359639039
    },
    {
      "type": "training",
      "description": "Training step 554",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:53",
      "total_flops_so_far": 794257931335680.0,
      "budget_used_percent": 0.79425793133568
    },
    {
      "type": "training",
      "description": "Training step 555",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:53",
      "total_flops_so_far": 795689026707456.0,
      "budget_used_percent": 0.795689026707456
    },
    {
      "type": "training",
      "description": "Training step 556",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:53",
      "total_flops_so_far": 797120122079232.0,
      "budget_used_percent": 0.7971201220792321
    },
    {
      "type": "training",
      "description": "Training step 557",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:54",
      "total_flops_so_far": 798551217451008.0,
      "budget_used_percent": 0.798551217451008
    },
    {
      "type": "training",
      "description": "Training step 558",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:54",
      "total_flops_so_far": 799982312822784.0,
      "budget_used_percent": 0.799982312822784
    },
    {
      "type": "training",
      "description": "Training step 559",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:54",
      "total_flops_so_far": 801413408194560.0,
      "budget_used_percent": 0.8014134081945601
    },
    {
      "type": "training",
      "description": "Training step 560",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:54",
      "total_flops_so_far": 802844503566336.0,
      "budget_used_percent": 0.802844503566336
    },
    {
      "type": "training",
      "description": "Training step 561",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:54",
      "total_flops_so_far": 804275598938112.0,
      "budget_used_percent": 0.8042755989381121
    },
    {
      "type": "training",
      "description": "Training step 562",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:54",
      "total_flops_so_far": 805706694309888.0,
      "budget_used_percent": 0.8057066943098881
    },
    {
      "type": "training",
      "description": "Training step 563",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:54",
      "total_flops_so_far": 807137789681664.0,
      "budget_used_percent": 0.8071377896816639
    },
    {
      "type": "training",
      "description": "Training step 564",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:54",
      "total_flops_so_far": 808568885053440.0,
      "budget_used_percent": 0.80856888505344
    },
    {
      "type": "training",
      "description": "Training step 565",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:55",
      "total_flops_so_far": 809999980425216.0,
      "budget_used_percent": 0.8099999804252159
    },
    {
      "type": "training",
      "description": "Training step 566",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:55",
      "total_flops_so_far": 811431075796992.0,
      "budget_used_percent": 0.811431075796992
    },
    {
      "type": "training",
      "description": "Training step 567",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:55",
      "total_flops_so_far": 812862171168768.0,
      "budget_used_percent": 0.812862171168768
    },
    {
      "type": "training",
      "description": "Training step 568",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:55",
      "total_flops_so_far": 814293266540544.0,
      "budget_used_percent": 0.8142932665405439
    },
    {
      "type": "training",
      "description": "Training step 569",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:55",
      "total_flops_so_far": 815724361912320.0,
      "budget_used_percent": 0.81572436191232
    },
    {
      "type": "training",
      "description": "Training step 570",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:55",
      "total_flops_so_far": 817155457284096.0,
      "budget_used_percent": 0.817155457284096
    },
    {
      "type": "training",
      "description": "Training step 571",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:55",
      "total_flops_so_far": 818586552655872.0,
      "budget_used_percent": 0.8185865526558721
    },
    {
      "type": "training",
      "description": "Training step 572",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:56",
      "total_flops_so_far": 820017648027648.0,
      "budget_used_percent": 0.820017648027648
    },
    {
      "type": "training",
      "description": "Training step 573",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:56",
      "total_flops_so_far": 821448743399424.0,
      "budget_used_percent": 0.821448743399424
    },
    {
      "type": "training",
      "description": "Training step 574",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:56",
      "total_flops_so_far": 822879838771200.0,
      "budget_used_percent": 0.8228798387712001
    },
    {
      "type": "training",
      "description": "Training step 575",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:56",
      "total_flops_so_far": 824310934142976.0,
      "budget_used_percent": 0.824310934142976
    },
    {
      "type": "training",
      "description": "Training step 576",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:56",
      "total_flops_so_far": 825742029514752.0,
      "budget_used_percent": 0.8257420295147521
    },
    {
      "type": "training",
      "description": "Training step 577",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:56",
      "total_flops_so_far": 827173124886528.0,
      "budget_used_percent": 0.8271731248865279
    },
    {
      "type": "training",
      "description": "Training step 578",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:56",
      "total_flops_so_far": 828604220258304.0,
      "budget_used_percent": 0.8286042202583039
    },
    {
      "type": "training",
      "description": "Training step 579",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:56",
      "total_flops_so_far": 830035315630080.0,
      "budget_used_percent": 0.83003531563008
    },
    {
      "type": "training",
      "description": "Training step 580",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:57",
      "total_flops_so_far": 831466411001856.0,
      "budget_used_percent": 0.8314664110018559
    },
    {
      "type": "training",
      "description": "Training step 581",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:57",
      "total_flops_so_far": 832897506373632.0,
      "budget_used_percent": 0.832897506373632
    },
    {
      "type": "training",
      "description": "Training step 582",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:57",
      "total_flops_so_far": 834328601745408.0,
      "budget_used_percent": 0.834328601745408
    },
    {
      "type": "training",
      "description": "Training step 583",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:57",
      "total_flops_so_far": 835759697117184.0,
      "budget_used_percent": 0.8357596971171839
    },
    {
      "type": "training",
      "description": "Training step 584",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:57",
      "total_flops_so_far": 837190792488960.0,
      "budget_used_percent": 0.83719079248896
    },
    {
      "type": "training",
      "description": "Training step 585",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:57",
      "total_flops_so_far": 838621887860736.0,
      "budget_used_percent": 0.838621887860736
    },
    {
      "type": "training",
      "description": "Training step 586",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:57",
      "total_flops_so_far": 840052983232512.0,
      "budget_used_percent": 0.8400529832325121
    },
    {
      "type": "training",
      "description": "Training step 587",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:58",
      "total_flops_so_far": 841484078604288.0,
      "budget_used_percent": 0.841484078604288
    },
    {
      "type": "training",
      "description": "Training step 588",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:58",
      "total_flops_so_far": 842915173976064.0,
      "budget_used_percent": 0.842915173976064
    },
    {
      "type": "training",
      "description": "Training step 589",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:58",
      "total_flops_so_far": 844346269347840.0,
      "budget_used_percent": 0.8443462693478401
    },
    {
      "type": "training",
      "description": "Training step 590",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:58",
      "total_flops_so_far": 845777364719616.0,
      "budget_used_percent": 0.845777364719616
    },
    {
      "type": "training",
      "description": "Training step 591",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:58",
      "total_flops_so_far": 847208460091392.0,
      "budget_used_percent": 0.8472084600913921
    },
    {
      "type": "training",
      "description": "Training step 592",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:58",
      "total_flops_so_far": 848639555463168.0,
      "budget_used_percent": 0.8486395554631679
    },
    {
      "type": "training",
      "description": "Training step 593",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:58",
      "total_flops_so_far": 850070650834944.0,
      "budget_used_percent": 0.8500706508349439
    },
    {
      "type": "training",
      "description": "Training step 594",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:59",
      "total_flops_so_far": 851501746206720.0,
      "budget_used_percent": 0.85150174620672
    },
    {
      "type": "training",
      "description": "Training step 595",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:59",
      "total_flops_so_far": 852932841578496.0,
      "budget_used_percent": 0.8529328415784959
    },
    {
      "type": "training",
      "description": "Training step 596",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:59",
      "total_flops_so_far": 854363936950272.0,
      "budget_used_percent": 0.854363936950272
    },
    {
      "type": "training",
      "description": "Training step 597",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:59",
      "total_flops_so_far": 855795032322048.0,
      "budget_used_percent": 0.855795032322048
    },
    {
      "type": "training",
      "description": "Training step 598",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:59",
      "total_flops_so_far": 857226127693824.0,
      "budget_used_percent": 0.8572261276938241
    },
    {
      "type": "training",
      "description": "Training step 599",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:59",
      "total_flops_so_far": 858657223065600.0,
      "budget_used_percent": 0.8586572230656
    },
    {
      "type": "training",
      "description": "Training step 600",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:59",
      "total_flops_so_far": 860088318437376.0,
      "budget_used_percent": 0.860088318437376
    },
    {
      "type": "training",
      "description": "Training step 601",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:50:59",
      "total_flops_so_far": 861519413809152.0,
      "budget_used_percent": 0.8615194138091521
    },
    {
      "type": "training",
      "description": "Training step 602",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:00",
      "total_flops_so_far": 862950509180928.0,
      "budget_used_percent": 0.862950509180928
    },
    {
      "type": "training",
      "description": "Training step 603",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:00",
      "total_flops_so_far": 864381604552704.0,
      "budget_used_percent": 0.8643816045527041
    },
    {
      "type": "training",
      "description": "Training step 604",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:00",
      "total_flops_so_far": 865812699924480.0,
      "budget_used_percent": 0.86581269992448
    },
    {
      "type": "training",
      "description": "Training step 605",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:00",
      "total_flops_so_far": 867243795296256.0,
      "budget_used_percent": 0.867243795296256
    },
    {
      "type": "training",
      "description": "Training step 606",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:00",
      "total_flops_so_far": 868674890668032.0,
      "budget_used_percent": 0.868674890668032
    },
    {
      "type": "training",
      "description": "Training step 607",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:00",
      "total_flops_so_far": 870105986039808.0,
      "budget_used_percent": 0.8701059860398079
    },
    {
      "type": "training",
      "description": "Training step 608",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:00",
      "total_flops_so_far": 871537081411584.0,
      "budget_used_percent": 0.871537081411584
    },
    {
      "type": "training",
      "description": "Training step 609",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:01",
      "total_flops_so_far": 872968176783360.0,
      "budget_used_percent": 0.87296817678336
    },
    {
      "type": "training",
      "description": "Training step 610",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:01",
      "total_flops_so_far": 874399272155136.0,
      "budget_used_percent": 0.8743992721551359
    },
    {
      "type": "training",
      "description": "Training step 611",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:01",
      "total_flops_so_far": 875830367526912.0,
      "budget_used_percent": 0.875830367526912
    },
    {
      "type": "training",
      "description": "Training step 612",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:01",
      "total_flops_so_far": 877261462898688.0,
      "budget_used_percent": 0.877261462898688
    },
    {
      "type": "training",
      "description": "Training step 613",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:01",
      "total_flops_so_far": 878692558270464.0,
      "budget_used_percent": 0.8786925582704641
    },
    {
      "type": "training",
      "description": "Training step 614",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:01",
      "total_flops_so_far": 880123653642240.0,
      "budget_used_percent": 0.88012365364224
    },
    {
      "type": "training",
      "description": "Training step 615",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:01",
      "total_flops_so_far": 881554749014016.0,
      "budget_used_percent": 0.881554749014016
    },
    {
      "type": "training",
      "description": "Training step 616",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:01",
      "total_flops_so_far": 882985844385792.0,
      "budget_used_percent": 0.8829858443857921
    },
    {
      "type": "training",
      "description": "Training step 617",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:02",
      "total_flops_so_far": 884416939757568.0,
      "budget_used_percent": 0.884416939757568
    },
    {
      "type": "training",
      "description": "Training step 618",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:02",
      "total_flops_so_far": 885848035129344.0,
      "budget_used_percent": 0.8858480351293441
    },
    {
      "type": "training",
      "description": "Training step 619",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:02",
      "total_flops_so_far": 887279130501120.0,
      "budget_used_percent": 0.88727913050112
    },
    {
      "type": "training",
      "description": "Training step 620",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:02",
      "total_flops_so_far": 888710225872896.0,
      "budget_used_percent": 0.8887102258728959
    },
    {
      "type": "training",
      "description": "Training step 621",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:02",
      "total_flops_so_far": 890141321244672.0,
      "budget_used_percent": 0.890141321244672
    },
    {
      "type": "training",
      "description": "Training step 622",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:02",
      "total_flops_so_far": 891572416616448.0,
      "budget_used_percent": 0.8915724166164479
    },
    {
      "type": "training",
      "description": "Training step 623",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:02",
      "total_flops_so_far": 893003511988224.0,
      "budget_used_percent": 0.893003511988224
    },
    {
      "type": "training",
      "description": "Training step 624",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:02",
      "total_flops_so_far": 894434607360000.0,
      "budget_used_percent": 0.89443460736
    },
    {
      "type": "training",
      "description": "Training step 625",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:03",
      "total_flops_so_far": 895865702731776.0,
      "budget_used_percent": 0.8958657027317759
    },
    {
      "type": "training",
      "description": "Training step 626",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:03",
      "total_flops_so_far": 897296798103552.0,
      "budget_used_percent": 0.897296798103552
    },
    {
      "type": "training",
      "description": "Training step 627",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:03",
      "total_flops_so_far": 898727893475328.0,
      "budget_used_percent": 0.898727893475328
    },
    {
      "type": "training",
      "description": "Training step 628",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:03",
      "total_flops_so_far": 900158988847104.0,
      "budget_used_percent": 0.9001589888471041
    },
    {
      "type": "training",
      "description": "Training step 629",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:03",
      "total_flops_so_far": 901590084218880.0,
      "budget_used_percent": 0.90159008421888
    },
    {
      "type": "training",
      "description": "Training step 630",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:03",
      "total_flops_so_far": 903021179590656.0,
      "budget_used_percent": 0.903021179590656
    },
    {
      "type": "training",
      "description": "Training step 631",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:03",
      "total_flops_so_far": 904452274962432.0,
      "budget_used_percent": 0.904452274962432
    },
    {
      "type": "training",
      "description": "Training step 632",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:04",
      "total_flops_so_far": 905883370334208.0,
      "budget_used_percent": 0.905883370334208
    },
    {
      "type": "training",
      "description": "Training step 633",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:04",
      "total_flops_so_far": 907314465705984.0,
      "budget_used_percent": 0.9073144657059841
    },
    {
      "type": "training",
      "description": "Training step 634",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:04",
      "total_flops_so_far": 908745561077760.0,
      "budget_used_percent": 0.90874556107776
    },
    {
      "type": "training",
      "description": "Training step 635",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:04",
      "total_flops_so_far": 910176656449536.0,
      "budget_used_percent": 0.9101766564495359
    },
    {
      "type": "training",
      "description": "Training step 636",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:04",
      "total_flops_so_far": 911607751821312.0,
      "budget_used_percent": 0.911607751821312
    },
    {
      "type": "training",
      "description": "Training step 637",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:04",
      "total_flops_so_far": 913038847193088.0,
      "budget_used_percent": 0.9130388471930879
    },
    {
      "type": "training",
      "description": "Training step 638",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:04",
      "total_flops_so_far": 914469942564864.0,
      "budget_used_percent": 0.914469942564864
    },
    {
      "type": "training",
      "description": "Training step 639",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:04",
      "total_flops_so_far": 915901037936640.0,
      "budget_used_percent": 0.91590103793664
    },
    {
      "type": "training",
      "description": "Training step 640",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:05",
      "total_flops_so_far": 917332133308416.0,
      "budget_used_percent": 0.9173321333084161
    },
    {
      "type": "training",
      "description": "Training step 641",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:05",
      "total_flops_so_far": 918763228680192.0,
      "budget_used_percent": 0.918763228680192
    },
    {
      "type": "training",
      "description": "Training step 642",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:05",
      "total_flops_so_far": 920194324051968.0,
      "budget_used_percent": 0.920194324051968
    },
    {
      "type": "training",
      "description": "Training step 643",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:05",
      "total_flops_so_far": 921625419423744.0,
      "budget_used_percent": 0.9216254194237441
    },
    {
      "type": "training",
      "description": "Training step 644",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:05",
      "total_flops_so_far": 923056514795520.0,
      "budget_used_percent": 0.92305651479552
    },
    {
      "type": "training",
      "description": "Training step 645",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:05",
      "total_flops_so_far": 924487610167296.0,
      "budget_used_percent": 0.9244876101672961
    },
    {
      "type": "training",
      "description": "Training step 646",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:05",
      "total_flops_so_far": 925918705539072.0,
      "budget_used_percent": 0.925918705539072
    },
    {
      "type": "training",
      "description": "Training step 647",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:06",
      "total_flops_so_far": 927349800910848.0,
      "budget_used_percent": 0.927349800910848
    },
    {
      "type": "training",
      "description": "Training step 648",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:06",
      "total_flops_so_far": 928780896282624.0,
      "budget_used_percent": 0.9287808962826241
    },
    {
      "type": "training",
      "description": "Training step 649",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:06",
      "total_flops_so_far": 930211991654400.0,
      "budget_used_percent": 0.9302119916543999
    },
    {
      "type": "training",
      "description": "Training step 650",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:06",
      "total_flops_so_far": 931643087026176.0,
      "budget_used_percent": 0.931643087026176
    },
    {
      "type": "training",
      "description": "Training step 651",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:06",
      "total_flops_so_far": 933074182397952.0,
      "budget_used_percent": 0.933074182397952
    },
    {
      "type": "training",
      "description": "Training step 652",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:06",
      "total_flops_so_far": 934505277769728.0,
      "budget_used_percent": 0.9345052777697279
    },
    {
      "type": "training",
      "description": "Training step 653",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:06",
      "total_flops_so_far": 935936373141504.0,
      "budget_used_percent": 0.935936373141504
    },
    {
      "type": "training",
      "description": "Training step 654",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:06",
      "total_flops_so_far": 937367468513280.0,
      "budget_used_percent": 0.93736746851328
    },
    {
      "type": "training",
      "description": "Training step 655",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:07",
      "total_flops_so_far": 938798563885056.0,
      "budget_used_percent": 0.9387985638850561
    },
    {
      "type": "training",
      "description": "Training step 656",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:07",
      "total_flops_so_far": 940229659256832.0,
      "budget_used_percent": 0.940229659256832
    },
    {
      "type": "training",
      "description": "Training step 657",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:07",
      "total_flops_so_far": 941660754628608.0,
      "budget_used_percent": 0.941660754628608
    },
    {
      "type": "training",
      "description": "Training step 658",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:07",
      "total_flops_so_far": 943091850000384.0,
      "budget_used_percent": 0.943091850000384
    },
    {
      "type": "training",
      "description": "Training step 659",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:07",
      "total_flops_so_far": 944522945372160.0,
      "budget_used_percent": 0.94452294537216
    },
    {
      "type": "training",
      "description": "Training step 660",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:07",
      "total_flops_so_far": 945954040743936.0,
      "budget_used_percent": 0.9459540407439361
    },
    {
      "type": "training",
      "description": "Training step 661",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:07",
      "total_flops_so_far": 947385136115712.0,
      "budget_used_percent": 0.947385136115712
    },
    {
      "type": "training",
      "description": "Training step 662",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:08",
      "total_flops_so_far": 948816231487488.0,
      "budget_used_percent": 0.948816231487488
    },
    {
      "type": "training",
      "description": "Training step 663",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:08",
      "total_flops_so_far": 950247326859264.0,
      "budget_used_percent": 0.950247326859264
    },
    {
      "type": "training",
      "description": "Training step 664",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:08",
      "total_flops_so_far": 951678422231040.0,
      "budget_used_percent": 0.9516784222310399
    },
    {
      "type": "training",
      "description": "Training step 665",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:08",
      "total_flops_so_far": 953109517602816.0,
      "budget_used_percent": 0.953109517602816
    },
    {
      "type": "training",
      "description": "Training step 666",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:08",
      "total_flops_so_far": 954540612974592.0,
      "budget_used_percent": 0.954540612974592
    },
    {
      "type": "training",
      "description": "Training step 667",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:08",
      "total_flops_so_far": 955971708346368.0,
      "budget_used_percent": 0.9559717083463679
    },
    {
      "type": "training",
      "description": "Training step 668",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:08",
      "total_flops_so_far": 957402803718144.0,
      "budget_used_percent": 0.957402803718144
    },
    {
      "type": "training",
      "description": "Training step 669",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:08",
      "total_flops_so_far": 958833899089920.0,
      "budget_used_percent": 0.95883389908992
    },
    {
      "type": "training",
      "description": "Training step 670",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:09",
      "total_flops_so_far": 960264994461696.0,
      "budget_used_percent": 0.9602649944616961
    },
    {
      "type": "training",
      "description": "Training step 671",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:09",
      "total_flops_so_far": 961696089833472.0,
      "budget_used_percent": 0.961696089833472
    },
    {
      "type": "training",
      "description": "Training step 672",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:09",
      "total_flops_so_far": 963127185205248.0,
      "budget_used_percent": 0.9631271852052479
    },
    {
      "type": "training",
      "description": "Training step 673",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:09",
      "total_flops_so_far": 964558280577024.0,
      "budget_used_percent": 0.964558280577024
    },
    {
      "type": "training",
      "description": "Training step 674",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:09",
      "total_flops_so_far": 965989375948800.0,
      "budget_used_percent": 0.9659893759488
    },
    {
      "type": "training",
      "description": "Training step 675",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:09",
      "total_flops_so_far": 967420471320576.0,
      "budget_used_percent": 0.9674204713205761
    },
    {
      "type": "training",
      "description": "Training step 676",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:09",
      "total_flops_so_far": 968851566692352.0,
      "budget_used_percent": 0.968851566692352
    },
    {
      "type": "training",
      "description": "Training step 677",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:10",
      "total_flops_so_far": 970282662064128.0,
      "budget_used_percent": 0.9702826620641279
    },
    {
      "type": "training",
      "description": "Training step 678",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:10",
      "total_flops_so_far": 971713757435904.0,
      "budget_used_percent": 0.971713757435904
    },
    {
      "type": "training",
      "description": "Training step 679",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:10",
      "total_flops_so_far": 973144852807680.0,
      "budget_used_percent": 0.9731448528076799
    },
    {
      "type": "training",
      "description": "Training step 680",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:10",
      "total_flops_so_far": 974575948179456.0,
      "budget_used_percent": 0.974575948179456
    },
    {
      "type": "training",
      "description": "Training step 681",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:10",
      "total_flops_so_far": 976007043551232.0,
      "budget_used_percent": 0.976007043551232
    },
    {
      "type": "training",
      "description": "Training step 682",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:10",
      "total_flops_so_far": 977438138923008.0,
      "budget_used_percent": 0.9774381389230081
    },
    {
      "type": "training",
      "description": "Training step 683",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:10",
      "total_flops_so_far": 978869234294784.0,
      "budget_used_percent": 0.978869234294784
    },
    {
      "type": "training",
      "description": "Training step 684",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:10",
      "total_flops_so_far": 980300329666560.0,
      "budget_used_percent": 0.98030032966656
    },
    {
      "type": "training",
      "description": "Training step 685",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:11",
      "total_flops_so_far": 981731425038336.0,
      "budget_used_percent": 0.981731425038336
    },
    {
      "type": "training",
      "description": "Training step 686",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:11",
      "total_flops_so_far": 983162520410112.0,
      "budget_used_percent": 0.983162520410112
    },
    {
      "type": "training",
      "description": "Training step 687",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:11",
      "total_flops_so_far": 984593615781888.0,
      "budget_used_percent": 0.9845936157818881
    },
    {
      "type": "training",
      "description": "Training step 688",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:11",
      "total_flops_so_far": 986024711153664.0,
      "budget_used_percent": 0.986024711153664
    },
    {
      "type": "training",
      "description": "Training step 689",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:11",
      "total_flops_so_far": 987455806525440.0,
      "budget_used_percent": 0.98745580652544
    },
    {
      "type": "training",
      "description": "Training step 690",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:11",
      "total_flops_so_far": 988886901897216.0,
      "budget_used_percent": 0.9888869018972161
    },
    {
      "type": "training",
      "description": "Training step 691",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:11",
      "total_flops_so_far": 990317997268992.0,
      "budget_used_percent": 0.990317997268992
    },
    {
      "type": "training",
      "description": "Training step 692",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:12",
      "total_flops_so_far": 991749092640768.0,
      "budget_used_percent": 0.991749092640768
    },
    {
      "type": "training",
      "description": "Training step 693",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:12",
      "total_flops_so_far": 993180188012544.0,
      "budget_used_percent": 0.993180188012544
    },
    {
      "type": "training",
      "description": "Training step 694",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:12",
      "total_flops_so_far": 994611283384320.0,
      "budget_used_percent": 0.9946112833843199
    },
    {
      "type": "training",
      "description": "Training step 695",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:12",
      "total_flops_so_far": 996042378756096.0,
      "budget_used_percent": 0.996042378756096
    },
    {
      "type": "training",
      "description": "Training step 696",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:12",
      "total_flops_so_far": 997473474127872.0,
      "budget_used_percent": 0.997473474127872
    },
    {
      "type": "training",
      "description": "Training step 697",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:12",
      "total_flops_so_far": 998904569499648.0,
      "budget_used_percent": 0.9989045694996481
    },
    {
      "type": "training",
      "description": "Training step 698",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:12",
      "total_flops_so_far": 1000335664871424.0,
      "budget_used_percent": 1.000335664871424
    },
    {
      "type": "training",
      "description": "Training step 699",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:13",
      "total_flops_so_far": 1001766760243200.0,
      "budget_used_percent": 1.0017667602431999
    },
    {
      "type": "training",
      "description": "Training step 700",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:13",
      "total_flops_so_far": 1003197855614976.0,
      "budget_used_percent": 1.003197855614976
    },
    {
      "type": "training",
      "description": "Training step 701",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:13",
      "total_flops_so_far": 1004628950986752.0,
      "budget_used_percent": 1.0046289509867519
    },
    {
      "type": "training",
      "description": "Training step 702",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:13",
      "total_flops_so_far": 1006060046358528.0,
      "budget_used_percent": 1.006060046358528
    },
    {
      "type": "training",
      "description": "Training step 703",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:13",
      "total_flops_so_far": 1007491141730304.0,
      "budget_used_percent": 1.007491141730304
    },
    {
      "type": "training",
      "description": "Training step 704",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:13",
      "total_flops_so_far": 1008922237102080.0,
      "budget_used_percent": 1.0089222371020798
    },
    {
      "type": "training",
      "description": "Training step 705",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:13",
      "total_flops_so_far": 1010353332473856.0,
      "budget_used_percent": 1.010353332473856
    },
    {
      "type": "training",
      "description": "Training step 706",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:13",
      "total_flops_so_far": 1011784427845632.0,
      "budget_used_percent": 1.011784427845632
    },
    {
      "type": "training",
      "description": "Training step 707",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:14",
      "total_flops_so_far": 1013215523217408.0,
      "budget_used_percent": 1.013215523217408
    },
    {
      "type": "training",
      "description": "Training step 708",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:14",
      "total_flops_so_far": 1014646618589184.0,
      "budget_used_percent": 1.014646618589184
    },
    {
      "type": "training",
      "description": "Training step 709",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:14",
      "total_flops_so_far": 1016077713960960.0,
      "budget_used_percent": 1.01607771396096
    },
    {
      "type": "training",
      "description": "Training step 710",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:14",
      "total_flops_so_far": 1017508809332736.0,
      "budget_used_percent": 1.017508809332736
    },
    {
      "type": "training",
      "description": "Training step 711",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:14",
      "total_flops_so_far": 1018939904704512.0,
      "budget_used_percent": 1.018939904704512
    },
    {
      "type": "training",
      "description": "Training step 712",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:14",
      "total_flops_so_far": 1020371000076288.0,
      "budget_used_percent": 1.020371000076288
    },
    {
      "type": "training",
      "description": "Training step 713",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:14",
      "total_flops_so_far": 1021802095448064.0,
      "budget_used_percent": 1.021802095448064
    },
    {
      "type": "training",
      "description": "Training step 714",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:15",
      "total_flops_so_far": 1023233190819840.0,
      "budget_used_percent": 1.02323319081984
    },
    {
      "type": "training",
      "description": "Training step 715",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:15",
      "total_flops_so_far": 1024664286191616.0,
      "budget_used_percent": 1.024664286191616
    },
    {
      "type": "training",
      "description": "Training step 716",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:15",
      "total_flops_so_far": 1026095381563392.0,
      "budget_used_percent": 1.026095381563392
    },
    {
      "type": "training",
      "description": "Training step 717",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:15",
      "total_flops_so_far": 1027526476935168.0,
      "budget_used_percent": 1.027526476935168
    },
    {
      "type": "training",
      "description": "Training step 718",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:15",
      "total_flops_so_far": 1028957572306944.0,
      "budget_used_percent": 1.028957572306944
    },
    {
      "type": "training",
      "description": "Training step 719",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:15",
      "total_flops_so_far": 1030388667678720.0,
      "budget_used_percent": 1.03038866767872
    },
    {
      "type": "training",
      "description": "Training step 720",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:15",
      "total_flops_so_far": 1031819763050496.0,
      "budget_used_percent": 1.031819763050496
    },
    {
      "type": "training",
      "description": "Training step 721",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:15",
      "total_flops_so_far": 1033250858422272.0,
      "budget_used_percent": 1.033250858422272
    },
    {
      "type": "training",
      "description": "Training step 722",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:16",
      "total_flops_so_far": 1034681953794048.0,
      "budget_used_percent": 1.0346819537940481
    },
    {
      "type": "training",
      "description": "Training step 723",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:16",
      "total_flops_so_far": 1036113049165824.0,
      "budget_used_percent": 1.036113049165824
    },
    {
      "type": "training",
      "description": "Training step 724",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:16",
      "total_flops_so_far": 1037544144537600.0,
      "budget_used_percent": 1.0375441445376001
    },
    {
      "type": "training",
      "description": "Training step 725",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:16",
      "total_flops_so_far": 1038975239909376.0,
      "budget_used_percent": 1.0389752399093761
    },
    {
      "type": "training",
      "description": "Training step 726",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:16",
      "total_flops_so_far": 1040406335281152.0,
      "budget_used_percent": 1.040406335281152
    },
    {
      "type": "training",
      "description": "Training step 727",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:16",
      "total_flops_so_far": 1041837430652928.0,
      "budget_used_percent": 1.041837430652928
    },
    {
      "type": "training",
      "description": "Training step 728",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:16",
      "total_flops_so_far": 1043268526024704.0,
      "budget_used_percent": 1.0432685260247039
    },
    {
      "type": "training",
      "description": "Training step 729",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:17",
      "total_flops_so_far": 1044699621396480.0,
      "budget_used_percent": 1.04469962139648
    },
    {
      "type": "training",
      "description": "Training step 730",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:17",
      "total_flops_so_far": 1046130716768256.0,
      "budget_used_percent": 1.046130716768256
    },
    {
      "type": "training",
      "description": "Training step 731",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:17",
      "total_flops_so_far": 1047561812140032.0,
      "budget_used_percent": 1.0475618121400319
    },
    {
      "type": "training",
      "description": "Training step 732",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:17",
      "total_flops_so_far": 1048992907511808.0,
      "budget_used_percent": 1.048992907511808
    },
    {
      "type": "training",
      "description": "Training step 733",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:17",
      "total_flops_so_far": 1050424002883584.0,
      "budget_used_percent": 1.050424002883584
    },
    {
      "type": "training",
      "description": "Training step 734",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:17",
      "total_flops_so_far": 1051855098255360.0,
      "budget_used_percent": 1.05185509825536
    },
    {
      "type": "training",
      "description": "Training step 735",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:17",
      "total_flops_so_far": 1053286193627136.0,
      "budget_used_percent": 1.053286193627136
    },
    {
      "type": "training",
      "description": "Training step 736",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:17",
      "total_flops_so_far": 1054717288998912.0,
      "budget_used_percent": 1.054717288998912
    },
    {
      "type": "training",
      "description": "Training step 737",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:18",
      "total_flops_so_far": 1056148384370688.0,
      "budget_used_percent": 1.056148384370688
    },
    {
      "type": "training",
      "description": "Training step 738",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:18",
      "total_flops_so_far": 1057579479742464.0,
      "budget_used_percent": 1.057579479742464
    },
    {
      "type": "training",
      "description": "Training step 739",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:18",
      "total_flops_so_far": 1059010575114240.0,
      "budget_used_percent": 1.05901057511424
    },
    {
      "type": "training",
      "description": "Training step 740",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:18",
      "total_flops_so_far": 1060441670486016.0,
      "budget_used_percent": 1.060441670486016
    },
    {
      "type": "training",
      "description": "Training step 741",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:18",
      "total_flops_so_far": 1061872765857792.0,
      "budget_used_percent": 1.061872765857792
    },
    {
      "type": "training",
      "description": "Training step 742",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:18",
      "total_flops_so_far": 1063303861229568.0,
      "budget_used_percent": 1.063303861229568
    },
    {
      "type": "training",
      "description": "Training step 743",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:18",
      "total_flops_so_far": 1064734956601344.0,
      "budget_used_percent": 1.064734956601344
    },
    {
      "type": "training",
      "description": "Training step 744",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:19",
      "total_flops_so_far": 1066166051973120.0,
      "budget_used_percent": 1.06616605197312
    },
    {
      "type": "training",
      "description": "Training step 745",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:19",
      "total_flops_so_far": 1067597147344896.0,
      "budget_used_percent": 1.067597147344896
    },
    {
      "type": "training",
      "description": "Training step 746",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:19",
      "total_flops_so_far": 1069028242716672.0,
      "budget_used_percent": 1.069028242716672
    },
    {
      "type": "training",
      "description": "Training step 747",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:19",
      "total_flops_so_far": 1070459338088448.0,
      "budget_used_percent": 1.070459338088448
    },
    {
      "type": "training",
      "description": "Training step 748",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:19",
      "total_flops_so_far": 1071890433460224.0,
      "budget_used_percent": 1.071890433460224
    },
    {
      "type": "training",
      "description": "Training step 749",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:19",
      "total_flops_so_far": 1073321528832000.0,
      "budget_used_percent": 1.0733215288320002
    },
    {
      "type": "training",
      "description": "Training step 750",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:19",
      "total_flops_so_far": 1074752624203776.0,
      "budget_used_percent": 1.074752624203776
    },
    {
      "type": "training",
      "description": "Training step 751",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:20",
      "total_flops_so_far": 1076183719575552.0,
      "budget_used_percent": 1.076183719575552
    },
    {
      "type": "training",
      "description": "Training step 752",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:20",
      "total_flops_so_far": 1077614814947328.0,
      "budget_used_percent": 1.077614814947328
    },
    {
      "type": "training",
      "description": "Training step 753",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:20",
      "total_flops_so_far": 1079045910319104.0,
      "budget_used_percent": 1.079045910319104
    },
    {
      "type": "training",
      "description": "Training step 754",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:20",
      "total_flops_so_far": 1080477005690880.0,
      "budget_used_percent": 1.0804770056908801
    },
    {
      "type": "training",
      "description": "Training step 755",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:20",
      "total_flops_so_far": 1081908101062656.0,
      "budget_used_percent": 1.081908101062656
    },
    {
      "type": "training",
      "description": "Training step 756",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:20",
      "total_flops_so_far": 1083339196434432.0,
      "budget_used_percent": 1.0833391964344319
    },
    {
      "type": "training",
      "description": "Training step 757",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:20",
      "total_flops_so_far": 1084770291806208.0,
      "budget_used_percent": 1.084770291806208
    },
    {
      "type": "training",
      "description": "Training step 758",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:20",
      "total_flops_so_far": 1086201387177984.0,
      "budget_used_percent": 1.0862013871779839
    },
    {
      "type": "training",
      "description": "Training step 759",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:21",
      "total_flops_so_far": 1087632482549760.0,
      "budget_used_percent": 1.08763248254976
    },
    {
      "type": "training",
      "description": "Training step 760",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:21",
      "total_flops_so_far": 1089063577921536.0,
      "budget_used_percent": 1.089063577921536
    },
    {
      "type": "training",
      "description": "Training step 761",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:21",
      "total_flops_so_far": 1090494673293312.0,
      "budget_used_percent": 1.0904946732933118
    },
    {
      "type": "training",
      "description": "Training step 762",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:21",
      "total_flops_so_far": 1091925768665088.0,
      "budget_used_percent": 1.091925768665088
    },
    {
      "type": "training",
      "description": "Training step 763",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:21",
      "total_flops_so_far": 1093356864036864.0,
      "budget_used_percent": 1.093356864036864
    },
    {
      "type": "training",
      "description": "Training step 764",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:21",
      "total_flops_so_far": 1094787959408640.0,
      "budget_used_percent": 1.09478795940864
    },
    {
      "type": "training",
      "description": "Training step 765",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:21",
      "total_flops_so_far": 1096219054780416.0,
      "budget_used_percent": 1.096219054780416
    },
    {
      "type": "training",
      "description": "Training step 766",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:22",
      "total_flops_so_far": 1097650150152192.0,
      "budget_used_percent": 1.097650150152192
    },
    {
      "type": "training",
      "description": "Training step 767",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:22",
      "total_flops_so_far": 1099081245523968.0,
      "budget_used_percent": 1.099081245523968
    },
    {
      "type": "training",
      "description": "Training step 768",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:22",
      "total_flops_so_far": 1100512340895744.0,
      "budget_used_percent": 1.100512340895744
    },
    {
      "type": "training",
      "description": "Training step 769",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:22",
      "total_flops_so_far": 1101943436267520.0,
      "budget_used_percent": 1.10194343626752
    },
    {
      "type": "training",
      "description": "Training step 770",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:22",
      "total_flops_so_far": 1103374531639296.0,
      "budget_used_percent": 1.103374531639296
    },
    {
      "type": "training",
      "description": "Training step 771",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:22",
      "total_flops_so_far": 1104805627011072.0,
      "budget_used_percent": 1.104805627011072
    },
    {
      "type": "training",
      "description": "Training step 772",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:22",
      "total_flops_so_far": 1106236722382848.0,
      "budget_used_percent": 1.106236722382848
    },
    {
      "type": "training",
      "description": "Training step 773",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:23",
      "total_flops_so_far": 1107667817754624.0,
      "budget_used_percent": 1.107667817754624
    },
    {
      "type": "training",
      "description": "Training step 774",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:23",
      "total_flops_so_far": 1109098913126400.0,
      "budget_used_percent": 1.1090989131264
    },
    {
      "type": "training",
      "description": "Training step 775",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:23",
      "total_flops_so_far": 1110530008498176.0,
      "budget_used_percent": 1.110530008498176
    },
    {
      "type": "training",
      "description": "Training step 776",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:23",
      "total_flops_so_far": 1111961103869952.0,
      "budget_used_percent": 1.1119611038699522
    },
    {
      "type": "training",
      "description": "Training step 777",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:23",
      "total_flops_so_far": 1113392199241728.0,
      "budget_used_percent": 1.113392199241728
    },
    {
      "type": "training",
      "description": "Training step 778",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:23",
      "total_flops_so_far": 1114823294613504.0,
      "budget_used_percent": 1.114823294613504
    },
    {
      "type": "training",
      "description": "Training step 779",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:23",
      "total_flops_so_far": 1116254389985280.0,
      "budget_used_percent": 1.1162543899852801
    },
    {
      "type": "training",
      "description": "Training step 780",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:24",
      "total_flops_so_far": 1117685485357056.0,
      "budget_used_percent": 1.117685485357056
    },
    {
      "type": "training",
      "description": "Training step 781",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:24",
      "total_flops_so_far": 1119116580728832.0,
      "budget_used_percent": 1.1191165807288321
    },
    {
      "type": "training",
      "description": "Training step 782",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:24",
      "total_flops_so_far": 1120547676100608.0,
      "budget_used_percent": 1.120547676100608
    },
    {
      "type": "training",
      "description": "Training step 783",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:24",
      "total_flops_so_far": 1121978771472384.0,
      "budget_used_percent": 1.121978771472384
    },
    {
      "type": "training",
      "description": "Training step 784",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:24",
      "total_flops_so_far": 1123409866844160.0,
      "budget_used_percent": 1.12340986684416
    },
    {
      "type": "training",
      "description": "Training step 785",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:24",
      "total_flops_so_far": 1124840962215936.0,
      "budget_used_percent": 1.1248409622159359
    },
    {
      "type": "training",
      "description": "Training step 786",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:24",
      "total_flops_so_far": 1126272057587712.0,
      "budget_used_percent": 1.126272057587712
    },
    {
      "type": "training",
      "description": "Training step 787",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:24",
      "total_flops_so_far": 1127703152959488.0,
      "budget_used_percent": 1.127703152959488
    },
    {
      "type": "training",
      "description": "Training step 788",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:25",
      "total_flops_so_far": 1129134248331264.0,
      "budget_used_percent": 1.1291342483312639
    },
    {
      "type": "training",
      "description": "Training step 789",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:25",
      "total_flops_so_far": 1130565343703040.0,
      "budget_used_percent": 1.13056534370304
    },
    {
      "type": "training",
      "description": "Training step 790",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:25",
      "total_flops_so_far": 1131996439074816.0,
      "budget_used_percent": 1.131996439074816
    },
    {
      "type": "training",
      "description": "Training step 791",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:25",
      "total_flops_so_far": 1133427534446592.0,
      "budget_used_percent": 1.133427534446592
    },
    {
      "type": "training",
      "description": "Training step 792",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:25",
      "total_flops_so_far": 1134858629818368.0,
      "budget_used_percent": 1.134858629818368
    },
    {
      "type": "training",
      "description": "Training step 793",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:25",
      "total_flops_so_far": 1136289725190144.0,
      "budget_used_percent": 1.1362897251901438
    },
    {
      "type": "training",
      "description": "Training step 794",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:25",
      "total_flops_so_far": 1137720820561920.0,
      "budget_used_percent": 1.13772082056192
    },
    {
      "type": "training",
      "description": "Training step 795",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:26",
      "total_flops_so_far": 1139151915933696.0,
      "budget_used_percent": 1.139151915933696
    },
    {
      "type": "training",
      "description": "Training step 796",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:26",
      "total_flops_so_far": 1140583011305472.0,
      "budget_used_percent": 1.140583011305472
    },
    {
      "type": "training",
      "description": "Training step 797",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:26",
      "total_flops_so_far": 1142014106677248.0,
      "budget_used_percent": 1.142014106677248
    },
    {
      "type": "training",
      "description": "Training step 798",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:26",
      "total_flops_so_far": 1143445202049024.0,
      "budget_used_percent": 1.143445202049024
    },
    {
      "type": "training",
      "description": "Training step 799",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:26",
      "total_flops_so_far": 1144876297420800.0,
      "budget_used_percent": 1.1448762974208
    },
    {
      "type": "training",
      "description": "Training step 800",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:26",
      "total_flops_so_far": 1146307392792576.0,
      "budget_used_percent": 1.146307392792576
    },
    {
      "type": "training",
      "description": "Training step 801",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:26",
      "total_flops_so_far": 1147738488164352.0,
      "budget_used_percent": 1.147738488164352
    },
    {
      "type": "training",
      "description": "Training step 802",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:27",
      "total_flops_so_far": 1149169583536128.0,
      "budget_used_percent": 1.149169583536128
    },
    {
      "type": "training",
      "description": "Training step 803",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:27",
      "total_flops_so_far": 1150600678907904.0,
      "budget_used_percent": 1.150600678907904
    },
    {
      "type": "training",
      "description": "Training step 804",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:27",
      "total_flops_so_far": 1152031774279680.0,
      "budget_used_percent": 1.15203177427968
    },
    {
      "type": "training",
      "description": "Training step 805",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:27",
      "total_flops_so_far": 1153462869651456.0,
      "budget_used_percent": 1.153462869651456
    },
    {
      "type": "training",
      "description": "Training step 806",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:27",
      "total_flops_so_far": 1154893965023232.0,
      "budget_used_percent": 1.154893965023232
    },
    {
      "type": "training",
      "description": "Training step 807",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:27",
      "total_flops_so_far": 1156325060395008.0,
      "budget_used_percent": 1.156325060395008
    },
    {
      "type": "training",
      "description": "Training step 808",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:27",
      "total_flops_so_far": 1157756155766784.0,
      "budget_used_percent": 1.1577561557667841
    },
    {
      "type": "training",
      "description": "Training step 809",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:27",
      "total_flops_so_far": 1159187251138560.0,
      "budget_used_percent": 1.15918725113856
    },
    {
      "type": "training",
      "description": "Training step 810",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:28",
      "total_flops_so_far": 1160618346510336.0,
      "budget_used_percent": 1.160618346510336
    },
    {
      "type": "training",
      "description": "Training step 811",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:28",
      "total_flops_so_far": 1162049441882112.0,
      "budget_used_percent": 1.1620494418821121
    },
    {
      "type": "training",
      "description": "Training step 812",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:28",
      "total_flops_so_far": 1163480537253888.0,
      "budget_used_percent": 1.163480537253888
    },
    {
      "type": "training",
      "description": "Training step 813",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:28",
      "total_flops_so_far": 1164911632625664.0,
      "budget_used_percent": 1.164911632625664
    },
    {
      "type": "training",
      "description": "Training step 814",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:28",
      "total_flops_so_far": 1166342727997440.0,
      "budget_used_percent": 1.16634272799744
    },
    {
      "type": "training",
      "description": "Training step 815",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:28",
      "total_flops_so_far": 1167773823369216.0,
      "budget_used_percent": 1.1677738233692159
    },
    {
      "type": "training",
      "description": "Training step 816",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:28",
      "total_flops_so_far": 1169204918740992.0,
      "budget_used_percent": 1.169204918740992
    },
    {
      "type": "training",
      "description": "Training step 817",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:29",
      "total_flops_so_far": 1170636014112768.0,
      "budget_used_percent": 1.170636014112768
    },
    {
      "type": "training",
      "description": "Training step 818",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:29",
      "total_flops_so_far": 1172067109484544.0,
      "budget_used_percent": 1.172067109484544
    },
    {
      "type": "training",
      "description": "Training step 819",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:29",
      "total_flops_so_far": 1173498204856320.0,
      "budget_used_percent": 1.17349820485632
    },
    {
      "type": "training",
      "description": "Training step 820",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:29",
      "total_flops_so_far": 1174929300228096.0,
      "budget_used_percent": 1.1749293002280958
    },
    {
      "type": "training",
      "description": "Training step 821",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:29",
      "total_flops_so_far": 1176360395599872.0,
      "budget_used_percent": 1.176360395599872
    },
    {
      "type": "training",
      "description": "Training step 822",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:29",
      "total_flops_so_far": 1177791490971648.0,
      "budget_used_percent": 1.177791490971648
    },
    {
      "type": "training",
      "description": "Training step 823",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:29",
      "total_flops_so_far": 1179222586343424.0,
      "budget_used_percent": 1.179222586343424
    },
    {
      "type": "training",
      "description": "Training step 824",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:30",
      "total_flops_so_far": 1180653681715200.0,
      "budget_used_percent": 1.1806536817152
    },
    {
      "type": "training",
      "description": "Training step 825",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:30",
      "total_flops_so_far": 1182084777086976.0,
      "budget_used_percent": 1.182084777086976
    },
    {
      "type": "training",
      "description": "Training step 826",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:30",
      "total_flops_so_far": 1183515872458752.0,
      "budget_used_percent": 1.183515872458752
    },
    {
      "type": "training",
      "description": "Training step 827",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:30",
      "total_flops_so_far": 1184946967830528.0,
      "budget_used_percent": 1.184946967830528
    },
    {
      "type": "training",
      "description": "Training step 828",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:30",
      "total_flops_so_far": 1186378063202304.0,
      "budget_used_percent": 1.186378063202304
    },
    {
      "type": "training",
      "description": "Training step 829",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:30",
      "total_flops_so_far": 1187809158574080.0,
      "budget_used_percent": 1.18780915857408
    },
    {
      "type": "training",
      "description": "Training step 830",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:30",
      "total_flops_so_far": 1189240253945856.0,
      "budget_used_percent": 1.189240253945856
    },
    {
      "type": "training",
      "description": "Training step 831",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:30",
      "total_flops_so_far": 1190671349317632.0,
      "budget_used_percent": 1.190671349317632
    },
    {
      "type": "training",
      "description": "Training step 832",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:31",
      "total_flops_so_far": 1192102444689408.0,
      "budget_used_percent": 1.192102444689408
    },
    {
      "type": "training",
      "description": "Training step 833",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:31",
      "total_flops_so_far": 1193533540061184.0,
      "budget_used_percent": 1.1935335400611842
    },
    {
      "type": "training",
      "description": "Training step 834",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:31",
      "total_flops_so_far": 1194964635432960.0,
      "budget_used_percent": 1.19496463543296
    },
    {
      "type": "training",
      "description": "Training step 835",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:31",
      "total_flops_so_far": 1196395730804736.0,
      "budget_used_percent": 1.196395730804736
    },
    {
      "type": "training",
      "description": "Training step 836",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:31",
      "total_flops_so_far": 1197826826176512.0,
      "budget_used_percent": 1.197826826176512
    },
    {
      "type": "training",
      "description": "Training step 837",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:31",
      "total_flops_so_far": 1199257921548288.0,
      "budget_used_percent": 1.199257921548288
    },
    {
      "type": "training",
      "description": "Training step 838",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:31",
      "total_flops_so_far": 1200689016920064.0,
      "budget_used_percent": 1.2006890169200641
    },
    {
      "type": "training",
      "description": "Training step 839",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:32",
      "total_flops_so_far": 1202120112291840.0,
      "budget_used_percent": 1.20212011229184
    },
    {
      "type": "training",
      "description": "Training step 840",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:32",
      "total_flops_so_far": 1203551207663616.0,
      "budget_used_percent": 1.203551207663616
    },
    {
      "type": "training",
      "description": "Training step 841",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:32",
      "total_flops_so_far": 1204982303035392.0,
      "budget_used_percent": 1.204982303035392
    },
    {
      "type": "training",
      "description": "Training step 842",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:32",
      "total_flops_so_far": 1206413398407168.0,
      "budget_used_percent": 1.2064133984071679
    },
    {
      "type": "training",
      "description": "Training step 843",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:32",
      "total_flops_so_far": 1207844493778944.0,
      "budget_used_percent": 1.207844493778944
    },
    {
      "type": "training",
      "description": "Training step 844",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:32",
      "total_flops_so_far": 1209275589150720.0,
      "budget_used_percent": 1.20927558915072
    },
    {
      "type": "training",
      "description": "Training step 845",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:32",
      "total_flops_so_far": 1210706684522496.0,
      "budget_used_percent": 1.210706684522496
    },
    {
      "type": "training",
      "description": "Training step 846",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:33",
      "total_flops_so_far": 1212137779894272.0,
      "budget_used_percent": 1.212137779894272
    },
    {
      "type": "training",
      "description": "Training step 847",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:33",
      "total_flops_so_far": 1213568875266048.0,
      "budget_used_percent": 1.2135688752660478
    },
    {
      "type": "training",
      "description": "Training step 848",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:33",
      "total_flops_so_far": 1214999970637824.0,
      "budget_used_percent": 1.214999970637824
    },
    {
      "type": "training",
      "description": "Training step 849",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:33",
      "total_flops_so_far": 1216431066009600.0,
      "budget_used_percent": 1.2164310660096
    },
    {
      "type": "training",
      "description": "Training step 850",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:33",
      "total_flops_so_far": 1217862161381376.0,
      "budget_used_percent": 1.217862161381376
    },
    {
      "type": "training",
      "description": "Training step 851",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:33",
      "total_flops_so_far": 1219293256753152.0,
      "budget_used_percent": 1.219293256753152
    },
    {
      "type": "training",
      "description": "Training step 852",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:33",
      "total_flops_so_far": 1220724352124928.0,
      "budget_used_percent": 1.220724352124928
    },
    {
      "type": "training",
      "description": "Training step 853",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:34",
      "total_flops_so_far": 1222155447496704.0,
      "budget_used_percent": 1.222155447496704
    },
    {
      "type": "training",
      "description": "Training step 854",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:34",
      "total_flops_so_far": 1223586542868480.0,
      "budget_used_percent": 1.22358654286848
    },
    {
      "type": "training",
      "description": "Training step 855",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:34",
      "total_flops_so_far": 1225017638240256.0,
      "budget_used_percent": 1.225017638240256
    },
    {
      "type": "training",
      "description": "Training step 856",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:34",
      "total_flops_so_far": 1226448733612032.0,
      "budget_used_percent": 1.226448733612032
    },
    {
      "type": "training",
      "description": "Training step 857",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:34",
      "total_flops_so_far": 1227879828983808.0,
      "budget_used_percent": 1.227879828983808
    },
    {
      "type": "training",
      "description": "Training step 858",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:34",
      "total_flops_so_far": 1229310924355584.0,
      "budget_used_percent": 1.229310924355584
    },
    {
      "type": "training",
      "description": "Training step 859",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:34",
      "total_flops_so_far": 1230742019727360.0,
      "budget_used_percent": 1.23074201972736
    },
    {
      "type": "training",
      "description": "Training step 860",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:35",
      "total_flops_so_far": 1232173115099136.0,
      "budget_used_percent": 1.232173115099136
    },
    {
      "type": "training",
      "description": "Training step 861",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:35",
      "total_flops_so_far": 1233604210470912.0,
      "budget_used_percent": 1.233604210470912
    },
    {
      "type": "training",
      "description": "Training step 862",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:35",
      "total_flops_so_far": 1235035305842688.0,
      "budget_used_percent": 1.235035305842688
    },
    {
      "type": "training",
      "description": "Training step 863",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:35",
      "total_flops_so_far": 1236466401214464.0,
      "budget_used_percent": 1.236466401214464
    },
    {
      "type": "training",
      "description": "Training step 864",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:35",
      "total_flops_so_far": 1237897496586240.0,
      "budget_used_percent": 1.23789749658624
    },
    {
      "type": "training",
      "description": "Training step 865",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:35",
      "total_flops_so_far": 1239328591958016.0,
      "budget_used_percent": 1.2393285919580161
    },
    {
      "type": "training",
      "description": "Training step 866",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:35",
      "total_flops_so_far": 1240759687329792.0,
      "budget_used_percent": 1.240759687329792
    },
    {
      "type": "training",
      "description": "Training step 867",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:36",
      "total_flops_so_far": 1242190782701568.0,
      "budget_used_percent": 1.242190782701568
    },
    {
      "type": "training",
      "description": "Training step 868",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:36",
      "total_flops_so_far": 1243621878073344.0,
      "budget_used_percent": 1.2436218780733441
    },
    {
      "type": "training",
      "description": "Training step 869",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:36",
      "total_flops_so_far": 1245052973445120.0,
      "budget_used_percent": 1.24505297344512
    },
    {
      "type": "training",
      "description": "Training step 870",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:36",
      "total_flops_so_far": 1246484068816896.0,
      "budget_used_percent": 1.246484068816896
    },
    {
      "type": "training",
      "description": "Training step 871",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:36",
      "total_flops_so_far": 1247915164188672.0,
      "budget_used_percent": 1.247915164188672
    },
    {
      "type": "training",
      "description": "Training step 872",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:36",
      "total_flops_so_far": 1249346259560448.0,
      "budget_used_percent": 1.2493462595604479
    },
    {
      "type": "training",
      "description": "Training step 873",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:36",
      "total_flops_so_far": 1250777354932224.0,
      "budget_used_percent": 1.250777354932224
    },
    {
      "type": "training",
      "description": "Training step 874",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:37",
      "total_flops_so_far": 1252208450304000.0,
      "budget_used_percent": 1.2522084503039999
    },
    {
      "type": "training",
      "description": "Training step 875",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:37",
      "total_flops_so_far": 1253639545675776.0,
      "budget_used_percent": 1.253639545675776
    },
    {
      "type": "training",
      "description": "Training step 876",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:37",
      "total_flops_so_far": 1255070641047552.0,
      "budget_used_percent": 1.255070641047552
    },
    {
      "type": "training",
      "description": "Training step 877",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:37",
      "total_flops_so_far": 1256501736419328.0,
      "budget_used_percent": 1.2565017364193278
    },
    {
      "type": "training",
      "description": "Training step 878",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:37",
      "total_flops_so_far": 1257932831791104.0,
      "budget_used_percent": 1.257932831791104
    },
    {
      "type": "training",
      "description": "Training step 879",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:37",
      "total_flops_so_far": 1259363927162880.0,
      "budget_used_percent": 1.25936392716288
    },
    {
      "type": "training",
      "description": "Training step 880",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:37",
      "total_flops_so_far": 1260795022534656.0,
      "budget_used_percent": 1.260795022534656
    },
    {
      "type": "training",
      "description": "Training step 881",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:38",
      "total_flops_so_far": 1262226117906432.0,
      "budget_used_percent": 1.262226117906432
    },
    {
      "type": "training",
      "description": "Training step 882",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:38",
      "total_flops_so_far": 1263657213278208.0,
      "budget_used_percent": 1.263657213278208
    },
    {
      "type": "training",
      "description": "Training step 883",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:38",
      "total_flops_so_far": 1265088308649984.0,
      "budget_used_percent": 1.265088308649984
    },
    {
      "type": "training",
      "description": "Training step 884",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:38",
      "total_flops_so_far": 1266519404021760.0,
      "budget_used_percent": 1.26651940402176
    },
    {
      "type": "training",
      "description": "Training step 885",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:38",
      "total_flops_so_far": 1267950499393536.0,
      "budget_used_percent": 1.267950499393536
    },
    {
      "type": "training",
      "description": "Training step 886",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:38",
      "total_flops_so_far": 1269381594765312.0,
      "budget_used_percent": 1.269381594765312
    },
    {
      "type": "training",
      "description": "Training step 887",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:38",
      "total_flops_so_far": 1270812690137088.0,
      "budget_used_percent": 1.2708126901370882
    },
    {
      "type": "training",
      "description": "Training step 888",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:38",
      "total_flops_so_far": 1272243785508864.0,
      "budget_used_percent": 1.272243785508864
    },
    {
      "type": "training",
      "description": "Training step 889",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:39",
      "total_flops_so_far": 1273674880880640.0,
      "budget_used_percent": 1.27367488088064
    },
    {
      "type": "training",
      "description": "Training step 890",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:39",
      "total_flops_so_far": 1275105976252416.0,
      "budget_used_percent": 1.275105976252416
    },
    {
      "type": "training",
      "description": "Training step 891",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:39",
      "total_flops_so_far": 1276537071624192.0,
      "budget_used_percent": 1.276537071624192
    },
    {
      "type": "training",
      "description": "Training step 892",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:39",
      "total_flops_so_far": 1277968166995968.0,
      "budget_used_percent": 1.2779681669959682
    },
    {
      "type": "training",
      "description": "Training step 893",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:39",
      "total_flops_so_far": 1279399262367744.0,
      "budget_used_percent": 1.279399262367744
    },
    {
      "type": "training",
      "description": "Training step 894",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:39",
      "total_flops_so_far": 1280830357739520.0,
      "budget_used_percent": 1.28083035773952
    },
    {
      "type": "training",
      "description": "Training step 895",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:39",
      "total_flops_so_far": 1282261453111296.0,
      "budget_used_percent": 1.2822614531112961
    },
    {
      "type": "training",
      "description": "Training step 896",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:40",
      "total_flops_so_far": 1283692548483072.0,
      "budget_used_percent": 1.283692548483072
    },
    {
      "type": "training",
      "description": "Training step 897",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:40",
      "total_flops_so_far": 1285123643854848.0,
      "budget_used_percent": 1.2851236438548481
    },
    {
      "type": "training",
      "description": "Training step 898",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:40",
      "total_flops_so_far": 1286554739226624.0,
      "budget_used_percent": 1.2865547392266241
    },
    {
      "type": "training",
      "description": "Training step 899",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:40",
      "total_flops_so_far": 1287985834598400.0,
      "budget_used_percent": 1.2879858345983999
    },
    {
      "type": "training",
      "description": "Training step 900",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:40",
      "total_flops_so_far": 1289416929970176.0,
      "budget_used_percent": 1.289416929970176
    },
    {
      "type": "training",
      "description": "Training step 901",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:40",
      "total_flops_so_far": 1290848025341952.0,
      "budget_used_percent": 1.2908480253419519
    },
    {
      "type": "training",
      "description": "Training step 902",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:40",
      "total_flops_so_far": 1292279120713728.0,
      "budget_used_percent": 1.292279120713728
    },
    {
      "type": "training",
      "description": "Training step 903",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:41",
      "total_flops_so_far": 1293710216085504.0,
      "budget_used_percent": 1.293710216085504
    },
    {
      "type": "training",
      "description": "Training step 904",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:41",
      "total_flops_so_far": 1295141311457280.0,
      "budget_used_percent": 1.2951413114572798
    },
    {
      "type": "training",
      "description": "Training step 905",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:41",
      "total_flops_so_far": 1296572406829056.0,
      "budget_used_percent": 1.296572406829056
    },
    {
      "type": "training",
      "description": "Training step 906",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:41",
      "total_flops_so_far": 1298003502200832.0,
      "budget_used_percent": 1.298003502200832
    },
    {
      "type": "training",
      "description": "Training step 907",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:41",
      "total_flops_so_far": 1299434597572608.0,
      "budget_used_percent": 1.299434597572608
    },
    {
      "type": "training",
      "description": "Training step 908",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:41",
      "total_flops_so_far": 1300865692944384.0,
      "budget_used_percent": 1.300865692944384
    },
    {
      "type": "training",
      "description": "Training step 909",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:41",
      "total_flops_so_far": 1302296788316160.0,
      "budget_used_percent": 1.30229678831616
    },
    {
      "type": "training",
      "description": "Training step 910",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:41",
      "total_flops_so_far": 1303727883687936.0,
      "budget_used_percent": 1.303727883687936
    },
    {
      "type": "training",
      "description": "Training step 911",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:42",
      "total_flops_so_far": 1305158979059712.0,
      "budget_used_percent": 1.305158979059712
    },
    {
      "type": "training",
      "description": "Training step 912",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:42",
      "total_flops_so_far": 1306590074431488.0,
      "budget_used_percent": 1.306590074431488
    },
    {
      "type": "training",
      "description": "Training step 913",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:42",
      "total_flops_so_far": 1308021169803264.0,
      "budget_used_percent": 1.308021169803264
    },
    {
      "type": "training",
      "description": "Training step 914",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:42",
      "total_flops_so_far": 1309452265175040.0,
      "budget_used_percent": 1.30945226517504
    },
    {
      "type": "training",
      "description": "Training step 915",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:42",
      "total_flops_so_far": 1310883360546816.0,
      "budget_used_percent": 1.310883360546816
    },
    {
      "type": "training",
      "description": "Training step 916",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:42",
      "total_flops_so_far": 1312314455918592.0,
      "budget_used_percent": 1.312314455918592
    },
    {
      "type": "training",
      "description": "Training step 917",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:42",
      "total_flops_so_far": 1313745551290368.0,
      "budget_used_percent": 1.313745551290368
    },
    {
      "type": "training",
      "description": "Training step 918",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:43",
      "total_flops_so_far": 1315176646662144.0,
      "budget_used_percent": 1.315176646662144
    },
    {
      "type": "training",
      "description": "Training step 919",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:43",
      "total_flops_so_far": 1316607742033920.0,
      "budget_used_percent": 1.31660774203392
    },
    {
      "type": "training",
      "description": "Training step 920",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:43",
      "total_flops_so_far": 1318038837405696.0,
      "budget_used_percent": 1.318038837405696
    },
    {
      "type": "training",
      "description": "Training step 921",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:43",
      "total_flops_so_far": 1319469932777472.0,
      "budget_used_percent": 1.319469932777472
    },
    {
      "type": "training",
      "description": "Training step 922",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:43",
      "total_flops_so_far": 1320901028149248.0,
      "budget_used_percent": 1.3209010281492481
    },
    {
      "type": "training",
      "description": "Training step 923",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:43",
      "total_flops_so_far": 1322332123521024.0,
      "budget_used_percent": 1.322332123521024
    },
    {
      "type": "training",
      "description": "Training step 924",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:43",
      "total_flops_so_far": 1323763218892800.0,
      "budget_used_percent": 1.3237632188928
    },
    {
      "type": "training",
      "description": "Training step 925",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:44",
      "total_flops_so_far": 1325194314264576.0,
      "budget_used_percent": 1.3251943142645761
    },
    {
      "type": "training",
      "description": "Training step 926",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:44",
      "total_flops_so_far": 1326625409636352.0,
      "budget_used_percent": 1.326625409636352
    },
    {
      "type": "training",
      "description": "Training step 927",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:44",
      "total_flops_so_far": 1328056505008128.0,
      "budget_used_percent": 1.328056505008128
    },
    {
      "type": "training",
      "description": "Training step 928",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:44",
      "total_flops_so_far": 1329487600379904.0,
      "budget_used_percent": 1.3294876003799039
    },
    {
      "type": "training",
      "description": "Training step 929",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:44",
      "total_flops_so_far": 1330918695751680.0,
      "budget_used_percent": 1.33091869575168
    },
    {
      "type": "training",
      "description": "Training step 930",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:44",
      "total_flops_so_far": 1332349791123456.0,
      "budget_used_percent": 1.332349791123456
    },
    {
      "type": "training",
      "description": "Training step 931",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:44",
      "total_flops_so_far": 1333780886495232.0,
      "budget_used_percent": 1.3337808864952319
    },
    {
      "type": "training",
      "description": "Training step 932",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:45",
      "total_flops_so_far": 1335211981867008.0,
      "budget_used_percent": 1.335211981867008
    },
    {
      "type": "training",
      "description": "Training step 933",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:45",
      "total_flops_so_far": 1336643077238784.0,
      "budget_used_percent": 1.336643077238784
    },
    {
      "type": "training",
      "description": "Training step 934",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:45",
      "total_flops_so_far": 1338074172610560.0,
      "budget_used_percent": 1.33807417261056
    },
    {
      "type": "training",
      "description": "Training step 935",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:45",
      "total_flops_so_far": 1339505267982336.0,
      "budget_used_percent": 1.339505267982336
    },
    {
      "type": "training",
      "description": "Training step 936",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:45",
      "total_flops_so_far": 1340936363354112.0,
      "budget_used_percent": 1.340936363354112
    },
    {
      "type": "training",
      "description": "Training step 937",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:45",
      "total_flops_so_far": 1342367458725888.0,
      "budget_used_percent": 1.342367458725888
    },
    {
      "type": "training",
      "description": "Training step 938",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:45",
      "total_flops_so_far": 1343798554097664.0,
      "budget_used_percent": 1.343798554097664
    },
    {
      "type": "training",
      "description": "Training step 939",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:46",
      "total_flops_so_far": 1345229649469440.0,
      "budget_used_percent": 1.34522964946944
    },
    {
      "type": "training",
      "description": "Training step 940",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:46",
      "total_flops_so_far": 1346660744841216.0,
      "budget_used_percent": 1.346660744841216
    },
    {
      "type": "training",
      "description": "Training step 941",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:46",
      "total_flops_so_far": 1348091840212992.0,
      "budget_used_percent": 1.348091840212992
    },
    {
      "type": "training",
      "description": "Training step 942",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:46",
      "total_flops_so_far": 1349522935584768.0,
      "budget_used_percent": 1.349522935584768
    },
    {
      "type": "training",
      "description": "Training step 943",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:46",
      "total_flops_so_far": 1350954030956544.0,
      "budget_used_percent": 1.350954030956544
    },
    {
      "type": "training",
      "description": "Training step 944",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:46",
      "total_flops_so_far": 1352385126328320.0,
      "budget_used_percent": 1.35238512632832
    },
    {
      "type": "training",
      "description": "Training step 945",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:47",
      "total_flops_so_far": 1353816221700096.0,
      "budget_used_percent": 1.353816221700096
    },
    {
      "type": "training",
      "description": "Training step 946",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:47",
      "total_flops_so_far": 1355247317071872.0,
      "budget_used_percent": 1.355247317071872
    },
    {
      "type": "training",
      "description": "Training step 947",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:47",
      "total_flops_so_far": 1356678412443648.0,
      "budget_used_percent": 1.356678412443648
    },
    {
      "type": "training",
      "description": "Training step 948",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:47",
      "total_flops_so_far": 1358109507815424.0,
      "budget_used_percent": 1.358109507815424
    },
    {
      "type": "training",
      "description": "Training step 949",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:47",
      "total_flops_so_far": 1359540603187200.0,
      "budget_used_percent": 1.3595406031872002
    },
    {
      "type": "training",
      "description": "Training step 950",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:47",
      "total_flops_so_far": 1360971698558976.0,
      "budget_used_percent": 1.360971698558976
    },
    {
      "type": "training",
      "description": "Training step 951",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:48",
      "total_flops_so_far": 1362402793930752.0,
      "budget_used_percent": 1.362402793930752
    },
    {
      "type": "training",
      "description": "Training step 952",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:48",
      "total_flops_so_far": 1363833889302528.0,
      "budget_used_percent": 1.3638338893025281
    },
    {
      "type": "training",
      "description": "Training step 953",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:48",
      "total_flops_so_far": 1365264984674304.0,
      "budget_used_percent": 1.365264984674304
    },
    {
      "type": "training",
      "description": "Training step 954",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:48",
      "total_flops_so_far": 1366696080046080.0,
      "budget_used_percent": 1.3666960800460801
    },
    {
      "type": "training",
      "description": "Training step 955",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:48",
      "total_flops_so_far": 1368127175417856.0,
      "budget_used_percent": 1.368127175417856
    },
    {
      "type": "training",
      "description": "Training step 956",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:48",
      "total_flops_so_far": 1369558270789632.0,
      "budget_used_percent": 1.3695582707896319
    },
    {
      "type": "training",
      "description": "Training step 957",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:48",
      "total_flops_so_far": 1370989366161408.0,
      "budget_used_percent": 1.370989366161408
    },
    {
      "type": "training",
      "description": "Training step 958",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:49",
      "total_flops_so_far": 1372420461533184.0,
      "budget_used_percent": 1.3724204615331839
    },
    {
      "type": "training",
      "description": "Training step 959",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:49",
      "total_flops_so_far": 1373851556904960.0,
      "budget_used_percent": 1.37385155690496
    },
    {
      "type": "training",
      "description": "Training step 960",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:49",
      "total_flops_so_far": 1375282652276736.0,
      "budget_used_percent": 1.375282652276736
    },
    {
      "type": "training",
      "description": "Training step 961",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:49",
      "total_flops_so_far": 1376713747648512.0,
      "budget_used_percent": 1.3767137476485118
    },
    {
      "type": "training",
      "description": "Training step 962",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:49",
      "total_flops_so_far": 1378144843020288.0,
      "budget_used_percent": 1.378144843020288
    },
    {
      "type": "training",
      "description": "Training step 963",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:49",
      "total_flops_so_far": 1379575938392064.0,
      "budget_used_percent": 1.379575938392064
    },
    {
      "type": "training",
      "description": "Training step 964",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:49",
      "total_flops_so_far": 1381007033763840.0,
      "budget_used_percent": 1.38100703376384
    },
    {
      "type": "training",
      "description": "Training step 965",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:50",
      "total_flops_so_far": 1382438129135616.0,
      "budget_used_percent": 1.382438129135616
    },
    {
      "type": "training",
      "description": "Training step 966",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:50",
      "total_flops_so_far": 1383869224507392.0,
      "budget_used_percent": 1.383869224507392
    },
    {
      "type": "training",
      "description": "Training step 967",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:50",
      "total_flops_so_far": 1385300319879168.0,
      "budget_used_percent": 1.385300319879168
    },
    {
      "type": "training",
      "description": "Training step 968",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:50",
      "total_flops_so_far": 1386731415250944.0,
      "budget_used_percent": 1.386731415250944
    },
    {
      "type": "training",
      "description": "Training step 969",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:50",
      "total_flops_so_far": 1388162510622720.0,
      "budget_used_percent": 1.38816251062272
    },
    {
      "type": "training",
      "description": "Training step 970",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:50",
      "total_flops_so_far": 1389593605994496.0,
      "budget_used_percent": 1.389593605994496
    },
    {
      "type": "training",
      "description": "Training step 971",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:50",
      "total_flops_so_far": 1391024701366272.0,
      "budget_used_percent": 1.391024701366272
    },
    {
      "type": "training",
      "description": "Training step 972",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:51",
      "total_flops_so_far": 1392455796738048.0,
      "budget_used_percent": 1.392455796738048
    },
    {
      "type": "training",
      "description": "Training step 973",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:51",
      "total_flops_so_far": 1393886892109824.0,
      "budget_used_percent": 1.393886892109824
    },
    {
      "type": "training",
      "description": "Training step 974",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:51",
      "total_flops_so_far": 1395317987481600.0,
      "budget_used_percent": 1.3953179874816
    },
    {
      "type": "training",
      "description": "Training step 975",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:51",
      "total_flops_so_far": 1396749082853376.0,
      "budget_used_percent": 1.396749082853376
    },
    {
      "type": "training",
      "description": "Training step 976",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:51",
      "total_flops_so_far": 1398180178225152.0,
      "budget_used_percent": 1.3981801782251522
    },
    {
      "type": "training",
      "description": "Training step 977",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:51",
      "total_flops_so_far": 1399611273596928.0,
      "budget_used_percent": 1.399611273596928
    },
    {
      "type": "training",
      "description": "Training step 978",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:51",
      "total_flops_so_far": 1401042368968704.0,
      "budget_used_percent": 1.401042368968704
    },
    {
      "type": "training",
      "description": "Training step 979",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:52",
      "total_flops_so_far": 1402473464340480.0,
      "budget_used_percent": 1.4024734643404801
    },
    {
      "type": "training",
      "description": "Training step 980",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:52",
      "total_flops_so_far": 1403904559712256.0,
      "budget_used_percent": 1.403904559712256
    },
    {
      "type": "training",
      "description": "Training step 981",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:52",
      "total_flops_so_far": 1405335655084032.0,
      "budget_used_percent": 1.4053356550840321
    },
    {
      "type": "training",
      "description": "Training step 982",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:52",
      "total_flops_so_far": 1406766750455808.0,
      "budget_used_percent": 1.406766750455808
    },
    {
      "type": "training",
      "description": "Training step 983",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:52",
      "total_flops_so_far": 1408197845827584.0,
      "budget_used_percent": 1.408197845827584
    },
    {
      "type": "training",
      "description": "Training step 984",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:52",
      "total_flops_so_far": 1409628941199360.0,
      "budget_used_percent": 1.40962894119936
    },
    {
      "type": "training",
      "description": "Training step 985",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:52",
      "total_flops_so_far": 1411060036571136.0,
      "budget_used_percent": 1.4110600365711359
    },
    {
      "type": "training",
      "description": "Training step 986",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:53",
      "total_flops_so_far": 1412491131942912.0,
      "budget_used_percent": 1.412491131942912
    },
    {
      "type": "training",
      "description": "Training step 987",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:53",
      "total_flops_so_far": 1413922227314688.0,
      "budget_used_percent": 1.413922227314688
    },
    {
      "type": "training",
      "description": "Training step 988",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:53",
      "total_flops_so_far": 1415353322686464.0,
      "budget_used_percent": 1.4153533226864639
    },
    {
      "type": "training",
      "description": "Training step 989",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:53",
      "total_flops_so_far": 1416784418058240.0,
      "budget_used_percent": 1.41678441805824
    },
    {
      "type": "training",
      "description": "Training step 990",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:53",
      "total_flops_so_far": 1418215513430016.0,
      "budget_used_percent": 1.418215513430016
    },
    {
      "type": "training",
      "description": "Training step 991",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:53",
      "total_flops_so_far": 1419646608801792.0,
      "budget_used_percent": 1.419646608801792
    },
    {
      "type": "training",
      "description": "Training step 992",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:53",
      "total_flops_so_far": 1421077704173568.0,
      "budget_used_percent": 1.421077704173568
    },
    {
      "type": "training",
      "description": "Training step 993",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:54",
      "total_flops_so_far": 1422508799545344.0,
      "budget_used_percent": 1.4225087995453438
    },
    {
      "type": "training",
      "description": "Training step 994",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:54",
      "total_flops_so_far": 1423939894917120.0,
      "budget_used_percent": 1.42393989491712
    },
    {
      "type": "training",
      "description": "Training step 995",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:54",
      "total_flops_so_far": 1425370990288896.0,
      "budget_used_percent": 1.425370990288896
    },
    {
      "type": "training",
      "description": "Training step 996",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:54",
      "total_flops_so_far": 1426802085660672.0,
      "budget_used_percent": 1.426802085660672
    },
    {
      "type": "training",
      "description": "Training step 997",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:54",
      "total_flops_so_far": 1428233181032448.0,
      "budget_used_percent": 1.428233181032448
    },
    {
      "type": "training",
      "description": "Training step 998",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:54",
      "total_flops_so_far": 1429664276404224.0,
      "budget_used_percent": 1.429664276404224
    },
    {
      "type": "training",
      "description": "Training step 999",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:51:54",
      "total_flops_so_far": 1431095371776000.0,
      "budget_used_percent": 1.431095371776
    },
    {
      "type": "training",
      "description": "Training step 1000",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:17",
      "total_flops_so_far": 1432526467147776.0,
      "budget_used_percent": 1.432526467147776
    },
    {
      "type": "training",
      "description": "Training step 1001",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:17",
      "total_flops_so_far": 1433957562519552.0,
      "budget_used_percent": 1.433957562519552
    },
    {
      "type": "training",
      "description": "Training step 1002",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:17",
      "total_flops_so_far": 1435388657891328.0,
      "budget_used_percent": 1.435388657891328
    },
    {
      "type": "training",
      "description": "Training step 1003",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:18",
      "total_flops_so_far": 1436819753263104.0,
      "budget_used_percent": 1.436819753263104
    },
    {
      "type": "training",
      "description": "Training step 1004",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:18",
      "total_flops_so_far": 1438250848634880.0,
      "budget_used_percent": 1.43825084863488
    },
    {
      "type": "training",
      "description": "Training step 1005",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:18",
      "total_flops_so_far": 1439681944006656.0,
      "budget_used_percent": 1.439681944006656
    },
    {
      "type": "training",
      "description": "Training step 1006",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:18",
      "total_flops_so_far": 1441113039378432.0,
      "budget_used_percent": 1.4411130393784322
    },
    {
      "type": "training",
      "description": "Training step 1007",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:18",
      "total_flops_so_far": 1442544134750208.0,
      "budget_used_percent": 1.442544134750208
    },
    {
      "type": "training",
      "description": "Training step 1008",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:18",
      "total_flops_so_far": 1443975230121984.0,
      "budget_used_percent": 1.443975230121984
    },
    {
      "type": "training",
      "description": "Training step 1009",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:18",
      "total_flops_so_far": 1445406325493760.0,
      "budget_used_percent": 1.44540632549376
    },
    {
      "type": "training",
      "description": "Training step 1010",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:19",
      "total_flops_so_far": 1446837420865536.0,
      "budget_used_percent": 1.446837420865536
    },
    {
      "type": "training",
      "description": "Training step 1011",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:19",
      "total_flops_so_far": 1448268516237312.0,
      "budget_used_percent": 1.4482685162373121
    },
    {
      "type": "training",
      "description": "Training step 1012",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:19",
      "total_flops_so_far": 1449699611609088.0,
      "budget_used_percent": 1.449699611609088
    },
    {
      "type": "training",
      "description": "Training step 1013",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:19",
      "total_flops_so_far": 1451130706980864.0,
      "budget_used_percent": 1.451130706980864
    },
    {
      "type": "training",
      "description": "Training step 1014",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:19",
      "total_flops_so_far": 1452561802352640.0,
      "budget_used_percent": 1.45256180235264
    },
    {
      "type": "training",
      "description": "Training step 1015",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:19",
      "total_flops_so_far": 1453992897724416.0,
      "budget_used_percent": 1.4539928977244159
    },
    {
      "type": "training",
      "description": "Training step 1016",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:19",
      "total_flops_so_far": 1455423993096192.0,
      "budget_used_percent": 1.455423993096192
    },
    {
      "type": "training",
      "description": "Training step 1017",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:20",
      "total_flops_so_far": 1456855088467968.0,
      "budget_used_percent": 1.456855088467968
    },
    {
      "type": "training",
      "description": "Training step 1018",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:20",
      "total_flops_so_far": 1458286183839744.0,
      "budget_used_percent": 1.458286183839744
    },
    {
      "type": "training",
      "description": "Training step 1019",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:20",
      "total_flops_so_far": 1459717279211520.0,
      "budget_used_percent": 1.45971727921152
    },
    {
      "type": "training",
      "description": "Training step 1020",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:20",
      "total_flops_so_far": 1461148374583296.0,
      "budget_used_percent": 1.461148374583296
    },
    {
      "type": "training",
      "description": "Training step 1021",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:20",
      "total_flops_so_far": 1462579469955072.0,
      "budget_used_percent": 1.462579469955072
    },
    {
      "type": "training",
      "description": "Training step 1022",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:20",
      "total_flops_so_far": 1464010565326848.0,
      "budget_used_percent": 1.464010565326848
    },
    {
      "type": "training",
      "description": "Training step 1023",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:20",
      "total_flops_so_far": 1465441660698624.0,
      "budget_used_percent": 1.465441660698624
    },
    {
      "type": "training",
      "description": "Training step 1024",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:21",
      "total_flops_so_far": 1466872756070400.0,
      "budget_used_percent": 1.4668727560704
    },
    {
      "type": "training",
      "description": "Training step 1025",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:21",
      "total_flops_so_far": 1468303851442176.0,
      "budget_used_percent": 1.468303851442176
    },
    {
      "type": "training",
      "description": "Training step 1026",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:21",
      "total_flops_so_far": 1469734946813952.0,
      "budget_used_percent": 1.469734946813952
    },
    {
      "type": "training",
      "description": "Training step 1027",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:21",
      "total_flops_so_far": 1471166042185728.0,
      "budget_used_percent": 1.471166042185728
    },
    {
      "type": "training",
      "description": "Training step 1028",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:21",
      "total_flops_so_far": 1472597137557504.0,
      "budget_used_percent": 1.472597137557504
    },
    {
      "type": "training",
      "description": "Training step 1029",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:21",
      "total_flops_so_far": 1474028232929280.0,
      "budget_used_percent": 1.47402823292928
    },
    {
      "type": "training",
      "description": "Training step 1030",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:21",
      "total_flops_so_far": 1475459328301056.0,
      "budget_used_percent": 1.475459328301056
    },
    {
      "type": "training",
      "description": "Training step 1031",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:22",
      "total_flops_so_far": 1476890423672832.0,
      "budget_used_percent": 1.476890423672832
    },
    {
      "type": "training",
      "description": "Training step 1032",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:22",
      "total_flops_so_far": 1478321519044608.0,
      "budget_used_percent": 1.478321519044608
    },
    {
      "type": "training",
      "description": "Training step 1033",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:22",
      "total_flops_so_far": 1479752614416384.0,
      "budget_used_percent": 1.4797526144163842
    },
    {
      "type": "training",
      "description": "Training step 1034",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:22",
      "total_flops_so_far": 1481183709788160.0,
      "budget_used_percent": 1.48118370978816
    },
    {
      "type": "training",
      "description": "Training step 1035",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:22",
      "total_flops_so_far": 1482614805159936.0,
      "budget_used_percent": 1.482614805159936
    },
    {
      "type": "training",
      "description": "Training step 1036",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:22",
      "total_flops_so_far": 1484045900531712.0,
      "budget_used_percent": 1.484045900531712
    },
    {
      "type": "training",
      "description": "Training step 1037",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:22",
      "total_flops_so_far": 1485476995903488.0,
      "budget_used_percent": 1.485476995903488
    },
    {
      "type": "training",
      "description": "Training step 1038",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:23",
      "total_flops_so_far": 1486908091275264.0,
      "budget_used_percent": 1.4869080912752641
    },
    {
      "type": "training",
      "description": "Training step 1039",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:23",
      "total_flops_so_far": 1488339186647040.0,
      "budget_used_percent": 1.48833918664704
    },
    {
      "type": "training",
      "description": "Training step 1040",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:23",
      "total_flops_so_far": 1489770282018816.0,
      "budget_used_percent": 1.489770282018816
    },
    {
      "type": "training",
      "description": "Training step 1041",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:23",
      "total_flops_so_far": 1491201377390592.0,
      "budget_used_percent": 1.491201377390592
    },
    {
      "type": "training",
      "description": "Training step 1042",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:23",
      "total_flops_so_far": 1492632472762368.0,
      "budget_used_percent": 1.4926324727623679
    },
    {
      "type": "training",
      "description": "Training step 1043",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:23",
      "total_flops_so_far": 1494063568134144.0,
      "budget_used_percent": 1.494063568134144
    },
    {
      "type": "training",
      "description": "Training step 1044",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:23",
      "total_flops_so_far": 1495494663505920.0,
      "budget_used_percent": 1.49549466350592
    },
    {
      "type": "training",
      "description": "Training step 1045",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:24",
      "total_flops_so_far": 1496925758877696.0,
      "budget_used_percent": 1.4969257588776959
    },
    {
      "type": "training",
      "description": "Training step 1046",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:24",
      "total_flops_so_far": 1498356854249472.0,
      "budget_used_percent": 1.498356854249472
    },
    {
      "type": "training",
      "description": "Training step 1047",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:24",
      "total_flops_so_far": 1499787949621248.0,
      "budget_used_percent": 1.4997879496212478
    },
    {
      "type": "training",
      "description": "Training step 1048",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:24",
      "total_flops_so_far": 1501219044993024.0,
      "budget_used_percent": 1.501219044993024
    },
    {
      "type": "training",
      "description": "Training step 1049",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:24",
      "total_flops_so_far": 1502650140364800.0,
      "budget_used_percent": 1.5026501403648
    },
    {
      "type": "training",
      "description": "Training step 1050",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:24",
      "total_flops_so_far": 1504081235736576.0,
      "budget_used_percent": 1.5040812357365758
    },
    {
      "type": "training",
      "description": "Training step 1051",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:24",
      "total_flops_so_far": 1505512331108352.0,
      "budget_used_percent": 1.505512331108352
    },
    {
      "type": "training",
      "description": "Training step 1052",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:25",
      "total_flops_so_far": 1506943426480128.0,
      "budget_used_percent": 1.506943426480128
    },
    {
      "type": "training",
      "description": "Training step 1053",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:25",
      "total_flops_so_far": 1508374521851904.0,
      "budget_used_percent": 1.508374521851904
    },
    {
      "type": "training",
      "description": "Training step 1054",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:25",
      "total_flops_so_far": 1509805617223680.0,
      "budget_used_percent": 1.50980561722368
    },
    {
      "type": "training",
      "description": "Training step 1055",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:25",
      "total_flops_so_far": 1511236712595456.0,
      "budget_used_percent": 1.511236712595456
    },
    {
      "type": "training",
      "description": "Training step 1056",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:25",
      "total_flops_so_far": 1512667807967232.0,
      "budget_used_percent": 1.512667807967232
    },
    {
      "type": "training",
      "description": "Training step 1057",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:25",
      "total_flops_so_far": 1514098903339008.0,
      "budget_used_percent": 1.514098903339008
    },
    {
      "type": "training",
      "description": "Training step 1058",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:25",
      "total_flops_so_far": 1515529998710784.0,
      "budget_used_percent": 1.515529998710784
    },
    {
      "type": "training",
      "description": "Training step 1059",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:26",
      "total_flops_so_far": 1516961094082560.0,
      "budget_used_percent": 1.51696109408256
    },
    {
      "type": "training",
      "description": "Training step 1060",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:26",
      "total_flops_so_far": 1518392189454336.0,
      "budget_used_percent": 1.5183921894543362
    },
    {
      "type": "training",
      "description": "Training step 1061",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:26",
      "total_flops_so_far": 1519823284826112.0,
      "budget_used_percent": 1.519823284826112
    },
    {
      "type": "training",
      "description": "Training step 1062",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:26",
      "total_flops_so_far": 1521254380197888.0,
      "budget_used_percent": 1.521254380197888
    },
    {
      "type": "training",
      "description": "Training step 1063",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:26",
      "total_flops_so_far": 1522685475569664.0,
      "budget_used_percent": 1.522685475569664
    },
    {
      "type": "training",
      "description": "Training step 1064",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:26",
      "total_flops_so_far": 1524116570941440.0,
      "budget_used_percent": 1.52411657094144
    },
    {
      "type": "training",
      "description": "Training step 1065",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:26",
      "total_flops_so_far": 1525547666313216.0,
      "budget_used_percent": 1.5255476663132161
    },
    {
      "type": "training",
      "description": "Training step 1066",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:27",
      "total_flops_so_far": 1526978761684992.0,
      "budget_used_percent": 1.526978761684992
    },
    {
      "type": "training",
      "description": "Training step 1067",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:27",
      "total_flops_so_far": 1528409857056768.0,
      "budget_used_percent": 1.528409857056768
    },
    {
      "type": "training",
      "description": "Training step 1068",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:27",
      "total_flops_so_far": 1529840952428544.0,
      "budget_used_percent": 1.5298409524285441
    },
    {
      "type": "training",
      "description": "Training step 1069",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:27",
      "total_flops_so_far": 1531272047800320.0,
      "budget_used_percent": 1.53127204780032
    },
    {
      "type": "training",
      "description": "Training step 1070",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:27",
      "total_flops_so_far": 1532703143172096.0,
      "budget_used_percent": 1.532703143172096
    },
    {
      "type": "training",
      "description": "Training step 1071",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:27",
      "total_flops_so_far": 1534134238543872.0,
      "budget_used_percent": 1.534134238543872
    },
    {
      "type": "training",
      "description": "Training step 1072",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:27",
      "total_flops_so_far": 1535565333915648.0,
      "budget_used_percent": 1.5355653339156479
    },
    {
      "type": "training",
      "description": "Training step 1073",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:28",
      "total_flops_so_far": 1536996429287424.0,
      "budget_used_percent": 1.536996429287424
    },
    {
      "type": "training",
      "description": "Training step 1074",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:28",
      "total_flops_so_far": 1538427524659200.0,
      "budget_used_percent": 1.5384275246592
    },
    {
      "type": "training",
      "description": "Training step 1075",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:28",
      "total_flops_so_far": 1539858620030976.0,
      "budget_used_percent": 1.539858620030976
    },
    {
      "type": "training",
      "description": "Training step 1076",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:28",
      "total_flops_so_far": 1541289715402752.0,
      "budget_used_percent": 1.541289715402752
    },
    {
      "type": "training",
      "description": "Training step 1077",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:28",
      "total_flops_so_far": 1542720810774528.0,
      "budget_used_percent": 1.5427208107745278
    },
    {
      "type": "training",
      "description": "Training step 1078",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:28",
      "total_flops_so_far": 1544151906146304.0,
      "budget_used_percent": 1.544151906146304
    },
    {
      "type": "training",
      "description": "Training step 1079",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:29",
      "total_flops_so_far": 1545583001518080.0,
      "budget_used_percent": 1.54558300151808
    },
    {
      "type": "training",
      "description": "Training step 1080",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:29",
      "total_flops_so_far": 1547014096889856.0,
      "budget_used_percent": 1.547014096889856
    },
    {
      "type": "training",
      "description": "Training step 1081",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:29",
      "total_flops_so_far": 1548445192261632.0,
      "budget_used_percent": 1.548445192261632
    },
    {
      "type": "training",
      "description": "Training step 1082",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:29",
      "total_flops_so_far": 1549876287633408.0,
      "budget_used_percent": 1.549876287633408
    },
    {
      "type": "training",
      "description": "Training step 1083",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:29",
      "total_flops_so_far": 1551307383005184.0,
      "budget_used_percent": 1.551307383005184
    },
    {
      "type": "training",
      "description": "Training step 1084",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:29",
      "total_flops_so_far": 1552738478376960.0,
      "budget_used_percent": 1.55273847837696
    },
    {
      "type": "training",
      "description": "Training step 1085",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:29",
      "total_flops_so_far": 1554169573748736.0,
      "budget_used_percent": 1.554169573748736
    },
    {
      "type": "training",
      "description": "Training step 1086",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:30",
      "total_flops_so_far": 1555600669120512.0,
      "budget_used_percent": 1.555600669120512
    },
    {
      "type": "training",
      "description": "Training step 1087",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:30",
      "total_flops_so_far": 1557031764492288.0,
      "budget_used_percent": 1.557031764492288
    },
    {
      "type": "training",
      "description": "Training step 1088",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:30",
      "total_flops_so_far": 1558462859864064.0,
      "budget_used_percent": 1.558462859864064
    },
    {
      "type": "training",
      "description": "Training step 1089",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:30",
      "total_flops_so_far": 1559893955235840.0,
      "budget_used_percent": 1.55989395523584
    },
    {
      "type": "training",
      "description": "Training step 1090",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:30",
      "total_flops_so_far": 1561325050607616.0,
      "budget_used_percent": 1.561325050607616
    },
    {
      "type": "training",
      "description": "Training step 1091",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:30",
      "total_flops_so_far": 1562756145979392.0,
      "budget_used_percent": 1.562756145979392
    },
    {
      "type": "training",
      "description": "Training step 1092",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:30",
      "total_flops_so_far": 1564187241351168.0,
      "budget_used_percent": 1.5641872413511682
    },
    {
      "type": "training",
      "description": "Training step 1093",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:31",
      "total_flops_so_far": 1565618336722944.0,
      "budget_used_percent": 1.565618336722944
    },
    {
      "type": "training",
      "description": "Training step 1094",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:31",
      "total_flops_so_far": 1567049432094720.0,
      "budget_used_percent": 1.56704943209472
    },
    {
      "type": "training",
      "description": "Training step 1095",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:31",
      "total_flops_so_far": 1568480527466496.0,
      "budget_used_percent": 1.5684805274664961
    },
    {
      "type": "training",
      "description": "Training step 1096",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:31",
      "total_flops_so_far": 1569911622838272.0,
      "budget_used_percent": 1.5699116228382721
    },
    {
      "type": "training",
      "description": "Training step 1097",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:31",
      "total_flops_so_far": 1571342718210048.0,
      "budget_used_percent": 1.571342718210048
    },
    {
      "type": "training",
      "description": "Training step 1098",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:31",
      "total_flops_so_far": 1572773813581824.0,
      "budget_used_percent": 1.572773813581824
    },
    {
      "type": "training",
      "description": "Training step 1099",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:31",
      "total_flops_so_far": 1574204908953600.0,
      "budget_used_percent": 1.5742049089536
    },
    {
      "type": "training",
      "description": "Training step 1100",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:32",
      "total_flops_so_far": 1575636004325376.0,
      "budget_used_percent": 1.5756360043253759
    },
    {
      "type": "training",
      "description": "Training step 1101",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:32",
      "total_flops_so_far": 1577067099697152.0,
      "budget_used_percent": 1.5770670996971519
    },
    {
      "type": "training",
      "description": "Training step 1102",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:32",
      "total_flops_so_far": 1578498195068928.0,
      "budget_used_percent": 1.578498195068928
    },
    {
      "type": "training",
      "description": "Training step 1103",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:32",
      "total_flops_so_far": 1579929290440704.0,
      "budget_used_percent": 1.5799292904407038
    },
    {
      "type": "training",
      "description": "Training step 1104",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:32",
      "total_flops_so_far": 1581360385812480.0,
      "budget_used_percent": 1.5813603858124798
    },
    {
      "type": "training",
      "description": "Training step 1105",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:32",
      "total_flops_so_far": 1582791481184256.0,
      "budget_used_percent": 1.582791481184256
    },
    {
      "type": "training",
      "description": "Training step 1106",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:32",
      "total_flops_so_far": 1584222576556032.0,
      "budget_used_percent": 1.584222576556032
    },
    {
      "type": "training",
      "description": "Training step 1107",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:33",
      "total_flops_so_far": 1585653671927808.0,
      "budget_used_percent": 1.5856536719278078
    },
    {
      "type": "training",
      "description": "Training step 1108",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:33",
      "total_flops_so_far": 1587084767299584.0,
      "budget_used_percent": 1.587084767299584
    },
    {
      "type": "training",
      "description": "Training step 1109",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:33",
      "total_flops_so_far": 1588515862671360.0,
      "budget_used_percent": 1.58851586267136
    },
    {
      "type": "training",
      "description": "Training step 1110",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:33",
      "total_flops_so_far": 1589946958043136.0,
      "budget_used_percent": 1.5899469580431358
    },
    {
      "type": "training",
      "description": "Training step 1111",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:33",
      "total_flops_so_far": 1591378053414912.0,
      "budget_used_percent": 1.591378053414912
    },
    {
      "type": "training",
      "description": "Training step 1112",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:33",
      "total_flops_so_far": 1592809148786688.0,
      "budget_used_percent": 1.592809148786688
    },
    {
      "type": "training",
      "description": "Training step 1113",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:33",
      "total_flops_so_far": 1594240244158464.0,
      "budget_used_percent": 1.5942402441584642
    },
    {
      "type": "training",
      "description": "Training step 1114",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:34",
      "total_flops_so_far": 1595671339530240.0,
      "budget_used_percent": 1.59567133953024
    },
    {
      "type": "training",
      "description": "Training step 1115",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:34",
      "total_flops_so_far": 1597102434902016.0,
      "budget_used_percent": 1.597102434902016
    },
    {
      "type": "training",
      "description": "Training step 1116",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:34",
      "total_flops_so_far": 1598533530273792.0,
      "budget_used_percent": 1.5985335302737922
    },
    {
      "type": "training",
      "description": "Training step 1117",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:34",
      "total_flops_so_far": 1599964625645568.0,
      "budget_used_percent": 1.599964625645568
    },
    {
      "type": "training",
      "description": "Training step 1118",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:34",
      "total_flops_so_far": 1601395721017344.0,
      "budget_used_percent": 1.601395721017344
    },
    {
      "type": "training",
      "description": "Training step 1119",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:34",
      "total_flops_so_far": 1602826816389120.0,
      "budget_used_percent": 1.6028268163891202
    },
    {
      "type": "training",
      "description": "Training step 1120",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:34",
      "total_flops_so_far": 1604257911760896.0,
      "budget_used_percent": 1.604257911760896
    },
    {
      "type": "training",
      "description": "Training step 1121",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:35",
      "total_flops_so_far": 1605689007132672.0,
      "budget_used_percent": 1.605689007132672
    },
    {
      "type": "training",
      "description": "Training step 1122",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:35",
      "total_flops_so_far": 1607120102504448.0,
      "budget_used_percent": 1.6071201025044481
    },
    {
      "type": "training",
      "description": "Training step 1123",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:35",
      "total_flops_so_far": 1608551197876224.0,
      "budget_used_percent": 1.6085511978762241
    },
    {
      "type": "training",
      "description": "Training step 1124",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:35",
      "total_flops_so_far": 1609982293248000.0,
      "budget_used_percent": 1.609982293248
    },
    {
      "type": "training",
      "description": "Training step 1125",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:35",
      "total_flops_so_far": 1611413388619776.0,
      "budget_used_percent": 1.6114133886197761
    },
    {
      "type": "training",
      "description": "Training step 1126",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:35",
      "total_flops_so_far": 1612844483991552.0,
      "budget_used_percent": 1.6128444839915521
    },
    {
      "type": "training",
      "description": "Training step 1127",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:35",
      "total_flops_so_far": 1614275579363328.0,
      "budget_used_percent": 1.6142755793633279
    },
    {
      "type": "training",
      "description": "Training step 1128",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:36",
      "total_flops_so_far": 1615706674735104.0,
      "budget_used_percent": 1.615706674735104
    },
    {
      "type": "training",
      "description": "Training step 1129",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:36",
      "total_flops_so_far": 1617137770106880.0,
      "budget_used_percent": 1.61713777010688
    },
    {
      "type": "training",
      "description": "Training step 1130",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:36",
      "total_flops_so_far": 1618568865478656.0,
      "budget_used_percent": 1.6185688654786559
    },
    {
      "type": "training",
      "description": "Training step 1131",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:36",
      "total_flops_so_far": 1619999960850432.0,
      "budget_used_percent": 1.6199999608504319
    },
    {
      "type": "training",
      "description": "Training step 1132",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:36",
      "total_flops_so_far": 1621431056222208.0,
      "budget_used_percent": 1.621431056222208
    },
    {
      "type": "training",
      "description": "Training step 1133",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:36",
      "total_flops_so_far": 1622862151593984.0,
      "budget_used_percent": 1.622862151593984
    },
    {
      "type": "training",
      "description": "Training step 1134",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:36",
      "total_flops_so_far": 1624293246965760.0,
      "budget_used_percent": 1.6242932469657598
    },
    {
      "type": "training",
      "description": "Training step 1135",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:37",
      "total_flops_so_far": 1625724342337536.0,
      "budget_used_percent": 1.625724342337536
    },
    {
      "type": "training",
      "description": "Training step 1136",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:37",
      "total_flops_so_far": 1627155437709312.0,
      "budget_used_percent": 1.627155437709312
    },
    {
      "type": "training",
      "description": "Training step 1137",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:37",
      "total_flops_so_far": 1628586533081088.0,
      "budget_used_percent": 1.6285865330810878
    },
    {
      "type": "training",
      "description": "Training step 1138",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:37",
      "total_flops_so_far": 1630017628452864.0,
      "budget_used_percent": 1.630017628452864
    },
    {
      "type": "training",
      "description": "Training step 1139",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:37",
      "total_flops_so_far": 1631448723824640.0,
      "budget_used_percent": 1.63144872382464
    },
    {
      "type": "training",
      "description": "Training step 1140",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:37",
      "total_flops_so_far": 1632879819196416.0,
      "budget_used_percent": 1.6328798191964158
    },
    {
      "type": "training",
      "description": "Training step 1141",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:37",
      "total_flops_so_far": 1634310914568192.0,
      "budget_used_percent": 1.634310914568192
    },
    {
      "type": "training",
      "description": "Training step 1142",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:38",
      "total_flops_so_far": 1635742009939968.0,
      "budget_used_percent": 1.635742009939968
    },
    {
      "type": "training",
      "description": "Training step 1143",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:38",
      "total_flops_so_far": 1637173105311744.0,
      "budget_used_percent": 1.6371731053117442
    },
    {
      "type": "training",
      "description": "Training step 1144",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:38",
      "total_flops_so_far": 1638604200683520.0,
      "budget_used_percent": 1.63860420068352
    },
    {
      "type": "training",
      "description": "Training step 1145",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:38",
      "total_flops_so_far": 1640035296055296.0,
      "budget_used_percent": 1.640035296055296
    },
    {
      "type": "training",
      "description": "Training step 1146",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:38",
      "total_flops_so_far": 1641466391427072.0,
      "budget_used_percent": 1.6414663914270722
    },
    {
      "type": "training",
      "description": "Training step 1147",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:38",
      "total_flops_so_far": 1642897486798848.0,
      "budget_used_percent": 1.642897486798848
    },
    {
      "type": "training",
      "description": "Training step 1148",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:39",
      "total_flops_so_far": 1644328582170624.0,
      "budget_used_percent": 1.644328582170624
    },
    {
      "type": "training",
      "description": "Training step 1149",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:39",
      "total_flops_so_far": 1645759677542400.0,
      "budget_used_percent": 1.6457596775424002
    },
    {
      "type": "training",
      "description": "Training step 1150",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:39",
      "total_flops_so_far": 1647190772914176.0,
      "budget_used_percent": 1.647190772914176
    },
    {
      "type": "training",
      "description": "Training step 1151",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:39",
      "total_flops_so_far": 1648621868285952.0,
      "budget_used_percent": 1.648621868285952
    },
    {
      "type": "training",
      "description": "Training step 1152",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:39",
      "total_flops_so_far": 1650052963657728.0,
      "budget_used_percent": 1.6500529636577281
    },
    {
      "type": "training",
      "description": "Training step 1153",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:39",
      "total_flops_so_far": 1651484059029504.0,
      "budget_used_percent": 1.6514840590295041
    },
    {
      "type": "training",
      "description": "Training step 1154",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:39",
      "total_flops_so_far": 1652915154401280.0,
      "budget_used_percent": 1.65291515440128
    },
    {
      "type": "training",
      "description": "Training step 1155",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:40",
      "total_flops_so_far": 1654346249773056.0,
      "budget_used_percent": 1.6543462497730559
    },
    {
      "type": "training",
      "description": "Training step 1156",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:40",
      "total_flops_so_far": 1655777345144832.0,
      "budget_used_percent": 1.655777345144832
    },
    {
      "type": "training",
      "description": "Training step 1157",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:40",
      "total_flops_so_far": 1657208440516608.0,
      "budget_used_percent": 1.6572084405166079
    },
    {
      "type": "training",
      "description": "Training step 1158",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:40",
      "total_flops_so_far": 1658639535888384.0,
      "budget_used_percent": 1.6586395358883839
    },
    {
      "type": "training",
      "description": "Training step 1159",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:40",
      "total_flops_so_far": 1660070631260160.0,
      "budget_used_percent": 1.66007063126016
    },
    {
      "type": "training",
      "description": "Training step 1160",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:40",
      "total_flops_so_far": 1661501726631936.0,
      "budget_used_percent": 1.661501726631936
    },
    {
      "type": "training",
      "description": "Training step 1161",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:40",
      "total_flops_so_far": 1662932822003712.0,
      "budget_used_percent": 1.6629328220037118
    },
    {
      "type": "training",
      "description": "Training step 1162",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:41",
      "total_flops_so_far": 1664363917375488.0,
      "budget_used_percent": 1.664363917375488
    },
    {
      "type": "training",
      "description": "Training step 1163",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:41",
      "total_flops_so_far": 1665795012747264.0,
      "budget_used_percent": 1.665795012747264
    },
    {
      "type": "training",
      "description": "Training step 1164",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:41",
      "total_flops_so_far": 1667226108119040.0,
      "budget_used_percent": 1.6672261081190398
    },
    {
      "type": "training",
      "description": "Training step 1165",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:41",
      "total_flops_so_far": 1668657203490816.0,
      "budget_used_percent": 1.668657203490816
    },
    {
      "type": "training",
      "description": "Training step 1166",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:41",
      "total_flops_so_far": 1670088298862592.0,
      "budget_used_percent": 1.670088298862592
    },
    {
      "type": "training",
      "description": "Training step 1167",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:41",
      "total_flops_so_far": 1671519394234368.0,
      "budget_used_percent": 1.6715193942343678
    },
    {
      "type": "training",
      "description": "Training step 1168",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:42",
      "total_flops_so_far": 1672950489606144.0,
      "budget_used_percent": 1.672950489606144
    },
    {
      "type": "training",
      "description": "Training step 1169",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:42",
      "total_flops_so_far": 1674381584977920.0,
      "budget_used_percent": 1.67438158497792
    },
    {
      "type": "training",
      "description": "Training step 1170",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:42",
      "total_flops_so_far": 1675812680349696.0,
      "budget_used_percent": 1.6758126803496962
    },
    {
      "type": "training",
      "description": "Training step 1171",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:42",
      "total_flops_so_far": 1677243775721472.0,
      "budget_used_percent": 1.677243775721472
    },
    {
      "type": "training",
      "description": "Training step 1172",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:42",
      "total_flops_so_far": 1678674871093248.0,
      "budget_used_percent": 1.678674871093248
    },
    {
      "type": "training",
      "description": "Training step 1173",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:42",
      "total_flops_so_far": 1680105966465024.0,
      "budget_used_percent": 1.6801059664650242
    },
    {
      "type": "training",
      "description": "Training step 1174",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:42",
      "total_flops_so_far": 1681537061836800.0,
      "budget_used_percent": 1.6815370618368
    },
    {
      "type": "training",
      "description": "Training step 1175",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:43",
      "total_flops_so_far": 1682968157208576.0,
      "budget_used_percent": 1.682968157208576
    },
    {
      "type": "training",
      "description": "Training step 1176",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:43",
      "total_flops_so_far": 1684399252580352.0,
      "budget_used_percent": 1.6843992525803522
    },
    {
      "type": "training",
      "description": "Training step 1177",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:43",
      "total_flops_so_far": 1685830347952128.0,
      "budget_used_percent": 1.685830347952128
    },
    {
      "type": "training",
      "description": "Training step 1178",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:43",
      "total_flops_so_far": 1687261443323904.0,
      "budget_used_percent": 1.687261443323904
    },
    {
      "type": "training",
      "description": "Training step 1179",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:43",
      "total_flops_so_far": 1688692538695680.0,
      "budget_used_percent": 1.6886925386956801
    },
    {
      "type": "training",
      "description": "Training step 1180",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:43",
      "total_flops_so_far": 1690123634067456.0,
      "budget_used_percent": 1.6901236340674561
    },
    {
      "type": "training",
      "description": "Training step 1181",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:43",
      "total_flops_so_far": 1691554729439232.0,
      "budget_used_percent": 1.691554729439232
    },
    {
      "type": "training",
      "description": "Training step 1182",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:44",
      "total_flops_so_far": 1692985824811008.0,
      "budget_used_percent": 1.6929858248110081
    },
    {
      "type": "training",
      "description": "Training step 1183",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:44",
      "total_flops_so_far": 1694416920182784.0,
      "budget_used_percent": 1.6944169201827841
    },
    {
      "type": "training",
      "description": "Training step 1184",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:44",
      "total_flops_so_far": 1695848015554560.0,
      "budget_used_percent": 1.6958480155545599
    },
    {
      "type": "training",
      "description": "Training step 1185",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:44",
      "total_flops_so_far": 1697279110926336.0,
      "budget_used_percent": 1.6972791109263359
    },
    {
      "type": "training",
      "description": "Training step 1186",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:44",
      "total_flops_so_far": 1698710206298112.0,
      "budget_used_percent": 1.698710206298112
    },
    {
      "type": "training",
      "description": "Training step 1187",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:44",
      "total_flops_so_far": 1700141301669888.0,
      "budget_used_percent": 1.7001413016698879
    },
    {
      "type": "training",
      "description": "Training step 1188",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:44",
      "total_flops_so_far": 1701572397041664.0,
      "budget_used_percent": 1.7015723970416639
    },
    {
      "type": "training",
      "description": "Training step 1189",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:45",
      "total_flops_so_far": 1703003492413440.0,
      "budget_used_percent": 1.70300349241344
    },
    {
      "type": "training",
      "description": "Training step 1190",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:45",
      "total_flops_so_far": 1704434587785216.0,
      "budget_used_percent": 1.704434587785216
    },
    {
      "type": "training",
      "description": "Training step 1191",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:45",
      "total_flops_so_far": 1705865683156992.0,
      "budget_used_percent": 1.7058656831569918
    },
    {
      "type": "training",
      "description": "Training step 1192",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:45",
      "total_flops_so_far": 1707296778528768.0,
      "budget_used_percent": 1.707296778528768
    },
    {
      "type": "training",
      "description": "Training step 1193",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:45",
      "total_flops_so_far": 1708727873900544.0,
      "budget_used_percent": 1.708727873900544
    },
    {
      "type": "training",
      "description": "Training step 1194",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:45",
      "total_flops_so_far": 1710158969272320.0,
      "budget_used_percent": 1.7101589692723198
    },
    {
      "type": "training",
      "description": "Training step 1195",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:45",
      "total_flops_so_far": 1711590064644096.0,
      "budget_used_percent": 1.711590064644096
    },
    {
      "type": "training",
      "description": "Training step 1196",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:46",
      "total_flops_so_far": 1713021160015872.0,
      "budget_used_percent": 1.713021160015872
    },
    {
      "type": "training",
      "description": "Training step 1197",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:46",
      "total_flops_so_far": 1714452255387648.0,
      "budget_used_percent": 1.7144522553876482
    },
    {
      "type": "training",
      "description": "Training step 1198",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:46",
      "total_flops_so_far": 1715883350759424.0,
      "budget_used_percent": 1.715883350759424
    },
    {
      "type": "training",
      "description": "Training step 1199",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:46",
      "total_flops_so_far": 1717314446131200.0,
      "budget_used_percent": 1.7173144461312
    },
    {
      "type": "training",
      "description": "Training step 1200",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:46",
      "total_flops_so_far": 1718745541502976.0,
      "budget_used_percent": 1.7187455415029762
    },
    {
      "type": "training",
      "description": "Training step 1201",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:46",
      "total_flops_so_far": 1720176636874752.0,
      "budget_used_percent": 1.720176636874752
    },
    {
      "type": "training",
      "description": "Training step 1202",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:46",
      "total_flops_so_far": 1721607732246528.0,
      "budget_used_percent": 1.721607732246528
    },
    {
      "type": "training",
      "description": "Training step 1203",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:47",
      "total_flops_so_far": 1723038827618304.0,
      "budget_used_percent": 1.7230388276183042
    },
    {
      "type": "training",
      "description": "Training step 1204",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:47",
      "total_flops_so_far": 1724469922990080.0,
      "budget_used_percent": 1.72446992299008
    },
    {
      "type": "training",
      "description": "Training step 1205",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:47",
      "total_flops_so_far": 1725901018361856.0,
      "budget_used_percent": 1.725901018361856
    },
    {
      "type": "training",
      "description": "Training step 1206",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:47",
      "total_flops_so_far": 1727332113733632.0,
      "budget_used_percent": 1.7273321137336322
    },
    {
      "type": "training",
      "description": "Training step 1207",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:47",
      "total_flops_so_far": 1728763209105408.0,
      "budget_used_percent": 1.7287632091054081
    },
    {
      "type": "training",
      "description": "Training step 1208",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:47",
      "total_flops_so_far": 1730194304477184.0,
      "budget_used_percent": 1.730194304477184
    },
    {
      "type": "training",
      "description": "Training step 1209",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:47",
      "total_flops_so_far": 1731625399848960.0,
      "budget_used_percent": 1.73162539984896
    },
    {
      "type": "training",
      "description": "Training step 1210",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:48",
      "total_flops_so_far": 1733056495220736.0,
      "budget_used_percent": 1.7330564952207361
    },
    {
      "type": "training",
      "description": "Training step 1211",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:48",
      "total_flops_so_far": 1734487590592512.0,
      "budget_used_percent": 1.734487590592512
    },
    {
      "type": "training",
      "description": "Training step 1212",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:48",
      "total_flops_so_far": 1735918685964288.0,
      "budget_used_percent": 1.7359186859642879
    },
    {
      "type": "training",
      "description": "Training step 1213",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:48",
      "total_flops_so_far": 1737349781336064.0,
      "budget_used_percent": 1.737349781336064
    },
    {
      "type": "training",
      "description": "Training step 1214",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:48",
      "total_flops_so_far": 1738780876707840.0,
      "budget_used_percent": 1.7387808767078399
    },
    {
      "type": "training",
      "description": "Training step 1215",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:48",
      "total_flops_so_far": 1740211972079616.0,
      "budget_used_percent": 1.7402119720796159
    },
    {
      "type": "training",
      "description": "Training step 1216",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:49",
      "total_flops_so_far": 1741643067451392.0,
      "budget_used_percent": 1.741643067451392
    },
    {
      "type": "training",
      "description": "Training step 1217",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:49",
      "total_flops_so_far": 1743074162823168.0,
      "budget_used_percent": 1.743074162823168
    },
    {
      "type": "training",
      "description": "Training step 1218",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:49",
      "total_flops_so_far": 1744505258194944.0,
      "budget_used_percent": 1.7445052581949438
    },
    {
      "type": "training",
      "description": "Training step 1219",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:49",
      "total_flops_so_far": 1745936353566720.0,
      "budget_used_percent": 1.74593635356672
    },
    {
      "type": "training",
      "description": "Training step 1220",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:49",
      "total_flops_so_far": 1747367448938496.0,
      "budget_used_percent": 1.747367448938496
    },
    {
      "type": "training",
      "description": "Training step 1221",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:49",
      "total_flops_so_far": 1748798544310272.0,
      "budget_used_percent": 1.7487985443102718
    },
    {
      "type": "training",
      "description": "Training step 1222",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:49",
      "total_flops_so_far": 1750229639682048.0,
      "budget_used_percent": 1.750229639682048
    },
    {
      "type": "training",
      "description": "Training step 1223",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:50",
      "total_flops_so_far": 1751660735053824.0,
      "budget_used_percent": 1.751660735053824
    },
    {
      "type": "training",
      "description": "Training step 1224",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:50",
      "total_flops_so_far": 1753091830425600.0,
      "budget_used_percent": 1.7530918304255998
    },
    {
      "type": "training",
      "description": "Training step 1225",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:50",
      "total_flops_so_far": 1754522925797376.0,
      "budget_used_percent": 1.754522925797376
    },
    {
      "type": "training",
      "description": "Training step 1226",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:50",
      "total_flops_so_far": 1755954021169152.0,
      "budget_used_percent": 1.755954021169152
    },
    {
      "type": "training",
      "description": "Training step 1227",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:50",
      "total_flops_so_far": 1757385116540928.0,
      "budget_used_percent": 1.7573851165409282
    },
    {
      "type": "training",
      "description": "Training step 1228",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:50",
      "total_flops_so_far": 1758816211912704.0,
      "budget_used_percent": 1.758816211912704
    },
    {
      "type": "training",
      "description": "Training step 1229",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:50",
      "total_flops_so_far": 1760247307284480.0,
      "budget_used_percent": 1.76024730728448
    },
    {
      "type": "training",
      "description": "Training step 1230",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:51",
      "total_flops_so_far": 1761678402656256.0,
      "budget_used_percent": 1.7616784026562562
    },
    {
      "type": "training",
      "description": "Training step 1231",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:51",
      "total_flops_so_far": 1763109498028032.0,
      "budget_used_percent": 1.763109498028032
    },
    {
      "type": "training",
      "description": "Training step 1232",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:51",
      "total_flops_so_far": 1764540593399808.0,
      "budget_used_percent": 1.764540593399808
    },
    {
      "type": "training",
      "description": "Training step 1233",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:51",
      "total_flops_so_far": 1765971688771584.0,
      "budget_used_percent": 1.7659716887715842
    },
    {
      "type": "training",
      "description": "Training step 1234",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:51",
      "total_flops_so_far": 1767402784143360.0,
      "budget_used_percent": 1.7674027841433597
    },
    {
      "type": "training",
      "description": "Training step 1235",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:51",
      "total_flops_so_far": 1768833879515136.0,
      "budget_used_percent": 1.768833879515136
    },
    {
      "type": "training",
      "description": "Training step 1236",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:51",
      "total_flops_so_far": 1770264974886912.0,
      "budget_used_percent": 1.7702649748869121
    },
    {
      "type": "training",
      "description": "Training step 1237",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:52",
      "total_flops_so_far": 1771696070258688.0,
      "budget_used_percent": 1.7716960702586881
    },
    {
      "type": "training",
      "description": "Training step 1238",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:52",
      "total_flops_so_far": 1773127165630464.0,
      "budget_used_percent": 1.773127165630464
    },
    {
      "type": "training",
      "description": "Training step 1239",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:52",
      "total_flops_so_far": 1774558261002240.0,
      "budget_used_percent": 1.77455826100224
    },
    {
      "type": "training",
      "description": "Training step 1240",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:52",
      "total_flops_so_far": 1775989356374016.0,
      "budget_used_percent": 1.7759893563740161
    },
    {
      "type": "training",
      "description": "Training step 1241",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:52",
      "total_flops_so_far": 1777420451745792.0,
      "budget_used_percent": 1.7774204517457919
    },
    {
      "type": "training",
      "description": "Training step 1242",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:52",
      "total_flops_so_far": 1778851547117568.0,
      "budget_used_percent": 1.7788515471175679
    },
    {
      "type": "training",
      "description": "Training step 1243",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:53",
      "total_flops_so_far": 1780282642489344.0,
      "budget_used_percent": 1.780282642489344
    },
    {
      "type": "training",
      "description": "Training step 1244",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:53",
      "total_flops_so_far": 1781713737861120.0,
      "budget_used_percent": 1.78171373786112
    },
    {
      "type": "training",
      "description": "Training step 1245",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:53",
      "total_flops_so_far": 1783144833232896.0,
      "budget_used_percent": 1.7831448332328959
    },
    {
      "type": "training",
      "description": "Training step 1246",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:53",
      "total_flops_so_far": 1784575928604672.0,
      "budget_used_percent": 1.784575928604672
    },
    {
      "type": "training",
      "description": "Training step 1247",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:53",
      "total_flops_so_far": 1786007023976448.0,
      "budget_used_percent": 1.786007023976448
    },
    {
      "type": "training",
      "description": "Training step 1248",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:53",
      "total_flops_so_far": 1787438119348224.0,
      "budget_used_percent": 1.7874381193482238
    },
    {
      "type": "training",
      "description": "Training step 1249",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:53",
      "total_flops_so_far": 1788869214720000.0,
      "budget_used_percent": 1.78886921472
    },
    {
      "type": "training",
      "description": "Training step 1250",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:54",
      "total_flops_so_far": 1790300310091776.0,
      "budget_used_percent": 1.790300310091776
    },
    {
      "type": "training",
      "description": "Training step 1251",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:54",
      "total_flops_so_far": 1791731405463552.0,
      "budget_used_percent": 1.7917314054635518
    },
    {
      "type": "training",
      "description": "Training step 1252",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:54",
      "total_flops_so_far": 1793162500835328.0,
      "budget_used_percent": 1.793162500835328
    },
    {
      "type": "training",
      "description": "Training step 1253",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:54",
      "total_flops_so_far": 1794593596207104.0,
      "budget_used_percent": 1.794593596207104
    },
    {
      "type": "training",
      "description": "Training step 1254",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:54",
      "total_flops_so_far": 1796024691578880.0,
      "budget_used_percent": 1.7960246915788802
    },
    {
      "type": "training",
      "description": "Training step 1255",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:54",
      "total_flops_so_far": 1797455786950656.0,
      "budget_used_percent": 1.797455786950656
    },
    {
      "type": "training",
      "description": "Training step 1256",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:54",
      "total_flops_so_far": 1798886882322432.0,
      "budget_used_percent": 1.798886882322432
    },
    {
      "type": "training",
      "description": "Training step 1257",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:55",
      "total_flops_so_far": 1800317977694208.0,
      "budget_used_percent": 1.8003179776942082
    },
    {
      "type": "training",
      "description": "Training step 1258",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:55",
      "total_flops_so_far": 1801749073065984.0,
      "budget_used_percent": 1.801749073065984
    },
    {
      "type": "training",
      "description": "Training step 1259",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:55",
      "total_flops_so_far": 1803180168437760.0,
      "budget_used_percent": 1.80318016843776
    },
    {
      "type": "training",
      "description": "Training step 1260",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:55",
      "total_flops_so_far": 1804611263809536.0,
      "budget_used_percent": 1.8046112638095362
    },
    {
      "type": "training",
      "description": "Training step 1261",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:55",
      "total_flops_so_far": 1806042359181312.0,
      "budget_used_percent": 1.806042359181312
    },
    {
      "type": "training",
      "description": "Training step 1262",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:55",
      "total_flops_so_far": 1807473454553088.0,
      "budget_used_percent": 1.807473454553088
    },
    {
      "type": "training",
      "description": "Training step 1263",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:56",
      "total_flops_so_far": 1808904549924864.0,
      "budget_used_percent": 1.808904549924864
    },
    {
      "type": "training",
      "description": "Training step 1264",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:56",
      "total_flops_so_far": 1810335645296640.0,
      "budget_used_percent": 1.8103356452966402
    },
    {
      "type": "training",
      "description": "Training step 1265",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:56",
      "total_flops_so_far": 1811766740668416.0,
      "budget_used_percent": 1.811766740668416
    },
    {
      "type": "training",
      "description": "Training step 1266",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:56",
      "total_flops_so_far": 1813197836040192.0,
      "budget_used_percent": 1.813197836040192
    },
    {
      "type": "training",
      "description": "Training step 1267",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:56",
      "total_flops_so_far": 1814628931411968.0,
      "budget_used_percent": 1.8146289314119681
    },
    {
      "type": "training",
      "description": "Training step 1268",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:56",
      "total_flops_so_far": 1816060026783744.0,
      "budget_used_percent": 1.816060026783744
    },
    {
      "type": "training",
      "description": "Training step 1269",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:56",
      "total_flops_so_far": 1817491122155520.0,
      "budget_used_percent": 1.81749112215552
    },
    {
      "type": "training",
      "description": "Training step 1270",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:57",
      "total_flops_so_far": 1818922217527296.0,
      "budget_used_percent": 1.818922217527296
    },
    {
      "type": "training",
      "description": "Training step 1271",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:57",
      "total_flops_so_far": 1820353312899072.0,
      "budget_used_percent": 1.8203533128990719
    },
    {
      "type": "training",
      "description": "Training step 1272",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:57",
      "total_flops_so_far": 1821784408270848.0,
      "budget_used_percent": 1.8217844082708479
    },
    {
      "type": "training",
      "description": "Training step 1273",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:57",
      "total_flops_so_far": 1823215503642624.0,
      "budget_used_percent": 1.823215503642624
    },
    {
      "type": "training",
      "description": "Training step 1274",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:57",
      "total_flops_so_far": 1824646599014400.0,
      "budget_used_percent": 1.8246465990144
    },
    {
      "type": "training",
      "description": "Training step 1275",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:57",
      "total_flops_so_far": 1826077694386176.0,
      "budget_used_percent": 1.8260776943861758
    },
    {
      "type": "training",
      "description": "Training step 1276",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:57",
      "total_flops_so_far": 1827508789757952.0,
      "budget_used_percent": 1.827508789757952
    },
    {
      "type": "training",
      "description": "Training step 1277",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:58",
      "total_flops_so_far": 1828939885129728.0,
      "budget_used_percent": 1.828939885129728
    },
    {
      "type": "training",
      "description": "Training step 1278",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:58",
      "total_flops_so_far": 1830370980501504.0,
      "budget_used_percent": 1.8303709805015038
    },
    {
      "type": "training",
      "description": "Training step 1279",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:58",
      "total_flops_so_far": 1831802075873280.0,
      "budget_used_percent": 1.83180207587328
    },
    {
      "type": "training",
      "description": "Training step 1280",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:58",
      "total_flops_so_far": 1833233171245056.0,
      "budget_used_percent": 1.833233171245056
    },
    {
      "type": "training",
      "description": "Training step 1281",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:58",
      "total_flops_so_far": 1834664266616832.0,
      "budget_used_percent": 1.8346642666168322
    },
    {
      "type": "training",
      "description": "Training step 1282",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:58",
      "total_flops_so_far": 1836095361988608.0,
      "budget_used_percent": 1.836095361988608
    },
    {
      "type": "training",
      "description": "Training step 1283",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:58",
      "total_flops_so_far": 1837526457360384.0,
      "budget_used_percent": 1.837526457360384
    },
    {
      "type": "training",
      "description": "Training step 1284",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:59",
      "total_flops_so_far": 1838957552732160.0,
      "budget_used_percent": 1.8389575527321602
    },
    {
      "type": "training",
      "description": "Training step 1285",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:59",
      "total_flops_so_far": 1840388648103936.0,
      "budget_used_percent": 1.840388648103936
    },
    {
      "type": "training",
      "description": "Training step 1286",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:59",
      "total_flops_so_far": 1841819743475712.0,
      "budget_used_percent": 1.841819743475712
    },
    {
      "type": "training",
      "description": "Training step 1287",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:59",
      "total_flops_so_far": 1843250838847488.0,
      "budget_used_percent": 1.8432508388474882
    },
    {
      "type": "training",
      "description": "Training step 1288",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:59",
      "total_flops_so_far": 1844681934219264.0,
      "budget_used_percent": 1.8446819342192637
    },
    {
      "type": "training",
      "description": "Training step 1289",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:54:59",
      "total_flops_so_far": 1846113029591040.0,
      "budget_used_percent": 1.84611302959104
    },
    {
      "type": "training",
      "description": "Training step 1290",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:00",
      "total_flops_so_far": 1847544124962816.0,
      "budget_used_percent": 1.8475441249628162
    },
    {
      "type": "training",
      "description": "Training step 1291",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:00",
      "total_flops_so_far": 1848975220334592.0,
      "budget_used_percent": 1.8489752203345922
    },
    {
      "type": "training",
      "description": "Training step 1292",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:00",
      "total_flops_so_far": 1850406315706368.0,
      "budget_used_percent": 1.850406315706368
    },
    {
      "type": "training",
      "description": "Training step 1293",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:00",
      "total_flops_so_far": 1851837411078144.0,
      "budget_used_percent": 1.851837411078144
    },
    {
      "type": "training",
      "description": "Training step 1294",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:00",
      "total_flops_so_far": 1853268506449920.0,
      "budget_used_percent": 1.8532685064499201
    },
    {
      "type": "training",
      "description": "Training step 1295",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:00",
      "total_flops_so_far": 1854699601821696.0,
      "budget_used_percent": 1.854699601821696
    },
    {
      "type": "training",
      "description": "Training step 1296",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:00",
      "total_flops_so_far": 1856130697193472.0,
      "budget_used_percent": 1.856130697193472
    },
    {
      "type": "training",
      "description": "Training step 1297",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:01",
      "total_flops_so_far": 1857561792565248.0,
      "budget_used_percent": 1.8575617925652481
    },
    {
      "type": "training",
      "description": "Training step 1298",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:01",
      "total_flops_so_far": 1858992887937024.0,
      "budget_used_percent": 1.8589928879370239
    },
    {
      "type": "training",
      "description": "Training step 1299",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:01",
      "total_flops_so_far": 1860423983308800.0,
      "budget_used_percent": 1.8604239833087999
    },
    {
      "type": "training",
      "description": "Training step 1300",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:01",
      "total_flops_so_far": 1861855078680576.0,
      "budget_used_percent": 1.861855078680576
    },
    {
      "type": "training",
      "description": "Training step 1301",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:01",
      "total_flops_so_far": 1863286174052352.0,
      "budget_used_percent": 1.863286174052352
    },
    {
      "type": "training",
      "description": "Training step 1302",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:01",
      "total_flops_so_far": 1864717269424128.0,
      "budget_used_percent": 1.8647172694241279
    },
    {
      "type": "training",
      "description": "Training step 1303",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:01",
      "total_flops_so_far": 1866148364795904.0,
      "budget_used_percent": 1.866148364795904
    },
    {
      "type": "training",
      "description": "Training step 1304",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:02",
      "total_flops_so_far": 1867579460167680.0,
      "budget_used_percent": 1.86757946016768
    },
    {
      "type": "training",
      "description": "Training step 1305",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:02",
      "total_flops_so_far": 1869010555539456.0,
      "budget_used_percent": 1.8690105555394558
    },
    {
      "type": "training",
      "description": "Training step 1306",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:02",
      "total_flops_so_far": 1870441650911232.0,
      "budget_used_percent": 1.870441650911232
    },
    {
      "type": "training",
      "description": "Training step 1307",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:02",
      "total_flops_so_far": 1871872746283008.0,
      "budget_used_percent": 1.871872746283008
    },
    {
      "type": "training",
      "description": "Training step 1308",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:02",
      "total_flops_so_far": 1873303841654784.0,
      "budget_used_percent": 1.8733038416547838
    },
    {
      "type": "training",
      "description": "Training step 1309",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:02",
      "total_flops_so_far": 1874734937026560.0,
      "budget_used_percent": 1.87473493702656
    },
    {
      "type": "training",
      "description": "Training step 1310",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:03",
      "total_flops_so_far": 1876166032398336.0,
      "budget_used_percent": 1.876166032398336
    },
    {
      "type": "training",
      "description": "Training step 1311",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:03",
      "total_flops_so_far": 1877597127770112.0,
      "budget_used_percent": 1.8775971277701122
    },
    {
      "type": "training",
      "description": "Training step 1312",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:03",
      "total_flops_so_far": 1879028223141888.0,
      "budget_used_percent": 1.879028223141888
    },
    {
      "type": "training",
      "description": "Training step 1313",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:03",
      "total_flops_so_far": 1880459318513664.0,
      "budget_used_percent": 1.880459318513664
    },
    {
      "type": "training",
      "description": "Training step 1314",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:03",
      "total_flops_so_far": 1881890413885440.0,
      "budget_used_percent": 1.8818904138854402
    },
    {
      "type": "training",
      "description": "Training step 1315",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:03",
      "total_flops_so_far": 1883321509257216.0,
      "budget_used_percent": 1.883321509257216
    },
    {
      "type": "training",
      "description": "Training step 1316",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:03",
      "total_flops_so_far": 1884752604628992.0,
      "budget_used_percent": 1.884752604628992
    },
    {
      "type": "training",
      "description": "Training step 1317",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:04",
      "total_flops_so_far": 1886183700000768.0,
      "budget_used_percent": 1.886183700000768
    },
    {
      "type": "training",
      "description": "Training step 1318",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:04",
      "total_flops_so_far": 1887614795372544.0,
      "budget_used_percent": 1.8876147953725437
    },
    {
      "type": "training",
      "description": "Training step 1319",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:04",
      "total_flops_so_far": 1889045890744320.0,
      "budget_used_percent": 1.88904589074432
    },
    {
      "type": "training",
      "description": "Training step 1320",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:04",
      "total_flops_so_far": 1890476986116096.0,
      "budget_used_percent": 1.890476986116096
    },
    {
      "type": "training",
      "description": "Training step 1321",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:04",
      "total_flops_so_far": 1891908081487872.0,
      "budget_used_percent": 1.8919080814878722
    },
    {
      "type": "training",
      "description": "Training step 1322",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:04",
      "total_flops_so_far": 1893339176859648.0,
      "budget_used_percent": 1.893339176859648
    },
    {
      "type": "training",
      "description": "Training step 1323",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:05",
      "total_flops_so_far": 1894770272231424.0,
      "budget_used_percent": 1.894770272231424
    },
    {
      "type": "training",
      "description": "Training step 1324",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:05",
      "total_flops_so_far": 1896201367603200.0,
      "budget_used_percent": 1.8962013676032001
    },
    {
      "type": "training",
      "description": "Training step 1325",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:05",
      "total_flops_so_far": 1897632462974976.0,
      "budget_used_percent": 1.897632462974976
    },
    {
      "type": "training",
      "description": "Training step 1326",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:05",
      "total_flops_so_far": 1899063558346752.0,
      "budget_used_percent": 1.899063558346752
    },
    {
      "type": "training",
      "description": "Training step 1327",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:05",
      "total_flops_so_far": 1900494653718528.0,
      "budget_used_percent": 1.900494653718528
    },
    {
      "type": "training",
      "description": "Training step 1328",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:05",
      "total_flops_so_far": 1901925749090304.0,
      "budget_used_percent": 1.901925749090304
    },
    {
      "type": "training",
      "description": "Training step 1329",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:05",
      "total_flops_so_far": 1903356844462080.0,
      "budget_used_percent": 1.9033568444620799
    },
    {
      "type": "training",
      "description": "Training step 1330",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:06",
      "total_flops_so_far": 1904787939833856.0,
      "budget_used_percent": 1.904787939833856
    },
    {
      "type": "training",
      "description": "Training step 1331",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:06",
      "total_flops_so_far": 1906219035205632.0,
      "budget_used_percent": 1.906219035205632
    },
    {
      "type": "training",
      "description": "Training step 1332",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:06",
      "total_flops_so_far": 1907650130577408.0,
      "budget_used_percent": 1.9076501305774078
    },
    {
      "type": "training",
      "description": "Training step 1333",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:06",
      "total_flops_so_far": 1909081225949184.0,
      "budget_used_percent": 1.909081225949184
    },
    {
      "type": "training",
      "description": "Training step 1334",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:06",
      "total_flops_so_far": 1910512321320960.0,
      "budget_used_percent": 1.91051232132096
    },
    {
      "type": "training",
      "description": "Training step 1335",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:06",
      "total_flops_so_far": 1911943416692736.0,
      "budget_used_percent": 1.9119434166927358
    },
    {
      "type": "training",
      "description": "Training step 1336",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:06",
      "total_flops_so_far": 1913374512064512.0,
      "budget_used_percent": 1.913374512064512
    },
    {
      "type": "training",
      "description": "Training step 1337",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:07",
      "total_flops_so_far": 1914805607436288.0,
      "budget_used_percent": 1.914805607436288
    },
    {
      "type": "training",
      "description": "Training step 1338",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:07",
      "total_flops_so_far": 1916236702808064.0,
      "budget_used_percent": 1.9162367028080642
    },
    {
      "type": "training",
      "description": "Training step 1339",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:07",
      "total_flops_so_far": 1917667798179840.0,
      "budget_used_percent": 1.91766779817984
    },
    {
      "type": "training",
      "description": "Training step 1340",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:07",
      "total_flops_so_far": 1919098893551616.0,
      "budget_used_percent": 1.919098893551616
    },
    {
      "type": "training",
      "description": "Training step 1341",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:07",
      "total_flops_so_far": 1920529988923392.0,
      "budget_used_percent": 1.9205299889233922
    },
    {
      "type": "training",
      "description": "Training step 1342",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:07",
      "total_flops_so_far": 1921961084295168.0,
      "budget_used_percent": 1.9219610842951678
    },
    {
      "type": "training",
      "description": "Training step 1343",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:08",
      "total_flops_so_far": 1923392179666944.0,
      "budget_used_percent": 1.923392179666944
    },
    {
      "type": "training",
      "description": "Training step 1344",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:08",
      "total_flops_so_far": 1924823275038720.0,
      "budget_used_percent": 1.9248232750387202
    },
    {
      "type": "training",
      "description": "Training step 1345",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:08",
      "total_flops_so_far": 1926254370410496.0,
      "budget_used_percent": 1.9262543704104957
    },
    {
      "type": "training",
      "description": "Training step 1346",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:08",
      "total_flops_so_far": 1927685465782272.0,
      "budget_used_percent": 1.927685465782272
    },
    {
      "type": "training",
      "description": "Training step 1347",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:08",
      "total_flops_so_far": 1929116561154048.0,
      "budget_used_percent": 1.929116561154048
    },
    {
      "type": "training",
      "description": "Training step 1348",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:08",
      "total_flops_so_far": 1930547656525824.0,
      "budget_used_percent": 1.9305476565258242
    },
    {
      "type": "training",
      "description": "Training step 1349",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:08",
      "total_flops_so_far": 1931978751897600.0,
      "budget_used_percent": 1.9319787518976
    },
    {
      "type": "training",
      "description": "Training step 1350",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:09",
      "total_flops_so_far": 1933409847269376.0,
      "budget_used_percent": 1.933409847269376
    },
    {
      "type": "training",
      "description": "Training step 1351",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:09",
      "total_flops_so_far": 1934840942641152.0,
      "budget_used_percent": 1.9348409426411521
    },
    {
      "type": "training",
      "description": "Training step 1352",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:09",
      "total_flops_so_far": 1936272038012928.0,
      "budget_used_percent": 1.936272038012928
    },
    {
      "type": "training",
      "description": "Training step 1353",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:09",
      "total_flops_so_far": 1937703133384704.0,
      "budget_used_percent": 1.937703133384704
    },
    {
      "type": "training",
      "description": "Training step 1354",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:09",
      "total_flops_so_far": 1939134228756480.0,
      "budget_used_percent": 1.9391342287564801
    },
    {
      "type": "training",
      "description": "Training step 1355",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:09",
      "total_flops_so_far": 1940565324128256.0,
      "budget_used_percent": 1.9405653241282559
    },
    {
      "type": "training",
      "description": "Training step 1356",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:09",
      "total_flops_so_far": 1941996419500032.0,
      "budget_used_percent": 1.9419964195000319
    },
    {
      "type": "training",
      "description": "Training step 1357",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:10",
      "total_flops_so_far": 1943427514871808.0,
      "budget_used_percent": 1.943427514871808
    },
    {
      "type": "training",
      "description": "Training step 1358",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:10",
      "total_flops_so_far": 1944858610243584.0,
      "budget_used_percent": 1.944858610243584
    },
    {
      "type": "training",
      "description": "Training step 1359",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:10",
      "total_flops_so_far": 1946289705615360.0,
      "budget_used_percent": 1.9462897056153599
    },
    {
      "type": "training",
      "description": "Training step 1360",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:10",
      "total_flops_so_far": 1947720800987136.0,
      "budget_used_percent": 1.947720800987136
    },
    {
      "type": "training",
      "description": "Training step 1361",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:11",
      "total_flops_so_far": 1949151896358912.0,
      "budget_used_percent": 1.949151896358912
    },
    {
      "type": "training",
      "description": "Training step 1362",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:11",
      "total_flops_so_far": 1950582991730688.0,
      "budget_used_percent": 1.9505829917306878
    },
    {
      "type": "training",
      "description": "Training step 1363",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:11",
      "total_flops_so_far": 1952014087102464.0,
      "budget_used_percent": 1.952014087102464
    },
    {
      "type": "training",
      "description": "Training step 1364",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:11",
      "total_flops_so_far": 1953445182474240.0,
      "budget_used_percent": 1.95344518247424
    },
    {
      "type": "training",
      "description": "Training step 1365",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:11",
      "total_flops_so_far": 1954876277846016.0,
      "budget_used_percent": 1.9548762778460163
    },
    {
      "type": "training",
      "description": "Training step 1366",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:11",
      "total_flops_so_far": 1956307373217792.0,
      "budget_used_percent": 1.956307373217792
    },
    {
      "type": "training",
      "description": "Training step 1367",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:11",
      "total_flops_so_far": 1957738468589568.0,
      "budget_used_percent": 1.957738468589568
    },
    {
      "type": "training",
      "description": "Training step 1368",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:12",
      "total_flops_so_far": 1959169563961344.0,
      "budget_used_percent": 1.9591695639613442
    },
    {
      "type": "training",
      "description": "Training step 1369",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:12",
      "total_flops_so_far": 1960600659333120.0,
      "budget_used_percent": 1.96060065933312
    },
    {
      "type": "training",
      "description": "Training step 1370",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:12",
      "total_flops_so_far": 1962031754704896.0,
      "budget_used_percent": 1.962031754704896
    },
    {
      "type": "training",
      "description": "Training step 1371",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:12",
      "total_flops_so_far": 1963462850076672.0,
      "budget_used_percent": 1.963462850076672
    },
    {
      "type": "training",
      "description": "Training step 1372",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:12",
      "total_flops_so_far": 1964893945448448.0,
      "budget_used_percent": 1.9648939454484478
    },
    {
      "type": "training",
      "description": "Training step 1373",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:12",
      "total_flops_so_far": 1966325040820224.0,
      "budget_used_percent": 1.966325040820224
    },
    {
      "type": "training",
      "description": "Training step 1374",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:12",
      "total_flops_so_far": 1967756136192000.0,
      "budget_used_percent": 1.967756136192
    },
    {
      "type": "training",
      "description": "Training step 1375",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:13",
      "total_flops_so_far": 1969187231563776.0,
      "budget_used_percent": 1.9691872315637762
    },
    {
      "type": "training",
      "description": "Training step 1376",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:13",
      "total_flops_so_far": 1970618326935552.0,
      "budget_used_percent": 1.970618326935552
    },
    {
      "type": "training",
      "description": "Training step 1377",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:13",
      "total_flops_so_far": 1972049422307328.0,
      "budget_used_percent": 1.972049422307328
    },
    {
      "type": "training",
      "description": "Training step 1378",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:13",
      "total_flops_so_far": 1973480517679104.0,
      "budget_used_percent": 1.9734805176791042
    },
    {
      "type": "training",
      "description": "Training step 1379",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:13",
      "total_flops_so_far": 1974911613050880.0,
      "budget_used_percent": 1.97491161305088
    },
    {
      "type": "training",
      "description": "Training step 1380",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:13",
      "total_flops_so_far": 1976342708422656.0,
      "budget_used_percent": 1.976342708422656
    },
    {
      "type": "training",
      "description": "Training step 1381",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:14",
      "total_flops_so_far": 1977773803794432.0,
      "budget_used_percent": 1.9777738037944321
    },
    {
      "type": "training",
      "description": "Training step 1382",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:14",
      "total_flops_so_far": 1979204899166208.0,
      "budget_used_percent": 1.979204899166208
    },
    {
      "type": "training",
      "description": "Training step 1383",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:14",
      "total_flops_so_far": 1980635994537984.0,
      "budget_used_percent": 1.980635994537984
    },
    {
      "type": "training",
      "description": "Training step 1384",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:14",
      "total_flops_so_far": 1982067089909760.0,
      "budget_used_percent": 1.98206708990976
    },
    {
      "type": "training",
      "description": "Training step 1385",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:14",
      "total_flops_so_far": 1983498185281536.0,
      "budget_used_percent": 1.983498185281536
    },
    {
      "type": "training",
      "description": "Training step 1386",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:14",
      "total_flops_so_far": 1984929280653312.0,
      "budget_used_percent": 1.9849292806533119
    },
    {
      "type": "training",
      "description": "Training step 1387",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:14",
      "total_flops_so_far": 1986360376025088.0,
      "budget_used_percent": 1.986360376025088
    },
    {
      "type": "training",
      "description": "Training step 1388",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:15",
      "total_flops_so_far": 1987791471396864.0,
      "budget_used_percent": 1.987791471396864
    },
    {
      "type": "training",
      "description": "Training step 1389",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:15",
      "total_flops_so_far": 1989222566768640.0,
      "budget_used_percent": 1.9892225667686398
    },
    {
      "type": "training",
      "description": "Training step 1390",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:15",
      "total_flops_so_far": 1990653662140416.0,
      "budget_used_percent": 1.990653662140416
    },
    {
      "type": "training",
      "description": "Training step 1391",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:15",
      "total_flops_so_far": 1992084757512192.0,
      "budget_used_percent": 1.992084757512192
    },
    {
      "type": "training",
      "description": "Training step 1392",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:15",
      "total_flops_so_far": 1993515852883968.0,
      "budget_used_percent": 1.9935158528839678
    },
    {
      "type": "training",
      "description": "Training step 1393",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:15",
      "total_flops_so_far": 1994946948255744.0,
      "budget_used_percent": 1.994946948255744
    },
    {
      "type": "training",
      "description": "Training step 1394",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:16",
      "total_flops_so_far": 1996378043627520.0,
      "budget_used_percent": 1.99637804362752
    },
    {
      "type": "training",
      "description": "Training step 1395",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:16",
      "total_flops_so_far": 1997809138999296.0,
      "budget_used_percent": 1.9978091389992962
    },
    {
      "type": "training",
      "description": "Training step 1396",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:16",
      "total_flops_so_far": 1999240234371072.0,
      "budget_used_percent": 1.9992402343710718
    },
    {
      "type": "training",
      "description": "Training step 1397",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:16",
      "total_flops_so_far": 2000671329742848.0,
      "budget_used_percent": 2.000671329742848
    },
    {
      "type": "training",
      "description": "Training step 1398",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:16",
      "total_flops_so_far": 2002102425114624.0,
      "budget_used_percent": 2.002102425114624
    },
    {
      "type": "training",
      "description": "Training step 1399",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:16",
      "total_flops_so_far": 2003533520486400.0,
      "budget_used_percent": 2.0035335204863998
    },
    {
      "type": "training",
      "description": "Training step 1400",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:17",
      "total_flops_so_far": 2004964615858176.0,
      "budget_used_percent": 2.0049646158581758
    },
    {
      "type": "training",
      "description": "Training step 1401",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:17",
      "total_flops_so_far": 2006395711229952.0,
      "budget_used_percent": 2.006395711229952
    },
    {
      "type": "training",
      "description": "Training step 1402",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:17",
      "total_flops_so_far": 2007826806601728.0,
      "budget_used_percent": 2.007826806601728
    },
    {
      "type": "training",
      "description": "Training step 1403",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:17",
      "total_flops_so_far": 2009257901973504.0,
      "budget_used_percent": 2.0092579019735037
    },
    {
      "type": "training",
      "description": "Training step 1404",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:17",
      "total_flops_so_far": 2010688997345280.0,
      "budget_used_percent": 2.01068899734528
    },
    {
      "type": "training",
      "description": "Training step 1405",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:17",
      "total_flops_so_far": 2012120092717056.0,
      "budget_used_percent": 2.012120092717056
    },
    {
      "type": "training",
      "description": "Training step 1406",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:17",
      "total_flops_so_far": 2013551188088832.0,
      "budget_used_percent": 2.0135511880888317
    },
    {
      "type": "training",
      "description": "Training step 1407",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:18",
      "total_flops_so_far": 2014982283460608.0,
      "budget_used_percent": 2.014982283460608
    },
    {
      "type": "training",
      "description": "Training step 1408",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:18",
      "total_flops_so_far": 2016413378832384.0,
      "budget_used_percent": 2.016413378832384
    },
    {
      "type": "training",
      "description": "Training step 1409",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:18",
      "total_flops_so_far": 2017844474204160.0,
      "budget_used_percent": 2.0178444742041597
    },
    {
      "type": "training",
      "description": "Training step 1410",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:18",
      "total_flops_so_far": 2019275569575936.0,
      "budget_used_percent": 2.019275569575936
    },
    {
      "type": "training",
      "description": "Training step 1411",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:18",
      "total_flops_so_far": 2020706664947712.0,
      "budget_used_percent": 2.020706664947712
    },
    {
      "type": "training",
      "description": "Training step 1412",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:18",
      "total_flops_so_far": 2022137760319488.0,
      "budget_used_percent": 2.022137760319488
    },
    {
      "type": "training",
      "description": "Training step 1413",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:19",
      "total_flops_so_far": 2023568855691264.0,
      "budget_used_percent": 2.023568855691264
    },
    {
      "type": "training",
      "description": "Training step 1414",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:19",
      "total_flops_so_far": 2024999951063040.0,
      "budget_used_percent": 2.02499995106304
    },
    {
      "type": "training",
      "description": "Training step 1415",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:19",
      "total_flops_so_far": 2026431046434816.0,
      "budget_used_percent": 2.026431046434816
    },
    {
      "type": "training",
      "description": "Training step 1416",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:19",
      "total_flops_so_far": 2027862141806592.0,
      "budget_used_percent": 2.027862141806592
    },
    {
      "type": "training",
      "description": "Training step 1417",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:19",
      "total_flops_so_far": 2029293237178368.0,
      "budget_used_percent": 2.029293237178368
    },
    {
      "type": "training",
      "description": "Training step 1418",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:19",
      "total_flops_so_far": 2030724332550144.0,
      "budget_used_percent": 2.030724332550144
    },
    {
      "type": "training",
      "description": "Training step 1419",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:19",
      "total_flops_so_far": 2032155427921920.0,
      "budget_used_percent": 2.03215542792192
    },
    {
      "type": "training",
      "description": "Training step 1420",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:20",
      "total_flops_so_far": 2033586523293696.0,
      "budget_used_percent": 2.033586523293696
    },
    {
      "type": "training",
      "description": "Training step 1421",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:20",
      "total_flops_so_far": 2035017618665472.0,
      "budget_used_percent": 2.035017618665472
    },
    {
      "type": "training",
      "description": "Training step 1422",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:20",
      "total_flops_so_far": 2036448714037248.0,
      "budget_used_percent": 2.036448714037248
    },
    {
      "type": "training",
      "description": "Training step 1423",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:20",
      "total_flops_so_far": 2037879809409024.0,
      "budget_used_percent": 2.037879809409024
    },
    {
      "type": "training",
      "description": "Training step 1424",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:20",
      "total_flops_so_far": 2039310904780800.0,
      "budget_used_percent": 2.0393109047808
    },
    {
      "type": "training",
      "description": "Training step 1425",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:20",
      "total_flops_so_far": 2040742000152576.0,
      "budget_used_percent": 2.040742000152576
    },
    {
      "type": "training",
      "description": "Training step 1426",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:20",
      "total_flops_so_far": 2042173095524352.0,
      "budget_used_percent": 2.042173095524352
    },
    {
      "type": "training",
      "description": "Training step 1427",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:21",
      "total_flops_so_far": 2043604190896128.0,
      "budget_used_percent": 2.043604190896128
    },
    {
      "type": "training",
      "description": "Training step 1428",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:21",
      "total_flops_so_far": 2045035286267904.0,
      "budget_used_percent": 2.045035286267904
    },
    {
      "type": "training",
      "description": "Training step 1429",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:21",
      "total_flops_so_far": 2046466381639680.0,
      "budget_used_percent": 2.04646638163968
    },
    {
      "type": "training",
      "description": "Training step 1430",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:21",
      "total_flops_so_far": 2047897477011456.0,
      "budget_used_percent": 2.047897477011456
    },
    {
      "type": "training",
      "description": "Training step 1431",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:21",
      "total_flops_so_far": 2049328572383232.0,
      "budget_used_percent": 2.049328572383232
    },
    {
      "type": "training",
      "description": "Training step 1432",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:21",
      "total_flops_so_far": 2050759667755008.0,
      "budget_used_percent": 2.050759667755008
    },
    {
      "type": "training",
      "description": "Training step 1433",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:22",
      "total_flops_so_far": 2052190763126784.0,
      "budget_used_percent": 2.052190763126784
    },
    {
      "type": "training",
      "description": "Training step 1434",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:22",
      "total_flops_so_far": 2053621858498560.0,
      "budget_used_percent": 2.05362185849856
    },
    {
      "type": "training",
      "description": "Training step 1435",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:22",
      "total_flops_so_far": 2055052953870336.0,
      "budget_used_percent": 2.055052953870336
    },
    {
      "type": "training",
      "description": "Training step 1436",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:22",
      "total_flops_so_far": 2056484049242112.0,
      "budget_used_percent": 2.056484049242112
    },
    {
      "type": "training",
      "description": "Training step 1437",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:22",
      "total_flops_so_far": 2057915144613888.0,
      "budget_used_percent": 2.057915144613888
    },
    {
      "type": "training",
      "description": "Training step 1438",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:22",
      "total_flops_so_far": 2059346239985664.0,
      "budget_used_percent": 2.059346239985664
    },
    {
      "type": "training",
      "description": "Training step 1439",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:22",
      "total_flops_so_far": 2060777335357440.0,
      "budget_used_percent": 2.06077733535744
    },
    {
      "type": "training",
      "description": "Training step 1440",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:23",
      "total_flops_so_far": 2062208430729216.0,
      "budget_used_percent": 2.062208430729216
    },
    {
      "type": "training",
      "description": "Training step 1441",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:23",
      "total_flops_so_far": 2063639526100992.0,
      "budget_used_percent": 2.063639526100992
    },
    {
      "type": "training",
      "description": "Training step 1442",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:23",
      "total_flops_so_far": 2065070621472768.0,
      "budget_used_percent": 2.0650706214727683
    },
    {
      "type": "training",
      "description": "Training step 1443",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:23",
      "total_flops_so_far": 2066501716844544.0,
      "budget_used_percent": 2.066501716844544
    },
    {
      "type": "training",
      "description": "Training step 1444",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:23",
      "total_flops_so_far": 2067932812216320.0,
      "budget_used_percent": 2.06793281221632
    },
    {
      "type": "training",
      "description": "Training step 1445",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:23",
      "total_flops_so_far": 2069363907588096.0,
      "budget_used_percent": 2.0693639075880963
    },
    {
      "type": "training",
      "description": "Training step 1446",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:24",
      "total_flops_so_far": 2070795002959872.0,
      "budget_used_percent": 2.070795002959872
    },
    {
      "type": "training",
      "description": "Training step 1447",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:24",
      "total_flops_so_far": 2072226098331648.0,
      "budget_used_percent": 2.072226098331648
    },
    {
      "type": "training",
      "description": "Training step 1448",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:24",
      "total_flops_so_far": 2073657193703424.0,
      "budget_used_percent": 2.0736571937034243
    },
    {
      "type": "training",
      "description": "Training step 1449",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:24",
      "total_flops_so_far": 2075088289075200.0,
      "budget_used_percent": 2.0750882890752003
    },
    {
      "type": "training",
      "description": "Training step 1450",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:24",
      "total_flops_so_far": 2076519384446976.0,
      "budget_used_percent": 2.076519384446976
    },
    {
      "type": "training",
      "description": "Training step 1451",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:24",
      "total_flops_so_far": 2077950479818752.0,
      "budget_used_percent": 2.0779504798187522
    },
    {
      "type": "training",
      "description": "Training step 1452",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:24",
      "total_flops_so_far": 2079381575190528.0,
      "budget_used_percent": 2.0793815751905282
    },
    {
      "type": "training",
      "description": "Training step 1453",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:25",
      "total_flops_so_far": 2080812670562304.0,
      "budget_used_percent": 2.080812670562304
    },
    {
      "type": "training",
      "description": "Training step 1454",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:25",
      "total_flops_so_far": 2082243765934080.0,
      "budget_used_percent": 2.08224376593408
    },
    {
      "type": "training",
      "description": "Training step 1455",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:25",
      "total_flops_so_far": 2083674861305856.0,
      "budget_used_percent": 2.083674861305856
    },
    {
      "type": "training",
      "description": "Training step 1456",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:25",
      "total_flops_so_far": 2085105956677632.0,
      "budget_used_percent": 2.0851059566776318
    },
    {
      "type": "training",
      "description": "Training step 1457",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:25",
      "total_flops_so_far": 2086537052049408.0,
      "budget_used_percent": 2.0865370520494078
    },
    {
      "type": "training",
      "description": "Training step 1458",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:25",
      "total_flops_so_far": 2087968147421184.0,
      "budget_used_percent": 2.087968147421184
    },
    {
      "type": "training",
      "description": "Training step 1459",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:25",
      "total_flops_so_far": 2089399242792960.0,
      "budget_used_percent": 2.08939924279296
    },
    {
      "type": "training",
      "description": "Training step 1460",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:26",
      "total_flops_so_far": 2090830338164736.0,
      "budget_used_percent": 2.0908303381647357
    },
    {
      "type": "training",
      "description": "Training step 1461",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:26",
      "total_flops_so_far": 2092261433536512.0,
      "budget_used_percent": 2.092261433536512
    },
    {
      "type": "training",
      "description": "Training step 1462",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:26",
      "total_flops_so_far": 2093692528908288.0,
      "budget_used_percent": 2.093692528908288
    },
    {
      "type": "training",
      "description": "Training step 1463",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:26",
      "total_flops_so_far": 2095123624280064.0,
      "budget_used_percent": 2.0951236242800637
    },
    {
      "type": "training",
      "description": "Training step 1464",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:26",
      "total_flops_so_far": 2096554719651840.0,
      "budget_used_percent": 2.09655471965184
    },
    {
      "type": "training",
      "description": "Training step 1465",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:26",
      "total_flops_so_far": 2097985815023616.0,
      "budget_used_percent": 2.097985815023616
    },
    {
      "type": "training",
      "description": "Training step 1466",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:27",
      "total_flops_so_far": 2099416910395392.0,
      "budget_used_percent": 2.0994169103953917
    },
    {
      "type": "training",
      "description": "Training step 1467",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:27",
      "total_flops_so_far": 2100848005767168.0,
      "budget_used_percent": 2.100848005767168
    },
    {
      "type": "training",
      "description": "Training step 1468",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:27",
      "total_flops_so_far": 2102279101138944.0,
      "budget_used_percent": 2.102279101138944
    },
    {
      "type": "training",
      "description": "Training step 1469",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:27",
      "total_flops_so_far": 2103710196510720.0,
      "budget_used_percent": 2.10371019651072
    },
    {
      "type": "training",
      "description": "Training step 1470",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:27",
      "total_flops_so_far": 2105141291882496.0,
      "budget_used_percent": 2.105141291882496
    },
    {
      "type": "training",
      "description": "Training step 1471",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:27",
      "total_flops_so_far": 2106572387254272.0,
      "budget_used_percent": 2.106572387254272
    },
    {
      "type": "training",
      "description": "Training step 1472",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:28",
      "total_flops_so_far": 2108003482626048.0,
      "budget_used_percent": 2.108003482626048
    },
    {
      "type": "training",
      "description": "Training step 1473",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:28",
      "total_flops_so_far": 2109434577997824.0,
      "budget_used_percent": 2.109434577997824
    },
    {
      "type": "training",
      "description": "Training step 1474",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:28",
      "total_flops_so_far": 2110865673369600.0,
      "budget_used_percent": 2.1108656733696
    },
    {
      "type": "training",
      "description": "Training step 1475",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:28",
      "total_flops_so_far": 2112296768741376.0,
      "budget_used_percent": 2.112296768741376
    },
    {
      "type": "training",
      "description": "Training step 1476",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:28",
      "total_flops_so_far": 2113727864113152.0,
      "budget_used_percent": 2.1137278641131516
    },
    {
      "type": "training",
      "description": "Training step 1477",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:28",
      "total_flops_so_far": 2115158959484928.0,
      "budget_used_percent": 2.115158959484928
    },
    {
      "type": "training",
      "description": "Training step 1478",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:28",
      "total_flops_so_far": 2116590054856704.0,
      "budget_used_percent": 2.116590054856704
    },
    {
      "type": "training",
      "description": "Training step 1479",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:29",
      "total_flops_so_far": 2118021150228480.0,
      "budget_used_percent": 2.11802115022848
    },
    {
      "type": "training",
      "description": "Training step 1480",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:29",
      "total_flops_so_far": 2119452245600256.0,
      "budget_used_percent": 2.119452245600256
    },
    {
      "type": "training",
      "description": "Training step 1481",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:29",
      "total_flops_so_far": 2120883340972032.0,
      "budget_used_percent": 2.120883340972032
    },
    {
      "type": "training",
      "description": "Training step 1482",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:29",
      "total_flops_so_far": 2122314436343808.0,
      "budget_used_percent": 2.122314436343808
    },
    {
      "type": "training",
      "description": "Training step 1483",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:29",
      "total_flops_so_far": 2123745531715584.0,
      "budget_used_percent": 2.123745531715584
    },
    {
      "type": "training",
      "description": "Training step 1484",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:29",
      "total_flops_so_far": 2125176627087360.0,
      "budget_used_percent": 2.12517662708736
    },
    {
      "type": "training",
      "description": "Training step 1485",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:30",
      "total_flops_so_far": 2126607722459136.0,
      "budget_used_percent": 2.126607722459136
    },
    {
      "type": "training",
      "description": "Training step 1486",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:30",
      "total_flops_so_far": 2128038817830912.0,
      "budget_used_percent": 2.128038817830912
    },
    {
      "type": "training",
      "description": "Training step 1487",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:30",
      "total_flops_so_far": 2129469913202688.0,
      "budget_used_percent": 2.129469913202688
    },
    {
      "type": "training",
      "description": "Training step 1488",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:30",
      "total_flops_so_far": 2130901008574464.0,
      "budget_used_percent": 2.130901008574464
    },
    {
      "type": "training",
      "description": "Training step 1489",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:30",
      "total_flops_so_far": 2132332103946240.0,
      "budget_used_percent": 2.13233210394624
    },
    {
      "type": "training",
      "description": "Training step 1490",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:30",
      "total_flops_so_far": 2133763199318016.0,
      "budget_used_percent": 2.133763199318016
    },
    {
      "type": "training",
      "description": "Training step 1491",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:30",
      "total_flops_so_far": 2135194294689792.0,
      "budget_used_percent": 2.135194294689792
    },
    {
      "type": "training",
      "description": "Training step 1492",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:31",
      "total_flops_so_far": 2136625390061568.0,
      "budget_used_percent": 2.136625390061568
    },
    {
      "type": "training",
      "description": "Training step 1493",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:31",
      "total_flops_so_far": 2138056485433344.0,
      "budget_used_percent": 2.138056485433344
    },
    {
      "type": "training",
      "description": "Training step 1494",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:31",
      "total_flops_so_far": 2139487580805120.0,
      "budget_used_percent": 2.13948758080512
    },
    {
      "type": "training",
      "description": "Training step 1495",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:31",
      "total_flops_so_far": 2140918676176896.0,
      "budget_used_percent": 2.140918676176896
    },
    {
      "type": "training",
      "description": "Training step 1496",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:31",
      "total_flops_so_far": 2142349771548672.0,
      "budget_used_percent": 2.1423497715486723
    },
    {
      "type": "training",
      "description": "Training step 1497",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:31",
      "total_flops_so_far": 2143780866920448.0,
      "budget_used_percent": 2.143780866920448
    },
    {
      "type": "training",
      "description": "Training step 1498",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:32",
      "total_flops_so_far": 2145211962292224.0,
      "budget_used_percent": 2.145211962292224
    },
    {
      "type": "training",
      "description": "Training step 1499",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:55:32",
      "total_flops_so_far": 2146643057664000.0,
      "budget_used_percent": 2.1466430576640003
    },
    {
      "type": "training",
      "description": "Training step 1500",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:55",
      "total_flops_so_far": 2148074153035776.0,
      "budget_used_percent": 2.148074153035776
    },
    {
      "type": "training",
      "description": "Training step 1501",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:55",
      "total_flops_so_far": 2149505248407552.0,
      "budget_used_percent": 2.149505248407552
    },
    {
      "type": "training",
      "description": "Training step 1502",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:55",
      "total_flops_so_far": 2150936343779328.0,
      "budget_used_percent": 2.1509363437793283
    },
    {
      "type": "training",
      "description": "Training step 1503",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:56",
      "total_flops_so_far": 2152367439151104.0,
      "budget_used_percent": 2.152367439151104
    },
    {
      "type": "training",
      "description": "Training step 1504",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:56",
      "total_flops_so_far": 2153798534522880.0,
      "budget_used_percent": 2.15379853452288
    },
    {
      "type": "training",
      "description": "Training step 1505",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:56",
      "total_flops_so_far": 2155229629894656.0,
      "budget_used_percent": 2.155229629894656
    },
    {
      "type": "training",
      "description": "Training step 1506",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:56",
      "total_flops_so_far": 2156660725266432.0,
      "budget_used_percent": 2.1566607252664323
    },
    {
      "type": "training",
      "description": "Training step 1507",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:56",
      "total_flops_so_far": 2158091820638208.0,
      "budget_used_percent": 2.158091820638208
    },
    {
      "type": "training",
      "description": "Training step 1508",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:56",
      "total_flops_so_far": 2159522916009984.0,
      "budget_used_percent": 2.159522916009984
    },
    {
      "type": "training",
      "description": "Training step 1509",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:56",
      "total_flops_so_far": 2160954011381760.0,
      "budget_used_percent": 2.1609540113817602
    },
    {
      "type": "training",
      "description": "Training step 1510",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:57",
      "total_flops_so_far": 2162385106753536.0,
      "budget_used_percent": 2.162385106753536
    },
    {
      "type": "training",
      "description": "Training step 1511",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:57",
      "total_flops_so_far": 2163816202125312.0,
      "budget_used_percent": 2.163816202125312
    },
    {
      "type": "training",
      "description": "Training step 1512",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:57",
      "total_flops_so_far": 2165247297497088.0,
      "budget_used_percent": 2.165247297497088
    },
    {
      "type": "training",
      "description": "Training step 1513",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:57",
      "total_flops_so_far": 2166678392868864.0,
      "budget_used_percent": 2.1666783928688638
    },
    {
      "type": "training",
      "description": "Training step 1514",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:57",
      "total_flops_so_far": 2168109488240640.0,
      "budget_used_percent": 2.1681094882406398
    },
    {
      "type": "training",
      "description": "Training step 1515",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:57",
      "total_flops_so_far": 2169540583612416.0,
      "budget_used_percent": 2.169540583612416
    },
    {
      "type": "training",
      "description": "Training step 1516",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:58",
      "total_flops_so_far": 2170971678984192.0,
      "budget_used_percent": 2.170971678984192
    },
    {
      "type": "training",
      "description": "Training step 1517",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:58",
      "total_flops_so_far": 2172402774355968.0,
      "budget_used_percent": 2.1724027743559677
    },
    {
      "type": "training",
      "description": "Training step 1518",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:58",
      "total_flops_so_far": 2173833869727744.0,
      "budget_used_percent": 2.173833869727744
    },
    {
      "type": "training",
      "description": "Training step 1519",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:58",
      "total_flops_so_far": 2175264965099520.0,
      "budget_used_percent": 2.17526496509952
    },
    {
      "type": "training",
      "description": "Training step 1520",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:58",
      "total_flops_so_far": 2176696060471296.0,
      "budget_used_percent": 2.1766960604712957
    },
    {
      "type": "training",
      "description": "Training step 1521",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:58",
      "total_flops_so_far": 2178127155843072.0,
      "budget_used_percent": 2.178127155843072
    },
    {
      "type": "training",
      "description": "Training step 1522",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:58",
      "total_flops_so_far": 2179558251214848.0,
      "budget_used_percent": 2.179558251214848
    },
    {
      "type": "training",
      "description": "Training step 1523",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:59",
      "total_flops_so_far": 2180989346586624.0,
      "budget_used_percent": 2.1809893465866237
    },
    {
      "type": "training",
      "description": "Training step 1524",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:59",
      "total_flops_so_far": 2182420441958400.0,
      "budget_used_percent": 2.1824204419584
    },
    {
      "type": "training",
      "description": "Training step 1525",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:59",
      "total_flops_so_far": 2183851537330176.0,
      "budget_used_percent": 2.183851537330176
    },
    {
      "type": "training",
      "description": "Training step 1526",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:59",
      "total_flops_so_far": 2185282632701952.0,
      "budget_used_percent": 2.185282632701952
    },
    {
      "type": "training",
      "description": "Training step 1527",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:59",
      "total_flops_so_far": 2186713728073728.0,
      "budget_used_percent": 2.186713728073728
    },
    {
      "type": "training",
      "description": "Training step 1528",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:57:59",
      "total_flops_so_far": 2188144823445504.0,
      "budget_used_percent": 2.188144823445504
    },
    {
      "type": "training",
      "description": "Training step 1529",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:00",
      "total_flops_so_far": 2189575918817280.0,
      "budget_used_percent": 2.18957591881728
    },
    {
      "type": "training",
      "description": "Training step 1530",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:00",
      "total_flops_so_far": 2191007014189056.0,
      "budget_used_percent": 2.191007014189056
    },
    {
      "type": "training",
      "description": "Training step 1531",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:00",
      "total_flops_so_far": 2192438109560832.0,
      "budget_used_percent": 2.192438109560832
    },
    {
      "type": "training",
      "description": "Training step 1532",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:00",
      "total_flops_so_far": 2193869204932608.0,
      "budget_used_percent": 2.193869204932608
    },
    {
      "type": "training",
      "description": "Training step 1533",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:00",
      "total_flops_so_far": 2195300300304384.0,
      "budget_used_percent": 2.195300300304384
    },
    {
      "type": "training",
      "description": "Training step 1534",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:00",
      "total_flops_so_far": 2196731395676160.0,
      "budget_used_percent": 2.19673139567616
    },
    {
      "type": "training",
      "description": "Training step 1535",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:01",
      "total_flops_so_far": 2198162491047936.0,
      "budget_used_percent": 2.198162491047936
    },
    {
      "type": "training",
      "description": "Training step 1536",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:01",
      "total_flops_so_far": 2199593586419712.0,
      "budget_used_percent": 2.199593586419712
    },
    {
      "type": "training",
      "description": "Training step 1537",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:01",
      "total_flops_so_far": 2201024681791488.0,
      "budget_used_percent": 2.201024681791488
    },
    {
      "type": "training",
      "description": "Training step 1538",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:01",
      "total_flops_so_far": 2202455777163264.0,
      "budget_used_percent": 2.202455777163264
    },
    {
      "type": "training",
      "description": "Training step 1539",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:01",
      "total_flops_so_far": 2203886872535040.0,
      "budget_used_percent": 2.20388687253504
    },
    {
      "type": "training",
      "description": "Training step 1540",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:01",
      "total_flops_so_far": 2205317967906816.0,
      "budget_used_percent": 2.205317967906816
    },
    {
      "type": "training",
      "description": "Training step 1541",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:01",
      "total_flops_so_far": 2206749063278592.0,
      "budget_used_percent": 2.206749063278592
    },
    {
      "type": "training",
      "description": "Training step 1542",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:02",
      "total_flops_so_far": 2208180158650368.0,
      "budget_used_percent": 2.208180158650368
    },
    {
      "type": "training",
      "description": "Training step 1543",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:02",
      "total_flops_so_far": 2209611254022144.0,
      "budget_used_percent": 2.209611254022144
    },
    {
      "type": "training",
      "description": "Training step 1544",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:02",
      "total_flops_so_far": 2211042349393920.0,
      "budget_used_percent": 2.21104234939392
    },
    {
      "type": "training",
      "description": "Training step 1545",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:02",
      "total_flops_so_far": 2212473444765696.0,
      "budget_used_percent": 2.212473444765696
    },
    {
      "type": "training",
      "description": "Training step 1546",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:02",
      "total_flops_so_far": 2213904540137472.0,
      "budget_used_percent": 2.213904540137472
    },
    {
      "type": "training",
      "description": "Training step 1547",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:02",
      "total_flops_so_far": 2215335635509248.0,
      "budget_used_percent": 2.215335635509248
    },
    {
      "type": "training",
      "description": "Training step 1548",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:03",
      "total_flops_so_far": 2216766730881024.0,
      "budget_used_percent": 2.216766730881024
    },
    {
      "type": "training",
      "description": "Training step 1549",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:03",
      "total_flops_so_far": 2218197826252800.0,
      "budget_used_percent": 2.2181978262528
    },
    {
      "type": "training",
      "description": "Training step 1550",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:03",
      "total_flops_so_far": 2219628921624576.0,
      "budget_used_percent": 2.219628921624576
    },
    {
      "type": "training",
      "description": "Training step 1551",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:03",
      "total_flops_so_far": 2221060016996352.0,
      "budget_used_percent": 2.221060016996352
    },
    {
      "type": "training",
      "description": "Training step 1552",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:03",
      "total_flops_so_far": 2222491112368128.0,
      "budget_used_percent": 2.222491112368128
    },
    {
      "type": "training",
      "description": "Training step 1553",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:03",
      "total_flops_so_far": 2223922207739904.0,
      "budget_used_percent": 2.2239222077399043
    },
    {
      "type": "training",
      "description": "Training step 1554",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:04",
      "total_flops_so_far": 2225353303111680.0,
      "budget_used_percent": 2.22535330311168
    },
    {
      "type": "training",
      "description": "Training step 1555",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:04",
      "total_flops_so_far": 2226784398483456.0,
      "budget_used_percent": 2.226784398483456
    },
    {
      "type": "training",
      "description": "Training step 1556",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:04",
      "total_flops_so_far": 2228215493855232.0,
      "budget_used_percent": 2.2282154938552323
    },
    {
      "type": "training",
      "description": "Training step 1557",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:04",
      "total_flops_so_far": 2229646589227008.0,
      "budget_used_percent": 2.229646589227008
    },
    {
      "type": "training",
      "description": "Training step 1558",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:04",
      "total_flops_so_far": 2231077684598784.0,
      "budget_used_percent": 2.231077684598784
    },
    {
      "type": "training",
      "description": "Training step 1559",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:04",
      "total_flops_so_far": 2232508779970560.0,
      "budget_used_percent": 2.2325087799705603
    },
    {
      "type": "training",
      "description": "Training step 1560",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:04",
      "total_flops_so_far": 2233939875342336.0,
      "budget_used_percent": 2.233939875342336
    },
    {
      "type": "training",
      "description": "Training step 1561",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:05",
      "total_flops_so_far": 2235370970714112.0,
      "budget_used_percent": 2.235370970714112
    },
    {
      "type": "training",
      "description": "Training step 1562",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:05",
      "total_flops_so_far": 2236802066085888.0,
      "budget_used_percent": 2.236802066085888
    },
    {
      "type": "training",
      "description": "Training step 1563",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:05",
      "total_flops_so_far": 2238233161457664.0,
      "budget_used_percent": 2.2382331614576643
    },
    {
      "type": "training",
      "description": "Training step 1564",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:05",
      "total_flops_so_far": 2239664256829440.0,
      "budget_used_percent": 2.23966425682944
    },
    {
      "type": "training",
      "description": "Training step 1565",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:05",
      "total_flops_so_far": 2241095352201216.0,
      "budget_used_percent": 2.241095352201216
    },
    {
      "type": "training",
      "description": "Training step 1566",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:05",
      "total_flops_so_far": 2242526447572992.0,
      "budget_used_percent": 2.2425264475729922
    },
    {
      "type": "training",
      "description": "Training step 1567",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:06",
      "total_flops_so_far": 2243957542944768.0,
      "budget_used_percent": 2.243957542944768
    },
    {
      "type": "training",
      "description": "Training step 1568",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:06",
      "total_flops_so_far": 2245388638316544.0,
      "budget_used_percent": 2.245388638316544
    },
    {
      "type": "training",
      "description": "Training step 1569",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:06",
      "total_flops_so_far": 2246819733688320.0,
      "budget_used_percent": 2.24681973368832
    },
    {
      "type": "training",
      "description": "Training step 1570",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:06",
      "total_flops_so_far": 2248250829060096.0,
      "budget_used_percent": 2.248250829060096
    },
    {
      "type": "training",
      "description": "Training step 1571",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:06",
      "total_flops_so_far": 2249681924431872.0,
      "budget_used_percent": 2.2496819244318718
    },
    {
      "type": "training",
      "description": "Training step 1572",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:06",
      "total_flops_so_far": 2251113019803648.0,
      "budget_used_percent": 2.251113019803648
    },
    {
      "type": "training",
      "description": "Training step 1573",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:07",
      "total_flops_so_far": 2252544115175424.0,
      "budget_used_percent": 2.252544115175424
    },
    {
      "type": "training",
      "description": "Training step 1574",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:07",
      "total_flops_so_far": 2253975210547200.0,
      "budget_used_percent": 2.2539752105471997
    },
    {
      "type": "training",
      "description": "Training step 1575",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:07",
      "total_flops_so_far": 2255406305918976.0,
      "budget_used_percent": 2.255406305918976
    },
    {
      "type": "training",
      "description": "Training step 1576",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:07",
      "total_flops_so_far": 2256837401290752.0,
      "budget_used_percent": 2.256837401290752
    },
    {
      "type": "training",
      "description": "Training step 1577",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:07",
      "total_flops_so_far": 2258268496662528.0,
      "budget_used_percent": 2.2582684966625277
    },
    {
      "type": "training",
      "description": "Training step 1578",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:07",
      "total_flops_so_far": 2259699592034304.0,
      "budget_used_percent": 2.259699592034304
    },
    {
      "type": "training",
      "description": "Training step 1579",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:07",
      "total_flops_so_far": 2261130687406080.0,
      "budget_used_percent": 2.26113068740608
    },
    {
      "type": "training",
      "description": "Training step 1580",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:08",
      "total_flops_so_far": 2262561782777856.0,
      "budget_used_percent": 2.262561782777856
    },
    {
      "type": "training",
      "description": "Training step 1581",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:08",
      "total_flops_so_far": 2263992878149632.0,
      "budget_used_percent": 2.263992878149632
    },
    {
      "type": "training",
      "description": "Training step 1582",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:08",
      "total_flops_so_far": 2265423973521408.0,
      "budget_used_percent": 2.265423973521408
    },
    {
      "type": "training",
      "description": "Training step 1583",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:08",
      "total_flops_so_far": 2266855068893184.0,
      "budget_used_percent": 2.266855068893184
    },
    {
      "type": "training",
      "description": "Training step 1584",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:08",
      "total_flops_so_far": 2268286164264960.0,
      "budget_used_percent": 2.2682861642649597
    },
    {
      "type": "training",
      "description": "Training step 1585",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:08",
      "total_flops_so_far": 2269717259636736.0,
      "budget_used_percent": 2.269717259636736
    },
    {
      "type": "training",
      "description": "Training step 1586",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:09",
      "total_flops_so_far": 2271148355008512.0,
      "budget_used_percent": 2.271148355008512
    },
    {
      "type": "training",
      "description": "Training step 1587",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:09",
      "total_flops_so_far": 2272579450380288.0,
      "budget_used_percent": 2.2725794503802876
    },
    {
      "type": "training",
      "description": "Training step 1588",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:09",
      "total_flops_so_far": 2274010545752064.0,
      "budget_used_percent": 2.274010545752064
    },
    {
      "type": "training",
      "description": "Training step 1589",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:09",
      "total_flops_so_far": 2275441641123840.0,
      "budget_used_percent": 2.27544164112384
    },
    {
      "type": "training",
      "description": "Training step 1590",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:09",
      "total_flops_so_far": 2276872736495616.0,
      "budget_used_percent": 2.276872736495616
    },
    {
      "type": "training",
      "description": "Training step 1591",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:09",
      "total_flops_so_far": 2278303831867392.0,
      "budget_used_percent": 2.278303831867392
    },
    {
      "type": "training",
      "description": "Training step 1592",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:10",
      "total_flops_so_far": 2279734927239168.0,
      "budget_used_percent": 2.279734927239168
    },
    {
      "type": "training",
      "description": "Training step 1593",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:10",
      "total_flops_so_far": 2281166022610944.0,
      "budget_used_percent": 2.281166022610944
    },
    {
      "type": "training",
      "description": "Training step 1594",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:10",
      "total_flops_so_far": 2282597117982720.0,
      "budget_used_percent": 2.28259711798272
    },
    {
      "type": "training",
      "description": "Training step 1595",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:10",
      "total_flops_so_far": 2284028213354496.0,
      "budget_used_percent": 2.284028213354496
    },
    {
      "type": "training",
      "description": "Training step 1596",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:10",
      "total_flops_so_far": 2285459308726272.0,
      "budget_used_percent": 2.285459308726272
    },
    {
      "type": "training",
      "description": "Training step 1597",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:10",
      "total_flops_so_far": 2286890404098048.0,
      "budget_used_percent": 2.286890404098048
    },
    {
      "type": "training",
      "description": "Training step 1598",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:10",
      "total_flops_so_far": 2288321499469824.0,
      "budget_used_percent": 2.288321499469824
    },
    {
      "type": "training",
      "description": "Training step 1599",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:11",
      "total_flops_so_far": 2289752594841600.0,
      "budget_used_percent": 2.2897525948416
    },
    {
      "type": "training",
      "description": "Training step 1600",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:11",
      "total_flops_so_far": 2291183690213376.0,
      "budget_used_percent": 2.291183690213376
    },
    {
      "type": "training",
      "description": "Training step 1601",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:11",
      "total_flops_so_far": 2292614785585152.0,
      "budget_used_percent": 2.292614785585152
    },
    {
      "type": "training",
      "description": "Training step 1602",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:11",
      "total_flops_so_far": 2294045880956928.0,
      "budget_used_percent": 2.294045880956928
    },
    {
      "type": "training",
      "description": "Training step 1603",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:11",
      "total_flops_so_far": 2295476976328704.0,
      "budget_used_percent": 2.295476976328704
    },
    {
      "type": "training",
      "description": "Training step 1604",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:11",
      "total_flops_so_far": 2296908071700480.0,
      "budget_used_percent": 2.29690807170048
    },
    {
      "type": "training",
      "description": "Training step 1605",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:12",
      "total_flops_so_far": 2298339167072256.0,
      "budget_used_percent": 2.298339167072256
    },
    {
      "type": "training",
      "description": "Training step 1606",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:12",
      "total_flops_so_far": 2299770262444032.0,
      "budget_used_percent": 2.299770262444032
    },
    {
      "type": "training",
      "description": "Training step 1607",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:12",
      "total_flops_so_far": 2301201357815808.0,
      "budget_used_percent": 2.301201357815808
    },
    {
      "type": "training",
      "description": "Training step 1608",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:12",
      "total_flops_so_far": 2302632453187584.0,
      "budget_used_percent": 2.302632453187584
    },
    {
      "type": "training",
      "description": "Training step 1609",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:12",
      "total_flops_so_far": 2304063548559360.0,
      "budget_used_percent": 2.30406354855936
    },
    {
      "type": "training",
      "description": "Training step 1610",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:12",
      "total_flops_so_far": 2305494643931136.0,
      "budget_used_percent": 2.3054946439311363
    },
    {
      "type": "training",
      "description": "Training step 1611",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:13",
      "total_flops_so_far": 2306925739302912.0,
      "budget_used_percent": 2.306925739302912
    },
    {
      "type": "training",
      "description": "Training step 1612",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:13",
      "total_flops_so_far": 2308356834674688.0,
      "budget_used_percent": 2.308356834674688
    },
    {
      "type": "training",
      "description": "Training step 1613",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:13",
      "total_flops_so_far": 2309787930046464.0,
      "budget_used_percent": 2.309787930046464
    },
    {
      "type": "training",
      "description": "Training step 1614",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:13",
      "total_flops_so_far": 2311219025418240.0,
      "budget_used_percent": 2.31121902541824
    },
    {
      "type": "training",
      "description": "Training step 1615",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:13",
      "total_flops_so_far": 2312650120790016.0,
      "budget_used_percent": 2.312650120790016
    },
    {
      "type": "training",
      "description": "Training step 1616",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:13",
      "total_flops_so_far": 2314081216161792.0,
      "budget_used_percent": 2.314081216161792
    },
    {
      "type": "training",
      "description": "Training step 1617",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:13",
      "total_flops_so_far": 2315512311533568.0,
      "budget_used_percent": 2.3155123115335683
    },
    {
      "type": "training",
      "description": "Training step 1618",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:14",
      "total_flops_so_far": 2316943406905344.0,
      "budget_used_percent": 2.316943406905344
    },
    {
      "type": "training",
      "description": "Training step 1619",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:14",
      "total_flops_so_far": 2318374502277120.0,
      "budget_used_percent": 2.31837450227712
    },
    {
      "type": "training",
      "description": "Training step 1620",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:14",
      "total_flops_so_far": 2319805597648896.0,
      "budget_used_percent": 2.3198055976488963
    },
    {
      "type": "training",
      "description": "Training step 1621",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:14",
      "total_flops_so_far": 2321236693020672.0,
      "budget_used_percent": 2.321236693020672
    },
    {
      "type": "training",
      "description": "Training step 1622",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:14",
      "total_flops_so_far": 2322667788392448.0,
      "budget_used_percent": 2.322667788392448
    },
    {
      "type": "training",
      "description": "Training step 1623",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:14",
      "total_flops_so_far": 2324098883764224.0,
      "budget_used_percent": 2.3240988837642242
    },
    {
      "type": "training",
      "description": "Training step 1624",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:15",
      "total_flops_so_far": 2325529979136000.0,
      "budget_used_percent": 2.325529979136
    },
    {
      "type": "training",
      "description": "Training step 1625",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:15",
      "total_flops_so_far": 2326961074507776.0,
      "budget_used_percent": 2.326961074507776
    },
    {
      "type": "training",
      "description": "Training step 1626",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:15",
      "total_flops_so_far": 2328392169879552.0,
      "budget_used_percent": 2.328392169879552
    },
    {
      "type": "training",
      "description": "Training step 1627",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:15",
      "total_flops_so_far": 2329823265251328.0,
      "budget_used_percent": 2.329823265251328
    },
    {
      "type": "training",
      "description": "Training step 1628",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:15",
      "total_flops_so_far": 2331254360623104.0,
      "budget_used_percent": 2.3312543606231038
    },
    {
      "type": "training",
      "description": "Training step 1629",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:15",
      "total_flops_so_far": 2332685455994880.0,
      "budget_used_percent": 2.33268545599488
    },
    {
      "type": "training",
      "description": "Training step 1630",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:15",
      "total_flops_so_far": 2334116551366656.0,
      "budget_used_percent": 2.334116551366656
    },
    {
      "type": "training",
      "description": "Training step 1631",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:16",
      "total_flops_so_far": 2335547646738432.0,
      "budget_used_percent": 2.3355476467384317
    },
    {
      "type": "training",
      "description": "Training step 1632",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:16",
      "total_flops_so_far": 2336978742110208.0,
      "budget_used_percent": 2.336978742110208
    },
    {
      "type": "training",
      "description": "Training step 1633",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:16",
      "total_flops_so_far": 2338409837481984.0,
      "budget_used_percent": 2.338409837481984
    },
    {
      "type": "training",
      "description": "Training step 1634",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:16",
      "total_flops_so_far": 2339840932853760.0,
      "budget_used_percent": 2.3398409328537597
    },
    {
      "type": "training",
      "description": "Training step 1635",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:16",
      "total_flops_so_far": 2341272028225536.0,
      "budget_used_percent": 2.341272028225536
    },
    {
      "type": "training",
      "description": "Training step 1636",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:16",
      "total_flops_so_far": 2342703123597312.0,
      "budget_used_percent": 2.342703123597312
    },
    {
      "type": "training",
      "description": "Training step 1637",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:17",
      "total_flops_so_far": 2344134218969088.0,
      "budget_used_percent": 2.344134218969088
    },
    {
      "type": "training",
      "description": "Training step 1638",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:17",
      "total_flops_so_far": 2345565314340864.0,
      "budget_used_percent": 2.345565314340864
    },
    {
      "type": "training",
      "description": "Training step 1639",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:17",
      "total_flops_so_far": 2346996409712640.0,
      "budget_used_percent": 2.34699640971264
    },
    {
      "type": "training",
      "description": "Training step 1640",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:17",
      "total_flops_so_far": 2348427505084416.0,
      "budget_used_percent": 2.348427505084416
    },
    {
      "type": "training",
      "description": "Training step 1641",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:17",
      "total_flops_so_far": 2349858600456192.0,
      "budget_used_percent": 2.3498586004561917
    },
    {
      "type": "training",
      "description": "Training step 1642",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:17",
      "total_flops_so_far": 2351289695827968.0,
      "budget_used_percent": 2.351289695827968
    },
    {
      "type": "training",
      "description": "Training step 1643",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:18",
      "total_flops_so_far": 2352720791199744.0,
      "budget_used_percent": 2.352720791199744
    },
    {
      "type": "training",
      "description": "Training step 1644",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:18",
      "total_flops_so_far": 2354151886571520.0,
      "budget_used_percent": 2.3541518865715196
    },
    {
      "type": "training",
      "description": "Training step 1645",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:18",
      "total_flops_so_far": 2355582981943296.0,
      "budget_used_percent": 2.355582981943296
    },
    {
      "type": "training",
      "description": "Training step 1646",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:18",
      "total_flops_so_far": 2357014077315072.0,
      "budget_used_percent": 2.357014077315072
    },
    {
      "type": "training",
      "description": "Training step 1647",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:18",
      "total_flops_so_far": 2358445172686848.0,
      "budget_used_percent": 2.358445172686848
    },
    {
      "type": "training",
      "description": "Training step 1648",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:18",
      "total_flops_so_far": 2359876268058624.0,
      "budget_used_percent": 2.359876268058624
    },
    {
      "type": "training",
      "description": "Training step 1649",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:18",
      "total_flops_so_far": 2361307363430400.0,
      "budget_used_percent": 2.3613073634304
    },
    {
      "type": "training",
      "description": "Training step 1650",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:19",
      "total_flops_so_far": 2362738458802176.0,
      "budget_used_percent": 2.362738458802176
    },
    {
      "type": "training",
      "description": "Training step 1651",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:19",
      "total_flops_so_far": 2364169554173952.0,
      "budget_used_percent": 2.364169554173952
    },
    {
      "type": "training",
      "description": "Training step 1652",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:19",
      "total_flops_so_far": 2365600649545728.0,
      "budget_used_percent": 2.365600649545728
    },
    {
      "type": "training",
      "description": "Training step 1653",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:19",
      "total_flops_so_far": 2367031744917504.0,
      "budget_used_percent": 2.367031744917504
    },
    {
      "type": "training",
      "description": "Training step 1654",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:19",
      "total_flops_so_far": 2368462840289280.0,
      "budget_used_percent": 2.36846284028928
    },
    {
      "type": "training",
      "description": "Training step 1655",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:19",
      "total_flops_so_far": 2369893935661056.0,
      "budget_used_percent": 2.369893935661056
    },
    {
      "type": "training",
      "description": "Training step 1656",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:20",
      "total_flops_so_far": 2371325031032832.0,
      "budget_used_percent": 2.371325031032832
    },
    {
      "type": "training",
      "description": "Training step 1657",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:20",
      "total_flops_so_far": 2372756126404608.0,
      "budget_used_percent": 2.372756126404608
    },
    {
      "type": "training",
      "description": "Training step 1658",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:20",
      "total_flops_so_far": 2374187221776384.0,
      "budget_used_percent": 2.374187221776384
    },
    {
      "type": "training",
      "description": "Training step 1659",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:20",
      "total_flops_so_far": 2375618317148160.0,
      "budget_used_percent": 2.37561831714816
    },
    {
      "type": "training",
      "description": "Training step 1660",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:20",
      "total_flops_so_far": 2377049412519936.0,
      "budget_used_percent": 2.377049412519936
    },
    {
      "type": "training",
      "description": "Training step 1661",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:20",
      "total_flops_so_far": 2378480507891712.0,
      "budget_used_percent": 2.378480507891712
    },
    {
      "type": "training",
      "description": "Training step 1662",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:21",
      "total_flops_so_far": 2379911603263488.0,
      "budget_used_percent": 2.379911603263488
    },
    {
      "type": "training",
      "description": "Training step 1663",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:21",
      "total_flops_so_far": 2381342698635264.0,
      "budget_used_percent": 2.381342698635264
    },
    {
      "type": "training",
      "description": "Training step 1664",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:21",
      "total_flops_so_far": 2382773794007040.0,
      "budget_used_percent": 2.3827737940070404
    },
    {
      "type": "training",
      "description": "Training step 1665",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:21",
      "total_flops_so_far": 2384204889378816.0,
      "budget_used_percent": 2.384204889378816
    },
    {
      "type": "training",
      "description": "Training step 1666",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:21",
      "total_flops_so_far": 2385635984750592.0,
      "budget_used_percent": 2.385635984750592
    },
    {
      "type": "training",
      "description": "Training step 1667",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:21",
      "total_flops_so_far": 2387067080122368.0,
      "budget_used_percent": 2.3870670801223683
    },
    {
      "type": "training",
      "description": "Training step 1668",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:22",
      "total_flops_so_far": 2388498175494144.0,
      "budget_used_percent": 2.388498175494144
    },
    {
      "type": "training",
      "description": "Training step 1669",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:22",
      "total_flops_so_far": 2389929270865920.0,
      "budget_used_percent": 2.38992927086592
    },
    {
      "type": "training",
      "description": "Training step 1670",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:22",
      "total_flops_so_far": 2391360366237696.0,
      "budget_used_percent": 2.391360366237696
    },
    {
      "type": "training",
      "description": "Training step 1671",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:22",
      "total_flops_so_far": 2392791461609472.0,
      "budget_used_percent": 2.392791461609472
    },
    {
      "type": "training",
      "description": "Training step 1672",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:22",
      "total_flops_so_far": 2394222556981248.0,
      "budget_used_percent": 2.394222556981248
    },
    {
      "type": "training",
      "description": "Training step 1673",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:22",
      "total_flops_so_far": 2395653652353024.0,
      "budget_used_percent": 2.395653652353024
    },
    {
      "type": "training",
      "description": "Training step 1674",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:22",
      "total_flops_so_far": 2397084747724800.0,
      "budget_used_percent": 2.3970847477248003
    },
    {
      "type": "training",
      "description": "Training step 1675",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:23",
      "total_flops_so_far": 2398515843096576.0,
      "budget_used_percent": 2.398515843096576
    },
    {
      "type": "training",
      "description": "Training step 1676",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:23",
      "total_flops_so_far": 2399946938468352.0,
      "budget_used_percent": 2.399946938468352
    },
    {
      "type": "training",
      "description": "Training step 1677",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:23",
      "total_flops_so_far": 2401378033840128.0,
      "budget_used_percent": 2.4013780338401283
    },
    {
      "type": "training",
      "description": "Training step 1678",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:23",
      "total_flops_so_far": 2402809129211904.0,
      "budget_used_percent": 2.402809129211904
    },
    {
      "type": "training",
      "description": "Training step 1679",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:23",
      "total_flops_so_far": 2404240224583680.0,
      "budget_used_percent": 2.40424022458368
    },
    {
      "type": "training",
      "description": "Training step 1680",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:23",
      "total_flops_so_far": 2405671319955456.0,
      "budget_used_percent": 2.4056713199554562
    },
    {
      "type": "training",
      "description": "Training step 1681",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:24",
      "total_flops_so_far": 2407102415327232.0,
      "budget_used_percent": 2.407102415327232
    },
    {
      "type": "training",
      "description": "Training step 1682",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:24",
      "total_flops_so_far": 2408533510699008.0,
      "budget_used_percent": 2.408533510699008
    },
    {
      "type": "training",
      "description": "Training step 1683",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:24",
      "total_flops_so_far": 2409964606070784.0,
      "budget_used_percent": 2.409964606070784
    },
    {
      "type": "training",
      "description": "Training step 1684",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:24",
      "total_flops_so_far": 2411395701442560.0,
      "budget_used_percent": 2.41139570144256
    },
    {
      "type": "training",
      "description": "Training step 1685",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:24",
      "total_flops_so_far": 2412826796814336.0,
      "budget_used_percent": 2.4128267968143358
    },
    {
      "type": "training",
      "description": "Training step 1686",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:24",
      "total_flops_so_far": 2414257892186112.0,
      "budget_used_percent": 2.414257892186112
    },
    {
      "type": "training",
      "description": "Training step 1687",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:25",
      "total_flops_so_far": 2415688987557888.0,
      "budget_used_percent": 2.415688987557888
    },
    {
      "type": "training",
      "description": "Training step 1688",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:25",
      "total_flops_so_far": 2417120082929664.0,
      "budget_used_percent": 2.4171200829296637
    },
    {
      "type": "training",
      "description": "Training step 1689",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:25",
      "total_flops_so_far": 2418551178301440.0,
      "budget_used_percent": 2.41855117830144
    },
    {
      "type": "training",
      "description": "Training step 1690",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:25",
      "total_flops_so_far": 2419982273673216.0,
      "budget_used_percent": 2.419982273673216
    },
    {
      "type": "training",
      "description": "Training step 1691",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:25",
      "total_flops_so_far": 2421413369044992.0,
      "budget_used_percent": 2.421413369044992
    },
    {
      "type": "training",
      "description": "Training step 1692",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:25",
      "total_flops_so_far": 2422844464416768.0,
      "budget_used_percent": 2.4228444644167677
    },
    {
      "type": "training",
      "description": "Training step 1693",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:26",
      "total_flops_so_far": 2424275559788544.0,
      "budget_used_percent": 2.424275559788544
    },
    {
      "type": "training",
      "description": "Training step 1694",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:26",
      "total_flops_so_far": 2425706655160320.0,
      "budget_used_percent": 2.42570665516032
    },
    {
      "type": "training",
      "description": "Training step 1695",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:26",
      "total_flops_so_far": 2427137750532096.0,
      "budget_used_percent": 2.4271377505320957
    },
    {
      "type": "training",
      "description": "Training step 1696",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:26",
      "total_flops_so_far": 2428568845903872.0,
      "budget_used_percent": 2.428568845903872
    },
    {
      "type": "training",
      "description": "Training step 1697",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:26",
      "total_flops_so_far": 2429999941275648.0,
      "budget_used_percent": 2.429999941275648
    },
    {
      "type": "training",
      "description": "Training step 1698",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:26",
      "total_flops_so_far": 2431431036647424.0,
      "budget_used_percent": 2.4314310366474237
    },
    {
      "type": "training",
      "description": "Training step 1699",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:26",
      "total_flops_so_far": 2432862132019200.0,
      "budget_used_percent": 2.4328621320192
    },
    {
      "type": "training",
      "description": "Training step 1700",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:27",
      "total_flops_so_far": 2434293227390976.0,
      "budget_used_percent": 2.434293227390976
    },
    {
      "type": "training",
      "description": "Training step 1701",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:27",
      "total_flops_so_far": 2435724322762752.0,
      "budget_used_percent": 2.435724322762752
    },
    {
      "type": "training",
      "description": "Training step 1702",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:27",
      "total_flops_so_far": 2437155418134528.0,
      "budget_used_percent": 2.437155418134528
    },
    {
      "type": "training",
      "description": "Training step 1703",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:27",
      "total_flops_so_far": 2438586513506304.0,
      "budget_used_percent": 2.438586513506304
    },
    {
      "type": "training",
      "description": "Training step 1704",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:27",
      "total_flops_so_far": 2440017608878080.0,
      "budget_used_percent": 2.44001760887808
    },
    {
      "type": "training",
      "description": "Training step 1705",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:27",
      "total_flops_so_far": 2441448704249856.0,
      "budget_used_percent": 2.441448704249856
    },
    {
      "type": "training",
      "description": "Training step 1706",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:28",
      "total_flops_so_far": 2442879799621632.0,
      "budget_used_percent": 2.442879799621632
    },
    {
      "type": "training",
      "description": "Training step 1707",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:28",
      "total_flops_so_far": 2444310894993408.0,
      "budget_used_percent": 2.444310894993408
    },
    {
      "type": "training",
      "description": "Training step 1708",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:28",
      "total_flops_so_far": 2445741990365184.0,
      "budget_used_percent": 2.445741990365184
    },
    {
      "type": "training",
      "description": "Training step 1709",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:28",
      "total_flops_so_far": 2447173085736960.0,
      "budget_used_percent": 2.44717308573696
    },
    {
      "type": "training",
      "description": "Training step 1710",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:28",
      "total_flops_so_far": 2448604181108736.0,
      "budget_used_percent": 2.448604181108736
    },
    {
      "type": "training",
      "description": "Training step 1711",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:28",
      "total_flops_so_far": 2450035276480512.0,
      "budget_used_percent": 2.450035276480512
    },
    {
      "type": "training",
      "description": "Training step 1712",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:29",
      "total_flops_so_far": 2451466371852288.0,
      "budget_used_percent": 2.451466371852288
    },
    {
      "type": "training",
      "description": "Training step 1713",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:29",
      "total_flops_so_far": 2452897467224064.0,
      "budget_used_percent": 2.452897467224064
    },
    {
      "type": "training",
      "description": "Training step 1714",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:29",
      "total_flops_so_far": 2454328562595840.0,
      "budget_used_percent": 2.45432856259584
    },
    {
      "type": "training",
      "description": "Training step 1715",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:29",
      "total_flops_so_far": 2455759657967616.0,
      "budget_used_percent": 2.455759657967616
    },
    {
      "type": "training",
      "description": "Training step 1716",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:29",
      "total_flops_so_far": 2457190753339392.0,
      "budget_used_percent": 2.457190753339392
    },
    {
      "type": "training",
      "description": "Training step 1717",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:29",
      "total_flops_so_far": 2458621848711168.0,
      "budget_used_percent": 2.458621848711168
    },
    {
      "type": "training",
      "description": "Training step 1718",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:29",
      "total_flops_so_far": 2460052944082944.0,
      "budget_used_percent": 2.460052944082944
    },
    {
      "type": "training",
      "description": "Training step 1719",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:30",
      "total_flops_so_far": 2461484039454720.0,
      "budget_used_percent": 2.46148403945472
    },
    {
      "type": "training",
      "description": "Training step 1720",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:30",
      "total_flops_so_far": 2462915134826496.0,
      "budget_used_percent": 2.462915134826496
    },
    {
      "type": "training",
      "description": "Training step 1721",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:30",
      "total_flops_so_far": 2464346230198272.0,
      "budget_used_percent": 2.464346230198272
    },
    {
      "type": "training",
      "description": "Training step 1722",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:30",
      "total_flops_so_far": 2465777325570048.0,
      "budget_used_percent": 2.465777325570048
    },
    {
      "type": "training",
      "description": "Training step 1723",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:30",
      "total_flops_so_far": 2467208420941824.0,
      "budget_used_percent": 2.467208420941824
    },
    {
      "type": "training",
      "description": "Training step 1724",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:30",
      "total_flops_so_far": 2468639516313600.0,
      "budget_used_percent": 2.4686395163136
    },
    {
      "type": "training",
      "description": "Training step 1725",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:31",
      "total_flops_so_far": 2470070611685376.0,
      "budget_used_percent": 2.470070611685376
    },
    {
      "type": "training",
      "description": "Training step 1726",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:31",
      "total_flops_so_far": 2471501707057152.0,
      "budget_used_percent": 2.471501707057152
    },
    {
      "type": "training",
      "description": "Training step 1727",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:31",
      "total_flops_so_far": 2472932802428928.0,
      "budget_used_percent": 2.472932802428928
    },
    {
      "type": "training",
      "description": "Training step 1728",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:31",
      "total_flops_so_far": 2474363897800704.0,
      "budget_used_percent": 2.474363897800704
    },
    {
      "type": "training",
      "description": "Training step 1729",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:31",
      "total_flops_so_far": 2475794993172480.0,
      "budget_used_percent": 2.47579499317248
    },
    {
      "type": "training",
      "description": "Training step 1730",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:31",
      "total_flops_so_far": 2477226088544256.0,
      "budget_used_percent": 2.477226088544256
    },
    {
      "type": "training",
      "description": "Training step 1731",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:32",
      "total_flops_so_far": 2478657183916032.0,
      "budget_used_percent": 2.4786571839160323
    },
    {
      "type": "training",
      "description": "Training step 1732",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:32",
      "total_flops_so_far": 2480088279287808.0,
      "budget_used_percent": 2.480088279287808
    },
    {
      "type": "training",
      "description": "Training step 1733",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:32",
      "total_flops_so_far": 2481519374659584.0,
      "budget_used_percent": 2.481519374659584
    },
    {
      "type": "training",
      "description": "Training step 1734",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:32",
      "total_flops_so_far": 2482950470031360.0,
      "budget_used_percent": 2.4829504700313603
    },
    {
      "type": "training",
      "description": "Training step 1735",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:32",
      "total_flops_so_far": 2484381565403136.0,
      "budget_used_percent": 2.484381565403136
    },
    {
      "type": "training",
      "description": "Training step 1736",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:32",
      "total_flops_so_far": 2485812660774912.0,
      "budget_used_percent": 2.485812660774912
    },
    {
      "type": "training",
      "description": "Training step 1737",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:32",
      "total_flops_so_far": 2487243756146688.0,
      "budget_used_percent": 2.4872437561466882
    },
    {
      "type": "training",
      "description": "Training step 1738",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:33",
      "total_flops_so_far": 2488674851518464.0,
      "budget_used_percent": 2.4886748515184642
    },
    {
      "type": "training",
      "description": "Training step 1739",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:33",
      "total_flops_so_far": 2490105946890240.0,
      "budget_used_percent": 2.49010594689024
    },
    {
      "type": "training",
      "description": "Training step 1740",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:33",
      "total_flops_so_far": 2491537042262016.0,
      "budget_used_percent": 2.491537042262016
    },
    {
      "type": "training",
      "description": "Training step 1741",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:33",
      "total_flops_so_far": 2492968137633792.0,
      "budget_used_percent": 2.492968137633792
    },
    {
      "type": "training",
      "description": "Training step 1742",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:33",
      "total_flops_so_far": 2494399233005568.0,
      "budget_used_percent": 2.4943992330055678
    },
    {
      "type": "training",
      "description": "Training step 1743",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:33",
      "total_flops_so_far": 2495830328377344.0,
      "budget_used_percent": 2.495830328377344
    },
    {
      "type": "training",
      "description": "Training step 1744",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:34",
      "total_flops_so_far": 2497261423749120.0,
      "budget_used_percent": 2.49726142374912
    },
    {
      "type": "training",
      "description": "Training step 1745",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:34",
      "total_flops_so_far": 2498692519120896.0,
      "budget_used_percent": 2.4986925191208957
    },
    {
      "type": "training",
      "description": "Training step 1746",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:34",
      "total_flops_so_far": 2500123614492672.0,
      "budget_used_percent": 2.500123614492672
    },
    {
      "type": "training",
      "description": "Training step 1747",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:34",
      "total_flops_so_far": 2501554709864448.0,
      "budget_used_percent": 2.501554709864448
    },
    {
      "type": "training",
      "description": "Training step 1748",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:34",
      "total_flops_so_far": 2502985805236224.0,
      "budget_used_percent": 2.502985805236224
    },
    {
      "type": "training",
      "description": "Training step 1749",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:34",
      "total_flops_so_far": 2504416900608000.0,
      "budget_used_percent": 2.5044169006079997
    },
    {
      "type": "training",
      "description": "Training step 1750",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:35",
      "total_flops_so_far": 2505847995979776.0,
      "budget_used_percent": 2.505847995979776
    },
    {
      "type": "training",
      "description": "Training step 1751",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:35",
      "total_flops_so_far": 2507279091351552.0,
      "budget_used_percent": 2.507279091351552
    },
    {
      "type": "training",
      "description": "Training step 1752",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:35",
      "total_flops_so_far": 2508710186723328.0,
      "budget_used_percent": 2.5087101867233277
    },
    {
      "type": "training",
      "description": "Training step 1753",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:35",
      "total_flops_so_far": 2510141282095104.0,
      "budget_used_percent": 2.510141282095104
    },
    {
      "type": "training",
      "description": "Training step 1754",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:36",
      "total_flops_so_far": 2511572377466880.0,
      "budget_used_percent": 2.51157237746688
    },
    {
      "type": "training",
      "description": "Training step 1755",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:36",
      "total_flops_so_far": 2513003472838656.0,
      "budget_used_percent": 2.5130034728386557
    },
    {
      "type": "training",
      "description": "Training step 1756",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:36",
      "total_flops_so_far": 2514434568210432.0,
      "budget_used_percent": 2.514434568210432
    },
    {
      "type": "training",
      "description": "Training step 1757",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:36",
      "total_flops_so_far": 2515865663582208.0,
      "budget_used_percent": 2.515865663582208
    },
    {
      "type": "training",
      "description": "Training step 1758",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:36",
      "total_flops_so_far": 2517296758953984.0,
      "budget_used_percent": 2.517296758953984
    },
    {
      "type": "training",
      "description": "Training step 1759",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:36",
      "total_flops_so_far": 2518727854325760.0,
      "budget_used_percent": 2.51872785432576
    },
    {
      "type": "training",
      "description": "Training step 1760",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:37",
      "total_flops_so_far": 2520158949697536.0,
      "budget_used_percent": 2.520158949697536
    },
    {
      "type": "training",
      "description": "Training step 1761",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:37",
      "total_flops_so_far": 2521590045069312.0,
      "budget_used_percent": 2.521590045069312
    },
    {
      "type": "training",
      "description": "Training step 1762",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:37",
      "total_flops_so_far": 2523021140441088.0,
      "budget_used_percent": 2.523021140441088
    },
    {
      "type": "training",
      "description": "Training step 1763",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:37",
      "total_flops_so_far": 2524452235812864.0,
      "budget_used_percent": 2.524452235812864
    },
    {
      "type": "training",
      "description": "Training step 1764",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:37",
      "total_flops_so_far": 2525883331184640.0,
      "budget_used_percent": 2.52588333118464
    },
    {
      "type": "training",
      "description": "Training step 1765",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:37",
      "total_flops_so_far": 2527314426556416.0,
      "budget_used_percent": 2.527314426556416
    },
    {
      "type": "training",
      "description": "Training step 1766",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:38",
      "total_flops_so_far": 2528745521928192.0,
      "budget_used_percent": 2.528745521928192
    },
    {
      "type": "training",
      "description": "Training step 1767",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:38",
      "total_flops_so_far": 2530176617299968.0,
      "budget_used_percent": 2.530176617299968
    },
    {
      "type": "training",
      "description": "Training step 1768",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:38",
      "total_flops_so_far": 2531607712671744.0,
      "budget_used_percent": 2.531607712671744
    },
    {
      "type": "training",
      "description": "Training step 1769",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:38",
      "total_flops_so_far": 2533038808043520.0,
      "budget_used_percent": 2.53303880804352
    },
    {
      "type": "training",
      "description": "Training step 1770",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:38",
      "total_flops_so_far": 2534469903415296.0,
      "budget_used_percent": 2.534469903415296
    },
    {
      "type": "training",
      "description": "Training step 1771",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:38",
      "total_flops_so_far": 2535900998787072.0,
      "budget_used_percent": 2.535900998787072
    },
    {
      "type": "training",
      "description": "Training step 1772",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:38",
      "total_flops_so_far": 2537332094158848.0,
      "budget_used_percent": 2.537332094158848
    },
    {
      "type": "training",
      "description": "Training step 1773",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:39",
      "total_flops_so_far": 2538763189530624.0,
      "budget_used_percent": 2.538763189530624
    },
    {
      "type": "training",
      "description": "Training step 1774",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:39",
      "total_flops_so_far": 2540194284902400.0,
      "budget_used_percent": 2.5401942849024
    },
    {
      "type": "training",
      "description": "Training step 1775",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:39",
      "total_flops_so_far": 2541625380274176.0,
      "budget_used_percent": 2.5416253802741764
    },
    {
      "type": "training",
      "description": "Training step 1776",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:39",
      "total_flops_so_far": 2543056475645952.0,
      "budget_used_percent": 2.543056475645952
    },
    {
      "type": "training",
      "description": "Training step 1777",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:39",
      "total_flops_so_far": 2544487571017728.0,
      "budget_used_percent": 2.544487571017728
    },
    {
      "type": "training",
      "description": "Training step 1778",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:39",
      "total_flops_so_far": 2545918666389504.0,
      "budget_used_percent": 2.545918666389504
    },
    {
      "type": "training",
      "description": "Training step 1779",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:40",
      "total_flops_so_far": 2547349761761280.0,
      "budget_used_percent": 2.54734976176128
    },
    {
      "type": "training",
      "description": "Training step 1780",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:40",
      "total_flops_so_far": 2548780857133056.0,
      "budget_used_percent": 2.548780857133056
    },
    {
      "type": "training",
      "description": "Training step 1781",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:40",
      "total_flops_so_far": 2550211952504832.0,
      "budget_used_percent": 2.550211952504832
    },
    {
      "type": "training",
      "description": "Training step 1782",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:40",
      "total_flops_so_far": 2551643047876608.0,
      "budget_used_percent": 2.551643047876608
    },
    {
      "type": "training",
      "description": "Training step 1783",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:40",
      "total_flops_so_far": 2553074143248384.0,
      "budget_used_percent": 2.553074143248384
    },
    {
      "type": "training",
      "description": "Training step 1784",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:40",
      "total_flops_so_far": 2554505238620160.0,
      "budget_used_percent": 2.55450523862016
    },
    {
      "type": "training",
      "description": "Training step 1785",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:41",
      "total_flops_so_far": 2555936333991936.0,
      "budget_used_percent": 2.5559363339919363
    },
    {
      "type": "training",
      "description": "Training step 1786",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:41",
      "total_flops_so_far": 2557367429363712.0,
      "budget_used_percent": 2.557367429363712
    },
    {
      "type": "training",
      "description": "Training step 1787",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:41",
      "total_flops_so_far": 2558798524735488.0,
      "budget_used_percent": 2.558798524735488
    },
    {
      "type": "training",
      "description": "Training step 1788",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:41",
      "total_flops_so_far": 2560229620107264.0,
      "budget_used_percent": 2.5602296201072643
    },
    {
      "type": "training",
      "description": "Training step 1789",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:41",
      "total_flops_so_far": 2561660715479040.0,
      "budget_used_percent": 2.56166071547904
    },
    {
      "type": "training",
      "description": "Training step 1790",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:41",
      "total_flops_so_far": 2563091810850816.0,
      "budget_used_percent": 2.563091810850816
    },
    {
      "type": "training",
      "description": "Training step 1791",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:42",
      "total_flops_so_far": 2564522906222592.0,
      "budget_used_percent": 2.5645229062225923
    },
    {
      "type": "training",
      "description": "Training step 1792",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:42",
      "total_flops_so_far": 2565954001594368.0,
      "budget_used_percent": 2.565954001594368
    },
    {
      "type": "training",
      "description": "Training step 1793",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:42",
      "total_flops_so_far": 2567385096966144.0,
      "budget_used_percent": 2.567385096966144
    },
    {
      "type": "training",
      "description": "Training step 1794",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:42",
      "total_flops_so_far": 2568816192337920.0,
      "budget_used_percent": 2.5688161923379202
    },
    {
      "type": "training",
      "description": "Training step 1795",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:42",
      "total_flops_so_far": 2570247287709696.0,
      "budget_used_percent": 2.5702472877096962
    },
    {
      "type": "training",
      "description": "Training step 1796",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:42",
      "total_flops_so_far": 2571678383081472.0,
      "budget_used_percent": 2.571678383081472
    },
    {
      "type": "training",
      "description": "Training step 1797",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:42",
      "total_flops_so_far": 2573109478453248.0,
      "budget_used_percent": 2.5731094784532482
    },
    {
      "type": "training",
      "description": "Training step 1798",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:43",
      "total_flops_so_far": 2574540573825024.0,
      "budget_used_percent": 2.574540573825024
    },
    {
      "type": "training",
      "description": "Training step 1799",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:43",
      "total_flops_so_far": 2575971669196800.0,
      "budget_used_percent": 2.5759716691967998
    },
    {
      "type": "training",
      "description": "Training step 1800",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:43",
      "total_flops_so_far": 2577402764568576.0,
      "budget_used_percent": 2.5774027645685758
    },
    {
      "type": "training",
      "description": "Training step 1801",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:43",
      "total_flops_so_far": 2578833859940352.0,
      "budget_used_percent": 2.578833859940352
    },
    {
      "type": "training",
      "description": "Training step 1802",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:43",
      "total_flops_so_far": 2580264955312128.0,
      "budget_used_percent": 2.5802649553121277
    },
    {
      "type": "training",
      "description": "Training step 1803",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:43",
      "total_flops_so_far": 2581696050683904.0,
      "budget_used_percent": 2.5816960506839037
    },
    {
      "type": "training",
      "description": "Training step 1804",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:44",
      "total_flops_so_far": 2583127146055680.0,
      "budget_used_percent": 2.58312714605568
    },
    {
      "type": "training",
      "description": "Training step 1805",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:44",
      "total_flops_so_far": 2584558241427456.0,
      "budget_used_percent": 2.584558241427456
    },
    {
      "type": "training",
      "description": "Training step 1806",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:44",
      "total_flops_so_far": 2585989336799232.0,
      "budget_used_percent": 2.5859893367992317
    },
    {
      "type": "training",
      "description": "Training step 1807",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:44",
      "total_flops_so_far": 2587420432171008.0,
      "budget_used_percent": 2.587420432171008
    },
    {
      "type": "training",
      "description": "Training step 1808",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:44",
      "total_flops_so_far": 2588851527542784.0,
      "budget_used_percent": 2.588851527542784
    },
    {
      "type": "training",
      "description": "Training step 1809",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:44",
      "total_flops_so_far": 2590282622914560.0,
      "budget_used_percent": 2.5902826229145597
    },
    {
      "type": "training",
      "description": "Training step 1810",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:45",
      "total_flops_so_far": 2591713718286336.0,
      "budget_used_percent": 2.591713718286336
    },
    {
      "type": "training",
      "description": "Training step 1811",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:45",
      "total_flops_so_far": 2593144813658112.0,
      "budget_used_percent": 2.593144813658112
    },
    {
      "type": "training",
      "description": "Training step 1812",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:45",
      "total_flops_so_far": 2594575909029888.0,
      "budget_used_percent": 2.5945759090298877
    },
    {
      "type": "training",
      "description": "Training step 1813",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:45",
      "total_flops_so_far": 2596007004401664.0,
      "budget_used_percent": 2.596007004401664
    },
    {
      "type": "training",
      "description": "Training step 1814",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:45",
      "total_flops_so_far": 2597438099773440.0,
      "budget_used_percent": 2.59743809977344
    },
    {
      "type": "training",
      "description": "Training step 1815",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:45",
      "total_flops_so_far": 2598869195145216.0,
      "budget_used_percent": 2.598869195145216
    },
    {
      "type": "training",
      "description": "Training step 1816",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:46",
      "total_flops_so_far": 2600300290516992.0,
      "budget_used_percent": 2.600300290516992
    },
    {
      "type": "training",
      "description": "Training step 1817",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:46",
      "total_flops_so_far": 2601731385888768.0,
      "budget_used_percent": 2.601731385888768
    },
    {
      "type": "training",
      "description": "Training step 1818",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:46",
      "total_flops_so_far": 2603162481260544.0,
      "budget_used_percent": 2.603162481260544
    },
    {
      "type": "training",
      "description": "Training step 1819",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:46",
      "total_flops_so_far": 2604593576632320.0,
      "budget_used_percent": 2.60459357663232
    },
    {
      "type": "training",
      "description": "Training step 1820",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:46",
      "total_flops_so_far": 2606024672004096.0,
      "budget_used_percent": 2.606024672004096
    },
    {
      "type": "training",
      "description": "Training step 1821",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:46",
      "total_flops_so_far": 2607455767375872.0,
      "budget_used_percent": 2.607455767375872
    },
    {
      "type": "training",
      "description": "Training step 1822",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:47",
      "total_flops_so_far": 2608886862747648.0,
      "budget_used_percent": 2.608886862747648
    },
    {
      "type": "training",
      "description": "Training step 1823",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:47",
      "total_flops_so_far": 2610317958119424.0,
      "budget_used_percent": 2.610317958119424
    },
    {
      "type": "training",
      "description": "Training step 1824",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:47",
      "total_flops_so_far": 2611749053491200.0,
      "budget_used_percent": 2.6117490534912
    },
    {
      "type": "training",
      "description": "Training step 1825",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:47",
      "total_flops_so_far": 2613180148862976.0,
      "budget_used_percent": 2.613180148862976
    },
    {
      "type": "training",
      "description": "Training step 1826",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:47",
      "total_flops_so_far": 2614611244234752.0,
      "budget_used_percent": 2.614611244234752
    },
    {
      "type": "training",
      "description": "Training step 1827",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:47",
      "total_flops_so_far": 2616042339606528.0,
      "budget_used_percent": 2.616042339606528
    },
    {
      "type": "training",
      "description": "Training step 1828",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:48",
      "total_flops_so_far": 2617473434978304.0,
      "budget_used_percent": 2.617473434978304
    },
    {
      "type": "training",
      "description": "Training step 1829",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:48",
      "total_flops_so_far": 2618904530350080.0,
      "budget_used_percent": 2.61890453035008
    },
    {
      "type": "training",
      "description": "Training step 1830",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:48",
      "total_flops_so_far": 2620335625721856.0,
      "budget_used_percent": 2.620335625721856
    },
    {
      "type": "training",
      "description": "Training step 1831",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:48",
      "total_flops_so_far": 2621766721093632.0,
      "budget_used_percent": 2.621766721093632
    },
    {
      "type": "training",
      "description": "Training step 1832",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:48",
      "total_flops_so_far": 2623197816465408.0,
      "budget_used_percent": 2.623197816465408
    },
    {
      "type": "training",
      "description": "Training step 1833",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:48",
      "total_flops_so_far": 2624628911837184.0,
      "budget_used_percent": 2.624628911837184
    },
    {
      "type": "training",
      "description": "Training step 1834",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:49",
      "total_flops_so_far": 2626060007208960.0,
      "budget_used_percent": 2.62606000720896
    },
    {
      "type": "training",
      "description": "Training step 1835",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:49",
      "total_flops_so_far": 2627491102580736.0,
      "budget_used_percent": 2.627491102580736
    },
    {
      "type": "training",
      "description": "Training step 1836",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:49",
      "total_flops_so_far": 2628922197952512.0,
      "budget_used_percent": 2.628922197952512
    },
    {
      "type": "training",
      "description": "Training step 1837",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:49",
      "total_flops_so_far": 2630353293324288.0,
      "budget_used_percent": 2.630353293324288
    },
    {
      "type": "training",
      "description": "Training step 1838",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:49",
      "total_flops_so_far": 2631784388696064.0,
      "budget_used_percent": 2.631784388696064
    },
    {
      "type": "training",
      "description": "Training step 1839",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:49",
      "total_flops_so_far": 2633215484067840.0,
      "budget_used_percent": 2.63321548406784
    },
    {
      "type": "training",
      "description": "Training step 1840",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:50",
      "total_flops_so_far": 2634646579439616.0,
      "budget_used_percent": 2.634646579439616
    },
    {
      "type": "training",
      "description": "Training step 1841",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:50",
      "total_flops_so_far": 2636077674811392.0,
      "budget_used_percent": 2.636077674811392
    },
    {
      "type": "training",
      "description": "Training step 1842",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:50",
      "total_flops_so_far": 2637508770183168.0,
      "budget_used_percent": 2.6375087701831683
    },
    {
      "type": "training",
      "description": "Training step 1843",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:50",
      "total_flops_so_far": 2638939865554944.0,
      "budget_used_percent": 2.638939865554944
    },
    {
      "type": "training",
      "description": "Training step 1844",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:50",
      "total_flops_so_far": 2640370960926720.0,
      "budget_used_percent": 2.64037096092672
    },
    {
      "type": "training",
      "description": "Training step 1845",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:50",
      "total_flops_so_far": 2641802056298496.0,
      "budget_used_percent": 2.6418020562984963
    },
    {
      "type": "training",
      "description": "Training step 1846",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:51",
      "total_flops_so_far": 2643233151670272.0,
      "budget_used_percent": 2.643233151670272
    },
    {
      "type": "training",
      "description": "Training step 1847",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:51",
      "total_flops_so_far": 2644664247042048.0,
      "budget_used_percent": 2.644664247042048
    },
    {
      "type": "training",
      "description": "Training step 1848",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:51",
      "total_flops_so_far": 2646095342413824.0,
      "budget_used_percent": 2.6460953424138243
    },
    {
      "type": "training",
      "description": "Training step 1849",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:51",
      "total_flops_so_far": 2647526437785600.0,
      "budget_used_percent": 2.6475264377856
    },
    {
      "type": "training",
      "description": "Training step 1850",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:51",
      "total_flops_so_far": 2648957533157376.0,
      "budget_used_percent": 2.648957533157376
    },
    {
      "type": "training",
      "description": "Training step 1851",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:51",
      "total_flops_so_far": 2650388628529152.0,
      "budget_used_percent": 2.6503886285291522
    },
    {
      "type": "training",
      "description": "Training step 1852",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:52",
      "total_flops_so_far": 2651819723900928.0,
      "budget_used_percent": 2.6518197239009282
    },
    {
      "type": "training",
      "description": "Training step 1853",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:52",
      "total_flops_so_far": 2653250819272704.0,
      "budget_used_percent": 2.653250819272704
    },
    {
      "type": "training",
      "description": "Training step 1854",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:52",
      "total_flops_so_far": 2654681914644480.0,
      "budget_used_percent": 2.6546819146444802
    },
    {
      "type": "training",
      "description": "Training step 1855",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:52",
      "total_flops_so_far": 2656113010016256.0,
      "budget_used_percent": 2.656113010016256
    },
    {
      "type": "training",
      "description": "Training step 1856",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:52",
      "total_flops_so_far": 2657544105388032.0,
      "budget_used_percent": 2.6575441053880318
    },
    {
      "type": "training",
      "description": "Training step 1857",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:52",
      "total_flops_so_far": 2658975200759808.0,
      "budget_used_percent": 2.6589752007598078
    },
    {
      "type": "training",
      "description": "Training step 1858",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:53",
      "total_flops_so_far": 2660406296131584.0,
      "budget_used_percent": 2.660406296131584
    },
    {
      "type": "training",
      "description": "Training step 1859",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:53",
      "total_flops_so_far": 2661837391503360.0,
      "budget_used_percent": 2.66183739150336
    },
    {
      "type": "training",
      "description": "Training step 1860",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:53",
      "total_flops_so_far": 2663268486875136.0,
      "budget_used_percent": 2.6632684868751357
    },
    {
      "type": "training",
      "description": "Training step 1861",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:53",
      "total_flops_so_far": 2664699582246912.0,
      "budget_used_percent": 2.664699582246912
    },
    {
      "type": "training",
      "description": "Training step 1862",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:53",
      "total_flops_so_far": 2666130677618688.0,
      "budget_used_percent": 2.666130677618688
    },
    {
      "type": "training",
      "description": "Training step 1863",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:53",
      "total_flops_so_far": 2667561772990464.0,
      "budget_used_percent": 2.6675617729904637
    },
    {
      "type": "training",
      "description": "Training step 1864",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:54",
      "total_flops_so_far": 2668992868362240.0,
      "budget_used_percent": 2.66899286836224
    },
    {
      "type": "training",
      "description": "Training step 1865",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:54",
      "total_flops_so_far": 2670423963734016.0,
      "budget_used_percent": 2.670423963734016
    },
    {
      "type": "training",
      "description": "Training step 1866",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:54",
      "total_flops_so_far": 2671855059105792.0,
      "budget_used_percent": 2.6718550591057917
    },
    {
      "type": "training",
      "description": "Training step 1867",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:54",
      "total_flops_so_far": 2673286154477568.0,
      "budget_used_percent": 2.673286154477568
    },
    {
      "type": "training",
      "description": "Training step 1868",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:54",
      "total_flops_so_far": 2674717249849344.0,
      "budget_used_percent": 2.674717249849344
    },
    {
      "type": "training",
      "description": "Training step 1869",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:54",
      "total_flops_so_far": 2676148345221120.0,
      "budget_used_percent": 2.67614834522112
    },
    {
      "type": "training",
      "description": "Training step 1870",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:54",
      "total_flops_so_far": 2677579440592896.0,
      "budget_used_percent": 2.677579440592896
    },
    {
      "type": "training",
      "description": "Training step 1871",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:55",
      "total_flops_so_far": 2679010535964672.0,
      "budget_used_percent": 2.679010535964672
    },
    {
      "type": "training",
      "description": "Training step 1872",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:55",
      "total_flops_so_far": 2680441631336448.0,
      "budget_used_percent": 2.680441631336448
    },
    {
      "type": "training",
      "description": "Training step 1873",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:55",
      "total_flops_so_far": 2681872726708224.0,
      "budget_used_percent": 2.681872726708224
    },
    {
      "type": "training",
      "description": "Training step 1874",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:55",
      "total_flops_so_far": 2683303822080000.0,
      "budget_used_percent": 2.68330382208
    },
    {
      "type": "training",
      "description": "Training step 1875",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:55",
      "total_flops_so_far": 2684734917451776.0,
      "budget_used_percent": 2.684734917451776
    },
    {
      "type": "training",
      "description": "Training step 1876",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:55",
      "total_flops_so_far": 2686166012823552.0,
      "budget_used_percent": 2.686166012823552
    },
    {
      "type": "training",
      "description": "Training step 1877",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:56",
      "total_flops_so_far": 2687597108195328.0,
      "budget_used_percent": 2.687597108195328
    },
    {
      "type": "training",
      "description": "Training step 1878",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:56",
      "total_flops_so_far": 2689028203567104.0,
      "budget_used_percent": 2.689028203567104
    },
    {
      "type": "training",
      "description": "Training step 1879",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:56",
      "total_flops_so_far": 2690459298938880.0,
      "budget_used_percent": 2.69045929893888
    },
    {
      "type": "training",
      "description": "Training step 1880",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:56",
      "total_flops_so_far": 2691890394310656.0,
      "budget_used_percent": 2.691890394310656
    },
    {
      "type": "training",
      "description": "Training step 1881",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:56",
      "total_flops_so_far": 2693321489682432.0,
      "budget_used_percent": 2.693321489682432
    },
    {
      "type": "training",
      "description": "Training step 1882",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:56",
      "total_flops_so_far": 2694752585054208.0,
      "budget_used_percent": 2.694752585054208
    },
    {
      "type": "training",
      "description": "Training step 1883",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:57",
      "total_flops_so_far": 2696183680425984.0,
      "budget_used_percent": 2.696183680425984
    },
    {
      "type": "training",
      "description": "Training step 1884",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:57",
      "total_flops_so_far": 2697614775797760.0,
      "budget_used_percent": 2.69761477579776
    },
    {
      "type": "training",
      "description": "Training step 1885",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:57",
      "total_flops_so_far": 2699045871169536.0,
      "budget_used_percent": 2.699045871169536
    },
    {
      "type": "training",
      "description": "Training step 1886",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:57",
      "total_flops_so_far": 2700476966541312.0,
      "budget_used_percent": 2.700476966541312
    },
    {
      "type": "training",
      "description": "Training step 1887",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:57",
      "total_flops_so_far": 2701908061913088.0,
      "budget_used_percent": 2.701908061913088
    },
    {
      "type": "training",
      "description": "Training step 1888",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:57",
      "total_flops_so_far": 2703339157284864.0,
      "budget_used_percent": 2.703339157284864
    },
    {
      "type": "training",
      "description": "Training step 1889",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:58",
      "total_flops_so_far": 2704770252656640.0,
      "budget_used_percent": 2.70477025265664
    },
    {
      "type": "training",
      "description": "Training step 1890",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:58",
      "total_flops_so_far": 2706201348028416.0,
      "budget_used_percent": 2.706201348028416
    },
    {
      "type": "training",
      "description": "Training step 1891",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:58",
      "total_flops_so_far": 2707632443400192.0,
      "budget_used_percent": 2.707632443400192
    },
    {
      "type": "training",
      "description": "Training step 1892",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:58",
      "total_flops_so_far": 2709063538771968.0,
      "budget_used_percent": 2.709063538771968
    },
    {
      "type": "training",
      "description": "Training step 1893",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:58",
      "total_flops_so_far": 2710494634143744.0,
      "budget_used_percent": 2.710494634143744
    },
    {
      "type": "training",
      "description": "Training step 1894",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:58",
      "total_flops_so_far": 2711925729515520.0,
      "budget_used_percent": 2.71192572951552
    },
    {
      "type": "training",
      "description": "Training step 1895",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:59",
      "total_flops_so_far": 2713356824887296.0,
      "budget_used_percent": 2.713356824887296
    },
    {
      "type": "training",
      "description": "Training step 1896",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:59",
      "total_flops_so_far": 2714787920259072.0,
      "budget_used_percent": 2.714787920259072
    },
    {
      "type": "training",
      "description": "Training step 1897",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:59",
      "total_flops_so_far": 2716219015630848.0,
      "budget_used_percent": 2.716219015630848
    },
    {
      "type": "training",
      "description": "Training step 1898",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:59",
      "total_flops_so_far": 2717650111002624.0,
      "budget_used_percent": 2.717650111002624
    },
    {
      "type": "training",
      "description": "Training step 1899",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:59",
      "total_flops_so_far": 2719081206374400.0,
      "budget_used_percent": 2.7190812063744003
    },
    {
      "type": "training",
      "description": "Training step 1900",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:58:59",
      "total_flops_so_far": 2720512301746176.0,
      "budget_used_percent": 2.720512301746176
    },
    {
      "type": "training",
      "description": "Training step 1901",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:00",
      "total_flops_so_far": 2721943397117952.0,
      "budget_used_percent": 2.721943397117952
    },
    {
      "type": "training",
      "description": "Training step 1902",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:00",
      "total_flops_so_far": 2723374492489728.0,
      "budget_used_percent": 2.7233744924897283
    },
    {
      "type": "training",
      "description": "Training step 1903",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:00",
      "total_flops_so_far": 2724805587861504.0,
      "budget_used_percent": 2.724805587861504
    },
    {
      "type": "training",
      "description": "Training step 1904",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:00",
      "total_flops_so_far": 2726236683233280.0,
      "budget_used_percent": 2.72623668323328
    },
    {
      "type": "training",
      "description": "Training step 1905",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:00",
      "total_flops_so_far": 2727667778605056.0,
      "budget_used_percent": 2.7276677786050563
    },
    {
      "type": "training",
      "description": "Training step 1906",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:00",
      "total_flops_so_far": 2729098873976832.0,
      "budget_used_percent": 2.7290988739768323
    },
    {
      "type": "training",
      "description": "Training step 1907",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:01",
      "total_flops_so_far": 2730529969348608.0,
      "budget_used_percent": 2.730529969348608
    },
    {
      "type": "training",
      "description": "Training step 1908",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:01",
      "total_flops_so_far": 2731961064720384.0,
      "budget_used_percent": 2.731961064720384
    },
    {
      "type": "training",
      "description": "Training step 1909",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:01",
      "total_flops_so_far": 2733392160092160.0,
      "budget_used_percent": 2.7333921600921602
    },
    {
      "type": "training",
      "description": "Training step 1910",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:01",
      "total_flops_so_far": 2734823255463936.0,
      "budget_used_percent": 2.734823255463936
    },
    {
      "type": "training",
      "description": "Training step 1911",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:01",
      "total_flops_so_far": 2736254350835712.0,
      "budget_used_percent": 2.736254350835712
    },
    {
      "type": "training",
      "description": "Training step 1912",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:01",
      "total_flops_so_far": 2737685446207488.0,
      "budget_used_percent": 2.737685446207488
    },
    {
      "type": "training",
      "description": "Training step 1913",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:02",
      "total_flops_so_far": 2739116541579264.0,
      "budget_used_percent": 2.7391165415792638
    },
    {
      "type": "training",
      "description": "Training step 1914",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:02",
      "total_flops_so_far": 2740547636951040.0,
      "budget_used_percent": 2.7405476369510398
    },
    {
      "type": "training",
      "description": "Training step 1915",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:02",
      "total_flops_so_far": 2741978732322816.0,
      "budget_used_percent": 2.741978732322816
    },
    {
      "type": "training",
      "description": "Training step 1916",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:02",
      "total_flops_so_far": 2743409827694592.0,
      "budget_used_percent": 2.743409827694592
    },
    {
      "type": "training",
      "description": "Training step 1917",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:02",
      "total_flops_so_far": 2744840923066368.0,
      "budget_used_percent": 2.7448409230663677
    },
    {
      "type": "training",
      "description": "Training step 1918",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:02",
      "total_flops_so_far": 2746272018438144.0,
      "budget_used_percent": 2.746272018438144
    },
    {
      "type": "training",
      "description": "Training step 1919",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:03",
      "total_flops_so_far": 2747703113809920.0,
      "budget_used_percent": 2.74770311380992
    },
    {
      "type": "training",
      "description": "Training step 1920",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:03",
      "total_flops_so_far": 2749134209181696.0,
      "budget_used_percent": 2.7491342091816957
    },
    {
      "type": "training",
      "description": "Training step 1921",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:03",
      "total_flops_so_far": 2750565304553472.0,
      "budget_used_percent": 2.750565304553472
    },
    {
      "type": "training",
      "description": "Training step 1922",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:03",
      "total_flops_so_far": 2751996399925248.0,
      "budget_used_percent": 2.751996399925248
    },
    {
      "type": "training",
      "description": "Training step 1923",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:03",
      "total_flops_so_far": 2753427495297024.0,
      "budget_used_percent": 2.7534274952970237
    },
    {
      "type": "training",
      "description": "Training step 1924",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:03",
      "total_flops_so_far": 2754858590668800.0,
      "budget_used_percent": 2.7548585906688
    },
    {
      "type": "training",
      "description": "Training step 1925",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:04",
      "total_flops_so_far": 2756289686040576.0,
      "budget_used_percent": 2.756289686040576
    },
    {
      "type": "training",
      "description": "Training step 1926",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:04",
      "total_flops_so_far": 2757720781412352.0,
      "budget_used_percent": 2.757720781412352
    },
    {
      "type": "training",
      "description": "Training step 1927",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:04",
      "total_flops_so_far": 2759151876784128.0,
      "budget_used_percent": 2.759151876784128
    },
    {
      "type": "training",
      "description": "Training step 1928",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:04",
      "total_flops_so_far": 2760582972155904.0,
      "budget_used_percent": 2.760582972155904
    },
    {
      "type": "training",
      "description": "Training step 1929",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:04",
      "total_flops_so_far": 2762014067527680.0,
      "budget_used_percent": 2.76201406752768
    },
    {
      "type": "training",
      "description": "Training step 1930",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:04",
      "total_flops_so_far": 2763445162899456.0,
      "budget_used_percent": 2.763445162899456
    },
    {
      "type": "training",
      "description": "Training step 1931",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:05",
      "total_flops_so_far": 2764876258271232.0,
      "budget_used_percent": 2.764876258271232
    },
    {
      "type": "training",
      "description": "Training step 1932",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:05",
      "total_flops_so_far": 2766307353643008.0,
      "budget_used_percent": 2.766307353643008
    },
    {
      "type": "training",
      "description": "Training step 1933",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:05",
      "total_flops_so_far": 2767738449014784.0,
      "budget_used_percent": 2.767738449014784
    },
    {
      "type": "training",
      "description": "Training step 1934",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:05",
      "total_flops_so_far": 2769169544386560.0,
      "budget_used_percent": 2.76916954438656
    },
    {
      "type": "training",
      "description": "Training step 1935",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:05",
      "total_flops_so_far": 2770600639758336.0,
      "budget_used_percent": 2.770600639758336
    },
    {
      "type": "training",
      "description": "Training step 1936",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:05",
      "total_flops_so_far": 2772031735130112.0,
      "budget_used_percent": 2.772031735130112
    },
    {
      "type": "training",
      "description": "Training step 1937",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:06",
      "total_flops_so_far": 2773462830501888.0,
      "budget_used_percent": 2.773462830501888
    },
    {
      "type": "training",
      "description": "Training step 1938",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:06",
      "total_flops_so_far": 2774893925873664.0,
      "budget_used_percent": 2.774893925873664
    },
    {
      "type": "training",
      "description": "Training step 1939",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:06",
      "total_flops_so_far": 2776325021245440.0,
      "budget_used_percent": 2.77632502124544
    },
    {
      "type": "training",
      "description": "Training step 1940",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:06",
      "total_flops_so_far": 2777756116617216.0,
      "budget_used_percent": 2.777756116617216
    },
    {
      "type": "training",
      "description": "Training step 1941",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:06",
      "total_flops_so_far": 2779187211988992.0,
      "budget_used_percent": 2.779187211988992
    },
    {
      "type": "training",
      "description": "Training step 1942",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:06",
      "total_flops_so_far": 2780618307360768.0,
      "budget_used_percent": 2.780618307360768
    },
    {
      "type": "training",
      "description": "Training step 1943",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:07",
      "total_flops_so_far": 2782049402732544.0,
      "budget_used_percent": 2.782049402732544
    },
    {
      "type": "training",
      "description": "Training step 1944",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:07",
      "total_flops_so_far": 2783480498104320.0,
      "budget_used_percent": 2.78348049810432
    },
    {
      "type": "training",
      "description": "Training step 1945",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:07",
      "total_flops_so_far": 2784911593476096.0,
      "budget_used_percent": 2.784911593476096
    },
    {
      "type": "training",
      "description": "Training step 1946",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:07",
      "total_flops_so_far": 2786342688847872.0,
      "budget_used_percent": 2.786342688847872
    },
    {
      "type": "training",
      "description": "Training step 1947",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:07",
      "total_flops_so_far": 2787773784219648.0,
      "budget_used_percent": 2.787773784219648
    },
    {
      "type": "training",
      "description": "Training step 1948",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:07",
      "total_flops_so_far": 2789204879591424.0,
      "budget_used_percent": 2.789204879591424
    },
    {
      "type": "training",
      "description": "Training step 1949",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:08",
      "total_flops_so_far": 2790635974963200.0,
      "budget_used_percent": 2.7906359749632
    },
    {
      "type": "training",
      "description": "Training step 1950",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:08",
      "total_flops_so_far": 2792067070334976.0,
      "budget_used_percent": 2.792067070334976
    },
    {
      "type": "training",
      "description": "Training step 1951",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:08",
      "total_flops_so_far": 2793498165706752.0,
      "budget_used_percent": 2.793498165706752
    },
    {
      "type": "training",
      "description": "Training step 1952",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:08",
      "total_flops_so_far": 2794929261078528.0,
      "budget_used_percent": 2.794929261078528
    },
    {
      "type": "training",
      "description": "Training step 1953",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:08",
      "total_flops_so_far": 2796360356450304.0,
      "budget_used_percent": 2.7963603564503043
    },
    {
      "type": "training",
      "description": "Training step 1954",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:08",
      "total_flops_so_far": 2797791451822080.0,
      "budget_used_percent": 2.79779145182208
    },
    {
      "type": "training",
      "description": "Training step 1955",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:09",
      "total_flops_so_far": 2799222547193856.0,
      "budget_used_percent": 2.799222547193856
    },
    {
      "type": "training",
      "description": "Training step 1956",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:09",
      "total_flops_so_far": 2800653642565632.0,
      "budget_used_percent": 2.8006536425656323
    },
    {
      "type": "training",
      "description": "Training step 1957",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:09",
      "total_flops_so_far": 2802084737937408.0,
      "budget_used_percent": 2.802084737937408
    },
    {
      "type": "training",
      "description": "Training step 1958",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:09",
      "total_flops_so_far": 2803515833309184.0,
      "budget_used_percent": 2.803515833309184
    },
    {
      "type": "training",
      "description": "Training step 1959",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:09",
      "total_flops_so_far": 2804946928680960.0,
      "budget_used_percent": 2.8049469286809603
    },
    {
      "type": "training",
      "description": "Training step 1960",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:09",
      "total_flops_so_far": 2806378024052736.0,
      "budget_used_percent": 2.806378024052736
    },
    {
      "type": "training",
      "description": "Training step 1961",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:10",
      "total_flops_so_far": 2807809119424512.0,
      "budget_used_percent": 2.807809119424512
    },
    {
      "type": "training",
      "description": "Training step 1962",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:10",
      "total_flops_so_far": 2809240214796288.0,
      "budget_used_percent": 2.8092402147962883
    },
    {
      "type": "training",
      "description": "Training step 1963",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:10",
      "total_flops_so_far": 2810671310168064.0,
      "budget_used_percent": 2.8106713101680643
    },
    {
      "type": "training",
      "description": "Training step 1964",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:10",
      "total_flops_so_far": 2812102405539840.0,
      "budget_used_percent": 2.81210240553984
    },
    {
      "type": "training",
      "description": "Training step 1965",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:11",
      "total_flops_so_far": 2813533500911616.0,
      "budget_used_percent": 2.813533500911616
    },
    {
      "type": "training",
      "description": "Training step 1966",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:11",
      "total_flops_so_far": 2814964596283392.0,
      "budget_used_percent": 2.8149645962833922
    },
    {
      "type": "training",
      "description": "Training step 1967",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:11",
      "total_flops_so_far": 2816395691655168.0,
      "budget_used_percent": 2.816395691655168
    },
    {
      "type": "training",
      "description": "Training step 1968",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:11",
      "total_flops_so_far": 2817826787026944.0,
      "budget_used_percent": 2.817826787026944
    },
    {
      "type": "training",
      "description": "Training step 1969",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:11",
      "total_flops_so_far": 2819257882398720.0,
      "budget_used_percent": 2.81925788239872
    },
    {
      "type": "training",
      "description": "Training step 1970",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:11",
      "total_flops_so_far": 2820688977770496.0,
      "budget_used_percent": 2.8206889777704958
    },
    {
      "type": "training",
      "description": "Training step 1971",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:12",
      "total_flops_so_far": 2822120073142272.0,
      "budget_used_percent": 2.8221200731422718
    },
    {
      "type": "training",
      "description": "Training step 1972",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:12",
      "total_flops_so_far": 2823551168514048.0,
      "budget_used_percent": 2.823551168514048
    },
    {
      "type": "training",
      "description": "Training step 1973",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:12",
      "total_flops_so_far": 2824982263885824.0,
      "budget_used_percent": 2.824982263885824
    },
    {
      "type": "training",
      "description": "Training step 1974",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:12",
      "total_flops_so_far": 2826413359257600.0,
      "budget_used_percent": 2.8264133592575997
    },
    {
      "type": "training",
      "description": "Training step 1975",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:12",
      "total_flops_so_far": 2827844454629376.0,
      "budget_used_percent": 2.827844454629376
    },
    {
      "type": "training",
      "description": "Training step 1976",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:13",
      "total_flops_so_far": 2829275550001152.0,
      "budget_used_percent": 2.829275550001152
    },
    {
      "type": "training",
      "description": "Training step 1977",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:13",
      "total_flops_so_far": 2830706645372928.0,
      "budget_used_percent": 2.8307066453729277
    },
    {
      "type": "training",
      "description": "Training step 1978",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:13",
      "total_flops_so_far": 2832137740744704.0,
      "budget_used_percent": 2.832137740744704
    },
    {
      "type": "training",
      "description": "Training step 1979",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:13",
      "total_flops_so_far": 2833568836116480.0,
      "budget_used_percent": 2.83356883611648
    },
    {
      "type": "training",
      "description": "Training step 1980",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:13",
      "total_flops_so_far": 2834999931488256.0,
      "budget_used_percent": 2.834999931488256
    },
    {
      "type": "training",
      "description": "Training step 1981",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:13",
      "total_flops_so_far": 2836431026860032.0,
      "budget_used_percent": 2.836431026860032
    },
    {
      "type": "training",
      "description": "Training step 1982",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:14",
      "total_flops_so_far": 2837862122231808.0,
      "budget_used_percent": 2.837862122231808
    },
    {
      "type": "training",
      "description": "Training step 1983",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:14",
      "total_flops_so_far": 2839293217603584.0,
      "budget_used_percent": 2.839293217603584
    },
    {
      "type": "training",
      "description": "Training step 1984",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:14",
      "total_flops_so_far": 2840724312975360.0,
      "budget_used_percent": 2.84072431297536
    },
    {
      "type": "training",
      "description": "Training step 1985",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:14",
      "total_flops_so_far": 2842155408347136.0,
      "budget_used_percent": 2.842155408347136
    },
    {
      "type": "training",
      "description": "Training step 1986",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:14",
      "total_flops_so_far": 2843586503718912.0,
      "budget_used_percent": 2.843586503718912
    },
    {
      "type": "training",
      "description": "Training step 1987",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:14",
      "total_flops_so_far": 2845017599090688.0,
      "budget_used_percent": 2.8450175990906876
    },
    {
      "type": "training",
      "description": "Training step 1988",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:15",
      "total_flops_so_far": 2846448694462464.0,
      "budget_used_percent": 2.846448694462464
    },
    {
      "type": "training",
      "description": "Training step 1989",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:15",
      "total_flops_so_far": 2847879789834240.0,
      "budget_used_percent": 2.84787978983424
    },
    {
      "type": "training",
      "description": "Training step 1990",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:15",
      "total_flops_so_far": 2849310885206016.0,
      "budget_used_percent": 2.849310885206016
    },
    {
      "type": "training",
      "description": "Training step 1991",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:15",
      "total_flops_so_far": 2850741980577792.0,
      "budget_used_percent": 2.850741980577792
    },
    {
      "type": "training",
      "description": "Training step 1992",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:15",
      "total_flops_so_far": 2852173075949568.0,
      "budget_used_percent": 2.852173075949568
    },
    {
      "type": "training",
      "description": "Training step 1993",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:15",
      "total_flops_so_far": 2853604171321344.0,
      "budget_used_percent": 2.853604171321344
    },
    {
      "type": "training",
      "description": "Training step 1994",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:15",
      "total_flops_so_far": 2855035266693120.0,
      "budget_used_percent": 2.85503526669312
    },
    {
      "type": "training",
      "description": "Training step 1995",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:16",
      "total_flops_so_far": 2856466362064896.0,
      "budget_used_percent": 2.856466362064896
    },
    {
      "type": "training",
      "description": "Training step 1996",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:16",
      "total_flops_so_far": 2857897457436672.0,
      "budget_used_percent": 2.857897457436672
    },
    {
      "type": "training",
      "description": "Training step 1997",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:16",
      "total_flops_so_far": 2859328552808448.0,
      "budget_used_percent": 2.859328552808448
    },
    {
      "type": "training",
      "description": "Training step 1998",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:16",
      "total_flops_so_far": 2860759648180224.0,
      "budget_used_percent": 2.860759648180224
    },
    {
      "type": "training",
      "description": "Training step 1999",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 15:59:16",
      "total_flops_so_far": 2862190743552000.0,
      "budget_used_percent": 2.862190743552
    }
  ],
  "total_flops": 2862190743552000.0,
  "budget_used_percent": 2.862190743552
}