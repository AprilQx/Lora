{
  "experiment_name": "lr1e-04_rank8_prec2",
  "model_config": {
    "hidden_size": 896,
    "num_attention_heads": 14,
    "num_hidden_layers": 24,
    "intermediate_size": 4864,
    "head_dim": 64,
    "vocab_size": 151936,
    "lora_r": 8,
    "lora_target_modules": [
      "q_proj",
      "v_proj"
    ]
  },
  "max_budget": 1e+17,
  "start_time": "2025-03-31 16:20:49",
  "operations": [
    {
      "type": "training",
      "description": "Training step 0",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:52",
      "total_flops_so_far": 1432152041472.0,
      "budget_used_percent": 0.001432152041472
    },
    {
      "type": "training",
      "description": "Training step 1",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:53",
      "total_flops_so_far": 2864304082944.0,
      "budget_used_percent": 0.002864304082944
    },
    {
      "type": "training",
      "description": "Training step 2",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:53",
      "total_flops_so_far": 4296456124416.0,
      "budget_used_percent": 0.004296456124416
    },
    {
      "type": "training",
      "description": "Training step 3",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:53",
      "total_flops_so_far": 5728608165888.0,
      "budget_used_percent": 0.005728608165888
    },
    {
      "type": "training",
      "description": "Training step 4",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:53",
      "total_flops_so_far": 7160760207360.0,
      "budget_used_percent": 0.007160760207359999
    },
    {
      "type": "training",
      "description": "Training step 5",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:53",
      "total_flops_so_far": 8592912248832.0,
      "budget_used_percent": 0.008592912248832
    },
    {
      "type": "training",
      "description": "Training step 6",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:53",
      "total_flops_so_far": 10025064290304.0,
      "budget_used_percent": 0.010025064290304
    },
    {
      "type": "training",
      "description": "Training step 7",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:53",
      "total_flops_so_far": 11457216331776.0,
      "budget_used_percent": 0.011457216331776
    },
    {
      "type": "training",
      "description": "Training step 8",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:53",
      "total_flops_so_far": 12889368373248.0,
      "budget_used_percent": 0.012889368373247998
    },
    {
      "type": "training",
      "description": "Training step 9",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:54",
      "total_flops_so_far": 14321520414720.0,
      "budget_used_percent": 0.014321520414719999
    },
    {
      "type": "training",
      "description": "Training step 10",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:54",
      "total_flops_so_far": 15753672456192.0,
      "budget_used_percent": 0.015753672456191997
    },
    {
      "type": "training",
      "description": "Training step 11",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:54",
      "total_flops_so_far": 17185824497664.0,
      "budget_used_percent": 0.017185824497664
    },
    {
      "type": "training",
      "description": "Training step 12",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:54",
      "total_flops_so_far": 18617976539136.0,
      "budget_used_percent": 0.018617976539136
    },
    {
      "type": "training",
      "description": "Training step 13",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:54",
      "total_flops_so_far": 20050128580608.0,
      "budget_used_percent": 0.020050128580608
    },
    {
      "type": "training",
      "description": "Training step 14",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:54",
      "total_flops_so_far": 21482280622080.0,
      "budget_used_percent": 0.02148228062208
    },
    {
      "type": "training",
      "description": "Training step 15",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:54",
      "total_flops_so_far": 22914432663552.0,
      "budget_used_percent": 0.022914432663552
    },
    {
      "type": "training",
      "description": "Training step 16",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:54",
      "total_flops_so_far": 24346584705024.0,
      "budget_used_percent": 0.024346584705024002
    },
    {
      "type": "training",
      "description": "Training step 17",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:55",
      "total_flops_so_far": 25778736746496.0,
      "budget_used_percent": 0.025778736746495997
    },
    {
      "type": "training",
      "description": "Training step 18",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:55",
      "total_flops_so_far": 27210888787968.0,
      "budget_used_percent": 0.027210888787968
    },
    {
      "type": "training",
      "description": "Training step 19",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:55",
      "total_flops_so_far": 28643040829440.0,
      "budget_used_percent": 0.028643040829439997
    },
    {
      "type": "training",
      "description": "Training step 20",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:55",
      "total_flops_so_far": 30075192870912.0,
      "budget_used_percent": 0.030075192870912
    },
    {
      "type": "training",
      "description": "Training step 21",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:55",
      "total_flops_so_far": 31507344912384.0,
      "budget_used_percent": 0.031507344912383994
    },
    {
      "type": "training",
      "description": "Training step 22",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:55",
      "total_flops_so_far": 32939496953856.0,
      "budget_used_percent": 0.032939496953856
    },
    {
      "type": "training",
      "description": "Training step 23",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:55",
      "total_flops_so_far": 34371648995328.0,
      "budget_used_percent": 0.034371648995328
    },
    {
      "type": "training",
      "description": "Training step 24",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:55",
      "total_flops_so_far": 35803801036800.0,
      "budget_used_percent": 0.0358038010368
    },
    {
      "type": "training",
      "description": "Training step 25",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:55",
      "total_flops_so_far": 37235953078272.0,
      "budget_used_percent": 0.037235953078272
    },
    {
      "type": "training",
      "description": "Training step 26",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:56",
      "total_flops_so_far": 38668105119744.0,
      "budget_used_percent": 0.038668105119744
    },
    {
      "type": "training",
      "description": "Training step 27",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:56",
      "total_flops_so_far": 40100257161216.0,
      "budget_used_percent": 0.040100257161216
    },
    {
      "type": "training",
      "description": "Training step 28",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:56",
      "total_flops_so_far": 41532409202688.0,
      "budget_used_percent": 0.041532409202688
    },
    {
      "type": "training",
      "description": "Training step 29",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:56",
      "total_flops_so_far": 42964561244160.0,
      "budget_used_percent": 0.04296456124416
    },
    {
      "type": "training",
      "description": "Training step 30",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:56",
      "total_flops_so_far": 44396713285632.0,
      "budget_used_percent": 0.044396713285632
    },
    {
      "type": "training",
      "description": "Training step 31",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:56",
      "total_flops_so_far": 45828865327104.0,
      "budget_used_percent": 0.045828865327104
    },
    {
      "type": "training",
      "description": "Training step 32",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:56",
      "total_flops_so_far": 47261017368576.0,
      "budget_used_percent": 0.047261017368576
    },
    {
      "type": "training",
      "description": "Training step 33",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:56",
      "total_flops_so_far": 48693169410048.0,
      "budget_used_percent": 0.048693169410048004
    },
    {
      "type": "training",
      "description": "Training step 34",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:57",
      "total_flops_so_far": 50125321451520.0,
      "budget_used_percent": 0.05012532145152
    },
    {
      "type": "training",
      "description": "Training step 35",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:57",
      "total_flops_so_far": 51557473492992.0,
      "budget_used_percent": 0.051557473492991994
    },
    {
      "type": "training",
      "description": "Training step 36",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:57",
      "total_flops_so_far": 52989625534464.0,
      "budget_used_percent": 0.052989625534464006
    },
    {
      "type": "training",
      "description": "Training step 37",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:57",
      "total_flops_so_far": 54421777575936.0,
      "budget_used_percent": 0.054421777575936
    },
    {
      "type": "training",
      "description": "Training step 38",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:57",
      "total_flops_so_far": 55853929617408.0,
      "budget_used_percent": 0.055853929617407996
    },
    {
      "type": "training",
      "description": "Training step 39",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:57",
      "total_flops_so_far": 57286081658880.0,
      "budget_used_percent": 0.057286081658879995
    },
    {
      "type": "training",
      "description": "Training step 40",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:57",
      "total_flops_so_far": 58718233700352.0,
      "budget_used_percent": 0.05871823370035201
    },
    {
      "type": "training",
      "description": "Training step 41",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:57",
      "total_flops_so_far": 60150385741824.0,
      "budget_used_percent": 0.060150385741824
    },
    {
      "type": "training",
      "description": "Training step 42",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:58",
      "total_flops_so_far": 61582537783296.0,
      "budget_used_percent": 0.061582537783296
    },
    {
      "type": "training",
      "description": "Training step 43",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:58",
      "total_flops_so_far": 63014689824768.0,
      "budget_used_percent": 0.06301468982476799
    },
    {
      "type": "training",
      "description": "Training step 44",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:58",
      "total_flops_so_far": 64446841866240.0,
      "budget_used_percent": 0.06444684186624
    },
    {
      "type": "training",
      "description": "Training step 45",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:58",
      "total_flops_so_far": 65878993907712.0,
      "budget_used_percent": 0.065878993907712
    },
    {
      "type": "training",
      "description": "Training step 46",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:58",
      "total_flops_so_far": 67311145949184.0,
      "budget_used_percent": 0.067311145949184
    },
    {
      "type": "training",
      "description": "Training step 47",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:58",
      "total_flops_so_far": 68743297990656.0,
      "budget_used_percent": 0.068743297990656
    },
    {
      "type": "training",
      "description": "Training step 48",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:58",
      "total_flops_so_far": 70175450032128.0,
      "budget_used_percent": 0.07017545003212801
    },
    {
      "type": "training",
      "description": "Training step 49",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:58",
      "total_flops_so_far": 71607602073600.0,
      "budget_used_percent": 0.0716076020736
    },
    {
      "type": "training",
      "description": "Training step 50",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:59",
      "total_flops_so_far": 73039754115072.0,
      "budget_used_percent": 0.07303975411507199
    },
    {
      "type": "training",
      "description": "Training step 51",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:59",
      "total_flops_so_far": 74471906156544.0,
      "budget_used_percent": 0.074471906156544
    },
    {
      "type": "training",
      "description": "Training step 52",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:59",
      "total_flops_so_far": 75904058198016.0,
      "budget_used_percent": 0.075904058198016
    },
    {
      "type": "training",
      "description": "Training step 53",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:59",
      "total_flops_so_far": 77336210239488.0,
      "budget_used_percent": 0.077336210239488
    },
    {
      "type": "training",
      "description": "Training step 54",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:59",
      "total_flops_so_far": 78768362280960.0,
      "budget_used_percent": 0.07876836228096
    },
    {
      "type": "training",
      "description": "Training step 55",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:59",
      "total_flops_so_far": 80200514322432.0,
      "budget_used_percent": 0.080200514322432
    },
    {
      "type": "training",
      "description": "Training step 56",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:20:59",
      "total_flops_so_far": 81632666363904.0,
      "budget_used_percent": 0.081632666363904
    },
    {
      "type": "training",
      "description": "Training step 57",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:00",
      "total_flops_so_far": 83064818405376.0,
      "budget_used_percent": 0.083064818405376
    },
    {
      "type": "training",
      "description": "Training step 58",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:00",
      "total_flops_so_far": 84496970446848.0,
      "budget_used_percent": 0.084496970446848
    },
    {
      "type": "training",
      "description": "Training step 59",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:00",
      "total_flops_so_far": 85929122488320.0,
      "budget_used_percent": 0.08592912248832
    },
    {
      "type": "training",
      "description": "Training step 60",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:00",
      "total_flops_so_far": 87361274529792.0,
      "budget_used_percent": 0.087361274529792
    },
    {
      "type": "training",
      "description": "Training step 61",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:00",
      "total_flops_so_far": 88793426571264.0,
      "budget_used_percent": 0.088793426571264
    },
    {
      "type": "training",
      "description": "Training step 62",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:00",
      "total_flops_so_far": 90225578612736.0,
      "budget_used_percent": 0.090225578612736
    },
    {
      "type": "training",
      "description": "Training step 63",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:00",
      "total_flops_so_far": 91657730654208.0,
      "budget_used_percent": 0.091657730654208
    },
    {
      "type": "training",
      "description": "Training step 64",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:00",
      "total_flops_so_far": 93089882695680.0,
      "budget_used_percent": 0.09308988269568
    },
    {
      "type": "training",
      "description": "Training step 65",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:00",
      "total_flops_so_far": 94522034737152.0,
      "budget_used_percent": 0.094522034737152
    },
    {
      "type": "training",
      "description": "Training step 66",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:01",
      "total_flops_so_far": 95954186778624.0,
      "budget_used_percent": 0.095954186778624
    },
    {
      "type": "training",
      "description": "Training step 67",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:01",
      "total_flops_so_far": 97386338820096.0,
      "budget_used_percent": 0.09738633882009601
    },
    {
      "type": "training",
      "description": "Training step 68",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:01",
      "total_flops_so_far": 98818490861568.0,
      "budget_used_percent": 0.09881849086156799
    },
    {
      "type": "training",
      "description": "Training step 69",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:01",
      "total_flops_so_far": 100250642903040.0,
      "budget_used_percent": 0.10025064290304
    },
    {
      "type": "training",
      "description": "Training step 70",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:01",
      "total_flops_so_far": 101682794944512.0,
      "budget_used_percent": 0.101682794944512
    },
    {
      "type": "training",
      "description": "Training step 71",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:01",
      "total_flops_so_far": 103114946985984.0,
      "budget_used_percent": 0.10311494698598399
    },
    {
      "type": "training",
      "description": "Training step 72",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:01",
      "total_flops_so_far": 104547099027456.0,
      "budget_used_percent": 0.104547099027456
    },
    {
      "type": "training",
      "description": "Training step 73",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:01",
      "total_flops_so_far": 105979251068928.0,
      "budget_used_percent": 0.10597925106892801
    },
    {
      "type": "training",
      "description": "Training step 74",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:02",
      "total_flops_so_far": 107411403110400.0,
      "budget_used_percent": 0.1074114031104
    },
    {
      "type": "training",
      "description": "Training step 75",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:02",
      "total_flops_so_far": 108843555151872.0,
      "budget_used_percent": 0.108843555151872
    },
    {
      "type": "training",
      "description": "Training step 76",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:02",
      "total_flops_so_far": 110275707193344.0,
      "budget_used_percent": 0.11027570719334401
    },
    {
      "type": "training",
      "description": "Training step 77",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:02",
      "total_flops_so_far": 111707859234816.0,
      "budget_used_percent": 0.11170785923481599
    },
    {
      "type": "training",
      "description": "Training step 78",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:02",
      "total_flops_so_far": 113140011276288.0,
      "budget_used_percent": 0.113140011276288
    },
    {
      "type": "training",
      "description": "Training step 79",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:02",
      "total_flops_so_far": 114572163317760.0,
      "budget_used_percent": 0.11457216331775999
    },
    {
      "type": "training",
      "description": "Training step 80",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:02",
      "total_flops_so_far": 116004315359232.0,
      "budget_used_percent": 0.116004315359232
    },
    {
      "type": "training",
      "description": "Training step 81",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:02",
      "total_flops_so_far": 117436467400704.0,
      "budget_used_percent": 0.11743646740070401
    },
    {
      "type": "training",
      "description": "Training step 82",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:03",
      "total_flops_so_far": 118868619442176.0,
      "budget_used_percent": 0.118868619442176
    },
    {
      "type": "training",
      "description": "Training step 83",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:03",
      "total_flops_so_far": 120300771483648.0,
      "budget_used_percent": 0.120300771483648
    },
    {
      "type": "training",
      "description": "Training step 84",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:03",
      "total_flops_so_far": 121732923525120.0,
      "budget_used_percent": 0.12173292352512001
    },
    {
      "type": "training",
      "description": "Training step 85",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:03",
      "total_flops_so_far": 123165075566592.0,
      "budget_used_percent": 0.123165075566592
    },
    {
      "type": "training",
      "description": "Training step 86",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:03",
      "total_flops_so_far": 124597227608064.0,
      "budget_used_percent": 0.124597227608064
    },
    {
      "type": "training",
      "description": "Training step 87",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:03",
      "total_flops_so_far": 126029379649536.0,
      "budget_used_percent": 0.12602937964953598
    },
    {
      "type": "training",
      "description": "Training step 88",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:03",
      "total_flops_so_far": 127461531691008.0,
      "budget_used_percent": 0.127461531691008
    },
    {
      "type": "training",
      "description": "Training step 89",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:03",
      "total_flops_so_far": 128893683732480.0,
      "budget_used_percent": 0.12889368373248
    },
    {
      "type": "training",
      "description": "Training step 90",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:04",
      "total_flops_so_far": 130325835773952.0,
      "budget_used_percent": 0.130325835773952
    },
    {
      "type": "training",
      "description": "Training step 91",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:04",
      "total_flops_so_far": 131757987815424.0,
      "budget_used_percent": 0.131757987815424
    },
    {
      "type": "training",
      "description": "Training step 92",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:04",
      "total_flops_so_far": 133190139856896.0,
      "budget_used_percent": 0.133190139856896
    },
    {
      "type": "training",
      "description": "Training step 93",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:04",
      "total_flops_so_far": 134622291898368.0,
      "budget_used_percent": 0.134622291898368
    },
    {
      "type": "training",
      "description": "Training step 94",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:04",
      "total_flops_so_far": 136054443939840.0,
      "budget_used_percent": 0.13605444393984
    },
    {
      "type": "training",
      "description": "Training step 95",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:04",
      "total_flops_so_far": 137486595981312.0,
      "budget_used_percent": 0.137486595981312
    },
    {
      "type": "training",
      "description": "Training step 96",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:04",
      "total_flops_so_far": 138918748022784.0,
      "budget_used_percent": 0.138918748022784
    },
    {
      "type": "training",
      "description": "Training step 97",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:04",
      "total_flops_so_far": 140350900064256.0,
      "budget_used_percent": 0.14035090006425602
    },
    {
      "type": "training",
      "description": "Training step 98",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:05",
      "total_flops_so_far": 141783052105728.0,
      "budget_used_percent": 0.141783052105728
    },
    {
      "type": "training",
      "description": "Training step 99",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:05",
      "total_flops_so_far": 143215204147200.0,
      "budget_used_percent": 0.1432152041472
    },
    {
      "type": "training",
      "description": "Training step 100",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:05",
      "total_flops_so_far": 144647356188672.0,
      "budget_used_percent": 0.144647356188672
    },
    {
      "type": "training",
      "description": "Training step 101",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:05",
      "total_flops_so_far": 146079508230144.0,
      "budget_used_percent": 0.14607950823014398
    },
    {
      "type": "training",
      "description": "Training step 102",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:05",
      "total_flops_so_far": 147511660271616.0,
      "budget_used_percent": 0.147511660271616
    },
    {
      "type": "training",
      "description": "Training step 103",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:05",
      "total_flops_so_far": 148943812313088.0,
      "budget_used_percent": 0.148943812313088
    },
    {
      "type": "training",
      "description": "Training step 104",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:05",
      "total_flops_so_far": 150375964354560.0,
      "budget_used_percent": 0.15037596435456
    },
    {
      "type": "training",
      "description": "Training step 105",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:05",
      "total_flops_so_far": 151808116396032.0,
      "budget_used_percent": 0.151808116396032
    },
    {
      "type": "training",
      "description": "Training step 106",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:06",
      "total_flops_so_far": 153240268437504.0,
      "budget_used_percent": 0.153240268437504
    },
    {
      "type": "training",
      "description": "Training step 107",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:06",
      "total_flops_so_far": 154672420478976.0,
      "budget_used_percent": 0.154672420478976
    },
    {
      "type": "training",
      "description": "Training step 108",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:06",
      "total_flops_so_far": 156104572520448.0,
      "budget_used_percent": 0.15610457252044802
    },
    {
      "type": "training",
      "description": "Training step 109",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:06",
      "total_flops_so_far": 157536724561920.0,
      "budget_used_percent": 0.15753672456192
    },
    {
      "type": "training",
      "description": "Training step 110",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:06",
      "total_flops_so_far": 158968876603392.0,
      "budget_used_percent": 0.158968876603392
    },
    {
      "type": "training",
      "description": "Training step 111",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:06",
      "total_flops_so_far": 160401028644864.0,
      "budget_used_percent": 0.160401028644864
    },
    {
      "type": "training",
      "description": "Training step 112",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:06",
      "total_flops_so_far": 161833180686336.0,
      "budget_used_percent": 0.161833180686336
    },
    {
      "type": "training",
      "description": "Training step 113",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:06",
      "total_flops_so_far": 163265332727808.0,
      "budget_used_percent": 0.163265332727808
    },
    {
      "type": "training",
      "description": "Training step 114",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:06",
      "total_flops_so_far": 164697484769280.0,
      "budget_used_percent": 0.16469748476927998
    },
    {
      "type": "training",
      "description": "Training step 115",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:07",
      "total_flops_so_far": 166129636810752.0,
      "budget_used_percent": 0.166129636810752
    },
    {
      "type": "training",
      "description": "Training step 116",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:07",
      "total_flops_so_far": 167561788852224.0,
      "budget_used_percent": 0.167561788852224
    },
    {
      "type": "training",
      "description": "Training step 117",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:07",
      "total_flops_so_far": 168993940893696.0,
      "budget_used_percent": 0.168993940893696
    },
    {
      "type": "training",
      "description": "Training step 118",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:07",
      "total_flops_so_far": 170426092935168.0,
      "budget_used_percent": 0.170426092935168
    },
    {
      "type": "training",
      "description": "Training step 119",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:07",
      "total_flops_so_far": 171858244976640.0,
      "budget_used_percent": 0.17185824497664
    },
    {
      "type": "training",
      "description": "Training step 120",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:07",
      "total_flops_so_far": 173290397018112.0,
      "budget_used_percent": 0.173290397018112
    },
    {
      "type": "training",
      "description": "Training step 121",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:07",
      "total_flops_so_far": 174722549059584.0,
      "budget_used_percent": 0.174722549059584
    },
    {
      "type": "training",
      "description": "Training step 122",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:07",
      "total_flops_so_far": 176154701101056.0,
      "budget_used_percent": 0.176154701101056
    },
    {
      "type": "training",
      "description": "Training step 123",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:08",
      "total_flops_so_far": 177586853142528.0,
      "budget_used_percent": 0.177586853142528
    },
    {
      "type": "training",
      "description": "Training step 124",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:08",
      "total_flops_so_far": 179019005184000.0,
      "budget_used_percent": 0.17901900518400002
    },
    {
      "type": "training",
      "description": "Training step 125",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:08",
      "total_flops_so_far": 180451157225472.0,
      "budget_used_percent": 0.180451157225472
    },
    {
      "type": "training",
      "description": "Training step 126",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:08",
      "total_flops_so_far": 181883309266944.0,
      "budget_used_percent": 0.181883309266944
    },
    {
      "type": "training",
      "description": "Training step 127",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:08",
      "total_flops_so_far": 183315461308416.0,
      "budget_used_percent": 0.183315461308416
    },
    {
      "type": "training",
      "description": "Training step 128",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:08",
      "total_flops_so_far": 184747613349888.0,
      "budget_used_percent": 0.18474761334988798
    },
    {
      "type": "training",
      "description": "Training step 129",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:08",
      "total_flops_so_far": 186179765391360.0,
      "budget_used_percent": 0.18617976539136
    },
    {
      "type": "training",
      "description": "Training step 130",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:08",
      "total_flops_so_far": 187611917432832.0,
      "budget_used_percent": 0.187611917432832
    },
    {
      "type": "training",
      "description": "Training step 131",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:09",
      "total_flops_so_far": 189044069474304.0,
      "budget_used_percent": 0.189044069474304
    },
    {
      "type": "training",
      "description": "Training step 132",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:09",
      "total_flops_so_far": 190476221515776.0,
      "budget_used_percent": 0.190476221515776
    },
    {
      "type": "training",
      "description": "Training step 133",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:09",
      "total_flops_so_far": 191908373557248.0,
      "budget_used_percent": 0.191908373557248
    },
    {
      "type": "training",
      "description": "Training step 134",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:09",
      "total_flops_so_far": 193340525598720.0,
      "budget_used_percent": 0.19334052559872
    },
    {
      "type": "training",
      "description": "Training step 135",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:09",
      "total_flops_so_far": 194772677640192.0,
      "budget_used_percent": 0.19477267764019202
    },
    {
      "type": "training",
      "description": "Training step 136",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:09",
      "total_flops_so_far": 196204829681664.0,
      "budget_used_percent": 0.196204829681664
    },
    {
      "type": "training",
      "description": "Training step 137",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:09",
      "total_flops_so_far": 197636981723136.0,
      "budget_used_percent": 0.19763698172313598
    },
    {
      "type": "training",
      "description": "Training step 138",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:09",
      "total_flops_so_far": 199069133764608.0,
      "budget_used_percent": 0.199069133764608
    },
    {
      "type": "training",
      "description": "Training step 139",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:10",
      "total_flops_so_far": 200501285806080.0,
      "budget_used_percent": 0.20050128580608
    },
    {
      "type": "training",
      "description": "Training step 140",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:10",
      "total_flops_so_far": 201933437847552.0,
      "budget_used_percent": 0.201933437847552
    },
    {
      "type": "training",
      "description": "Training step 141",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:10",
      "total_flops_so_far": 203365589889024.0,
      "budget_used_percent": 0.203365589889024
    },
    {
      "type": "training",
      "description": "Training step 142",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:10",
      "total_flops_so_far": 204797741930496.0,
      "budget_used_percent": 0.204797741930496
    },
    {
      "type": "training",
      "description": "Training step 143",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:10",
      "total_flops_so_far": 206229893971968.0,
      "budget_used_percent": 0.20622989397196798
    },
    {
      "type": "training",
      "description": "Training step 144",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:10",
      "total_flops_so_far": 207662046013440.0,
      "budget_used_percent": 0.20766204601344002
    },
    {
      "type": "training",
      "description": "Training step 145",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:10",
      "total_flops_so_far": 209094198054912.0,
      "budget_used_percent": 0.209094198054912
    },
    {
      "type": "training",
      "description": "Training step 146",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:10",
      "total_flops_so_far": 210526350096384.0,
      "budget_used_percent": 0.21052635009638399
    },
    {
      "type": "training",
      "description": "Training step 147",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:11",
      "total_flops_so_far": 211958502137856.0,
      "budget_used_percent": 0.21195850213785603
    },
    {
      "type": "training",
      "description": "Training step 148",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:11",
      "total_flops_so_far": 213390654179328.0,
      "budget_used_percent": 0.213390654179328
    },
    {
      "type": "training",
      "description": "Training step 149",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:11",
      "total_flops_so_far": 214822806220800.0,
      "budget_used_percent": 0.2148228062208
    },
    {
      "type": "training",
      "description": "Training step 150",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:11",
      "total_flops_so_far": 216254958262272.0,
      "budget_used_percent": 0.216254958262272
    },
    {
      "type": "training",
      "description": "Training step 151",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:11",
      "total_flops_so_far": 217687110303744.0,
      "budget_used_percent": 0.217687110303744
    },
    {
      "type": "training",
      "description": "Training step 152",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:11",
      "total_flops_so_far": 219119262345216.0,
      "budget_used_percent": 0.219119262345216
    },
    {
      "type": "training",
      "description": "Training step 153",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:11",
      "total_flops_so_far": 220551414386688.0,
      "budget_used_percent": 0.22055141438668802
    },
    {
      "type": "training",
      "description": "Training step 154",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:11",
      "total_flops_so_far": 221983566428160.0,
      "budget_used_percent": 0.22198356642816
    },
    {
      "type": "training",
      "description": "Training step 155",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:12",
      "total_flops_so_far": 223415718469632.0,
      "budget_used_percent": 0.22341571846963199
    },
    {
      "type": "training",
      "description": "Training step 156",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:12",
      "total_flops_so_far": 224847870511104.0,
      "budget_used_percent": 0.22484787051110397
    },
    {
      "type": "training",
      "description": "Training step 157",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:12",
      "total_flops_so_far": 226280022552576.0,
      "budget_used_percent": 0.226280022552576
    },
    {
      "type": "training",
      "description": "Training step 158",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:12",
      "total_flops_so_far": 227712174594048.0,
      "budget_used_percent": 0.227712174594048
    },
    {
      "type": "training",
      "description": "Training step 159",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:12",
      "total_flops_so_far": 229144326635520.0,
      "budget_used_percent": 0.22914432663551998
    },
    {
      "type": "training",
      "description": "Training step 160",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:12",
      "total_flops_so_far": 230576478676992.0,
      "budget_used_percent": 0.23057647867699202
    },
    {
      "type": "training",
      "description": "Training step 161",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:12",
      "total_flops_so_far": 232008630718464.0,
      "budget_used_percent": 0.232008630718464
    },
    {
      "type": "training",
      "description": "Training step 162",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:12",
      "total_flops_so_far": 233440782759936.0,
      "budget_used_percent": 0.233440782759936
    },
    {
      "type": "training",
      "description": "Training step 163",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:13",
      "total_flops_so_far": 234872934801408.0,
      "budget_used_percent": 0.23487293480140803
    },
    {
      "type": "training",
      "description": "Training step 164",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:13",
      "total_flops_so_far": 236305086842880.0,
      "budget_used_percent": 0.23630508684288
    },
    {
      "type": "training",
      "description": "Training step 165",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:13",
      "total_flops_so_far": 237737238884352.0,
      "budget_used_percent": 0.237737238884352
    },
    {
      "type": "training",
      "description": "Training step 166",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:13",
      "total_flops_so_far": 239169390925824.0,
      "budget_used_percent": 0.239169390925824
    },
    {
      "type": "training",
      "description": "Training step 167",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:13",
      "total_flops_so_far": 240601542967296.0,
      "budget_used_percent": 0.240601542967296
    },
    {
      "type": "training",
      "description": "Training step 168",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:13",
      "total_flops_so_far": 242033695008768.0,
      "budget_used_percent": 0.24203369500876798
    },
    {
      "type": "training",
      "description": "Training step 169",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:13",
      "total_flops_so_far": 243465847050240.0,
      "budget_used_percent": 0.24346584705024002
    },
    {
      "type": "training",
      "description": "Training step 170",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:13",
      "total_flops_so_far": 244897999091712.0,
      "budget_used_percent": 0.244897999091712
    },
    {
      "type": "training",
      "description": "Training step 171",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:13",
      "total_flops_so_far": 246330151133184.0,
      "budget_used_percent": 0.246330151133184
    },
    {
      "type": "training",
      "description": "Training step 172",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:14",
      "total_flops_so_far": 247762303174656.0,
      "budget_used_percent": 0.24776230317465597
    },
    {
      "type": "training",
      "description": "Training step 173",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:14",
      "total_flops_so_far": 249194455216128.0,
      "budget_used_percent": 0.249194455216128
    },
    {
      "type": "training",
      "description": "Training step 174",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:14",
      "total_flops_so_far": 250626607257600.0,
      "budget_used_percent": 0.2506266072576
    },
    {
      "type": "training",
      "description": "Training step 175",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:14",
      "total_flops_so_far": 252058759299072.0,
      "budget_used_percent": 0.25205875929907195
    },
    {
      "type": "training",
      "description": "Training step 176",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:14",
      "total_flops_so_far": 253490911340544.0,
      "budget_used_percent": 0.253490911340544
    },
    {
      "type": "training",
      "description": "Training step 177",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:14",
      "total_flops_so_far": 254923063382016.0,
      "budget_used_percent": 0.254923063382016
    },
    {
      "type": "training",
      "description": "Training step 178",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:14",
      "total_flops_so_far": 256355215423488.0,
      "budget_used_percent": 0.256355215423488
    },
    {
      "type": "training",
      "description": "Training step 179",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:14",
      "total_flops_so_far": 257787367464960.0,
      "budget_used_percent": 0.25778736746496
    },
    {
      "type": "training",
      "description": "Training step 180",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:15",
      "total_flops_so_far": 259219519506432.0,
      "budget_used_percent": 0.259219519506432
    },
    {
      "type": "training",
      "description": "Training step 181",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:15",
      "total_flops_so_far": 260651671547904.0,
      "budget_used_percent": 0.260651671547904
    },
    {
      "type": "training",
      "description": "Training step 182",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:15",
      "total_flops_so_far": 262083823589376.0,
      "budget_used_percent": 0.26208382358937604
    },
    {
      "type": "training",
      "description": "Training step 183",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:15",
      "total_flops_so_far": 263515975630848.0,
      "budget_used_percent": 0.263515975630848
    },
    {
      "type": "training",
      "description": "Training step 184",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:15",
      "total_flops_so_far": 264948127672320.0,
      "budget_used_percent": 0.26494812767232
    },
    {
      "type": "training",
      "description": "Training step 185",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:15",
      "total_flops_so_far": 266380279713792.0,
      "budget_used_percent": 0.266380279713792
    },
    {
      "type": "training",
      "description": "Training step 186",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:15",
      "total_flops_so_far": 267812431755264.0,
      "budget_used_percent": 0.267812431755264
    },
    {
      "type": "training",
      "description": "Training step 187",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:15",
      "total_flops_so_far": 269244583796736.0,
      "budget_used_percent": 0.269244583796736
    },
    {
      "type": "training",
      "description": "Training step 188",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:16",
      "total_flops_so_far": 270676735838208.0,
      "budget_used_percent": 0.270676735838208
    },
    {
      "type": "training",
      "description": "Training step 189",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:16",
      "total_flops_so_far": 272108887879680.0,
      "budget_used_percent": 0.27210888787968
    },
    {
      "type": "training",
      "description": "Training step 190",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:16",
      "total_flops_so_far": 273541039921152.0,
      "budget_used_percent": 0.273541039921152
    },
    {
      "type": "training",
      "description": "Training step 191",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:16",
      "total_flops_so_far": 274973191962624.0,
      "budget_used_percent": 0.274973191962624
    },
    {
      "type": "training",
      "description": "Training step 192",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:16",
      "total_flops_so_far": 276405344004096.0,
      "budget_used_percent": 0.276405344004096
    },
    {
      "type": "training",
      "description": "Training step 193",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:16",
      "total_flops_so_far": 277837496045568.0,
      "budget_used_percent": 0.277837496045568
    },
    {
      "type": "training",
      "description": "Training step 194",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:16",
      "total_flops_so_far": 279269648087040.0,
      "budget_used_percent": 0.27926964808703997
    },
    {
      "type": "training",
      "description": "Training step 195",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:16",
      "total_flops_so_far": 280701800128512.0,
      "budget_used_percent": 0.28070180012851204
    },
    {
      "type": "training",
      "description": "Training step 196",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:17",
      "total_flops_so_far": 282133952169984.0,
      "budget_used_percent": 0.282133952169984
    },
    {
      "type": "training",
      "description": "Training step 197",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:17",
      "total_flops_so_far": 283566104211456.0,
      "budget_used_percent": 0.283566104211456
    },
    {
      "type": "training",
      "description": "Training step 198",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:17",
      "total_flops_so_far": 284998256252928.0,
      "budget_used_percent": 0.284998256252928
    },
    {
      "type": "training",
      "description": "Training step 199",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:17",
      "total_flops_so_far": 286430408294400.0,
      "budget_used_percent": 0.2864304082944
    },
    {
      "type": "training",
      "description": "Training step 200",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:17",
      "total_flops_so_far": 287862560335872.0,
      "budget_used_percent": 0.287862560335872
    },
    {
      "type": "training",
      "description": "Training step 201",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:17",
      "total_flops_so_far": 289294712377344.0,
      "budget_used_percent": 0.289294712377344
    },
    {
      "type": "training",
      "description": "Training step 202",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:17",
      "total_flops_so_far": 290726864418816.0,
      "budget_used_percent": 0.290726864418816
    },
    {
      "type": "training",
      "description": "Training step 203",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:18",
      "total_flops_so_far": 292159016460288.0,
      "budget_used_percent": 0.29215901646028797
    },
    {
      "type": "training",
      "description": "Training step 204",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:18",
      "total_flops_so_far": 293591168501760.0,
      "budget_used_percent": 0.29359116850176004
    },
    {
      "type": "training",
      "description": "Training step 205",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:18",
      "total_flops_so_far": 295023320543232.0,
      "budget_used_percent": 0.295023320543232
    },
    {
      "type": "training",
      "description": "Training step 206",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:18",
      "total_flops_so_far": 296455472584704.0,
      "budget_used_percent": 0.296455472584704
    },
    {
      "type": "training",
      "description": "Training step 207",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:18",
      "total_flops_so_far": 297887624626176.0,
      "budget_used_percent": 0.297887624626176
    },
    {
      "type": "training",
      "description": "Training step 208",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:18",
      "total_flops_so_far": 299319776667648.0,
      "budget_used_percent": 0.29931977666764803
    },
    {
      "type": "training",
      "description": "Training step 209",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:18",
      "total_flops_so_far": 300751928709120.0,
      "budget_used_percent": 0.30075192870912
    },
    {
      "type": "training",
      "description": "Training step 210",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:18",
      "total_flops_so_far": 302184080750592.0,
      "budget_used_percent": 0.302184080750592
    },
    {
      "type": "training",
      "description": "Training step 211",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:19",
      "total_flops_so_far": 303616232792064.0,
      "budget_used_percent": 0.303616232792064
    },
    {
      "type": "training",
      "description": "Training step 212",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:19",
      "total_flops_so_far": 305048384833536.0,
      "budget_used_percent": 0.305048384833536
    },
    {
      "type": "training",
      "description": "Training step 213",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:19",
      "total_flops_so_far": 306480536875008.0,
      "budget_used_percent": 0.306480536875008
    },
    {
      "type": "training",
      "description": "Training step 214",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:19",
      "total_flops_so_far": 307912688916480.0,
      "budget_used_percent": 0.30791268891648
    },
    {
      "type": "training",
      "description": "Training step 215",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:19",
      "total_flops_so_far": 309344840957952.0,
      "budget_used_percent": 0.309344840957952
    },
    {
      "type": "training",
      "description": "Training step 216",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:19",
      "total_flops_so_far": 310776992999424.0,
      "budget_used_percent": 0.31077699299942396
    },
    {
      "type": "training",
      "description": "Training step 217",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:19",
      "total_flops_so_far": 312209145040896.0,
      "budget_used_percent": 0.31220914504089603
    },
    {
      "type": "training",
      "description": "Training step 218",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:19",
      "total_flops_so_far": 313641297082368.0,
      "budget_used_percent": 0.313641297082368
    },
    {
      "type": "training",
      "description": "Training step 219",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:20",
      "total_flops_so_far": 315073449123840.0,
      "budget_used_percent": 0.31507344912384
    },
    {
      "type": "training",
      "description": "Training step 220",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:20",
      "total_flops_so_far": 316505601165312.0,
      "budget_used_percent": 0.316505601165312
    },
    {
      "type": "training",
      "description": "Training step 221",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:20",
      "total_flops_so_far": 317937753206784.0,
      "budget_used_percent": 0.317937753206784
    },
    {
      "type": "training",
      "description": "Training step 222",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:20",
      "total_flops_so_far": 319369905248256.0,
      "budget_used_percent": 0.319369905248256
    },
    {
      "type": "training",
      "description": "Training step 223",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:20",
      "total_flops_so_far": 320802057289728.0,
      "budget_used_percent": 0.320802057289728
    },
    {
      "type": "training",
      "description": "Training step 224",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:20",
      "total_flops_so_far": 322234209331200.0,
      "budget_used_percent": 0.3222342093312
    },
    {
      "type": "training",
      "description": "Training step 225",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:20",
      "total_flops_so_far": 323666361372672.0,
      "budget_used_percent": 0.323666361372672
    },
    {
      "type": "training",
      "description": "Training step 226",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:20",
      "total_flops_so_far": 325098513414144.0,
      "budget_used_percent": 0.32509851341414403
    },
    {
      "type": "training",
      "description": "Training step 227",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:20",
      "total_flops_so_far": 326530665455616.0,
      "budget_used_percent": 0.326530665455616
    },
    {
      "type": "training",
      "description": "Training step 228",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:21",
      "total_flops_so_far": 327962817497088.0,
      "budget_used_percent": 0.327962817497088
    },
    {
      "type": "training",
      "description": "Training step 229",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:21",
      "total_flops_so_far": 329394969538560.0,
      "budget_used_percent": 0.32939496953855996
    },
    {
      "type": "training",
      "description": "Training step 230",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:21",
      "total_flops_so_far": 330827121580032.0,
      "budget_used_percent": 0.330827121580032
    },
    {
      "type": "training",
      "description": "Training step 231",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:21",
      "total_flops_so_far": 332259273621504.0,
      "budget_used_percent": 0.332259273621504
    },
    {
      "type": "training",
      "description": "Training step 232",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:21",
      "total_flops_so_far": 333691425662976.0,
      "budget_used_percent": 0.333691425662976
    },
    {
      "type": "training",
      "description": "Training step 233",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:21",
      "total_flops_so_far": 335123577704448.0,
      "budget_used_percent": 0.335123577704448
    },
    {
      "type": "training",
      "description": "Training step 234",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:21",
      "total_flops_so_far": 336555729745920.0,
      "budget_used_percent": 0.33655572974592
    },
    {
      "type": "training",
      "description": "Training step 235",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:21",
      "total_flops_so_far": 337987881787392.0,
      "budget_used_percent": 0.337987881787392
    },
    {
      "type": "training",
      "description": "Training step 236",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:22",
      "total_flops_so_far": 339420033828864.0,
      "budget_used_percent": 0.339420033828864
    },
    {
      "type": "training",
      "description": "Training step 237",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:22",
      "total_flops_so_far": 340852185870336.0,
      "budget_used_percent": 0.340852185870336
    },
    {
      "type": "training",
      "description": "Training step 238",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:22",
      "total_flops_so_far": 342284337911808.0,
      "budget_used_percent": 0.342284337911808
    },
    {
      "type": "training",
      "description": "Training step 239",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:22",
      "total_flops_so_far": 343716489953280.0,
      "budget_used_percent": 0.34371648995328
    },
    {
      "type": "training",
      "description": "Training step 240",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:22",
      "total_flops_so_far": 345148641994752.0,
      "budget_used_percent": 0.345148641994752
    },
    {
      "type": "training",
      "description": "Training step 241",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:22",
      "total_flops_so_far": 346580794036224.0,
      "budget_used_percent": 0.346580794036224
    },
    {
      "type": "training",
      "description": "Training step 242",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:22",
      "total_flops_so_far": 348012946077696.0,
      "budget_used_percent": 0.348012946077696
    },
    {
      "type": "training",
      "description": "Training step 243",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:23",
      "total_flops_so_far": 349445098119168.0,
      "budget_used_percent": 0.349445098119168
    },
    {
      "type": "training",
      "description": "Training step 244",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:23",
      "total_flops_so_far": 350877250160640.0,
      "budget_used_percent": 0.35087725016064
    },
    {
      "type": "training",
      "description": "Training step 245",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:23",
      "total_flops_so_far": 352309402202112.0,
      "budget_used_percent": 0.352309402202112
    },
    {
      "type": "training",
      "description": "Training step 246",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:23",
      "total_flops_so_far": 353741554243584.0,
      "budget_used_percent": 0.353741554243584
    },
    {
      "type": "training",
      "description": "Training step 247",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:23",
      "total_flops_so_far": 355173706285056.0,
      "budget_used_percent": 0.355173706285056
    },
    {
      "type": "training",
      "description": "Training step 248",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:23",
      "total_flops_so_far": 356605858326528.0,
      "budget_used_percent": 0.35660585832652797
    },
    {
      "type": "training",
      "description": "Training step 249",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:23",
      "total_flops_so_far": 358038010368000.0,
      "budget_used_percent": 0.35803801036800004
    },
    {
      "type": "training",
      "description": "Training step 250",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:23",
      "total_flops_so_far": 359470162409472.0,
      "budget_used_percent": 0.359470162409472
    },
    {
      "type": "training",
      "description": "Training step 251",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:23",
      "total_flops_so_far": 360902314450944.0,
      "budget_used_percent": 0.360902314450944
    },
    {
      "type": "training",
      "description": "Training step 252",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:24",
      "total_flops_so_far": 362334466492416.0,
      "budget_used_percent": 0.362334466492416
    },
    {
      "type": "training",
      "description": "Training step 253",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:24",
      "total_flops_so_far": 363766618533888.0,
      "budget_used_percent": 0.363766618533888
    },
    {
      "type": "training",
      "description": "Training step 254",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:24",
      "total_flops_so_far": 365198770575360.0,
      "budget_used_percent": 0.36519877057536
    },
    {
      "type": "training",
      "description": "Training step 255",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:24",
      "total_flops_so_far": 366630922616832.0,
      "budget_used_percent": 0.366630922616832
    },
    {
      "type": "training",
      "description": "Training step 256",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:24",
      "total_flops_so_far": 368063074658304.0,
      "budget_used_percent": 0.368063074658304
    },
    {
      "type": "training",
      "description": "Training step 257",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:24",
      "total_flops_so_far": 369495226699776.0,
      "budget_used_percent": 0.36949522669977597
    },
    {
      "type": "training",
      "description": "Training step 258",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:24",
      "total_flops_so_far": 370927378741248.0,
      "budget_used_percent": 0.37092737874124804
    },
    {
      "type": "training",
      "description": "Training step 259",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:25",
      "total_flops_so_far": 372359530782720.0,
      "budget_used_percent": 0.37235953078272
    },
    {
      "type": "training",
      "description": "Training step 260",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:25",
      "total_flops_so_far": 373791682824192.0,
      "budget_used_percent": 0.373791682824192
    },
    {
      "type": "training",
      "description": "Training step 261",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:25",
      "total_flops_so_far": 375223834865664.0,
      "budget_used_percent": 0.375223834865664
    },
    {
      "type": "training",
      "description": "Training step 262",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:25",
      "total_flops_so_far": 376655986907136.0,
      "budget_used_percent": 0.37665598690713603
    },
    {
      "type": "training",
      "description": "Training step 263",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:25",
      "total_flops_so_far": 378088138948608.0,
      "budget_used_percent": 0.378088138948608
    },
    {
      "type": "training",
      "description": "Training step 264",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:25",
      "total_flops_so_far": 379520290990080.0,
      "budget_used_percent": 0.37952029099008
    },
    {
      "type": "training",
      "description": "Training step 265",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:25",
      "total_flops_so_far": 380952443031552.0,
      "budget_used_percent": 0.380952443031552
    },
    {
      "type": "training",
      "description": "Training step 266",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:25",
      "total_flops_so_far": 382384595073024.0,
      "budget_used_percent": 0.38238459507302397
    },
    {
      "type": "training",
      "description": "Training step 267",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:25",
      "total_flops_so_far": 383816747114496.0,
      "budget_used_percent": 0.383816747114496
    },
    {
      "type": "training",
      "description": "Training step 268",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:26",
      "total_flops_so_far": 385248899155968.0,
      "budget_used_percent": 0.385248899155968
    },
    {
      "type": "training",
      "description": "Training step 269",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:26",
      "total_flops_so_far": 386681051197440.0,
      "budget_used_percent": 0.38668105119744
    },
    {
      "type": "training",
      "description": "Training step 270",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:26",
      "total_flops_so_far": 388113203238912.0,
      "budget_used_percent": 0.38811320323891196
    },
    {
      "type": "training",
      "description": "Training step 271",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:26",
      "total_flops_so_far": 389545355280384.0,
      "budget_used_percent": 0.38954535528038403
    },
    {
      "type": "training",
      "description": "Training step 272",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:26",
      "total_flops_so_far": 390977507321856.0,
      "budget_used_percent": 0.39097750732185593
    },
    {
      "type": "training",
      "description": "Training step 273",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:26",
      "total_flops_so_far": 392409659363328.0,
      "budget_used_percent": 0.392409659363328
    },
    {
      "type": "training",
      "description": "Training step 274",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:26",
      "total_flops_so_far": 393841811404800.0,
      "budget_used_percent": 0.3938418114048
    },
    {
      "type": "training",
      "description": "Training step 275",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:26",
      "total_flops_so_far": 395273963446272.0,
      "budget_used_percent": 0.39527396344627197
    },
    {
      "type": "training",
      "description": "Training step 276",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:27",
      "total_flops_so_far": 396706115487744.0,
      "budget_used_percent": 0.396706115487744
    },
    {
      "type": "training",
      "description": "Training step 277",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:27",
      "total_flops_so_far": 398138267529216.0,
      "budget_used_percent": 0.398138267529216
    },
    {
      "type": "training",
      "description": "Training step 278",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:27",
      "total_flops_so_far": 399570419570688.0,
      "budget_used_percent": 0.39957041957068795
    },
    {
      "type": "training",
      "description": "Training step 279",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:27",
      "total_flops_so_far": 401002571612160.0,
      "budget_used_percent": 0.40100257161216
    },
    {
      "type": "training",
      "description": "Training step 280",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:27",
      "total_flops_so_far": 402434723653632.0,
      "budget_used_percent": 0.40243472365363203
    },
    {
      "type": "training",
      "description": "Training step 281",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:27",
      "total_flops_so_far": 403866875695104.0,
      "budget_used_percent": 0.403866875695104
    },
    {
      "type": "training",
      "description": "Training step 282",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:27",
      "total_flops_so_far": 405299027736576.0,
      "budget_used_percent": 0.405299027736576
    },
    {
      "type": "training",
      "description": "Training step 283",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:28",
      "total_flops_so_far": 406731179778048.0,
      "budget_used_percent": 0.406731179778048
    },
    {
      "type": "training",
      "description": "Training step 284",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:28",
      "total_flops_so_far": 408163331819520.0,
      "budget_used_percent": 0.40816333181951997
    },
    {
      "type": "training",
      "description": "Training step 285",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:28",
      "total_flops_so_far": 409595483860992.0,
      "budget_used_percent": 0.409595483860992
    },
    {
      "type": "training",
      "description": "Training step 286",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:28",
      "total_flops_so_far": 411027635902464.0,
      "budget_used_percent": 0.41102763590246405
    },
    {
      "type": "training",
      "description": "Training step 287",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:28",
      "total_flops_so_far": 412459787943936.0,
      "budget_used_percent": 0.41245978794393595
    },
    {
      "type": "training",
      "description": "Training step 288",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:28",
      "total_flops_so_far": 413891939985408.0,
      "budget_used_percent": 0.413891939985408
    },
    {
      "type": "training",
      "description": "Training step 289",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:28",
      "total_flops_so_far": 415324092026880.0,
      "budget_used_percent": 0.41532409202688003
    },
    {
      "type": "training",
      "description": "Training step 290",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:28",
      "total_flops_so_far": 416756244068352.0,
      "budget_used_percent": 0.416756244068352
    },
    {
      "type": "training",
      "description": "Training step 291",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:29",
      "total_flops_so_far": 418188396109824.0,
      "budget_used_percent": 0.418188396109824
    },
    {
      "type": "training",
      "description": "Training step 292",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:29",
      "total_flops_so_far": 419620548151296.0,
      "budget_used_percent": 0.419620548151296
    },
    {
      "type": "training",
      "description": "Training step 293",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:29",
      "total_flops_so_far": 421052700192768.0,
      "budget_used_percent": 0.42105270019276797
    },
    {
      "type": "training",
      "description": "Training step 294",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:29",
      "total_flops_so_far": 422484852234240.0,
      "budget_used_percent": 0.42248485223424
    },
    {
      "type": "training",
      "description": "Training step 295",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:29",
      "total_flops_so_far": 423917004275712.0,
      "budget_used_percent": 0.42391700427571205
    },
    {
      "type": "training",
      "description": "Training step 296",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:29",
      "total_flops_so_far": 425349156317184.0,
      "budget_used_percent": 0.42534915631718395
    },
    {
      "type": "training",
      "description": "Training step 297",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:29",
      "total_flops_so_far": 426781308358656.0,
      "budget_used_percent": 0.426781308358656
    },
    {
      "type": "training",
      "description": "Training step 298",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:29",
      "total_flops_so_far": 428213460400128.0,
      "budget_used_percent": 0.42821346040012803
    },
    {
      "type": "training",
      "description": "Training step 299",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:30",
      "total_flops_so_far": 429645612441600.0,
      "budget_used_percent": 0.4296456124416
    },
    {
      "type": "training",
      "description": "Training step 300",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:30",
      "total_flops_so_far": 431077764483072.0,
      "budget_used_percent": 0.431077764483072
    },
    {
      "type": "training",
      "description": "Training step 301",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:30",
      "total_flops_so_far": 432509916524544.0,
      "budget_used_percent": 0.432509916524544
    },
    {
      "type": "training",
      "description": "Training step 302",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:30",
      "total_flops_so_far": 433942068566016.0,
      "budget_used_percent": 0.43394206856601597
    },
    {
      "type": "training",
      "description": "Training step 303",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:30",
      "total_flops_so_far": 435374220607488.0,
      "budget_used_percent": 0.435374220607488
    },
    {
      "type": "training",
      "description": "Training step 304",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:30",
      "total_flops_so_far": 436806372648960.0,
      "budget_used_percent": 0.43680637264896005
    },
    {
      "type": "training",
      "description": "Training step 305",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:30",
      "total_flops_so_far": 438238524690432.0,
      "budget_used_percent": 0.438238524690432
    },
    {
      "type": "training",
      "description": "Training step 306",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:30",
      "total_flops_so_far": 439670676731904.0,
      "budget_used_percent": 0.439670676731904
    },
    {
      "type": "training",
      "description": "Training step 307",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:31",
      "total_flops_so_far": 441102828773376.0,
      "budget_used_percent": 0.44110282877337603
    },
    {
      "type": "training",
      "description": "Training step 308",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:31",
      "total_flops_so_far": 442534980814848.0,
      "budget_used_percent": 0.442534980814848
    },
    {
      "type": "training",
      "description": "Training step 309",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:31",
      "total_flops_so_far": 443967132856320.0,
      "budget_used_percent": 0.44396713285632
    },
    {
      "type": "training",
      "description": "Training step 310",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:31",
      "total_flops_so_far": 445399284897792.0,
      "budget_used_percent": 0.44539928489779196
    },
    {
      "type": "training",
      "description": "Training step 311",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:31",
      "total_flops_so_far": 446831436939264.0,
      "budget_used_percent": 0.44683143693926397
    },
    {
      "type": "training",
      "description": "Training step 312",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:31",
      "total_flops_so_far": 448263588980736.0,
      "budget_used_percent": 0.44826358898073604
    },
    {
      "type": "training",
      "description": "Training step 313",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:31",
      "total_flops_so_far": 449695741022208.0,
      "budget_used_percent": 0.44969574102220794
    },
    {
      "type": "training",
      "description": "Training step 314",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:31",
      "total_flops_so_far": 451127893063680.0,
      "budget_used_percent": 0.45112789306368
    },
    {
      "type": "training",
      "description": "Training step 315",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:32",
      "total_flops_so_far": 452560045105152.0,
      "budget_used_percent": 0.452560045105152
    },
    {
      "type": "training",
      "description": "Training step 316",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:32",
      "total_flops_so_far": 453992197146624.0,
      "budget_used_percent": 0.453992197146624
    },
    {
      "type": "training",
      "description": "Training step 317",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:32",
      "total_flops_so_far": 455424349188096.0,
      "budget_used_percent": 0.455424349188096
    },
    {
      "type": "training",
      "description": "Training step 318",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:32",
      "total_flops_so_far": 456856501229568.0,
      "budget_used_percent": 0.456856501229568
    },
    {
      "type": "training",
      "description": "Training step 319",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:32",
      "total_flops_so_far": 458288653271040.0,
      "budget_used_percent": 0.45828865327103996
    },
    {
      "type": "training",
      "description": "Training step 320",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:32",
      "total_flops_so_far": 459720805312512.0,
      "budget_used_percent": 0.45972080531251197
    },
    {
      "type": "training",
      "description": "Training step 321",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:32",
      "total_flops_so_far": 461152957353984.0,
      "budget_used_percent": 0.46115295735398404
    },
    {
      "type": "training",
      "description": "Training step 322",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:32",
      "total_flops_so_far": 462585109395456.0,
      "budget_used_percent": 0.46258510939545594
    },
    {
      "type": "training",
      "description": "Training step 323",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:33",
      "total_flops_so_far": 464017261436928.0,
      "budget_used_percent": 0.464017261436928
    },
    {
      "type": "training",
      "description": "Training step 324",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:33",
      "total_flops_so_far": 465449413478400.0,
      "budget_used_percent": 0.4654494134784
    },
    {
      "type": "training",
      "description": "Training step 325",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:33",
      "total_flops_so_far": 466881565519872.0,
      "budget_used_percent": 0.466881565519872
    },
    {
      "type": "training",
      "description": "Training step 326",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:33",
      "total_flops_so_far": 468313717561344.0,
      "budget_used_percent": 0.468313717561344
    },
    {
      "type": "training",
      "description": "Training step 327",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:33",
      "total_flops_so_far": 469745869602816.0,
      "budget_used_percent": 0.46974586960281606
    },
    {
      "type": "training",
      "description": "Training step 328",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:33",
      "total_flops_so_far": 471178021644288.0,
      "budget_used_percent": 0.47117802164428796
    },
    {
      "type": "training",
      "description": "Training step 329",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:33",
      "total_flops_so_far": 472610173685760.0,
      "budget_used_percent": 0.47261017368576
    },
    {
      "type": "training",
      "description": "Training step 330",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:33",
      "total_flops_so_far": 474042325727232.0,
      "budget_used_percent": 0.47404232572723204
    },
    {
      "type": "training",
      "description": "Training step 331",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:34",
      "total_flops_so_far": 475474477768704.0,
      "budget_used_percent": 0.475474477768704
    },
    {
      "type": "training",
      "description": "Training step 332",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:34",
      "total_flops_so_far": 476906629810176.0,
      "budget_used_percent": 0.476906629810176
    },
    {
      "type": "training",
      "description": "Training step 333",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:34",
      "total_flops_so_far": 478338781851648.0,
      "budget_used_percent": 0.478338781851648
    },
    {
      "type": "training",
      "description": "Training step 334",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:34",
      "total_flops_so_far": 479770933893120.0,
      "budget_used_percent": 0.47977093389312
    },
    {
      "type": "training",
      "description": "Training step 335",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:34",
      "total_flops_so_far": 481203085934592.0,
      "budget_used_percent": 0.481203085934592
    },
    {
      "type": "training",
      "description": "Training step 336",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:34",
      "total_flops_so_far": 482635237976064.0,
      "budget_used_percent": 0.48263523797606406
    },
    {
      "type": "training",
      "description": "Training step 337",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:34",
      "total_flops_so_far": 484067390017536.0,
      "budget_used_percent": 0.48406739001753596
    },
    {
      "type": "training",
      "description": "Training step 338",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:34",
      "total_flops_so_far": 485499542059008.0,
      "budget_used_percent": 0.485499542059008
    },
    {
      "type": "training",
      "description": "Training step 339",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:35",
      "total_flops_so_far": 486931694100480.0,
      "budget_used_percent": 0.48693169410048004
    },
    {
      "type": "training",
      "description": "Training step 340",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:35",
      "total_flops_so_far": 488363846141952.0,
      "budget_used_percent": 0.488363846141952
    },
    {
      "type": "training",
      "description": "Training step 341",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:35",
      "total_flops_so_far": 489795998183424.0,
      "budget_used_percent": 0.489795998183424
    },
    {
      "type": "training",
      "description": "Training step 342",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:35",
      "total_flops_so_far": 491228150224896.0,
      "budget_used_percent": 0.491228150224896
    },
    {
      "type": "training",
      "description": "Training step 343",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:35",
      "total_flops_so_far": 492660302266368.0,
      "budget_used_percent": 0.492660302266368
    },
    {
      "type": "training",
      "description": "Training step 344",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:35",
      "total_flops_so_far": 494092454307840.0,
      "budget_used_percent": 0.49409245430784
    },
    {
      "type": "training",
      "description": "Training step 345",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:35",
      "total_flops_so_far": 495524606349312.0,
      "budget_used_percent": 0.49552460634931195
    },
    {
      "type": "training",
      "description": "Training step 346",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:35",
      "total_flops_so_far": 496956758390784.0,
      "budget_used_percent": 0.496956758390784
    },
    {
      "type": "training",
      "description": "Training step 347",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:36",
      "total_flops_so_far": 498388910432256.0,
      "budget_used_percent": 0.498388910432256
    },
    {
      "type": "training",
      "description": "Training step 348",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:36",
      "total_flops_so_far": 499821062473728.0,
      "budget_used_percent": 0.499821062473728
    },
    {
      "type": "training",
      "description": "Training step 349",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:36",
      "total_flops_so_far": 501253214515200.0,
      "budget_used_percent": 0.5012532145152
    },
    {
      "type": "training",
      "description": "Training step 350",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:36",
      "total_flops_so_far": 502685366556672.0,
      "budget_used_percent": 0.5026853665566721
    },
    {
      "type": "training",
      "description": "Training step 351",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:36",
      "total_flops_so_far": 504117518598144.0,
      "budget_used_percent": 0.5041175185981439
    },
    {
      "type": "training",
      "description": "Training step 352",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:36",
      "total_flops_so_far": 505549670639616.0,
      "budget_used_percent": 0.505549670639616
    },
    {
      "type": "training",
      "description": "Training step 353",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:36",
      "total_flops_so_far": 506981822681088.0,
      "budget_used_percent": 0.506981822681088
    },
    {
      "type": "training",
      "description": "Training step 354",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:37",
      "total_flops_so_far": 508413974722560.0,
      "budget_used_percent": 0.50841397472256
    },
    {
      "type": "training",
      "description": "Training step 355",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:37",
      "total_flops_so_far": 509846126764032.0,
      "budget_used_percent": 0.509846126764032
    },
    {
      "type": "training",
      "description": "Training step 356",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:37",
      "total_flops_so_far": 511278278805504.0,
      "budget_used_percent": 0.511278278805504
    },
    {
      "type": "training",
      "description": "Training step 357",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:37",
      "total_flops_so_far": 512710430846976.0,
      "budget_used_percent": 0.512710430846976
    },
    {
      "type": "training",
      "description": "Training step 358",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:37",
      "total_flops_so_far": 514142582888448.0,
      "budget_used_percent": 0.514142582888448
    },
    {
      "type": "training",
      "description": "Training step 359",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:37",
      "total_flops_so_far": 515574734929920.0,
      "budget_used_percent": 0.51557473492992
    },
    {
      "type": "training",
      "description": "Training step 360",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:37",
      "total_flops_so_far": 517006886971392.0,
      "budget_used_percent": 0.517006886971392
    },
    {
      "type": "training",
      "description": "Training step 361",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:37",
      "total_flops_so_far": 518439039012864.0,
      "budget_used_percent": 0.518439039012864
    },
    {
      "type": "training",
      "description": "Training step 362",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:38",
      "total_flops_so_far": 519871191054336.0,
      "budget_used_percent": 0.519871191054336
    },
    {
      "type": "training",
      "description": "Training step 363",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:38",
      "total_flops_so_far": 521303343095808.0,
      "budget_used_percent": 0.521303343095808
    },
    {
      "type": "training",
      "description": "Training step 364",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:38",
      "total_flops_so_far": 522735495137280.0,
      "budget_used_percent": 0.52273549513728
    },
    {
      "type": "training",
      "description": "Training step 365",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:38",
      "total_flops_so_far": 524167647178752.0,
      "budget_used_percent": 0.5241676471787521
    },
    {
      "type": "training",
      "description": "Training step 366",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:38",
      "total_flops_so_far": 525599799220224.0,
      "budget_used_percent": 0.5255997992202239
    },
    {
      "type": "training",
      "description": "Training step 367",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:38",
      "total_flops_so_far": 527031951261696.0,
      "budget_used_percent": 0.527031951261696
    },
    {
      "type": "training",
      "description": "Training step 368",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:38",
      "total_flops_so_far": 528464103303168.0,
      "budget_used_percent": 0.5284641033031681
    },
    {
      "type": "training",
      "description": "Training step 369",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:38",
      "total_flops_so_far": 529896255344640.0,
      "budget_used_percent": 0.52989625534464
    },
    {
      "type": "training",
      "description": "Training step 370",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:39",
      "total_flops_so_far": 531328407386112.0,
      "budget_used_percent": 0.531328407386112
    },
    {
      "type": "training",
      "description": "Training step 371",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:39",
      "total_flops_so_far": 532760559427584.0,
      "budget_used_percent": 0.532760559427584
    },
    {
      "type": "training",
      "description": "Training step 372",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:39",
      "total_flops_so_far": 534192711469056.0,
      "budget_used_percent": 0.534192711469056
    },
    {
      "type": "training",
      "description": "Training step 373",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:39",
      "total_flops_so_far": 535624863510528.0,
      "budget_used_percent": 0.535624863510528
    },
    {
      "type": "training",
      "description": "Training step 374",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:39",
      "total_flops_so_far": 537057015552000.0,
      "budget_used_percent": 0.537057015552
    },
    {
      "type": "training",
      "description": "Training step 375",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:39",
      "total_flops_so_far": 538489167593472.0,
      "budget_used_percent": 0.538489167593472
    },
    {
      "type": "training",
      "description": "Training step 376",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:39",
      "total_flops_so_far": 539921319634944.0,
      "budget_used_percent": 0.539921319634944
    },
    {
      "type": "training",
      "description": "Training step 377",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:39",
      "total_flops_so_far": 541353471676416.0,
      "budget_used_percent": 0.541353471676416
    },
    {
      "type": "training",
      "description": "Training step 378",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:40",
      "total_flops_so_far": 542785623717888.0,
      "budget_used_percent": 0.542785623717888
    },
    {
      "type": "training",
      "description": "Training step 379",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:40",
      "total_flops_so_far": 544217775759360.0,
      "budget_used_percent": 0.54421777575936
    },
    {
      "type": "training",
      "description": "Training step 380",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:40",
      "total_flops_so_far": 545649927800832.0,
      "budget_used_percent": 0.545649927800832
    },
    {
      "type": "training",
      "description": "Training step 381",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:40",
      "total_flops_so_far": 547082079842304.0,
      "budget_used_percent": 0.547082079842304
    },
    {
      "type": "training",
      "description": "Training step 382",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:40",
      "total_flops_so_far": 548514231883776.0,
      "budget_used_percent": 0.548514231883776
    },
    {
      "type": "training",
      "description": "Training step 383",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:40",
      "total_flops_so_far": 549946383925248.0,
      "budget_used_percent": 0.549946383925248
    },
    {
      "type": "training",
      "description": "Training step 384",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:40",
      "total_flops_so_far": 551378535966720.0,
      "budget_used_percent": 0.55137853596672
    },
    {
      "type": "training",
      "description": "Training step 385",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:41",
      "total_flops_so_far": 552810688008192.0,
      "budget_used_percent": 0.552810688008192
    },
    {
      "type": "training",
      "description": "Training step 386",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:41",
      "total_flops_so_far": 554242840049664.0,
      "budget_used_percent": 0.554242840049664
    },
    {
      "type": "training",
      "description": "Training step 387",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:41",
      "total_flops_so_far": 555674992091136.0,
      "budget_used_percent": 0.555674992091136
    },
    {
      "type": "training",
      "description": "Training step 388",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:41",
      "total_flops_so_far": 557107144132608.0,
      "budget_used_percent": 0.557107144132608
    },
    {
      "type": "training",
      "description": "Training step 389",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:41",
      "total_flops_so_far": 558539296174080.0,
      "budget_used_percent": 0.5585392961740799
    },
    {
      "type": "training",
      "description": "Training step 390",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:41",
      "total_flops_so_far": 559971448215552.0,
      "budget_used_percent": 0.559971448215552
    },
    {
      "type": "training",
      "description": "Training step 391",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:41",
      "total_flops_so_far": 561403600257024.0,
      "budget_used_percent": 0.5614036002570241
    },
    {
      "type": "training",
      "description": "Training step 392",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:41",
      "total_flops_so_far": 562835752298496.0,
      "budget_used_percent": 0.5628357522984959
    },
    {
      "type": "training",
      "description": "Training step 393",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:42",
      "total_flops_so_far": 564267904339968.0,
      "budget_used_percent": 0.564267904339968
    },
    {
      "type": "training",
      "description": "Training step 394",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:42",
      "total_flops_so_far": 565700056381440.0,
      "budget_used_percent": 0.56570005638144
    },
    {
      "type": "training",
      "description": "Training step 395",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:42",
      "total_flops_so_far": 567132208422912.0,
      "budget_used_percent": 0.567132208422912
    },
    {
      "type": "training",
      "description": "Training step 396",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:42",
      "total_flops_so_far": 568564360464384.0,
      "budget_used_percent": 0.568564360464384
    },
    {
      "type": "training",
      "description": "Training step 397",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:42",
      "total_flops_so_far": 569996512505856.0,
      "budget_used_percent": 0.569996512505856
    },
    {
      "type": "training",
      "description": "Training step 398",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:42",
      "total_flops_so_far": 571428664547328.0,
      "budget_used_percent": 0.571428664547328
    },
    {
      "type": "training",
      "description": "Training step 399",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:42",
      "total_flops_so_far": 572860816588800.0,
      "budget_used_percent": 0.5728608165888
    },
    {
      "type": "training",
      "description": "Training step 400",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:42",
      "total_flops_so_far": 574292968630272.0,
      "budget_used_percent": 0.574292968630272
    },
    {
      "type": "training",
      "description": "Training step 401",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:43",
      "total_flops_so_far": 575725120671744.0,
      "budget_used_percent": 0.575725120671744
    },
    {
      "type": "training",
      "description": "Training step 402",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:43",
      "total_flops_so_far": 577157272713216.0,
      "budget_used_percent": 0.577157272713216
    },
    {
      "type": "training",
      "description": "Training step 403",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:43",
      "total_flops_so_far": 578589424754688.0,
      "budget_used_percent": 0.578589424754688
    },
    {
      "type": "training",
      "description": "Training step 404",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:43",
      "total_flops_so_far": 580021576796160.0,
      "budget_used_percent": 0.58002157679616
    },
    {
      "type": "training",
      "description": "Training step 405",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:43",
      "total_flops_so_far": 581453728837632.0,
      "budget_used_percent": 0.581453728837632
    },
    {
      "type": "training",
      "description": "Training step 406",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:43",
      "total_flops_so_far": 582885880879104.0,
      "budget_used_percent": 0.582885880879104
    },
    {
      "type": "training",
      "description": "Training step 407",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:43",
      "total_flops_so_far": 584318032920576.0,
      "budget_used_percent": 0.5843180329205759
    },
    {
      "type": "training",
      "description": "Training step 408",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:43",
      "total_flops_so_far": 585750184962048.0,
      "budget_used_percent": 0.585750184962048
    },
    {
      "type": "training",
      "description": "Training step 409",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:44",
      "total_flops_so_far": 587182337003520.0,
      "budget_used_percent": 0.5871823370035201
    },
    {
      "type": "training",
      "description": "Training step 410",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:44",
      "total_flops_so_far": 588614489044992.0,
      "budget_used_percent": 0.588614489044992
    },
    {
      "type": "training",
      "description": "Training step 411",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:44",
      "total_flops_so_far": 590046641086464.0,
      "budget_used_percent": 0.590046641086464
    },
    {
      "type": "training",
      "description": "Training step 412",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:44",
      "total_flops_so_far": 591478793127936.0,
      "budget_used_percent": 0.591478793127936
    },
    {
      "type": "training",
      "description": "Training step 413",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:44",
      "total_flops_so_far": 592910945169408.0,
      "budget_used_percent": 0.592910945169408
    },
    {
      "type": "training",
      "description": "Training step 414",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:44",
      "total_flops_so_far": 594343097210880.0,
      "budget_used_percent": 0.59434309721088
    },
    {
      "type": "training",
      "description": "Training step 415",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:44",
      "total_flops_so_far": 595775249252352.0,
      "budget_used_percent": 0.595775249252352
    },
    {
      "type": "training",
      "description": "Training step 416",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:44",
      "total_flops_so_far": 597207401293824.0,
      "budget_used_percent": 0.597207401293824
    },
    {
      "type": "training",
      "description": "Training step 417",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:45",
      "total_flops_so_far": 598639553335296.0,
      "budget_used_percent": 0.5986395533352961
    },
    {
      "type": "training",
      "description": "Training step 418",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:45",
      "total_flops_so_far": 600071705376768.0,
      "budget_used_percent": 0.6000717053767679
    },
    {
      "type": "training",
      "description": "Training step 419",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:45",
      "total_flops_so_far": 601503857418240.0,
      "budget_used_percent": 0.60150385741824
    },
    {
      "type": "training",
      "description": "Training step 420",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:45",
      "total_flops_so_far": 602936009459712.0,
      "budget_used_percent": 0.602936009459712
    },
    {
      "type": "training",
      "description": "Training step 421",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:45",
      "total_flops_so_far": 604368161501184.0,
      "budget_used_percent": 0.604368161501184
    },
    {
      "type": "training",
      "description": "Training step 422",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:45",
      "total_flops_so_far": 605800313542656.0,
      "budget_used_percent": 0.605800313542656
    },
    {
      "type": "training",
      "description": "Training step 423",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:45",
      "total_flops_so_far": 607232465584128.0,
      "budget_used_percent": 0.607232465584128
    },
    {
      "type": "training",
      "description": "Training step 424",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:46",
      "total_flops_so_far": 608664617625600.0,
      "budget_used_percent": 0.6086646176256
    },
    {
      "type": "training",
      "description": "Training step 425",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:46",
      "total_flops_so_far": 610096769667072.0,
      "budget_used_percent": 0.610096769667072
    },
    {
      "type": "training",
      "description": "Training step 426",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:46",
      "total_flops_so_far": 611528921708544.0,
      "budget_used_percent": 0.611528921708544
    },
    {
      "type": "training",
      "description": "Training step 427",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:46",
      "total_flops_so_far": 612961073750016.0,
      "budget_used_percent": 0.612961073750016
    },
    {
      "type": "training",
      "description": "Training step 428",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:46",
      "total_flops_so_far": 614393225791488.0,
      "budget_used_percent": 0.614393225791488
    },
    {
      "type": "training",
      "description": "Training step 429",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:46",
      "total_flops_so_far": 615825377832960.0,
      "budget_used_percent": 0.61582537783296
    },
    {
      "type": "training",
      "description": "Training step 430",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:46",
      "total_flops_so_far": 617257529874432.0,
      "budget_used_percent": 0.6172575298744319
    },
    {
      "type": "training",
      "description": "Training step 431",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:46",
      "total_flops_so_far": 618689681915904.0,
      "budget_used_percent": 0.618689681915904
    },
    {
      "type": "training",
      "description": "Training step 432",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:47",
      "total_flops_so_far": 620121833957376.0,
      "budget_used_percent": 0.6201218339573761
    },
    {
      "type": "training",
      "description": "Training step 433",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:47",
      "total_flops_so_far": 621553985998848.0,
      "budget_used_percent": 0.6215539859988479
    },
    {
      "type": "training",
      "description": "Training step 434",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:47",
      "total_flops_so_far": 622986138040320.0,
      "budget_used_percent": 0.62298613804032
    },
    {
      "type": "training",
      "description": "Training step 435",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:47",
      "total_flops_so_far": 624418290081792.0,
      "budget_used_percent": 0.6244182900817921
    },
    {
      "type": "training",
      "description": "Training step 436",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:47",
      "total_flops_so_far": 625850442123264.0,
      "budget_used_percent": 0.625850442123264
    },
    {
      "type": "training",
      "description": "Training step 437",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:47",
      "total_flops_so_far": 627282594164736.0,
      "budget_used_percent": 0.627282594164736
    },
    {
      "type": "training",
      "description": "Training step 438",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:47",
      "total_flops_so_far": 628714746206208.0,
      "budget_used_percent": 0.628714746206208
    },
    {
      "type": "training",
      "description": "Training step 439",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:47",
      "total_flops_so_far": 630146898247680.0,
      "budget_used_percent": 0.63014689824768
    },
    {
      "type": "training",
      "description": "Training step 440",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:48",
      "total_flops_so_far": 631579050289152.0,
      "budget_used_percent": 0.631579050289152
    },
    {
      "type": "training",
      "description": "Training step 441",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:48",
      "total_flops_so_far": 633011202330624.0,
      "budget_used_percent": 0.633011202330624
    },
    {
      "type": "training",
      "description": "Training step 442",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:48",
      "total_flops_so_far": 634443354372096.0,
      "budget_used_percent": 0.634443354372096
    },
    {
      "type": "training",
      "description": "Training step 443",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:48",
      "total_flops_so_far": 635875506413568.0,
      "budget_used_percent": 0.635875506413568
    },
    {
      "type": "training",
      "description": "Training step 444",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:48",
      "total_flops_so_far": 637307658455040.0,
      "budget_used_percent": 0.63730765845504
    },
    {
      "type": "training",
      "description": "Training step 445",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:48",
      "total_flops_so_far": 638739810496512.0,
      "budget_used_percent": 0.638739810496512
    },
    {
      "type": "training",
      "description": "Training step 446",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:48",
      "total_flops_so_far": 640171962537984.0,
      "budget_used_percent": 0.640171962537984
    },
    {
      "type": "training",
      "description": "Training step 447",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:48",
      "total_flops_so_far": 641604114579456.0,
      "budget_used_percent": 0.641604114579456
    },
    {
      "type": "training",
      "description": "Training step 448",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:49",
      "total_flops_so_far": 643036266620928.0,
      "budget_used_percent": 0.6430362666209279
    },
    {
      "type": "training",
      "description": "Training step 449",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:49",
      "total_flops_so_far": 644468418662400.0,
      "budget_used_percent": 0.6444684186624
    },
    {
      "type": "training",
      "description": "Training step 450",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:49",
      "total_flops_so_far": 645900570703872.0,
      "budget_used_percent": 0.6459005707038721
    },
    {
      "type": "training",
      "description": "Training step 451",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:49",
      "total_flops_so_far": 647332722745344.0,
      "budget_used_percent": 0.647332722745344
    },
    {
      "type": "training",
      "description": "Training step 452",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:49",
      "total_flops_so_far": 648764874786816.0,
      "budget_used_percent": 0.648764874786816
    },
    {
      "type": "training",
      "description": "Training step 453",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:49",
      "total_flops_so_far": 650197026828288.0,
      "budget_used_percent": 0.6501970268282881
    },
    {
      "type": "training",
      "description": "Training step 454",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:49",
      "total_flops_so_far": 651629178869760.0,
      "budget_used_percent": 0.65162917886976
    },
    {
      "type": "training",
      "description": "Training step 455",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:50",
      "total_flops_so_far": 653061330911232.0,
      "budget_used_percent": 0.653061330911232
    },
    {
      "type": "training",
      "description": "Training step 456",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:50",
      "total_flops_so_far": 654493482952704.0,
      "budget_used_percent": 0.6544934829527039
    },
    {
      "type": "training",
      "description": "Training step 457",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:50",
      "total_flops_so_far": 655925634994176.0,
      "budget_used_percent": 0.655925634994176
    },
    {
      "type": "training",
      "description": "Training step 458",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:50",
      "total_flops_so_far": 657357787035648.0,
      "budget_used_percent": 0.6573577870356481
    },
    {
      "type": "training",
      "description": "Training step 459",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:50",
      "total_flops_so_far": 658789939077120.0,
      "budget_used_percent": 0.6587899390771199
    },
    {
      "type": "training",
      "description": "Training step 460",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:50",
      "total_flops_so_far": 660222091118592.0,
      "budget_used_percent": 0.660222091118592
    },
    {
      "type": "training",
      "description": "Training step 461",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:50",
      "total_flops_so_far": 661654243160064.0,
      "budget_used_percent": 0.661654243160064
    },
    {
      "type": "training",
      "description": "Training step 462",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:50",
      "total_flops_so_far": 663086395201536.0,
      "budget_used_percent": 0.663086395201536
    },
    {
      "type": "training",
      "description": "Training step 463",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:51",
      "total_flops_so_far": 664518547243008.0,
      "budget_used_percent": 0.664518547243008
    },
    {
      "type": "training",
      "description": "Training step 464",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:51",
      "total_flops_so_far": 665950699284480.0,
      "budget_used_percent": 0.66595069928448
    },
    {
      "type": "training",
      "description": "Training step 465",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:51",
      "total_flops_so_far": 667382851325952.0,
      "budget_used_percent": 0.667382851325952
    },
    {
      "type": "training",
      "description": "Training step 466",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:51",
      "total_flops_so_far": 668815003367424.0,
      "budget_used_percent": 0.6688150033674239
    },
    {
      "type": "training",
      "description": "Training step 467",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:51",
      "total_flops_so_far": 670247155408896.0,
      "budget_used_percent": 0.670247155408896
    },
    {
      "type": "training",
      "description": "Training step 468",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:51",
      "total_flops_so_far": 671679307450368.0,
      "budget_used_percent": 0.671679307450368
    },
    {
      "type": "training",
      "description": "Training step 469",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:51",
      "total_flops_so_far": 673111459491840.0,
      "budget_used_percent": 0.67311145949184
    },
    {
      "type": "training",
      "description": "Training step 470",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:51",
      "total_flops_so_far": 674543611533312.0,
      "budget_used_percent": 0.674543611533312
    },
    {
      "type": "training",
      "description": "Training step 471",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:52",
      "total_flops_so_far": 675975763574784.0,
      "budget_used_percent": 0.675975763574784
    },
    {
      "type": "training",
      "description": "Training step 472",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:52",
      "total_flops_so_far": 677407915616256.0,
      "budget_used_percent": 0.677407915616256
    },
    {
      "type": "training",
      "description": "Training step 473",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:52",
      "total_flops_so_far": 678840067657728.0,
      "budget_used_percent": 0.678840067657728
    },
    {
      "type": "training",
      "description": "Training step 474",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:52",
      "total_flops_so_far": 680272219699200.0,
      "budget_used_percent": 0.6802722196991999
    },
    {
      "type": "training",
      "description": "Training step 475",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:52",
      "total_flops_so_far": 681704371740672.0,
      "budget_used_percent": 0.681704371740672
    },
    {
      "type": "training",
      "description": "Training step 476",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:52",
      "total_flops_so_far": 683136523782144.0,
      "budget_used_percent": 0.6831365237821441
    },
    {
      "type": "training",
      "description": "Training step 477",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:52",
      "total_flops_so_far": 684568675823616.0,
      "budget_used_percent": 0.684568675823616
    },
    {
      "type": "training",
      "description": "Training step 478",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:52",
      "total_flops_so_far": 686000827865088.0,
      "budget_used_percent": 0.686000827865088
    },
    {
      "type": "training",
      "description": "Training step 479",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:53",
      "total_flops_so_far": 687432979906560.0,
      "budget_used_percent": 0.68743297990656
    },
    {
      "type": "training",
      "description": "Training step 480",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:53",
      "total_flops_so_far": 688865131948032.0,
      "budget_used_percent": 0.688865131948032
    },
    {
      "type": "training",
      "description": "Training step 481",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:53",
      "total_flops_so_far": 690297283989504.0,
      "budget_used_percent": 0.690297283989504
    },
    {
      "type": "training",
      "description": "Training step 482",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:53",
      "total_flops_so_far": 691729436030976.0,
      "budget_used_percent": 0.691729436030976
    },
    {
      "type": "training",
      "description": "Training step 483",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:53",
      "total_flops_so_far": 693161588072448.0,
      "budget_used_percent": 0.693161588072448
    },
    {
      "type": "training",
      "description": "Training step 484",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:53",
      "total_flops_so_far": 694593740113920.0,
      "budget_used_percent": 0.69459374011392
    },
    {
      "type": "training",
      "description": "Training step 485",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:53",
      "total_flops_so_far": 696025892155392.0,
      "budget_used_percent": 0.696025892155392
    },
    {
      "type": "training",
      "description": "Training step 486",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:54",
      "total_flops_so_far": 697458044196864.0,
      "budget_used_percent": 0.697458044196864
    },
    {
      "type": "training",
      "description": "Training step 487",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:54",
      "total_flops_so_far": 698890196238336.0,
      "budget_used_percent": 0.698890196238336
    },
    {
      "type": "training",
      "description": "Training step 488",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:54",
      "total_flops_so_far": 700322348279808.0,
      "budget_used_percent": 0.700322348279808
    },
    {
      "type": "training",
      "description": "Training step 489",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:54",
      "total_flops_so_far": 701754500321280.0,
      "budget_used_percent": 0.70175450032128
    },
    {
      "type": "training",
      "description": "Training step 490",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:54",
      "total_flops_so_far": 703186652362752.0,
      "budget_used_percent": 0.703186652362752
    },
    {
      "type": "training",
      "description": "Training step 491",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:54",
      "total_flops_so_far": 704618804404224.0,
      "budget_used_percent": 0.704618804404224
    },
    {
      "type": "training",
      "description": "Training step 492",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:54",
      "total_flops_so_far": 706050956445696.0,
      "budget_used_percent": 0.706050956445696
    },
    {
      "type": "training",
      "description": "Training step 493",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:54",
      "total_flops_so_far": 707483108487168.0,
      "budget_used_percent": 0.707483108487168
    },
    {
      "type": "training",
      "description": "Training step 494",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:55",
      "total_flops_so_far": 708915260528640.0,
      "budget_used_percent": 0.70891526052864
    },
    {
      "type": "training",
      "description": "Training step 495",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:55",
      "total_flops_so_far": 710347412570112.0,
      "budget_used_percent": 0.710347412570112
    },
    {
      "type": "training",
      "description": "Training step 496",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:55",
      "total_flops_so_far": 711779564611584.0,
      "budget_used_percent": 0.711779564611584
    },
    {
      "type": "training",
      "description": "Training step 497",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:55",
      "total_flops_so_far": 713211716653056.0,
      "budget_used_percent": 0.7132117166530559
    },
    {
      "type": "training",
      "description": "Training step 498",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:55",
      "total_flops_so_far": 714643868694528.0,
      "budget_used_percent": 0.714643868694528
    },
    {
      "type": "training",
      "description": "Training step 499",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:21:55",
      "total_flops_so_far": 716076020736000.0,
      "budget_used_percent": 0.7160760207360001
    },
    {
      "type": "training",
      "description": "Training step 500",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:17",
      "total_flops_so_far": 717508172777472.0,
      "budget_used_percent": 0.7175081727774719
    },
    {
      "type": "training",
      "description": "Training step 501",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:17",
      "total_flops_so_far": 718940324818944.0,
      "budget_used_percent": 0.718940324818944
    },
    {
      "type": "training",
      "description": "Training step 502",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:17",
      "total_flops_so_far": 720372476860416.0,
      "budget_used_percent": 0.7203724768604161
    },
    {
      "type": "training",
      "description": "Training step 503",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:18",
      "total_flops_so_far": 721804628901888.0,
      "budget_used_percent": 0.721804628901888
    },
    {
      "type": "training",
      "description": "Training step 504",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:18",
      "total_flops_so_far": 723236780943360.0,
      "budget_used_percent": 0.72323678094336
    },
    {
      "type": "training",
      "description": "Training step 505",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:18",
      "total_flops_so_far": 724668932984832.0,
      "budget_used_percent": 0.724668932984832
    },
    {
      "type": "training",
      "description": "Training step 506",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:18",
      "total_flops_so_far": 726101085026304.0,
      "budget_used_percent": 0.726101085026304
    },
    {
      "type": "training",
      "description": "Training step 507",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:18",
      "total_flops_so_far": 727533237067776.0,
      "budget_used_percent": 0.727533237067776
    },
    {
      "type": "training",
      "description": "Training step 508",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:18",
      "total_flops_so_far": 728965389109248.0,
      "budget_used_percent": 0.728965389109248
    },
    {
      "type": "training",
      "description": "Training step 509",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:18",
      "total_flops_so_far": 730397541150720.0,
      "budget_used_percent": 0.73039754115072
    },
    {
      "type": "training",
      "description": "Training step 510",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:19",
      "total_flops_so_far": 731829693192192.0,
      "budget_used_percent": 0.731829693192192
    },
    {
      "type": "training",
      "description": "Training step 511",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:19",
      "total_flops_so_far": 733261845233664.0,
      "budget_used_percent": 0.733261845233664
    },
    {
      "type": "training",
      "description": "Training step 512",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:19",
      "total_flops_so_far": 734693997275136.0,
      "budget_used_percent": 0.734693997275136
    },
    {
      "type": "training",
      "description": "Training step 513",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:19",
      "total_flops_so_far": 736126149316608.0,
      "budget_used_percent": 0.736126149316608
    },
    {
      "type": "training",
      "description": "Training step 514",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:19",
      "total_flops_so_far": 737558301358080.0,
      "budget_used_percent": 0.73755830135808
    },
    {
      "type": "training",
      "description": "Training step 515",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:19",
      "total_flops_so_far": 738990453399552.0,
      "budget_used_percent": 0.7389904533995519
    },
    {
      "type": "training",
      "description": "Training step 516",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:19",
      "total_flops_so_far": 740422605441024.0,
      "budget_used_percent": 0.740422605441024
    },
    {
      "type": "training",
      "description": "Training step 517",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:20",
      "total_flops_so_far": 741854757482496.0,
      "budget_used_percent": 0.7418547574824961
    },
    {
      "type": "training",
      "description": "Training step 518",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:20",
      "total_flops_so_far": 743286909523968.0,
      "budget_used_percent": 0.743286909523968
    },
    {
      "type": "training",
      "description": "Training step 519",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:20",
      "total_flops_so_far": 744719061565440.0,
      "budget_used_percent": 0.74471906156544
    },
    {
      "type": "training",
      "description": "Training step 520",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:20",
      "total_flops_so_far": 746151213606912.0,
      "budget_used_percent": 0.7461512136069121
    },
    {
      "type": "training",
      "description": "Training step 521",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:20",
      "total_flops_so_far": 747583365648384.0,
      "budget_used_percent": 0.747583365648384
    },
    {
      "type": "training",
      "description": "Training step 522",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:20",
      "total_flops_so_far": 749015517689856.0,
      "budget_used_percent": 0.749015517689856
    },
    {
      "type": "training",
      "description": "Training step 523",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:20",
      "total_flops_so_far": 750447669731328.0,
      "budget_used_percent": 0.750447669731328
    },
    {
      "type": "training",
      "description": "Training step 524",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:20",
      "total_flops_so_far": 751879821772800.0,
      "budget_used_percent": 0.7518798217728
    },
    {
      "type": "training",
      "description": "Training step 525",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:21",
      "total_flops_so_far": 753311973814272.0,
      "budget_used_percent": 0.7533119738142721
    },
    {
      "type": "training",
      "description": "Training step 526",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:21",
      "total_flops_so_far": 754744125855744.0,
      "budget_used_percent": 0.7547441258557439
    },
    {
      "type": "training",
      "description": "Training step 527",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:21",
      "total_flops_so_far": 756176277897216.0,
      "budget_used_percent": 0.756176277897216
    },
    {
      "type": "training",
      "description": "Training step 528",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:21",
      "total_flops_so_far": 757608429938688.0,
      "budget_used_percent": 0.757608429938688
    },
    {
      "type": "training",
      "description": "Training step 529",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:21",
      "total_flops_so_far": 759040581980160.0,
      "budget_used_percent": 0.75904058198016
    },
    {
      "type": "training",
      "description": "Training step 530",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:21",
      "total_flops_so_far": 760472734021632.0,
      "budget_used_percent": 0.760472734021632
    },
    {
      "type": "training",
      "description": "Training step 531",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:21",
      "total_flops_so_far": 761904886063104.0,
      "budget_used_percent": 0.761904886063104
    },
    {
      "type": "training",
      "description": "Training step 532",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:22",
      "total_flops_so_far": 763337038104576.0,
      "budget_used_percent": 0.763337038104576
    },
    {
      "type": "training",
      "description": "Training step 533",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:22",
      "total_flops_so_far": 764769190146048.0,
      "budget_used_percent": 0.7647691901460479
    },
    {
      "type": "training",
      "description": "Training step 534",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:22",
      "total_flops_so_far": 766201342187520.0,
      "budget_used_percent": 0.76620134218752
    },
    {
      "type": "training",
      "description": "Training step 535",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:22",
      "total_flops_so_far": 767633494228992.0,
      "budget_used_percent": 0.767633494228992
    },
    {
      "type": "training",
      "description": "Training step 536",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:22",
      "total_flops_so_far": 769065646270464.0,
      "budget_used_percent": 0.769065646270464
    },
    {
      "type": "training",
      "description": "Training step 537",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:22",
      "total_flops_so_far": 770497798311936.0,
      "budget_used_percent": 0.770497798311936
    },
    {
      "type": "training",
      "description": "Training step 538",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:22",
      "total_flops_so_far": 771929950353408.0,
      "budget_used_percent": 0.771929950353408
    },
    {
      "type": "training",
      "description": "Training step 539",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:23",
      "total_flops_so_far": 773362102394880.0,
      "budget_used_percent": 0.77336210239488
    },
    {
      "type": "training",
      "description": "Training step 540",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:23",
      "total_flops_so_far": 774794254436352.0,
      "budget_used_percent": 0.774794254436352
    },
    {
      "type": "training",
      "description": "Training step 541",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:23",
      "total_flops_so_far": 776226406477824.0,
      "budget_used_percent": 0.7762264064778239
    },
    {
      "type": "training",
      "description": "Training step 542",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:23",
      "total_flops_so_far": 777658558519296.0,
      "budget_used_percent": 0.777658558519296
    },
    {
      "type": "training",
      "description": "Training step 543",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:23",
      "total_flops_so_far": 779090710560768.0,
      "budget_used_percent": 0.7790907105607681
    },
    {
      "type": "training",
      "description": "Training step 544",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:23",
      "total_flops_so_far": 780522862602240.0,
      "budget_used_percent": 0.78052286260224
    },
    {
      "type": "training",
      "description": "Training step 545",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:23",
      "total_flops_so_far": 781955014643712.0,
      "budget_used_percent": 0.7819550146437119
    },
    {
      "type": "training",
      "description": "Training step 546",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:23",
      "total_flops_so_far": 783387166685184.0,
      "budget_used_percent": 0.783387166685184
    },
    {
      "type": "training",
      "description": "Training step 547",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:24",
      "total_flops_so_far": 784819318726656.0,
      "budget_used_percent": 0.784819318726656
    },
    {
      "type": "training",
      "description": "Training step 548",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:24",
      "total_flops_so_far": 786251470768128.0,
      "budget_used_percent": 0.786251470768128
    },
    {
      "type": "training",
      "description": "Training step 549",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:24",
      "total_flops_so_far": 787683622809600.0,
      "budget_used_percent": 0.7876836228096
    },
    {
      "type": "training",
      "description": "Training step 550",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:24",
      "total_flops_so_far": 789115774851072.0,
      "budget_used_percent": 0.789115774851072
    },
    {
      "type": "training",
      "description": "Training step 551",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:24",
      "total_flops_so_far": 790547926892544.0,
      "budget_used_percent": 0.7905479268925439
    },
    {
      "type": "training",
      "description": "Training step 552",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:24",
      "total_flops_so_far": 791980078934016.0,
      "budget_used_percent": 0.791980078934016
    },
    {
      "type": "training",
      "description": "Training step 553",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:24",
      "total_flops_so_far": 793412230975488.0,
      "budget_used_percent": 0.793412230975488
    },
    {
      "type": "training",
      "description": "Training step 554",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:25",
      "total_flops_so_far": 794844383016960.0,
      "budget_used_percent": 0.7948443830169599
    },
    {
      "type": "training",
      "description": "Training step 555",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:25",
      "total_flops_so_far": 796276535058432.0,
      "budget_used_percent": 0.796276535058432
    },
    {
      "type": "training",
      "description": "Training step 556",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:25",
      "total_flops_so_far": 797708687099904.0,
      "budget_used_percent": 0.797708687099904
    },
    {
      "type": "training",
      "description": "Training step 557",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:25",
      "total_flops_so_far": 799140839141376.0,
      "budget_used_percent": 0.7991408391413759
    },
    {
      "type": "training",
      "description": "Training step 558",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:25",
      "total_flops_so_far": 800572991182848.0,
      "budget_used_percent": 0.8005729911828481
    },
    {
      "type": "training",
      "description": "Training step 559",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:25",
      "total_flops_so_far": 802005143224320.0,
      "budget_used_percent": 0.80200514322432
    },
    {
      "type": "training",
      "description": "Training step 560",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:25",
      "total_flops_so_far": 803437295265792.0,
      "budget_used_percent": 0.8034372952657919
    },
    {
      "type": "training",
      "description": "Training step 561",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:26",
      "total_flops_so_far": 804869447307264.0,
      "budget_used_percent": 0.8048694473072641
    },
    {
      "type": "training",
      "description": "Training step 562",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:26",
      "total_flops_so_far": 806301599348736.0,
      "budget_used_percent": 0.806301599348736
    },
    {
      "type": "training",
      "description": "Training step 563",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:26",
      "total_flops_so_far": 807733751390208.0,
      "budget_used_percent": 0.807733751390208
    },
    {
      "type": "training",
      "description": "Training step 564",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:26",
      "total_flops_so_far": 809165903431680.0,
      "budget_used_percent": 0.80916590343168
    },
    {
      "type": "training",
      "description": "Training step 565",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:26",
      "total_flops_so_far": 810598055473152.0,
      "budget_used_percent": 0.810598055473152
    },
    {
      "type": "training",
      "description": "Training step 566",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:26",
      "total_flops_so_far": 812030207514624.0,
      "budget_used_percent": 0.812030207514624
    },
    {
      "type": "training",
      "description": "Training step 567",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:26",
      "total_flops_so_far": 813462359556096.0,
      "budget_used_percent": 0.813462359556096
    },
    {
      "type": "training",
      "description": "Training step 568",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:26",
      "total_flops_so_far": 814894511597568.0,
      "budget_used_percent": 0.814894511597568
    },
    {
      "type": "training",
      "description": "Training step 569",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:27",
      "total_flops_so_far": 816326663639040.0,
      "budget_used_percent": 0.8163266636390399
    },
    {
      "type": "training",
      "description": "Training step 570",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:27",
      "total_flops_so_far": 817758815680512.0,
      "budget_used_percent": 0.817758815680512
    },
    {
      "type": "training",
      "description": "Training step 571",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:27",
      "total_flops_so_far": 819190967721984.0,
      "budget_used_percent": 0.819190967721984
    },
    {
      "type": "training",
      "description": "Training step 572",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:27",
      "total_flops_so_far": 820623119763456.0,
      "budget_used_percent": 0.8206231197634559
    },
    {
      "type": "training",
      "description": "Training step 573",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:27",
      "total_flops_so_far": 822055271804928.0,
      "budget_used_percent": 0.8220552718049281
    },
    {
      "type": "training",
      "description": "Training step 574",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:27",
      "total_flops_so_far": 823487423846400.0,
      "budget_used_percent": 0.8234874238464
    },
    {
      "type": "training",
      "description": "Training step 575",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:27",
      "total_flops_so_far": 824919575887872.0,
      "budget_used_percent": 0.8249195758878719
    },
    {
      "type": "training",
      "description": "Training step 576",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:28",
      "total_flops_so_far": 826351727929344.0,
      "budget_used_percent": 0.8263517279293441
    },
    {
      "type": "training",
      "description": "Training step 577",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:28",
      "total_flops_so_far": 827783879970816.0,
      "budget_used_percent": 0.827783879970816
    },
    {
      "type": "training",
      "description": "Training step 578",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:28",
      "total_flops_so_far": 829216032012288.0,
      "budget_used_percent": 0.8292160320122879
    },
    {
      "type": "training",
      "description": "Training step 579",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:28",
      "total_flops_so_far": 830648184053760.0,
      "budget_used_percent": 0.8306481840537601
    },
    {
      "type": "training",
      "description": "Training step 580",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:28",
      "total_flops_so_far": 832080336095232.0,
      "budget_used_percent": 0.832080336095232
    },
    {
      "type": "training",
      "description": "Training step 581",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:28",
      "total_flops_so_far": 833512488136704.0,
      "budget_used_percent": 0.833512488136704
    },
    {
      "type": "training",
      "description": "Training step 582",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:28",
      "total_flops_so_far": 834944640178176.0,
      "budget_used_percent": 0.834944640178176
    },
    {
      "type": "training",
      "description": "Training step 583",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:28",
      "total_flops_so_far": 836376792219648.0,
      "budget_used_percent": 0.836376792219648
    },
    {
      "type": "training",
      "description": "Training step 584",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:29",
      "total_flops_so_far": 837808944261120.0,
      "budget_used_percent": 0.83780894426112
    },
    {
      "type": "training",
      "description": "Training step 585",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:29",
      "total_flops_so_far": 839241096302592.0,
      "budget_used_percent": 0.839241096302592
    },
    {
      "type": "training",
      "description": "Training step 586",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:29",
      "total_flops_so_far": 840673248344064.0,
      "budget_used_percent": 0.840673248344064
    },
    {
      "type": "training",
      "description": "Training step 587",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:29",
      "total_flops_so_far": 842105400385536.0,
      "budget_used_percent": 0.8421054003855359
    },
    {
      "type": "training",
      "description": "Training step 588",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:29",
      "total_flops_so_far": 843537552427008.0,
      "budget_used_percent": 0.8435375524270081
    },
    {
      "type": "training",
      "description": "Training step 589",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:29",
      "total_flops_so_far": 844969704468480.0,
      "budget_used_percent": 0.84496970446848
    },
    {
      "type": "training",
      "description": "Training step 590",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:29",
      "total_flops_so_far": 846401856509952.0,
      "budget_used_percent": 0.8464018565099519
    },
    {
      "type": "training",
      "description": "Training step 591",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:30",
      "total_flops_so_far": 847834008551424.0,
      "budget_used_percent": 0.8478340085514241
    },
    {
      "type": "training",
      "description": "Training step 592",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:30",
      "total_flops_so_far": 849266160592896.0,
      "budget_used_percent": 0.8492661605928961
    },
    {
      "type": "training",
      "description": "Training step 593",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:30",
      "total_flops_so_far": 850698312634368.0,
      "budget_used_percent": 0.8506983126343679
    },
    {
      "type": "training",
      "description": "Training step 594",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:30",
      "total_flops_so_far": 852130464675840.0,
      "budget_used_percent": 0.8521304646758401
    },
    {
      "type": "training",
      "description": "Training step 595",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:30",
      "total_flops_so_far": 853562616717312.0,
      "budget_used_percent": 0.853562616717312
    },
    {
      "type": "training",
      "description": "Training step 596",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:30",
      "total_flops_so_far": 854994768758784.0,
      "budget_used_percent": 0.854994768758784
    },
    {
      "type": "training",
      "description": "Training step 597",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:30",
      "total_flops_so_far": 856426920800256.0,
      "budget_used_percent": 0.8564269208002561
    },
    {
      "type": "training",
      "description": "Training step 598",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:31",
      "total_flops_so_far": 857859072841728.0,
      "budget_used_percent": 0.857859072841728
    },
    {
      "type": "training",
      "description": "Training step 599",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:31",
      "total_flops_so_far": 859291224883200.0,
      "budget_used_percent": 0.8592912248832
    },
    {
      "type": "training",
      "description": "Training step 600",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:31",
      "total_flops_so_far": 860723376924672.0,
      "budget_used_percent": 0.860723376924672
    },
    {
      "type": "training",
      "description": "Training step 601",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:31",
      "total_flops_so_far": 862155528966144.0,
      "budget_used_percent": 0.862155528966144
    },
    {
      "type": "training",
      "description": "Training step 602",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:31",
      "total_flops_so_far": 863587681007616.0,
      "budget_used_percent": 0.863587681007616
    },
    {
      "type": "training",
      "description": "Training step 603",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:31",
      "total_flops_so_far": 865019833049088.0,
      "budget_used_percent": 0.865019833049088
    },
    {
      "type": "training",
      "description": "Training step 604",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:31",
      "total_flops_so_far": 866451985090560.0,
      "budget_used_percent": 0.86645198509056
    },
    {
      "type": "training",
      "description": "Training step 605",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:32",
      "total_flops_so_far": 867884137132032.0,
      "budget_used_percent": 0.8678841371320319
    },
    {
      "type": "training",
      "description": "Training step 606",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:32",
      "total_flops_so_far": 869316289173504.0,
      "budget_used_percent": 0.8693162891735041
    },
    {
      "type": "training",
      "description": "Training step 607",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:32",
      "total_flops_so_far": 870748441214976.0,
      "budget_used_percent": 0.870748441214976
    },
    {
      "type": "training",
      "description": "Training step 608",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:32",
      "total_flops_so_far": 872180593256448.0,
      "budget_used_percent": 0.8721805932564479
    },
    {
      "type": "training",
      "description": "Training step 609",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:32",
      "total_flops_so_far": 873612745297920.0,
      "budget_used_percent": 0.8736127452979201
    },
    {
      "type": "training",
      "description": "Training step 610",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:32",
      "total_flops_so_far": 875044897339392.0,
      "budget_used_percent": 0.8750448973393921
    },
    {
      "type": "training",
      "description": "Training step 611",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:32",
      "total_flops_so_far": 876477049380864.0,
      "budget_used_percent": 0.876477049380864
    },
    {
      "type": "training",
      "description": "Training step 612",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:32",
      "total_flops_so_far": 877909201422336.0,
      "budget_used_percent": 0.8779092014223361
    },
    {
      "type": "training",
      "description": "Training step 613",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:33",
      "total_flops_so_far": 879341353463808.0,
      "budget_used_percent": 0.879341353463808
    },
    {
      "type": "training",
      "description": "Training step 614",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:33",
      "total_flops_so_far": 880773505505280.0,
      "budget_used_percent": 0.88077350550528
    },
    {
      "type": "training",
      "description": "Training step 615",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:33",
      "total_flops_so_far": 882205657546752.0,
      "budget_used_percent": 0.8822056575467521
    },
    {
      "type": "training",
      "description": "Training step 616",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:33",
      "total_flops_so_far": 883637809588224.0,
      "budget_used_percent": 0.883637809588224
    },
    {
      "type": "training",
      "description": "Training step 617",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:33",
      "total_flops_so_far": 885069961629696.0,
      "budget_used_percent": 0.885069961629696
    },
    {
      "type": "training",
      "description": "Training step 618",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:33",
      "total_flops_so_far": 886502113671168.0,
      "budget_used_percent": 0.8865021136711679
    },
    {
      "type": "training",
      "description": "Training step 619",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:33",
      "total_flops_so_far": 887934265712640.0,
      "budget_used_percent": 0.88793426571264
    },
    {
      "type": "training",
      "description": "Training step 620",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:34",
      "total_flops_so_far": 889366417754112.0,
      "budget_used_percent": 0.889366417754112
    },
    {
      "type": "training",
      "description": "Training step 621",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:34",
      "total_flops_so_far": 890798569795584.0,
      "budget_used_percent": 0.8907985697955839
    },
    {
      "type": "training",
      "description": "Training step 622",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:34",
      "total_flops_so_far": 892230721837056.0,
      "budget_used_percent": 0.892230721837056
    },
    {
      "type": "training",
      "description": "Training step 623",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:34",
      "total_flops_so_far": 893662873878528.0,
      "budget_used_percent": 0.8936628738785279
    },
    {
      "type": "training",
      "description": "Training step 624",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:34",
      "total_flops_so_far": 895095025920000.0,
      "budget_used_percent": 0.8950950259199999
    },
    {
      "type": "training",
      "description": "Training step 625",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:34",
      "total_flops_so_far": 896527177961472.0,
      "budget_used_percent": 0.8965271779614721
    },
    {
      "type": "training",
      "description": "Training step 626",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:34",
      "total_flops_so_far": 897959330002944.0,
      "budget_used_percent": 0.897959330002944
    },
    {
      "type": "training",
      "description": "Training step 627",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:34",
      "total_flops_so_far": 899391482044416.0,
      "budget_used_percent": 0.8993914820444159
    },
    {
      "type": "training",
      "description": "Training step 628",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:35",
      "total_flops_so_far": 900823634085888.0,
      "budget_used_percent": 0.9008236340858881
    },
    {
      "type": "training",
      "description": "Training step 629",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:35",
      "total_flops_so_far": 902255786127360.0,
      "budget_used_percent": 0.90225578612736
    },
    {
      "type": "training",
      "description": "Training step 630",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:35",
      "total_flops_so_far": 903687938168832.0,
      "budget_used_percent": 0.903687938168832
    },
    {
      "type": "training",
      "description": "Training step 631",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:35",
      "total_flops_so_far": 905120090210304.0,
      "budget_used_percent": 0.905120090210304
    },
    {
      "type": "training",
      "description": "Training step 632",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:35",
      "total_flops_so_far": 906552242251776.0,
      "budget_used_percent": 0.906552242251776
    },
    {
      "type": "training",
      "description": "Training step 633",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:35",
      "total_flops_so_far": 907984394293248.0,
      "budget_used_percent": 0.907984394293248
    },
    {
      "type": "training",
      "description": "Training step 634",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:35",
      "total_flops_so_far": 909416546334720.0,
      "budget_used_percent": 0.90941654633472
    },
    {
      "type": "training",
      "description": "Training step 635",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:36",
      "total_flops_so_far": 910848698376192.0,
      "budget_used_percent": 0.910848698376192
    },
    {
      "type": "training",
      "description": "Training step 636",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:36",
      "total_flops_so_far": 912280850417664.0,
      "budget_used_percent": 0.9122808504176639
    },
    {
      "type": "training",
      "description": "Training step 637",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:36",
      "total_flops_so_far": 913713002459136.0,
      "budget_used_percent": 0.913713002459136
    },
    {
      "type": "training",
      "description": "Training step 638",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:36",
      "total_flops_so_far": 915145154500608.0,
      "budget_used_percent": 0.915145154500608
    },
    {
      "type": "training",
      "description": "Training step 639",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:36",
      "total_flops_so_far": 916577306542080.0,
      "budget_used_percent": 0.9165773065420799
    },
    {
      "type": "training",
      "description": "Training step 640",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:36",
      "total_flops_so_far": 918009458583552.0,
      "budget_used_percent": 0.9180094585835521
    },
    {
      "type": "training",
      "description": "Training step 641",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:36",
      "total_flops_so_far": 919441610625024.0,
      "budget_used_percent": 0.9194416106250239
    },
    {
      "type": "training",
      "description": "Training step 642",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:37",
      "total_flops_so_far": 920873762666496.0,
      "budget_used_percent": 0.9208737626664959
    },
    {
      "type": "training",
      "description": "Training step 643",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:37",
      "total_flops_so_far": 922305914707968.0,
      "budget_used_percent": 0.9223059147079681
    },
    {
      "type": "training",
      "description": "Training step 644",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:37",
      "total_flops_so_far": 923738066749440.0,
      "budget_used_percent": 0.92373806674944
    },
    {
      "type": "training",
      "description": "Training step 645",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:37",
      "total_flops_so_far": 925170218790912.0,
      "budget_used_percent": 0.9251702187909119
    },
    {
      "type": "training",
      "description": "Training step 646",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:37",
      "total_flops_so_far": 926602370832384.0,
      "budget_used_percent": 0.9266023708323841
    },
    {
      "type": "training",
      "description": "Training step 647",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:37",
      "total_flops_so_far": 928034522873856.0,
      "budget_used_percent": 0.928034522873856
    },
    {
      "type": "training",
      "description": "Training step 648",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:37",
      "total_flops_so_far": 929466674915328.0,
      "budget_used_percent": 0.929466674915328
    },
    {
      "type": "training",
      "description": "Training step 649",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:38",
      "total_flops_so_far": 930898826956800.0,
      "budget_used_percent": 0.9308988269568
    },
    {
      "type": "training",
      "description": "Training step 650",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:38",
      "total_flops_so_far": 932330978998272.0,
      "budget_used_percent": 0.932330978998272
    },
    {
      "type": "training",
      "description": "Training step 651",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:38",
      "total_flops_so_far": 933763131039744.0,
      "budget_used_percent": 0.933763131039744
    },
    {
      "type": "training",
      "description": "Training step 652",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:38",
      "total_flops_so_far": 935195283081216.0,
      "budget_used_percent": 0.935195283081216
    },
    {
      "type": "training",
      "description": "Training step 653",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:38",
      "total_flops_so_far": 936627435122688.0,
      "budget_used_percent": 0.936627435122688
    },
    {
      "type": "training",
      "description": "Training step 654",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:38",
      "total_flops_so_far": 938059587164160.0,
      "budget_used_percent": 0.9380595871641599
    },
    {
      "type": "training",
      "description": "Training step 655",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:38",
      "total_flops_so_far": 939491739205632.0,
      "budget_used_percent": 0.9394917392056321
    },
    {
      "type": "training",
      "description": "Training step 656",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:39",
      "total_flops_so_far": 940923891247104.0,
      "budget_used_percent": 0.940923891247104
    },
    {
      "type": "training",
      "description": "Training step 657",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:39",
      "total_flops_so_far": 942356043288576.0,
      "budget_used_percent": 0.9423560432885759
    },
    {
      "type": "training",
      "description": "Training step 658",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:39",
      "total_flops_so_far": 943788195330048.0,
      "budget_used_percent": 0.9437881953300481
    },
    {
      "type": "training",
      "description": "Training step 659",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:39",
      "total_flops_so_far": 945220347371520.0,
      "budget_used_percent": 0.94522034737152
    },
    {
      "type": "training",
      "description": "Training step 660",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:39",
      "total_flops_so_far": 946652499412992.0,
      "budget_used_percent": 0.9466524994129919
    },
    {
      "type": "training",
      "description": "Training step 661",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:39",
      "total_flops_so_far": 948084651454464.0,
      "budget_used_percent": 0.9480846514544641
    },
    {
      "type": "training",
      "description": "Training step 662",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:39",
      "total_flops_so_far": 949516803495936.0,
      "budget_used_percent": 0.949516803495936
    },
    {
      "type": "training",
      "description": "Training step 663",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:40",
      "total_flops_so_far": 950948955537408.0,
      "budget_used_percent": 0.950948955537408
    },
    {
      "type": "training",
      "description": "Training step 664",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:40",
      "total_flops_so_far": 952381107578880.0,
      "budget_used_percent": 0.9523811075788801
    },
    {
      "type": "training",
      "description": "Training step 665",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:40",
      "total_flops_so_far": 953813259620352.0,
      "budget_used_percent": 0.953813259620352
    },
    {
      "type": "training",
      "description": "Training step 666",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:40",
      "total_flops_so_far": 955245411661824.0,
      "budget_used_percent": 0.955245411661824
    },
    {
      "type": "training",
      "description": "Training step 667",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:40",
      "total_flops_so_far": 956677563703296.0,
      "budget_used_percent": 0.956677563703296
    },
    {
      "type": "training",
      "description": "Training step 668",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:40",
      "total_flops_so_far": 958109715744768.0,
      "budget_used_percent": 0.958109715744768
    },
    {
      "type": "training",
      "description": "Training step 669",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:40",
      "total_flops_so_far": 959541867786240.0,
      "budget_used_percent": 0.95954186778624
    },
    {
      "type": "training",
      "description": "Training step 670",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:41",
      "total_flops_so_far": 960974019827712.0,
      "budget_used_percent": 0.960974019827712
    },
    {
      "type": "training",
      "description": "Training step 671",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:41",
      "total_flops_so_far": 962406171869184.0,
      "budget_used_percent": 0.962406171869184
    },
    {
      "type": "training",
      "description": "Training step 672",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:41",
      "total_flops_so_far": 963838323910656.0,
      "budget_used_percent": 0.9638383239106559
    },
    {
      "type": "training",
      "description": "Training step 673",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:41",
      "total_flops_so_far": 965270475952128.0,
      "budget_used_percent": 0.9652704759521281
    },
    {
      "type": "training",
      "description": "Training step 674",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:41",
      "total_flops_so_far": 966702627993600.0,
      "budget_used_percent": 0.9667026279936
    },
    {
      "type": "training",
      "description": "Training step 675",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:41",
      "total_flops_so_far": 968134780035072.0,
      "budget_used_percent": 0.9681347800350719
    },
    {
      "type": "training",
      "description": "Training step 676",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:41",
      "total_flops_so_far": 969566932076544.0,
      "budget_used_percent": 0.9695669320765441
    },
    {
      "type": "training",
      "description": "Training step 677",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:42",
      "total_flops_so_far": 970999084118016.0,
      "budget_used_percent": 0.970999084118016
    },
    {
      "type": "training",
      "description": "Training step 678",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:42",
      "total_flops_so_far": 972431236159488.0,
      "budget_used_percent": 0.972431236159488
    },
    {
      "type": "training",
      "description": "Training step 679",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:42",
      "total_flops_so_far": 973863388200960.0,
      "budget_used_percent": 0.9738633882009601
    },
    {
      "type": "training",
      "description": "Training step 680",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:42",
      "total_flops_so_far": 975295540242432.0,
      "budget_used_percent": 0.975295540242432
    },
    {
      "type": "training",
      "description": "Training step 681",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:42",
      "total_flops_so_far": 976727692283904.0,
      "budget_used_percent": 0.976727692283904
    },
    {
      "type": "training",
      "description": "Training step 682",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:42",
      "total_flops_so_far": 978159844325376.0,
      "budget_used_percent": 0.9781598443253761
    },
    {
      "type": "training",
      "description": "Training step 683",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:42",
      "total_flops_so_far": 979591996366848.0,
      "budget_used_percent": 0.979591996366848
    },
    {
      "type": "training",
      "description": "Training step 684",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:43",
      "total_flops_so_far": 981024148408320.0,
      "budget_used_percent": 0.98102414840832
    },
    {
      "type": "training",
      "description": "Training step 685",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:43",
      "total_flops_so_far": 982456300449792.0,
      "budget_used_percent": 0.982456300449792
    },
    {
      "type": "training",
      "description": "Training step 686",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:43",
      "total_flops_so_far": 983888452491264.0,
      "budget_used_percent": 0.983888452491264
    },
    {
      "type": "training",
      "description": "Training step 687",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:43",
      "total_flops_so_far": 985320604532736.0,
      "budget_used_percent": 0.985320604532736
    },
    {
      "type": "training",
      "description": "Training step 688",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:43",
      "total_flops_so_far": 986752756574208.0,
      "budget_used_percent": 0.9867527565742081
    },
    {
      "type": "training",
      "description": "Training step 689",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:43",
      "total_flops_so_far": 988184908615680.0,
      "budget_used_percent": 0.98818490861568
    },
    {
      "type": "training",
      "description": "Training step 690",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:43",
      "total_flops_so_far": 989617060657152.0,
      "budget_used_percent": 0.9896170606571519
    },
    {
      "type": "training",
      "description": "Training step 691",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:44",
      "total_flops_so_far": 991049212698624.0,
      "budget_used_percent": 0.9910492126986239
    },
    {
      "type": "training",
      "description": "Training step 692",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:44",
      "total_flops_so_far": 992481364740096.0,
      "budget_used_percent": 0.9924813647400961
    },
    {
      "type": "training",
      "description": "Training step 693",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:44",
      "total_flops_so_far": 993913516781568.0,
      "budget_used_percent": 0.993913516781568
    },
    {
      "type": "training",
      "description": "Training step 694",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:44",
      "total_flops_so_far": 995345668823040.0,
      "budget_used_percent": 0.9953456688230399
    },
    {
      "type": "training",
      "description": "Training step 695",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:44",
      "total_flops_so_far": 996777820864512.0,
      "budget_used_percent": 0.996777820864512
    },
    {
      "type": "training",
      "description": "Training step 696",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:44",
      "total_flops_so_far": 998209972905984.0,
      "budget_used_percent": 0.998209972905984
    },
    {
      "type": "training",
      "description": "Training step 697",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:44",
      "total_flops_so_far": 999642124947456.0,
      "budget_used_percent": 0.999642124947456
    },
    {
      "type": "training",
      "description": "Training step 698",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:45",
      "total_flops_so_far": 1001074276988928.0,
      "budget_used_percent": 1.001074276988928
    },
    {
      "type": "training",
      "description": "Training step 699",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:45",
      "total_flops_so_far": 1002506429030400.0,
      "budget_used_percent": 1.0025064290304
    },
    {
      "type": "training",
      "description": "Training step 700",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:45",
      "total_flops_so_far": 1003938581071872.0,
      "budget_used_percent": 1.003938581071872
    },
    {
      "type": "training",
      "description": "Training step 701",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:45",
      "total_flops_so_far": 1005370733113344.0,
      "budget_used_percent": 1.0053707331133441
    },
    {
      "type": "training",
      "description": "Training step 702",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:45",
      "total_flops_so_far": 1006802885154816.0,
      "budget_used_percent": 1.006802885154816
    },
    {
      "type": "training",
      "description": "Training step 703",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:45",
      "total_flops_so_far": 1008235037196288.0,
      "budget_used_percent": 1.0082350371962878
    },
    {
      "type": "training",
      "description": "Training step 704",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:45",
      "total_flops_so_far": 1009667189237760.0,
      "budget_used_percent": 1.00966718923776
    },
    {
      "type": "training",
      "description": "Training step 705",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:46",
      "total_flops_so_far": 1011099341279232.0,
      "budget_used_percent": 1.011099341279232
    },
    {
      "type": "training",
      "description": "Training step 706",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:46",
      "total_flops_so_far": 1012531493320704.0,
      "budget_used_percent": 1.012531493320704
    },
    {
      "type": "training",
      "description": "Training step 707",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:46",
      "total_flops_so_far": 1013963645362176.0,
      "budget_used_percent": 1.013963645362176
    },
    {
      "type": "training",
      "description": "Training step 708",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:46",
      "total_flops_so_far": 1015395797403648.0,
      "budget_used_percent": 1.015395797403648
    },
    {
      "type": "training",
      "description": "Training step 709",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:46",
      "total_flops_so_far": 1016827949445120.0,
      "budget_used_percent": 1.01682794944512
    },
    {
      "type": "training",
      "description": "Training step 710",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:46",
      "total_flops_so_far": 1018260101486592.0,
      "budget_used_percent": 1.018260101486592
    },
    {
      "type": "training",
      "description": "Training step 711",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:46",
      "total_flops_so_far": 1019692253528064.0,
      "budget_used_percent": 1.019692253528064
    },
    {
      "type": "training",
      "description": "Training step 712",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:47",
      "total_flops_so_far": 1021124405569536.0,
      "budget_used_percent": 1.0211244055695359
    },
    {
      "type": "training",
      "description": "Training step 713",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:47",
      "total_flops_so_far": 1022556557611008.0,
      "budget_used_percent": 1.022556557611008
    },
    {
      "type": "training",
      "description": "Training step 714",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:47",
      "total_flops_so_far": 1023988709652480.0,
      "budget_used_percent": 1.02398870965248
    },
    {
      "type": "training",
      "description": "Training step 715",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:47",
      "total_flops_so_far": 1025420861693952.0,
      "budget_used_percent": 1.025420861693952
    },
    {
      "type": "training",
      "description": "Training step 716",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:47",
      "total_flops_so_far": 1026853013735424.0,
      "budget_used_percent": 1.0268530137354241
    },
    {
      "type": "training",
      "description": "Training step 717",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:47",
      "total_flops_so_far": 1028285165776896.0,
      "budget_used_percent": 1.028285165776896
    },
    {
      "type": "training",
      "description": "Training step 718",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:47",
      "total_flops_so_far": 1029717317818368.0,
      "budget_used_percent": 1.0297173178183678
    },
    {
      "type": "training",
      "description": "Training step 719",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:48",
      "total_flops_so_far": 1031149469859840.0,
      "budget_used_percent": 1.03114946985984
    },
    {
      "type": "training",
      "description": "Training step 720",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:48",
      "total_flops_so_far": 1032581621901312.0,
      "budget_used_percent": 1.032581621901312
    },
    {
      "type": "training",
      "description": "Training step 721",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:48",
      "total_flops_so_far": 1034013773942784.0,
      "budget_used_percent": 1.034013773942784
    },
    {
      "type": "training",
      "description": "Training step 722",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:48",
      "total_flops_so_far": 1035445925984256.0,
      "budget_used_percent": 1.035445925984256
    },
    {
      "type": "training",
      "description": "Training step 723",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:48",
      "total_flops_so_far": 1036878078025728.0,
      "budget_used_percent": 1.036878078025728
    },
    {
      "type": "training",
      "description": "Training step 724",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:48",
      "total_flops_so_far": 1038310230067200.0,
      "budget_used_percent": 1.0383102300672
    },
    {
      "type": "training",
      "description": "Training step 725",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:48",
      "total_flops_so_far": 1039742382108672.0,
      "budget_used_percent": 1.039742382108672
    },
    {
      "type": "training",
      "description": "Training step 726",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:49",
      "total_flops_so_far": 1041174534150144.0,
      "budget_used_percent": 1.041174534150144
    },
    {
      "type": "training",
      "description": "Training step 727",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:49",
      "total_flops_so_far": 1042606686191616.0,
      "budget_used_percent": 1.042606686191616
    },
    {
      "type": "training",
      "description": "Training step 728",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:49",
      "total_flops_so_far": 1044038838233088.0,
      "budget_used_percent": 1.044038838233088
    },
    {
      "type": "training",
      "description": "Training step 729",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:49",
      "total_flops_so_far": 1045470990274560.0,
      "budget_used_percent": 1.04547099027456
    },
    {
      "type": "training",
      "description": "Training step 730",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:49",
      "total_flops_so_far": 1046903142316032.0,
      "budget_used_percent": 1.046903142316032
    },
    {
      "type": "training",
      "description": "Training step 731",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:49",
      "total_flops_so_far": 1048335294357504.0,
      "budget_used_percent": 1.0483352943575042
    },
    {
      "type": "training",
      "description": "Training step 732",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:49",
      "total_flops_so_far": 1049767446398976.0,
      "budget_used_percent": 1.049767446398976
    },
    {
      "type": "training",
      "description": "Training step 733",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:49",
      "total_flops_so_far": 1051199598440448.0,
      "budget_used_percent": 1.0511995984404479
    },
    {
      "type": "training",
      "description": "Training step 734",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:50",
      "total_flops_so_far": 1052631750481920.0,
      "budget_used_percent": 1.05263175048192
    },
    {
      "type": "training",
      "description": "Training step 735",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:50",
      "total_flops_so_far": 1054063902523392.0,
      "budget_used_percent": 1.054063902523392
    },
    {
      "type": "training",
      "description": "Training step 736",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:50",
      "total_flops_so_far": 1055496054564864.0,
      "budget_used_percent": 1.055496054564864
    },
    {
      "type": "training",
      "description": "Training step 737",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:50",
      "total_flops_so_far": 1056928206606336.0,
      "budget_used_percent": 1.0569282066063361
    },
    {
      "type": "training",
      "description": "Training step 738",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:50",
      "total_flops_so_far": 1058360358647808.0,
      "budget_used_percent": 1.058360358647808
    },
    {
      "type": "training",
      "description": "Training step 739",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:50",
      "total_flops_so_far": 1059792510689280.0,
      "budget_used_percent": 1.05979251068928
    },
    {
      "type": "training",
      "description": "Training step 740",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:50",
      "total_flops_so_far": 1061224662730752.0,
      "budget_used_percent": 1.061224662730752
    },
    {
      "type": "training",
      "description": "Training step 741",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:51",
      "total_flops_so_far": 1062656814772224.0,
      "budget_used_percent": 1.062656814772224
    },
    {
      "type": "training",
      "description": "Training step 742",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:51",
      "total_flops_so_far": 1064088966813696.0,
      "budget_used_percent": 1.064088966813696
    },
    {
      "type": "training",
      "description": "Training step 743",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:51",
      "total_flops_so_far": 1065521118855168.0,
      "budget_used_percent": 1.065521118855168
    },
    {
      "type": "training",
      "description": "Training step 744",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:51",
      "total_flops_so_far": 1066953270896640.0,
      "budget_used_percent": 1.06695327089664
    },
    {
      "type": "training",
      "description": "Training step 745",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:51",
      "total_flops_so_far": 1068385422938112.0,
      "budget_used_percent": 1.068385422938112
    },
    {
      "type": "training",
      "description": "Training step 746",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:51",
      "total_flops_so_far": 1069817574979584.0,
      "budget_used_percent": 1.069817574979584
    },
    {
      "type": "training",
      "description": "Training step 747",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:51",
      "total_flops_so_far": 1071249727021056.0,
      "budget_used_percent": 1.071249727021056
    },
    {
      "type": "training",
      "description": "Training step 748",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:52",
      "total_flops_so_far": 1072681879062528.0,
      "budget_used_percent": 1.0726818790625279
    },
    {
      "type": "training",
      "description": "Training step 749",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:52",
      "total_flops_so_far": 1074114031104000.0,
      "budget_used_percent": 1.074114031104
    },
    {
      "type": "training",
      "description": "Training step 750",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:52",
      "total_flops_so_far": 1075546183145472.0,
      "budget_used_percent": 1.075546183145472
    },
    {
      "type": "training",
      "description": "Training step 751",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:52",
      "total_flops_so_far": 1076978335186944.0,
      "budget_used_percent": 1.076978335186944
    },
    {
      "type": "training",
      "description": "Training step 752",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:52",
      "total_flops_so_far": 1078410487228416.0,
      "budget_used_percent": 1.0784104872284161
    },
    {
      "type": "training",
      "description": "Training step 753",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:52",
      "total_flops_so_far": 1079842639269888.0,
      "budget_used_percent": 1.079842639269888
    },
    {
      "type": "training",
      "description": "Training step 754",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:52",
      "total_flops_so_far": 1081274791311360.0,
      "budget_used_percent": 1.08127479131136
    },
    {
      "type": "training",
      "description": "Training step 755",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:53",
      "total_flops_so_far": 1082706943352832.0,
      "budget_used_percent": 1.082706943352832
    },
    {
      "type": "training",
      "description": "Training step 756",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:53",
      "total_flops_so_far": 1084139095394304.0,
      "budget_used_percent": 1.084139095394304
    },
    {
      "type": "training",
      "description": "Training step 757",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:53",
      "total_flops_so_far": 1085571247435776.0,
      "budget_used_percent": 1.085571247435776
    },
    {
      "type": "training",
      "description": "Training step 758",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:53",
      "total_flops_so_far": 1087003399477248.0,
      "budget_used_percent": 1.0870033994772481
    },
    {
      "type": "training",
      "description": "Training step 759",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:53",
      "total_flops_so_far": 1088435551518720.0,
      "budget_used_percent": 1.08843555151872
    },
    {
      "type": "training",
      "description": "Training step 760",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:53",
      "total_flops_so_far": 1089867703560192.0,
      "budget_used_percent": 1.089867703560192
    },
    {
      "type": "training",
      "description": "Training step 761",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:53",
      "total_flops_so_far": 1091299855601664.0,
      "budget_used_percent": 1.091299855601664
    },
    {
      "type": "training",
      "description": "Training step 762",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:54",
      "total_flops_so_far": 1092732007643136.0,
      "budget_used_percent": 1.092732007643136
    },
    {
      "type": "training",
      "description": "Training step 763",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:54",
      "total_flops_so_far": 1094164159684608.0,
      "budget_used_percent": 1.094164159684608
    },
    {
      "type": "training",
      "description": "Training step 764",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:54",
      "total_flops_so_far": 1095596311726080.0,
      "budget_used_percent": 1.0955963117260799
    },
    {
      "type": "training",
      "description": "Training step 765",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:54",
      "total_flops_so_far": 1097028463767552.0,
      "budget_used_percent": 1.097028463767552
    },
    {
      "type": "training",
      "description": "Training step 766",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:54",
      "total_flops_so_far": 1098460615809024.0,
      "budget_used_percent": 1.098460615809024
    },
    {
      "type": "training",
      "description": "Training step 767",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:54",
      "total_flops_so_far": 1099892767850496.0,
      "budget_used_percent": 1.099892767850496
    },
    {
      "type": "training",
      "description": "Training step 768",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:54",
      "total_flops_so_far": 1101324919891968.0,
      "budget_used_percent": 1.1013249198919681
    },
    {
      "type": "training",
      "description": "Training step 769",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:55",
      "total_flops_so_far": 1102757071933440.0,
      "budget_used_percent": 1.10275707193344
    },
    {
      "type": "training",
      "description": "Training step 770",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:55",
      "total_flops_so_far": 1104189223974912.0,
      "budget_used_percent": 1.1041892239749118
    },
    {
      "type": "training",
      "description": "Training step 771",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:55",
      "total_flops_so_far": 1105621376016384.0,
      "budget_used_percent": 1.105621376016384
    },
    {
      "type": "training",
      "description": "Training step 772",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:55",
      "total_flops_so_far": 1107053528057856.0,
      "budget_used_percent": 1.107053528057856
    },
    {
      "type": "training",
      "description": "Training step 773",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:55",
      "total_flops_so_far": 1108485680099328.0,
      "budget_used_percent": 1.108485680099328
    },
    {
      "type": "training",
      "description": "Training step 774",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:55",
      "total_flops_so_far": 1109917832140800.0,
      "budget_used_percent": 1.1099178321408
    },
    {
      "type": "training",
      "description": "Training step 775",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:55",
      "total_flops_so_far": 1111349984182272.0,
      "budget_used_percent": 1.111349984182272
    },
    {
      "type": "training",
      "description": "Training step 776",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:56",
      "total_flops_so_far": 1112782136223744.0,
      "budget_used_percent": 1.112782136223744
    },
    {
      "type": "training",
      "description": "Training step 777",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:56",
      "total_flops_so_far": 1114214288265216.0,
      "budget_used_percent": 1.114214288265216
    },
    {
      "type": "training",
      "description": "Training step 778",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:56",
      "total_flops_so_far": 1115646440306688.0,
      "budget_used_percent": 1.115646440306688
    },
    {
      "type": "training",
      "description": "Training step 779",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:56",
      "total_flops_so_far": 1117078592348160.0,
      "budget_used_percent": 1.1170785923481599
    },
    {
      "type": "training",
      "description": "Training step 780",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:56",
      "total_flops_so_far": 1118510744389632.0,
      "budget_used_percent": 1.118510744389632
    },
    {
      "type": "training",
      "description": "Training step 781",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:56",
      "total_flops_so_far": 1119942896431104.0,
      "budget_used_percent": 1.119942896431104
    },
    {
      "type": "training",
      "description": "Training step 782",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:56",
      "total_flops_so_far": 1121375048472576.0,
      "budget_used_percent": 1.121375048472576
    },
    {
      "type": "training",
      "description": "Training step 783",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:57",
      "total_flops_so_far": 1122807200514048.0,
      "budget_used_percent": 1.1228072005140481
    },
    {
      "type": "training",
      "description": "Training step 784",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:57",
      "total_flops_so_far": 1124239352555520.0,
      "budget_used_percent": 1.12423935255552
    },
    {
      "type": "training",
      "description": "Training step 785",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:57",
      "total_flops_so_far": 1125671504596992.0,
      "budget_used_percent": 1.1256715045969918
    },
    {
      "type": "training",
      "description": "Training step 786",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:57",
      "total_flops_so_far": 1127103656638464.0,
      "budget_used_percent": 1.127103656638464
    },
    {
      "type": "training",
      "description": "Training step 787",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:57",
      "total_flops_so_far": 1128535808679936.0,
      "budget_used_percent": 1.128535808679936
    },
    {
      "type": "training",
      "description": "Training step 788",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:57",
      "total_flops_so_far": 1129967960721408.0,
      "budget_used_percent": 1.129967960721408
    },
    {
      "type": "training",
      "description": "Training step 789",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:57",
      "total_flops_so_far": 1131400112762880.0,
      "budget_used_percent": 1.13140011276288
    },
    {
      "type": "training",
      "description": "Training step 790",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:58",
      "total_flops_so_far": 1132832264804352.0,
      "budget_used_percent": 1.132832264804352
    },
    {
      "type": "training",
      "description": "Training step 791",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:58",
      "total_flops_so_far": 1134264416845824.0,
      "budget_used_percent": 1.134264416845824
    },
    {
      "type": "training",
      "description": "Training step 792",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:58",
      "total_flops_so_far": 1135696568887296.0,
      "budget_used_percent": 1.135696568887296
    },
    {
      "type": "training",
      "description": "Training step 793",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:58",
      "total_flops_so_far": 1137128720928768.0,
      "budget_used_percent": 1.137128720928768
    },
    {
      "type": "training",
      "description": "Training step 794",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:58",
      "total_flops_so_far": 1138560872970240.0,
      "budget_used_percent": 1.13856087297024
    },
    {
      "type": "training",
      "description": "Training step 795",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:58",
      "total_flops_so_far": 1139993025011712.0,
      "budget_used_percent": 1.139993025011712
    },
    {
      "type": "training",
      "description": "Training step 796",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:58",
      "total_flops_so_far": 1141425177053184.0,
      "budget_used_percent": 1.141425177053184
    },
    {
      "type": "training",
      "description": "Training step 797",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:59",
      "total_flops_so_far": 1142857329094656.0,
      "budget_used_percent": 1.142857329094656
    },
    {
      "type": "training",
      "description": "Training step 798",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:59",
      "total_flops_so_far": 1144289481136128.0,
      "budget_used_percent": 1.1442894811361282
    },
    {
      "type": "training",
      "description": "Training step 799",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:59",
      "total_flops_so_far": 1145721633177600.0,
      "budget_used_percent": 1.1457216331776
    },
    {
      "type": "training",
      "description": "Training step 800",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:59",
      "total_flops_so_far": 1147153785219072.0,
      "budget_used_percent": 1.1471537852190719
    },
    {
      "type": "training",
      "description": "Training step 801",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:59",
      "total_flops_so_far": 1148585937260544.0,
      "budget_used_percent": 1.148585937260544
    },
    {
      "type": "training",
      "description": "Training step 802",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:59",
      "total_flops_so_far": 1150018089302016.0,
      "budget_used_percent": 1.150018089302016
    },
    {
      "type": "training",
      "description": "Training step 803",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:24:59",
      "total_flops_so_far": 1151450241343488.0,
      "budget_used_percent": 1.151450241343488
    },
    {
      "type": "training",
      "description": "Training step 804",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:00",
      "total_flops_so_far": 1152882393384960.0,
      "budget_used_percent": 1.1528823933849601
    },
    {
      "type": "training",
      "description": "Training step 805",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:00",
      "total_flops_so_far": 1154314545426432.0,
      "budget_used_percent": 1.154314545426432
    },
    {
      "type": "training",
      "description": "Training step 806",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:00",
      "total_flops_so_far": 1155746697467904.0,
      "budget_used_percent": 1.155746697467904
    },
    {
      "type": "training",
      "description": "Training step 807",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:00",
      "total_flops_so_far": 1157178849509376.0,
      "budget_used_percent": 1.157178849509376
    },
    {
      "type": "training",
      "description": "Training step 808",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:00",
      "total_flops_so_far": 1158611001550848.0,
      "budget_used_percent": 1.158611001550848
    },
    {
      "type": "training",
      "description": "Training step 809",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:00",
      "total_flops_so_far": 1160043153592320.0,
      "budget_used_percent": 1.16004315359232
    },
    {
      "type": "training",
      "description": "Training step 810",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:00",
      "total_flops_so_far": 1161475305633792.0,
      "budget_used_percent": 1.161475305633792
    },
    {
      "type": "training",
      "description": "Training step 811",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:01",
      "total_flops_so_far": 1162907457675264.0,
      "budget_used_percent": 1.162907457675264
    },
    {
      "type": "training",
      "description": "Training step 812",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:01",
      "total_flops_so_far": 1164339609716736.0,
      "budget_used_percent": 1.164339609716736
    },
    {
      "type": "training",
      "description": "Training step 813",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:01",
      "total_flops_so_far": 1165771761758208.0,
      "budget_used_percent": 1.165771761758208
    },
    {
      "type": "training",
      "description": "Training step 814",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:01",
      "total_flops_so_far": 1167203913799680.0,
      "budget_used_percent": 1.16720391379968
    },
    {
      "type": "training",
      "description": "Training step 815",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:01",
      "total_flops_so_far": 1168636065841152.0,
      "budget_used_percent": 1.1686360658411519
    },
    {
      "type": "training",
      "description": "Training step 816",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:01",
      "total_flops_so_far": 1170068217882624.0,
      "budget_used_percent": 1.170068217882624
    },
    {
      "type": "training",
      "description": "Training step 817",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:02",
      "total_flops_so_far": 1171500369924096.0,
      "budget_used_percent": 1.171500369924096
    },
    {
      "type": "training",
      "description": "Training step 818",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:02",
      "total_flops_so_far": 1172932521965568.0,
      "budget_used_percent": 1.172932521965568
    },
    {
      "type": "training",
      "description": "Training step 819",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:02",
      "total_flops_so_far": 1174364674007040.0,
      "budget_used_percent": 1.1743646740070401
    },
    {
      "type": "training",
      "description": "Training step 820",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:02",
      "total_flops_so_far": 1175796826048512.0,
      "budget_used_percent": 1.175796826048512
    },
    {
      "type": "training",
      "description": "Training step 821",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:02",
      "total_flops_so_far": 1177228978089984.0,
      "budget_used_percent": 1.177228978089984
    },
    {
      "type": "training",
      "description": "Training step 822",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:02",
      "total_flops_so_far": 1178661130131456.0,
      "budget_used_percent": 1.178661130131456
    },
    {
      "type": "training",
      "description": "Training step 823",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:02",
      "total_flops_so_far": 1180093282172928.0,
      "budget_used_percent": 1.180093282172928
    },
    {
      "type": "training",
      "description": "Training step 824",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:03",
      "total_flops_so_far": 1181525434214400.0,
      "budget_used_percent": 1.1815254342144
    },
    {
      "type": "training",
      "description": "Training step 825",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:03",
      "total_flops_so_far": 1182957586255872.0,
      "budget_used_percent": 1.182957586255872
    },
    {
      "type": "training",
      "description": "Training step 826",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:03",
      "total_flops_so_far": 1184389738297344.0,
      "budget_used_percent": 1.184389738297344
    },
    {
      "type": "training",
      "description": "Training step 827",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:03",
      "total_flops_so_far": 1185821890338816.0,
      "budget_used_percent": 1.185821890338816
    },
    {
      "type": "training",
      "description": "Training step 828",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:03",
      "total_flops_so_far": 1187254042380288.0,
      "budget_used_percent": 1.187254042380288
    },
    {
      "type": "training",
      "description": "Training step 829",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:03",
      "total_flops_so_far": 1188686194421760.0,
      "budget_used_percent": 1.18868619442176
    },
    {
      "type": "training",
      "description": "Training step 830",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:03",
      "total_flops_so_far": 1190118346463232.0,
      "budget_used_percent": 1.190118346463232
    },
    {
      "type": "training",
      "description": "Training step 831",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:04",
      "total_flops_so_far": 1191550498504704.0,
      "budget_used_percent": 1.191550498504704
    },
    {
      "type": "training",
      "description": "Training step 832",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:04",
      "total_flops_so_far": 1192982650546176.0,
      "budget_used_percent": 1.192982650546176
    },
    {
      "type": "training",
      "description": "Training step 833",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:04",
      "total_flops_so_far": 1194414802587648.0,
      "budget_used_percent": 1.194414802587648
    },
    {
      "type": "training",
      "description": "Training step 834",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:04",
      "total_flops_so_far": 1195846954629120.0,
      "budget_used_percent": 1.1958469546291202
    },
    {
      "type": "training",
      "description": "Training step 835",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:04",
      "total_flops_so_far": 1197279106670592.0,
      "budget_used_percent": 1.1972791066705921
    },
    {
      "type": "training",
      "description": "Training step 836",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:04",
      "total_flops_so_far": 1198711258712064.0,
      "budget_used_percent": 1.198711258712064
    },
    {
      "type": "training",
      "description": "Training step 837",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:04",
      "total_flops_so_far": 1200143410753536.0,
      "budget_used_percent": 1.2001434107535358
    },
    {
      "type": "training",
      "description": "Training step 838",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:05",
      "total_flops_so_far": 1201575562795008.0,
      "budget_used_percent": 1.201575562795008
    },
    {
      "type": "training",
      "description": "Training step 839",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:05",
      "total_flops_so_far": 1203007714836480.0,
      "budget_used_percent": 1.20300771483648
    },
    {
      "type": "training",
      "description": "Training step 840",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:05",
      "total_flops_so_far": 1204439866877952.0,
      "budget_used_percent": 1.204439866877952
    },
    {
      "type": "training",
      "description": "Training step 841",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:05",
      "total_flops_so_far": 1205872018919424.0,
      "budget_used_percent": 1.205872018919424
    },
    {
      "type": "training",
      "description": "Training step 842",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:05",
      "total_flops_so_far": 1207304170960896.0,
      "budget_used_percent": 1.207304170960896
    },
    {
      "type": "training",
      "description": "Training step 843",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:05",
      "total_flops_so_far": 1208736323002368.0,
      "budget_used_percent": 1.208736323002368
    },
    {
      "type": "training",
      "description": "Training step 844",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:05",
      "total_flops_so_far": 1210168475043840.0,
      "budget_used_percent": 1.21016847504384
    },
    {
      "type": "training",
      "description": "Training step 845",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:06",
      "total_flops_so_far": 1211600627085312.0,
      "budget_used_percent": 1.211600627085312
    },
    {
      "type": "training",
      "description": "Training step 846",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:06",
      "total_flops_so_far": 1213032779126784.0,
      "budget_used_percent": 1.2130327791267839
    },
    {
      "type": "training",
      "description": "Training step 847",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:06",
      "total_flops_so_far": 1214464931168256.0,
      "budget_used_percent": 1.214464931168256
    },
    {
      "type": "training",
      "description": "Training step 848",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:06",
      "total_flops_so_far": 1215897083209728.0,
      "budget_used_percent": 1.215897083209728
    },
    {
      "type": "training",
      "description": "Training step 849",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:06",
      "total_flops_so_far": 1217329235251200.0,
      "budget_used_percent": 1.2173292352512
    },
    {
      "type": "training",
      "description": "Training step 850",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:06",
      "total_flops_so_far": 1218761387292672.0,
      "budget_used_percent": 1.2187613872926721
    },
    {
      "type": "training",
      "description": "Training step 851",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:06",
      "total_flops_so_far": 1220193539334144.0,
      "budget_used_percent": 1.220193539334144
    },
    {
      "type": "training",
      "description": "Training step 852",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:07",
      "total_flops_so_far": 1221625691375616.0,
      "budget_used_percent": 1.2216256913756158
    },
    {
      "type": "training",
      "description": "Training step 853",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:07",
      "total_flops_so_far": 1223057843417088.0,
      "budget_used_percent": 1.223057843417088
    },
    {
      "type": "training",
      "description": "Training step 854",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:07",
      "total_flops_so_far": 1224489995458560.0,
      "budget_used_percent": 1.22448999545856
    },
    {
      "type": "training",
      "description": "Training step 855",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:07",
      "total_flops_so_far": 1225922147500032.0,
      "budget_used_percent": 1.225922147500032
    },
    {
      "type": "training",
      "description": "Training step 856",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:07",
      "total_flops_so_far": 1227354299541504.0,
      "budget_used_percent": 1.227354299541504
    },
    {
      "type": "training",
      "description": "Training step 857",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:07",
      "total_flops_so_far": 1228786451582976.0,
      "budget_used_percent": 1.228786451582976
    },
    {
      "type": "training",
      "description": "Training step 858",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:08",
      "total_flops_so_far": 1230218603624448.0,
      "budget_used_percent": 1.230218603624448
    },
    {
      "type": "training",
      "description": "Training step 859",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:08",
      "total_flops_so_far": 1231650755665920.0,
      "budget_used_percent": 1.23165075566592
    },
    {
      "type": "training",
      "description": "Training step 860",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:08",
      "total_flops_so_far": 1233082907707392.0,
      "budget_used_percent": 1.233082907707392
    },
    {
      "type": "training",
      "description": "Training step 861",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:08",
      "total_flops_so_far": 1234515059748864.0,
      "budget_used_percent": 1.2345150597488639
    },
    {
      "type": "training",
      "description": "Training step 862",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:08",
      "total_flops_so_far": 1235947211790336.0,
      "budget_used_percent": 1.235947211790336
    },
    {
      "type": "training",
      "description": "Training step 863",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:08",
      "total_flops_so_far": 1237379363831808.0,
      "budget_used_percent": 1.237379363831808
    },
    {
      "type": "training",
      "description": "Training step 864",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:08",
      "total_flops_so_far": 1238811515873280.0,
      "budget_used_percent": 1.23881151587328
    },
    {
      "type": "training",
      "description": "Training step 865",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:09",
      "total_flops_so_far": 1240243667914752.0,
      "budget_used_percent": 1.2402436679147522
    },
    {
      "type": "training",
      "description": "Training step 866",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:09",
      "total_flops_so_far": 1241675819956224.0,
      "budget_used_percent": 1.241675819956224
    },
    {
      "type": "training",
      "description": "Training step 867",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:09",
      "total_flops_so_far": 1243107971997696.0,
      "budget_used_percent": 1.2431079719976958
    },
    {
      "type": "training",
      "description": "Training step 868",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:09",
      "total_flops_so_far": 1244540124039168.0,
      "budget_used_percent": 1.244540124039168
    },
    {
      "type": "training",
      "description": "Training step 869",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:09",
      "total_flops_so_far": 1245972276080640.0,
      "budget_used_percent": 1.24597227608064
    },
    {
      "type": "training",
      "description": "Training step 870",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:09",
      "total_flops_so_far": 1247404428122112.0,
      "budget_used_percent": 1.247404428122112
    },
    {
      "type": "training",
      "description": "Training step 871",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:09",
      "total_flops_so_far": 1248836580163584.0,
      "budget_used_percent": 1.2488365801635841
    },
    {
      "type": "training",
      "description": "Training step 872",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:10",
      "total_flops_so_far": 1250268732205056.0,
      "budget_used_percent": 1.250268732205056
    },
    {
      "type": "training",
      "description": "Training step 873",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:10",
      "total_flops_so_far": 1251700884246528.0,
      "budget_used_percent": 1.251700884246528
    },
    {
      "type": "training",
      "description": "Training step 874",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:10",
      "total_flops_so_far": 1253133036288000.0,
      "budget_used_percent": 1.253133036288
    },
    {
      "type": "training",
      "description": "Training step 875",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:10",
      "total_flops_so_far": 1254565188329472.0,
      "budget_used_percent": 1.254565188329472
    },
    {
      "type": "training",
      "description": "Training step 876",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:10",
      "total_flops_so_far": 1255997340370944.0,
      "budget_used_percent": 1.255997340370944
    },
    {
      "type": "training",
      "description": "Training step 877",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:10",
      "total_flops_so_far": 1257429492412416.0,
      "budget_used_percent": 1.257429492412416
    },
    {
      "type": "training",
      "description": "Training step 878",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:10",
      "total_flops_so_far": 1258861644453888.0,
      "budget_used_percent": 1.258861644453888
    },
    {
      "type": "training",
      "description": "Training step 879",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:11",
      "total_flops_so_far": 1260293796495360.0,
      "budget_used_percent": 1.26029379649536
    },
    {
      "type": "training",
      "description": "Training step 880",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:11",
      "total_flops_so_far": 1261725948536832.0,
      "budget_used_percent": 1.261725948536832
    },
    {
      "type": "training",
      "description": "Training step 881",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:11",
      "total_flops_so_far": 1263158100578304.0,
      "budget_used_percent": 1.263158100578304
    },
    {
      "type": "training",
      "description": "Training step 882",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:11",
      "total_flops_so_far": 1264590252619776.0,
      "budget_used_percent": 1.2645902526197759
    },
    {
      "type": "training",
      "description": "Training step 883",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:11",
      "total_flops_so_far": 1266022404661248.0,
      "budget_used_percent": 1.266022404661248
    },
    {
      "type": "training",
      "description": "Training step 884",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:11",
      "total_flops_so_far": 1267454556702720.0,
      "budget_used_percent": 1.26745455670272
    },
    {
      "type": "training",
      "description": "Training step 885",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:11",
      "total_flops_so_far": 1268886708744192.0,
      "budget_used_percent": 1.268886708744192
    },
    {
      "type": "training",
      "description": "Training step 886",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:12",
      "total_flops_so_far": 1270318860785664.0,
      "budget_used_percent": 1.2703188607856641
    },
    {
      "type": "training",
      "description": "Training step 887",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:12",
      "total_flops_so_far": 1271751012827136.0,
      "budget_used_percent": 1.271751012827136
    },
    {
      "type": "training",
      "description": "Training step 888",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:12",
      "total_flops_so_far": 1273183164868608.0,
      "budget_used_percent": 1.273183164868608
    },
    {
      "type": "training",
      "description": "Training step 889",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:12",
      "total_flops_so_far": 1274615316910080.0,
      "budget_used_percent": 1.27461531691008
    },
    {
      "type": "training",
      "description": "Training step 890",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:12",
      "total_flops_so_far": 1276047468951552.0,
      "budget_used_percent": 1.276047468951552
    },
    {
      "type": "training",
      "description": "Training step 891",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:12",
      "total_flops_so_far": 1277479620993024.0,
      "budget_used_percent": 1.277479620993024
    },
    {
      "type": "training",
      "description": "Training step 892",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:12",
      "total_flops_so_far": 1278911773034496.0,
      "budget_used_percent": 1.278911773034496
    },
    {
      "type": "training",
      "description": "Training step 893",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:13",
      "total_flops_so_far": 1280343925075968.0,
      "budget_used_percent": 1.280343925075968
    },
    {
      "type": "training",
      "description": "Training step 894",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:13",
      "total_flops_so_far": 1281776077117440.0,
      "budget_used_percent": 1.28177607711744
    },
    {
      "type": "training",
      "description": "Training step 895",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:13",
      "total_flops_so_far": 1283208229158912.0,
      "budget_used_percent": 1.283208229158912
    },
    {
      "type": "training",
      "description": "Training step 896",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:13",
      "total_flops_so_far": 1284640381200384.0,
      "budget_used_percent": 1.284640381200384
    },
    {
      "type": "training",
      "description": "Training step 897",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:13",
      "total_flops_so_far": 1286072533241856.0,
      "budget_used_percent": 1.2860725332418559
    },
    {
      "type": "training",
      "description": "Training step 898",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:13",
      "total_flops_so_far": 1287504685283328.0,
      "budget_used_percent": 1.287504685283328
    },
    {
      "type": "training",
      "description": "Training step 899",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:13",
      "total_flops_so_far": 1288936837324800.0,
      "budget_used_percent": 1.2889368373248
    },
    {
      "type": "training",
      "description": "Training step 900",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:14",
      "total_flops_so_far": 1290368989366272.0,
      "budget_used_percent": 1.290368989366272
    },
    {
      "type": "training",
      "description": "Training step 901",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:14",
      "total_flops_so_far": 1291801141407744.0,
      "budget_used_percent": 1.2918011414077442
    },
    {
      "type": "training",
      "description": "Training step 902",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:14",
      "total_flops_so_far": 1293233293449216.0,
      "budget_used_percent": 1.2932332934492161
    },
    {
      "type": "training",
      "description": "Training step 903",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:14",
      "total_flops_so_far": 1294665445490688.0,
      "budget_used_percent": 1.294665445490688
    },
    {
      "type": "training",
      "description": "Training step 904",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:14",
      "total_flops_so_far": 1296097597532160.0,
      "budget_used_percent": 1.29609759753216
    },
    {
      "type": "training",
      "description": "Training step 905",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:14",
      "total_flops_so_far": 1297529749573632.0,
      "budget_used_percent": 1.297529749573632
    },
    {
      "type": "training",
      "description": "Training step 906",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:14",
      "total_flops_so_far": 1298961901615104.0,
      "budget_used_percent": 1.298961901615104
    },
    {
      "type": "training",
      "description": "Training step 907",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:15",
      "total_flops_so_far": 1300394053656576.0,
      "budget_used_percent": 1.3003940536565761
    },
    {
      "type": "training",
      "description": "Training step 908",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:15",
      "total_flops_so_far": 1301826205698048.0,
      "budget_used_percent": 1.301826205698048
    },
    {
      "type": "training",
      "description": "Training step 909",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:15",
      "total_flops_so_far": 1303258357739520.0,
      "budget_used_percent": 1.30325835773952
    },
    {
      "type": "training",
      "description": "Training step 910",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:15",
      "total_flops_so_far": 1304690509780992.0,
      "budget_used_percent": 1.304690509780992
    },
    {
      "type": "training",
      "description": "Training step 911",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:15",
      "total_flops_so_far": 1306122661822464.0,
      "budget_used_percent": 1.306122661822464
    },
    {
      "type": "training",
      "description": "Training step 912",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:15",
      "total_flops_so_far": 1307554813863936.0,
      "budget_used_percent": 1.307554813863936
    },
    {
      "type": "training",
      "description": "Training step 913",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:15",
      "total_flops_so_far": 1308986965905408.0,
      "budget_used_percent": 1.3089869659054079
    },
    {
      "type": "training",
      "description": "Training step 914",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:16",
      "total_flops_so_far": 1310419117946880.0,
      "budget_used_percent": 1.31041911794688
    },
    {
      "type": "training",
      "description": "Training step 915",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:16",
      "total_flops_so_far": 1311851269988352.0,
      "budget_used_percent": 1.311851269988352
    },
    {
      "type": "training",
      "description": "Training step 916",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:16",
      "total_flops_so_far": 1313283422029824.0,
      "budget_used_percent": 1.313283422029824
    },
    {
      "type": "training",
      "description": "Training step 917",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:16",
      "total_flops_so_far": 1314715574071296.0,
      "budget_used_percent": 1.3147155740712961
    },
    {
      "type": "training",
      "description": "Training step 918",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:16",
      "total_flops_so_far": 1316147726112768.0,
      "budget_used_percent": 1.316147726112768
    },
    {
      "type": "training",
      "description": "Training step 919",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:16",
      "total_flops_so_far": 1317579878154240.0,
      "budget_used_percent": 1.3175798781542398
    },
    {
      "type": "training",
      "description": "Training step 920",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:16",
      "total_flops_so_far": 1319012030195712.0,
      "budget_used_percent": 1.319012030195712
    },
    {
      "type": "training",
      "description": "Training step 921",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:17",
      "total_flops_so_far": 1320444182237184.0,
      "budget_used_percent": 1.320444182237184
    },
    {
      "type": "training",
      "description": "Training step 922",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:17",
      "total_flops_so_far": 1321876334278656.0,
      "budget_used_percent": 1.321876334278656
    },
    {
      "type": "training",
      "description": "Training step 923",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:17",
      "total_flops_so_far": 1323308486320128.0,
      "budget_used_percent": 1.323308486320128
    },
    {
      "type": "training",
      "description": "Training step 924",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:17",
      "total_flops_so_far": 1324740638361600.0,
      "budget_used_percent": 1.3247406383616
    },
    {
      "type": "training",
      "description": "Training step 925",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:17",
      "total_flops_so_far": 1326172790403072.0,
      "budget_used_percent": 1.326172790403072
    },
    {
      "type": "training",
      "description": "Training step 926",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:17",
      "total_flops_so_far": 1327604942444544.0,
      "budget_used_percent": 1.327604942444544
    },
    {
      "type": "training",
      "description": "Training step 927",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:18",
      "total_flops_so_far": 1329037094486016.0,
      "budget_used_percent": 1.329037094486016
    },
    {
      "type": "training",
      "description": "Training step 928",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:18",
      "total_flops_so_far": 1330469246527488.0,
      "budget_used_percent": 1.3304692465274879
    },
    {
      "type": "training",
      "description": "Training step 929",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:18",
      "total_flops_so_far": 1331901398568960.0,
      "budget_used_percent": 1.33190139856896
    },
    {
      "type": "training",
      "description": "Training step 930",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:18",
      "total_flops_so_far": 1333333550610432.0,
      "budget_used_percent": 1.333333550610432
    },
    {
      "type": "training",
      "description": "Training step 931",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:18",
      "total_flops_so_far": 1334765702651904.0,
      "budget_used_percent": 1.334765702651904
    },
    {
      "type": "training",
      "description": "Training step 932",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:18",
      "total_flops_so_far": 1336197854693376.0,
      "budget_used_percent": 1.3361978546933762
    },
    {
      "type": "training",
      "description": "Training step 933",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:18",
      "total_flops_so_far": 1337630006734848.0,
      "budget_used_percent": 1.3376300067348479
    },
    {
      "type": "training",
      "description": "Training step 934",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:19",
      "total_flops_so_far": 1339062158776320.0,
      "budget_used_percent": 1.3390621587763198
    },
    {
      "type": "training",
      "description": "Training step 935",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:19",
      "total_flops_so_far": 1340494310817792.0,
      "budget_used_percent": 1.340494310817792
    },
    {
      "type": "training",
      "description": "Training step 936",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:19",
      "total_flops_so_far": 1341926462859264.0,
      "budget_used_percent": 1.341926462859264
    },
    {
      "type": "training",
      "description": "Training step 937",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:19",
      "total_flops_so_far": 1343358614900736.0,
      "budget_used_percent": 1.343358614900736
    },
    {
      "type": "training",
      "description": "Training step 938",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:19",
      "total_flops_so_far": 1344790766942208.0,
      "budget_used_percent": 1.3447907669422081
    },
    {
      "type": "training",
      "description": "Training step 939",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:19",
      "total_flops_so_far": 1346222918983680.0,
      "budget_used_percent": 1.34622291898368
    },
    {
      "type": "training",
      "description": "Training step 940",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:19",
      "total_flops_so_far": 1347655071025152.0,
      "budget_used_percent": 1.347655071025152
    },
    {
      "type": "training",
      "description": "Training step 941",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:20",
      "total_flops_so_far": 1349087223066624.0,
      "budget_used_percent": 1.349087223066624
    },
    {
      "type": "training",
      "description": "Training step 942",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:20",
      "total_flops_so_far": 1350519375108096.0,
      "budget_used_percent": 1.350519375108096
    },
    {
      "type": "training",
      "description": "Training step 943",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:20",
      "total_flops_so_far": 1351951527149568.0,
      "budget_used_percent": 1.351951527149568
    },
    {
      "type": "training",
      "description": "Training step 944",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:20",
      "total_flops_so_far": 1353383679191040.0,
      "budget_used_percent": 1.35338367919104
    },
    {
      "type": "training",
      "description": "Training step 945",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:20",
      "total_flops_so_far": 1354815831232512.0,
      "budget_used_percent": 1.354815831232512
    },
    {
      "type": "training",
      "description": "Training step 946",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:20",
      "total_flops_so_far": 1356247983273984.0,
      "budget_used_percent": 1.356247983273984
    },
    {
      "type": "training",
      "description": "Training step 947",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:20",
      "total_flops_so_far": 1357680135315456.0,
      "budget_used_percent": 1.357680135315456
    },
    {
      "type": "training",
      "description": "Training step 948",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:21",
      "total_flops_so_far": 1359112287356928.0,
      "budget_used_percent": 1.359112287356928
    },
    {
      "type": "training",
      "description": "Training step 949",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:21",
      "total_flops_so_far": 1360544439398400.0,
      "budget_used_percent": 1.3605444393983999
    },
    {
      "type": "training",
      "description": "Training step 950",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:21",
      "total_flops_so_far": 1361976591439872.0,
      "budget_used_percent": 1.361976591439872
    },
    {
      "type": "training",
      "description": "Training step 951",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:21",
      "total_flops_so_far": 1363408743481344.0,
      "budget_used_percent": 1.363408743481344
    },
    {
      "type": "training",
      "description": "Training step 952",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:21",
      "total_flops_so_far": 1364840895522816.0,
      "budget_used_percent": 1.364840895522816
    },
    {
      "type": "training",
      "description": "Training step 953",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:21",
      "total_flops_so_far": 1366273047564288.0,
      "budget_used_percent": 1.3662730475642881
    },
    {
      "type": "training",
      "description": "Training step 954",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:21",
      "total_flops_so_far": 1367705199605760.0,
      "budget_used_percent": 1.36770519960576
    },
    {
      "type": "training",
      "description": "Training step 955",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:22",
      "total_flops_so_far": 1369137351647232.0,
      "budget_used_percent": 1.369137351647232
    },
    {
      "type": "training",
      "description": "Training step 956",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:22",
      "total_flops_so_far": 1370569503688704.0,
      "budget_used_percent": 1.370569503688704
    },
    {
      "type": "training",
      "description": "Training step 957",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:22",
      "total_flops_so_far": 1372001655730176.0,
      "budget_used_percent": 1.372001655730176
    },
    {
      "type": "training",
      "description": "Training step 958",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:22",
      "total_flops_so_far": 1373433807771648.0,
      "budget_used_percent": 1.373433807771648
    },
    {
      "type": "training",
      "description": "Training step 959",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:22",
      "total_flops_so_far": 1374865959813120.0,
      "budget_used_percent": 1.37486595981312
    },
    {
      "type": "training",
      "description": "Training step 960",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:22",
      "total_flops_so_far": 1376298111854592.0,
      "budget_used_percent": 1.376298111854592
    },
    {
      "type": "training",
      "description": "Training step 961",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:23",
      "total_flops_so_far": 1377730263896064.0,
      "budget_used_percent": 1.377730263896064
    },
    {
      "type": "training",
      "description": "Training step 962",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:23",
      "total_flops_so_far": 1379162415937536.0,
      "budget_used_percent": 1.379162415937536
    },
    {
      "type": "training",
      "description": "Training step 963",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:23",
      "total_flops_so_far": 1380594567979008.0,
      "budget_used_percent": 1.380594567979008
    },
    {
      "type": "training",
      "description": "Training step 964",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:23",
      "total_flops_so_far": 1382026720020480.0,
      "budget_used_percent": 1.3820267200204799
    },
    {
      "type": "training",
      "description": "Training step 965",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:23",
      "total_flops_so_far": 1383458872061952.0,
      "budget_used_percent": 1.383458872061952
    },
    {
      "type": "training",
      "description": "Training step 966",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:23",
      "total_flops_so_far": 1384891024103424.0,
      "budget_used_percent": 1.384891024103424
    },
    {
      "type": "training",
      "description": "Training step 967",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:23",
      "total_flops_so_far": 1386323176144896.0,
      "budget_used_percent": 1.386323176144896
    },
    {
      "type": "training",
      "description": "Training step 968",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:24",
      "total_flops_so_far": 1387755328186368.0,
      "budget_used_percent": 1.3877553281863682
    },
    {
      "type": "training",
      "description": "Training step 969",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:24",
      "total_flops_so_far": 1389187480227840.0,
      "budget_used_percent": 1.38918748022784
    },
    {
      "type": "training",
      "description": "Training step 970",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:24",
      "total_flops_so_far": 1390619632269312.0,
      "budget_used_percent": 1.390619632269312
    },
    {
      "type": "training",
      "description": "Training step 971",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:24",
      "total_flops_so_far": 1392051784310784.0,
      "budget_used_percent": 1.392051784310784
    },
    {
      "type": "training",
      "description": "Training step 972",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:24",
      "total_flops_so_far": 1393483936352256.0,
      "budget_used_percent": 1.393483936352256
    },
    {
      "type": "training",
      "description": "Training step 973",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:25",
      "total_flops_so_far": 1394916088393728.0,
      "budget_used_percent": 1.394916088393728
    },
    {
      "type": "training",
      "description": "Training step 974",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:25",
      "total_flops_so_far": 1396348240435200.0,
      "budget_used_percent": 1.3963482404352001
    },
    {
      "type": "training",
      "description": "Training step 975",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:25",
      "total_flops_so_far": 1397780392476672.0,
      "budget_used_percent": 1.397780392476672
    },
    {
      "type": "training",
      "description": "Training step 976",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:25",
      "total_flops_so_far": 1399212544518144.0,
      "budget_used_percent": 1.399212544518144
    },
    {
      "type": "training",
      "description": "Training step 977",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:25",
      "total_flops_so_far": 1400644696559616.0,
      "budget_used_percent": 1.400644696559616
    },
    {
      "type": "training",
      "description": "Training step 978",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:25",
      "total_flops_so_far": 1402076848601088.0,
      "budget_used_percent": 1.402076848601088
    },
    {
      "type": "training",
      "description": "Training step 979",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:25",
      "total_flops_so_far": 1403509000642560.0,
      "budget_used_percent": 1.40350900064256
    },
    {
      "type": "training",
      "description": "Training step 980",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:26",
      "total_flops_so_far": 1404941152684032.0,
      "budget_used_percent": 1.404941152684032
    },
    {
      "type": "training",
      "description": "Training step 981",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:26",
      "total_flops_so_far": 1406373304725504.0,
      "budget_used_percent": 1.406373304725504
    },
    {
      "type": "training",
      "description": "Training step 982",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:26",
      "total_flops_so_far": 1407805456766976.0,
      "budget_used_percent": 1.407805456766976
    },
    {
      "type": "training",
      "description": "Training step 983",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:26",
      "total_flops_so_far": 1409237608808448.0,
      "budget_used_percent": 1.409237608808448
    },
    {
      "type": "training",
      "description": "Training step 984",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:26",
      "total_flops_so_far": 1410669760849920.0,
      "budget_used_percent": 1.4106697608499201
    },
    {
      "type": "training",
      "description": "Training step 985",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:26",
      "total_flops_so_far": 1412101912891392.0,
      "budget_used_percent": 1.412101912891392
    },
    {
      "type": "training",
      "description": "Training step 986",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:26",
      "total_flops_so_far": 1413534064932864.0,
      "budget_used_percent": 1.4135340649328638
    },
    {
      "type": "training",
      "description": "Training step 987",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:27",
      "total_flops_so_far": 1414966216974336.0,
      "budget_used_percent": 1.414966216974336
    },
    {
      "type": "training",
      "description": "Training step 988",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:27",
      "total_flops_so_far": 1416398369015808.0,
      "budget_used_percent": 1.416398369015808
    },
    {
      "type": "training",
      "description": "Training step 989",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:27",
      "total_flops_so_far": 1417830521057280.0,
      "budget_used_percent": 1.41783052105728
    },
    {
      "type": "training",
      "description": "Training step 990",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:27",
      "total_flops_so_far": 1419262673098752.0,
      "budget_used_percent": 1.419262673098752
    },
    {
      "type": "training",
      "description": "Training step 991",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:27",
      "total_flops_so_far": 1420694825140224.0,
      "budget_used_percent": 1.420694825140224
    },
    {
      "type": "training",
      "description": "Training step 992",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:27",
      "total_flops_so_far": 1422126977181696.0,
      "budget_used_percent": 1.422126977181696
    },
    {
      "type": "training",
      "description": "Training step 993",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:27",
      "total_flops_so_far": 1423559129223168.0,
      "budget_used_percent": 1.423559129223168
    },
    {
      "type": "training",
      "description": "Training step 994",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:28",
      "total_flops_so_far": 1424991281264640.0,
      "budget_used_percent": 1.42499128126464
    },
    {
      "type": "training",
      "description": "Training step 995",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:28",
      "total_flops_so_far": 1426423433306112.0,
      "budget_used_percent": 1.4264234333061119
    },
    {
      "type": "training",
      "description": "Training step 996",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:28",
      "total_flops_so_far": 1427855585347584.0,
      "budget_used_percent": 1.427855585347584
    },
    {
      "type": "training",
      "description": "Training step 997",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:28",
      "total_flops_so_far": 1429287737389056.0,
      "budget_used_percent": 1.429287737389056
    },
    {
      "type": "training",
      "description": "Training step 998",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:28",
      "total_flops_so_far": 1430719889430528.0,
      "budget_used_percent": 1.430719889430528
    },
    {
      "type": "training",
      "description": "Training step 999",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:25:28",
      "total_flops_so_far": 1432152041472000.0,
      "budget_used_percent": 1.4321520414720001
    },
    {
      "type": "training",
      "description": "Training step 1000",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:50",
      "total_flops_so_far": 1433584193513472.0,
      "budget_used_percent": 1.4335841935134719
    },
    {
      "type": "training",
      "description": "Training step 1001",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:51",
      "total_flops_so_far": 1435016345554944.0,
      "budget_used_percent": 1.4350163455549438
    },
    {
      "type": "training",
      "description": "Training step 1002",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:51",
      "total_flops_so_far": 1436448497596416.0,
      "budget_used_percent": 1.436448497596416
    },
    {
      "type": "training",
      "description": "Training step 1003",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:51",
      "total_flops_so_far": 1437880649637888.0,
      "budget_used_percent": 1.437880649637888
    },
    {
      "type": "training",
      "description": "Training step 1004",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:51",
      "total_flops_so_far": 1439312801679360.0,
      "budget_used_percent": 1.43931280167936
    },
    {
      "type": "training",
      "description": "Training step 1005",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:51",
      "total_flops_so_far": 1440744953720832.0,
      "budget_used_percent": 1.4407449537208321
    },
    {
      "type": "training",
      "description": "Training step 1006",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:51",
      "total_flops_so_far": 1442177105762304.0,
      "budget_used_percent": 1.442177105762304
    },
    {
      "type": "training",
      "description": "Training step 1007",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:52",
      "total_flops_so_far": 1443609257803776.0,
      "budget_used_percent": 1.443609257803776
    },
    {
      "type": "training",
      "description": "Training step 1008",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:52",
      "total_flops_so_far": 1445041409845248.0,
      "budget_used_percent": 1.445041409845248
    },
    {
      "type": "training",
      "description": "Training step 1009",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:52",
      "total_flops_so_far": 1446473561886720.0,
      "budget_used_percent": 1.44647356188672
    },
    {
      "type": "training",
      "description": "Training step 1010",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:52",
      "total_flops_so_far": 1447905713928192.0,
      "budget_used_percent": 1.447905713928192
    },
    {
      "type": "training",
      "description": "Training step 1011",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:52",
      "total_flops_so_far": 1449337865969664.0,
      "budget_used_percent": 1.449337865969664
    },
    {
      "type": "training",
      "description": "Training step 1012",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:52",
      "total_flops_so_far": 1450770018011136.0,
      "budget_used_percent": 1.450770018011136
    },
    {
      "type": "training",
      "description": "Training step 1013",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:52",
      "total_flops_so_far": 1452202170052608.0,
      "budget_used_percent": 1.452202170052608
    },
    {
      "type": "training",
      "description": "Training step 1014",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:53",
      "total_flops_so_far": 1453634322094080.0,
      "budget_used_percent": 1.45363432209408
    },
    {
      "type": "training",
      "description": "Training step 1015",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:53",
      "total_flops_so_far": 1455066474135552.0,
      "budget_used_percent": 1.455066474135552
    },
    {
      "type": "training",
      "description": "Training step 1016",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:53",
      "total_flops_so_far": 1456498626177024.0,
      "budget_used_percent": 1.4564986261770239
    },
    {
      "type": "training",
      "description": "Training step 1017",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:53",
      "total_flops_so_far": 1457930778218496.0,
      "budget_used_percent": 1.457930778218496
    },
    {
      "type": "training",
      "description": "Training step 1018",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:53",
      "total_flops_so_far": 1459362930259968.0,
      "budget_used_percent": 1.459362930259968
    },
    {
      "type": "training",
      "description": "Training step 1019",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:53",
      "total_flops_so_far": 1460795082301440.0,
      "budget_used_percent": 1.46079508230144
    },
    {
      "type": "training",
      "description": "Training step 1020",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:53",
      "total_flops_so_far": 1462227234342912.0,
      "budget_used_percent": 1.4622272343429121
    },
    {
      "type": "training",
      "description": "Training step 1021",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:54",
      "total_flops_so_far": 1463659386384384.0,
      "budget_used_percent": 1.463659386384384
    },
    {
      "type": "training",
      "description": "Training step 1022",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:54",
      "total_flops_so_far": 1465091538425856.0,
      "budget_used_percent": 1.465091538425856
    },
    {
      "type": "training",
      "description": "Training step 1023",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:54",
      "total_flops_so_far": 1466523690467328.0,
      "budget_used_percent": 1.466523690467328
    },
    {
      "type": "training",
      "description": "Training step 1024",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:54",
      "total_flops_so_far": 1467955842508800.0,
      "budget_used_percent": 1.4679558425088
    },
    {
      "type": "training",
      "description": "Training step 1025",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:54",
      "total_flops_so_far": 1469387994550272.0,
      "budget_used_percent": 1.469387994550272
    },
    {
      "type": "training",
      "description": "Training step 1026",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:54",
      "total_flops_so_far": 1470820146591744.0,
      "budget_used_percent": 1.470820146591744
    },
    {
      "type": "training",
      "description": "Training step 1027",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:54",
      "total_flops_so_far": 1472252298633216.0,
      "budget_used_percent": 1.472252298633216
    },
    {
      "type": "training",
      "description": "Training step 1028",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:55",
      "total_flops_so_far": 1473684450674688.0,
      "budget_used_percent": 1.473684450674688
    },
    {
      "type": "training",
      "description": "Training step 1029",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:55",
      "total_flops_so_far": 1475116602716160.0,
      "budget_used_percent": 1.47511660271616
    },
    {
      "type": "training",
      "description": "Training step 1030",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:55",
      "total_flops_so_far": 1476548754757632.0,
      "budget_used_percent": 1.476548754757632
    },
    {
      "type": "training",
      "description": "Training step 1031",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:55",
      "total_flops_so_far": 1477980906799104.0,
      "budget_used_percent": 1.4779809067991039
    },
    {
      "type": "training",
      "description": "Training step 1032",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:55",
      "total_flops_so_far": 1479413058840576.0,
      "budget_used_percent": 1.479413058840576
    },
    {
      "type": "training",
      "description": "Training step 1033",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:55",
      "total_flops_so_far": 1480845210882048.0,
      "budget_used_percent": 1.480845210882048
    },
    {
      "type": "training",
      "description": "Training step 1034",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:55",
      "total_flops_so_far": 1482277362923520.0,
      "budget_used_percent": 1.48227736292352
    },
    {
      "type": "training",
      "description": "Training step 1035",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:56",
      "total_flops_so_far": 1483709514964992.0,
      "budget_used_percent": 1.4837095149649921
    },
    {
      "type": "training",
      "description": "Training step 1036",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:56",
      "total_flops_so_far": 1485141667006464.0,
      "budget_used_percent": 1.485141667006464
    },
    {
      "type": "training",
      "description": "Training step 1037",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:56",
      "total_flops_so_far": 1486573819047936.0,
      "budget_used_percent": 1.486573819047936
    },
    {
      "type": "training",
      "description": "Training step 1038",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:56",
      "total_flops_so_far": 1488005971089408.0,
      "budget_used_percent": 1.488005971089408
    },
    {
      "type": "training",
      "description": "Training step 1039",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:56",
      "total_flops_so_far": 1489438123130880.0,
      "budget_used_percent": 1.48943812313088
    },
    {
      "type": "training",
      "description": "Training step 1040",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:56",
      "total_flops_so_far": 1490870275172352.0,
      "budget_used_percent": 1.490870275172352
    },
    {
      "type": "training",
      "description": "Training step 1041",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:56",
      "total_flops_so_far": 1492302427213824.0,
      "budget_used_percent": 1.4923024272138241
    },
    {
      "type": "training",
      "description": "Training step 1042",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:57",
      "total_flops_so_far": 1493734579255296.0,
      "budget_used_percent": 1.493734579255296
    },
    {
      "type": "training",
      "description": "Training step 1043",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:57",
      "total_flops_so_far": 1495166731296768.0,
      "budget_used_percent": 1.495166731296768
    },
    {
      "type": "training",
      "description": "Training step 1044",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:57",
      "total_flops_so_far": 1496598883338240.0,
      "budget_used_percent": 1.49659888333824
    },
    {
      "type": "training",
      "description": "Training step 1045",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:57",
      "total_flops_so_far": 1498031035379712.0,
      "budget_used_percent": 1.498031035379712
    },
    {
      "type": "training",
      "description": "Training step 1046",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:57",
      "total_flops_so_far": 1499463187421184.0,
      "budget_used_percent": 1.499463187421184
    },
    {
      "type": "training",
      "description": "Training step 1047",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:57",
      "total_flops_so_far": 1500895339462656.0,
      "budget_used_percent": 1.500895339462656
    },
    {
      "type": "training",
      "description": "Training step 1048",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:57",
      "total_flops_so_far": 1502327491504128.0,
      "budget_used_percent": 1.502327491504128
    },
    {
      "type": "training",
      "description": "Training step 1049",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:58",
      "total_flops_so_far": 1503759643545600.0,
      "budget_used_percent": 1.5037596435456
    },
    {
      "type": "training",
      "description": "Training step 1050",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:58",
      "total_flops_so_far": 1505191795587072.0,
      "budget_used_percent": 1.5051917955870722
    },
    {
      "type": "training",
      "description": "Training step 1051",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:58",
      "total_flops_so_far": 1506623947628544.0,
      "budget_used_percent": 1.5066239476285441
    },
    {
      "type": "training",
      "description": "Training step 1052",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:58",
      "total_flops_so_far": 1508056099670016.0,
      "budget_used_percent": 1.508056099670016
    },
    {
      "type": "training",
      "description": "Training step 1053",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:58",
      "total_flops_so_far": 1509488251711488.0,
      "budget_used_percent": 1.5094882517114878
    },
    {
      "type": "training",
      "description": "Training step 1054",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:58",
      "total_flops_so_far": 1510920403752960.0,
      "budget_used_percent": 1.51092040375296
    },
    {
      "type": "training",
      "description": "Training step 1055",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:58",
      "total_flops_so_far": 1512352555794432.0,
      "budget_used_percent": 1.512352555794432
    },
    {
      "type": "training",
      "description": "Training step 1056",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:59",
      "total_flops_so_far": 1513784707835904.0,
      "budget_used_percent": 1.513784707835904
    },
    {
      "type": "training",
      "description": "Training step 1057",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:59",
      "total_flops_so_far": 1515216859877376.0,
      "budget_used_percent": 1.515216859877376
    },
    {
      "type": "training",
      "description": "Training step 1058",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:59",
      "total_flops_so_far": 1516649011918848.0,
      "budget_used_percent": 1.516649011918848
    },
    {
      "type": "training",
      "description": "Training step 1059",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:59",
      "total_flops_so_far": 1518081163960320.0,
      "budget_used_percent": 1.51808116396032
    },
    {
      "type": "training",
      "description": "Training step 1060",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:59",
      "total_flops_so_far": 1519513316001792.0,
      "budget_used_percent": 1.519513316001792
    },
    {
      "type": "training",
      "description": "Training step 1061",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:59",
      "total_flops_so_far": 1520945468043264.0,
      "budget_used_percent": 1.520945468043264
    },
    {
      "type": "training",
      "description": "Training step 1062",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:27:59",
      "total_flops_so_far": 1522377620084736.0,
      "budget_used_percent": 1.5223776200847359
    },
    {
      "type": "training",
      "description": "Training step 1063",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:00",
      "total_flops_so_far": 1523809772126208.0,
      "budget_used_percent": 1.523809772126208
    },
    {
      "type": "training",
      "description": "Training step 1064",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:00",
      "total_flops_so_far": 1525241924167680.0,
      "budget_used_percent": 1.52524192416768
    },
    {
      "type": "training",
      "description": "Training step 1065",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:00",
      "total_flops_so_far": 1526674076209152.0,
      "budget_used_percent": 1.526674076209152
    },
    {
      "type": "training",
      "description": "Training step 1066",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:00",
      "total_flops_so_far": 1528106228250624.0,
      "budget_used_percent": 1.5281062282506241
    },
    {
      "type": "training",
      "description": "Training step 1067",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:00",
      "total_flops_so_far": 1529538380292096.0,
      "budget_used_percent": 1.5295383802920959
    },
    {
      "type": "training",
      "description": "Training step 1068",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:00",
      "total_flops_so_far": 1530970532333568.0,
      "budget_used_percent": 1.5309705323335678
    },
    {
      "type": "training",
      "description": "Training step 1069",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:00",
      "total_flops_so_far": 1532402684375040.0,
      "budget_used_percent": 1.53240268437504
    },
    {
      "type": "training",
      "description": "Training step 1070",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:01",
      "total_flops_so_far": 1533834836416512.0,
      "budget_used_percent": 1.533834836416512
    },
    {
      "type": "training",
      "description": "Training step 1071",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:01",
      "total_flops_so_far": 1535266988457984.0,
      "budget_used_percent": 1.535266988457984
    },
    {
      "type": "training",
      "description": "Training step 1072",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:01",
      "total_flops_so_far": 1536699140499456.0,
      "budget_used_percent": 1.536699140499456
    },
    {
      "type": "training",
      "description": "Training step 1073",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:01",
      "total_flops_so_far": 1538131292540928.0,
      "budget_used_percent": 1.538131292540928
    },
    {
      "type": "training",
      "description": "Training step 1074",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:01",
      "total_flops_so_far": 1539563444582400.0,
      "budget_used_percent": 1.5395634445824
    },
    {
      "type": "training",
      "description": "Training step 1075",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:01",
      "total_flops_so_far": 1540995596623872.0,
      "budget_used_percent": 1.540995596623872
    },
    {
      "type": "training",
      "description": "Training step 1076",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:01",
      "total_flops_so_far": 1542427748665344.0,
      "budget_used_percent": 1.542427748665344
    },
    {
      "type": "training",
      "description": "Training step 1077",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:02",
      "total_flops_so_far": 1543859900706816.0,
      "budget_used_percent": 1.543859900706816
    },
    {
      "type": "training",
      "description": "Training step 1078",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:02",
      "total_flops_so_far": 1545292052748288.0,
      "budget_used_percent": 1.545292052748288
    },
    {
      "type": "training",
      "description": "Training step 1079",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:02",
      "total_flops_so_far": 1546724204789760.0,
      "budget_used_percent": 1.54672420478976
    },
    {
      "type": "training",
      "description": "Training step 1080",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:02",
      "total_flops_so_far": 1548156356831232.0,
      "budget_used_percent": 1.548156356831232
    },
    {
      "type": "training",
      "description": "Training step 1081",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:02",
      "total_flops_so_far": 1549588508872704.0,
      "budget_used_percent": 1.549588508872704
    },
    {
      "type": "training",
      "description": "Training step 1082",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:02",
      "total_flops_so_far": 1551020660914176.0,
      "budget_used_percent": 1.551020660914176
    },
    {
      "type": "training",
      "description": "Training step 1083",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:03",
      "total_flops_so_far": 1552452812955648.0,
      "budget_used_percent": 1.5524528129556479
    },
    {
      "type": "training",
      "description": "Training step 1084",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:03",
      "total_flops_so_far": 1553884964997120.0,
      "budget_used_percent": 1.55388496499712
    },
    {
      "type": "training",
      "description": "Training step 1085",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:03",
      "total_flops_so_far": 1555317117038592.0,
      "budget_used_percent": 1.555317117038592
    },
    {
      "type": "training",
      "description": "Training step 1086",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:03",
      "total_flops_so_far": 1556749269080064.0,
      "budget_used_percent": 1.556749269080064
    },
    {
      "type": "training",
      "description": "Training step 1087",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:03",
      "total_flops_so_far": 1558181421121536.0,
      "budget_used_percent": 1.5581814211215361
    },
    {
      "type": "training",
      "description": "Training step 1088",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:03",
      "total_flops_so_far": 1559613573163008.0,
      "budget_used_percent": 1.559613573163008
    },
    {
      "type": "training",
      "description": "Training step 1089",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:03",
      "total_flops_so_far": 1561045725204480.0,
      "budget_used_percent": 1.56104572520448
    },
    {
      "type": "training",
      "description": "Training step 1090",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:04",
      "total_flops_so_far": 1562477877245952.0,
      "budget_used_percent": 1.562477877245952
    },
    {
      "type": "training",
      "description": "Training step 1091",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:04",
      "total_flops_so_far": 1563910029287424.0,
      "budget_used_percent": 1.5639100292874237
    },
    {
      "type": "training",
      "description": "Training step 1092",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:04",
      "total_flops_so_far": 1565342181328896.0,
      "budget_used_percent": 1.5653421813288961
    },
    {
      "type": "training",
      "description": "Training step 1093",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:04",
      "total_flops_so_far": 1566774333370368.0,
      "budget_used_percent": 1.566774333370368
    },
    {
      "type": "training",
      "description": "Training step 1094",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:04",
      "total_flops_so_far": 1568206485411840.0,
      "budget_used_percent": 1.56820648541184
    },
    {
      "type": "training",
      "description": "Training step 1095",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:04",
      "total_flops_so_far": 1569638637453312.0,
      "budget_used_percent": 1.569638637453312
    },
    {
      "type": "training",
      "description": "Training step 1096",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:04",
      "total_flops_so_far": 1571070789494784.0,
      "budget_used_percent": 1.571070789494784
    },
    {
      "type": "training",
      "description": "Training step 1097",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:05",
      "total_flops_so_far": 1572502941536256.0,
      "budget_used_percent": 1.572502941536256
    },
    {
      "type": "training",
      "description": "Training step 1098",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:05",
      "total_flops_so_far": 1573935093577728.0,
      "budget_used_percent": 1.573935093577728
    },
    {
      "type": "training",
      "description": "Training step 1099",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:05",
      "total_flops_so_far": 1575367245619200.0,
      "budget_used_percent": 1.5753672456192
    },
    {
      "type": "training",
      "description": "Training step 1100",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:05",
      "total_flops_so_far": 1576799397660672.0,
      "budget_used_percent": 1.576799397660672
    },
    {
      "type": "training",
      "description": "Training step 1101",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:05",
      "total_flops_so_far": 1578231549702144.0,
      "budget_used_percent": 1.578231549702144
    },
    {
      "type": "training",
      "description": "Training step 1102",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:05",
      "total_flops_so_far": 1579663701743616.0,
      "budget_used_percent": 1.579663701743616
    },
    {
      "type": "training",
      "description": "Training step 1103",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:06",
      "total_flops_so_far": 1581095853785088.0,
      "budget_used_percent": 1.5810958537850879
    },
    {
      "type": "training",
      "description": "Training step 1104",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:06",
      "total_flops_so_far": 1582528005826560.0,
      "budget_used_percent": 1.58252800582656
    },
    {
      "type": "training",
      "description": "Training step 1105",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:06",
      "total_flops_so_far": 1583960157868032.0,
      "budget_used_percent": 1.583960157868032
    },
    {
      "type": "training",
      "description": "Training step 1106",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:06",
      "total_flops_so_far": 1585392309909504.0,
      "budget_used_percent": 1.585392309909504
    },
    {
      "type": "training",
      "description": "Training step 1107",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:06",
      "total_flops_so_far": 1586824461950976.0,
      "budget_used_percent": 1.586824461950976
    },
    {
      "type": "training",
      "description": "Training step 1108",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:06",
      "total_flops_so_far": 1588256613992448.0,
      "budget_used_percent": 1.5882566139924479
    },
    {
      "type": "training",
      "description": "Training step 1109",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:06",
      "total_flops_so_far": 1589688766033920.0,
      "budget_used_percent": 1.5896887660339198
    },
    {
      "type": "training",
      "description": "Training step 1110",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:07",
      "total_flops_so_far": 1591120918075392.0,
      "budget_used_percent": 1.5911209180753922
    },
    {
      "type": "training",
      "description": "Training step 1111",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:07",
      "total_flops_so_far": 1592553070116864.0,
      "budget_used_percent": 1.592553070116864
    },
    {
      "type": "training",
      "description": "Training step 1112",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:07",
      "total_flops_so_far": 1593985222158336.0,
      "budget_used_percent": 1.593985222158336
    },
    {
      "type": "training",
      "description": "Training step 1113",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:07",
      "total_flops_so_far": 1595417374199808.0,
      "budget_used_percent": 1.595417374199808
    },
    {
      "type": "training",
      "description": "Training step 1114",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:07",
      "total_flops_so_far": 1596849526241280.0,
      "budget_used_percent": 1.5968495262412798
    },
    {
      "type": "training",
      "description": "Training step 1115",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:07",
      "total_flops_so_far": 1598281678282752.0,
      "budget_used_percent": 1.5982816782827518
    },
    {
      "type": "training",
      "description": "Training step 1116",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:07",
      "total_flops_so_far": 1599713830324224.0,
      "budget_used_percent": 1.5997138303242242
    },
    {
      "type": "training",
      "description": "Training step 1117",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:08",
      "total_flops_so_far": 1601145982365696.0,
      "budget_used_percent": 1.6011459823656962
    },
    {
      "type": "training",
      "description": "Training step 1118",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:08",
      "total_flops_so_far": 1602578134407168.0,
      "budget_used_percent": 1.6025781344071681
    },
    {
      "type": "training",
      "description": "Training step 1119",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:08",
      "total_flops_so_far": 1604010286448640.0,
      "budget_used_percent": 1.60401028644864
    },
    {
      "type": "training",
      "description": "Training step 1120",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:08",
      "total_flops_so_far": 1605442438490112.0,
      "budget_used_percent": 1.6054424384901118
    },
    {
      "type": "training",
      "description": "Training step 1121",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:08",
      "total_flops_so_far": 1606874590531584.0,
      "budget_used_percent": 1.6068745905315838
    },
    {
      "type": "training",
      "description": "Training step 1122",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:08",
      "total_flops_so_far": 1608306742573056.0,
      "budget_used_percent": 1.6083067425730562
    },
    {
      "type": "training",
      "description": "Training step 1123",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:08",
      "total_flops_so_far": 1609738894614528.0,
      "budget_used_percent": 1.6097388946145281
    },
    {
      "type": "training",
      "description": "Training step 1124",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:09",
      "total_flops_so_far": 1611171046656000.0,
      "budget_used_percent": 1.611171046656
    },
    {
      "type": "training",
      "description": "Training step 1125",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:09",
      "total_flops_so_far": 1612603198697472.0,
      "budget_used_percent": 1.612603198697472
    },
    {
      "type": "training",
      "description": "Training step 1126",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:09",
      "total_flops_so_far": 1614035350738944.0,
      "budget_used_percent": 1.614035350738944
    },
    {
      "type": "training",
      "description": "Training step 1127",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:09",
      "total_flops_so_far": 1615467502780416.0,
      "budget_used_percent": 1.615467502780416
    },
    {
      "type": "training",
      "description": "Training step 1128",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:09",
      "total_flops_so_far": 1616899654821888.0,
      "budget_used_percent": 1.6168996548218881
    },
    {
      "type": "training",
      "description": "Training step 1129",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:09",
      "total_flops_so_far": 1618331806863360.0,
      "budget_used_percent": 1.61833180686336
    },
    {
      "type": "training",
      "description": "Training step 1130",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:09",
      "total_flops_so_far": 1619763958904832.0,
      "budget_used_percent": 1.619763958904832
    },
    {
      "type": "training",
      "description": "Training step 1131",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:10",
      "total_flops_so_far": 1621196110946304.0,
      "budget_used_percent": 1.621196110946304
    },
    {
      "type": "training",
      "description": "Training step 1132",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:10",
      "total_flops_so_far": 1622628262987776.0,
      "budget_used_percent": 1.622628262987776
    },
    {
      "type": "training",
      "description": "Training step 1133",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:10",
      "total_flops_so_far": 1624060415029248.0,
      "budget_used_percent": 1.624060415029248
    },
    {
      "type": "training",
      "description": "Training step 1134",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:10",
      "total_flops_so_far": 1625492567070720.0,
      "budget_used_percent": 1.62549256707072
    },
    {
      "type": "training",
      "description": "Training step 1135",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:10",
      "total_flops_so_far": 1626924719112192.0,
      "budget_used_percent": 1.626924719112192
    },
    {
      "type": "training",
      "description": "Training step 1136",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:10",
      "total_flops_so_far": 1628356871153664.0,
      "budget_used_percent": 1.628356871153664
    },
    {
      "type": "training",
      "description": "Training step 1137",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:10",
      "total_flops_so_far": 1629789023195136.0,
      "budget_used_percent": 1.629789023195136
    },
    {
      "type": "training",
      "description": "Training step 1138",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:11",
      "total_flops_so_far": 1631221175236608.0,
      "budget_used_percent": 1.631221175236608
    },
    {
      "type": "training",
      "description": "Training step 1139",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:11",
      "total_flops_so_far": 1632653327278080.0,
      "budget_used_percent": 1.6326533272780799
    },
    {
      "type": "training",
      "description": "Training step 1140",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:11",
      "total_flops_so_far": 1634085479319552.0,
      "budget_used_percent": 1.634085479319552
    },
    {
      "type": "training",
      "description": "Training step 1141",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:11",
      "total_flops_so_far": 1635517631361024.0,
      "budget_used_percent": 1.635517631361024
    },
    {
      "type": "training",
      "description": "Training step 1142",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:11",
      "total_flops_so_far": 1636949783402496.0,
      "budget_used_percent": 1.636949783402496
    },
    {
      "type": "training",
      "description": "Training step 1143",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:11",
      "total_flops_so_far": 1638381935443968.0,
      "budget_used_percent": 1.638381935443968
    },
    {
      "type": "training",
      "description": "Training step 1144",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:12",
      "total_flops_so_far": 1639814087485440.0,
      "budget_used_percent": 1.6398140874854399
    },
    {
      "type": "training",
      "description": "Training step 1145",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:12",
      "total_flops_so_far": 1641246239526912.0,
      "budget_used_percent": 1.6412462395269118
    },
    {
      "type": "training",
      "description": "Training step 1146",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:12",
      "total_flops_so_far": 1642678391568384.0,
      "budget_used_percent": 1.6426783915683842
    },
    {
      "type": "training",
      "description": "Training step 1147",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:12",
      "total_flops_so_far": 1644110543609856.0,
      "budget_used_percent": 1.6441105436098562
    },
    {
      "type": "training",
      "description": "Training step 1148",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:12",
      "total_flops_so_far": 1645542695651328.0,
      "budget_used_percent": 1.645542695651328
    },
    {
      "type": "training",
      "description": "Training step 1149",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:12",
      "total_flops_so_far": 1646974847692800.0,
      "budget_used_percent": 1.6469748476928
    },
    {
      "type": "training",
      "description": "Training step 1150",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:12",
      "total_flops_so_far": 1648406999734272.0,
      "budget_used_percent": 1.6484069997342718
    },
    {
      "type": "training",
      "description": "Training step 1151",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:13",
      "total_flops_so_far": 1649839151775744.0,
      "budget_used_percent": 1.6498391517757438
    },
    {
      "type": "training",
      "description": "Training step 1152",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:13",
      "total_flops_so_far": 1651271303817216.0,
      "budget_used_percent": 1.6512713038172162
    },
    {
      "type": "training",
      "description": "Training step 1153",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:13",
      "total_flops_so_far": 1652703455858688.0,
      "budget_used_percent": 1.6527034558586882
    },
    {
      "type": "training",
      "description": "Training step 1154",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:13",
      "total_flops_so_far": 1654135607900160.0,
      "budget_used_percent": 1.6541356079001601
    },
    {
      "type": "training",
      "description": "Training step 1155",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:13",
      "total_flops_so_far": 1655567759941632.0,
      "budget_used_percent": 1.655567759941632
    },
    {
      "type": "training",
      "description": "Training step 1156",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:13",
      "total_flops_so_far": 1656999911983104.0,
      "budget_used_percent": 1.656999911983104
    },
    {
      "type": "training",
      "description": "Training step 1157",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:13",
      "total_flops_so_far": 1658432064024576.0,
      "budget_used_percent": 1.6584320640245758
    },
    {
      "type": "training",
      "description": "Training step 1158",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:14",
      "total_flops_so_far": 1659864216066048.0,
      "budget_used_percent": 1.6598642160660482
    },
    {
      "type": "training",
      "description": "Training step 1159",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:14",
      "total_flops_so_far": 1661296368107520.0,
      "budget_used_percent": 1.6612963681075201
    },
    {
      "type": "training",
      "description": "Training step 1160",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:14",
      "total_flops_so_far": 1662728520148992.0,
      "budget_used_percent": 1.662728520148992
    },
    {
      "type": "training",
      "description": "Training step 1161",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:14",
      "total_flops_so_far": 1664160672190464.0,
      "budget_used_percent": 1.664160672190464
    },
    {
      "type": "training",
      "description": "Training step 1162",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:14",
      "total_flops_so_far": 1665592824231936.0,
      "budget_used_percent": 1.665592824231936
    },
    {
      "type": "training",
      "description": "Training step 1163",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:14",
      "total_flops_so_far": 1667024976273408.0,
      "budget_used_percent": 1.667024976273408
    },
    {
      "type": "training",
      "description": "Training step 1164",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:14",
      "total_flops_so_far": 1668457128314880.0,
      "budget_used_percent": 1.66845712831488
    },
    {
      "type": "training",
      "description": "Training step 1165",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:15",
      "total_flops_so_far": 1669889280356352.0,
      "budget_used_percent": 1.669889280356352
    },
    {
      "type": "training",
      "description": "Training step 1166",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:15",
      "total_flops_so_far": 1671321432397824.0,
      "budget_used_percent": 1.671321432397824
    },
    {
      "type": "training",
      "description": "Training step 1167",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:15",
      "total_flops_so_far": 1672753584439296.0,
      "budget_used_percent": 1.672753584439296
    },
    {
      "type": "training",
      "description": "Training step 1168",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:15",
      "total_flops_so_far": 1674185736480768.0,
      "budget_used_percent": 1.674185736480768
    },
    {
      "type": "training",
      "description": "Training step 1169",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:15",
      "total_flops_so_far": 1675617888522240.0,
      "budget_used_percent": 1.67561788852224
    },
    {
      "type": "training",
      "description": "Training step 1170",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:15",
      "total_flops_so_far": 1677050040563712.0,
      "budget_used_percent": 1.6770500405637119
    },
    {
      "type": "training",
      "description": "Training step 1171",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:16",
      "total_flops_so_far": 1678482192605184.0,
      "budget_used_percent": 1.678482192605184
    },
    {
      "type": "training",
      "description": "Training step 1172",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:16",
      "total_flops_so_far": 1679914344646656.0,
      "budget_used_percent": 1.679914344646656
    },
    {
      "type": "training",
      "description": "Training step 1173",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:16",
      "total_flops_so_far": 1681346496688128.0,
      "budget_used_percent": 1.681346496688128
    },
    {
      "type": "training",
      "description": "Training step 1174",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:16",
      "total_flops_so_far": 1682778648729600.0,
      "budget_used_percent": 1.6827786487296
    },
    {
      "type": "training",
      "description": "Training step 1175",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:16",
      "total_flops_so_far": 1684210800771072.0,
      "budget_used_percent": 1.6842108007710719
    },
    {
      "type": "training",
      "description": "Training step 1176",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:16",
      "total_flops_so_far": 1685642952812544.0,
      "budget_used_percent": 1.6856429528125438
    },
    {
      "type": "training",
      "description": "Training step 1177",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:16",
      "total_flops_so_far": 1687075104854016.0,
      "budget_used_percent": 1.6870751048540162
    },
    {
      "type": "training",
      "description": "Training step 1178",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:17",
      "total_flops_so_far": 1688507256895488.0,
      "budget_used_percent": 1.688507256895488
    },
    {
      "type": "training",
      "description": "Training step 1179",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:17",
      "total_flops_so_far": 1689939408936960.0,
      "budget_used_percent": 1.68993940893696
    },
    {
      "type": "training",
      "description": "Training step 1180",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:17",
      "total_flops_so_far": 1691371560978432.0,
      "budget_used_percent": 1.6913715609784319
    },
    {
      "type": "training",
      "description": "Training step 1181",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:17",
      "total_flops_so_far": 1692803713019904.0,
      "budget_used_percent": 1.6928037130199038
    },
    {
      "type": "training",
      "description": "Training step 1182",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:17",
      "total_flops_so_far": 1694235865061376.0,
      "budget_used_percent": 1.6942358650613758
    },
    {
      "type": "training",
      "description": "Training step 1183",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:17",
      "total_flops_so_far": 1695668017102848.0,
      "budget_used_percent": 1.6956680171028482
    },
    {
      "type": "training",
      "description": "Training step 1184",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:17",
      "total_flops_so_far": 1697100169144320.0,
      "budget_used_percent": 1.6971001691443202
    },
    {
      "type": "training",
      "description": "Training step 1185",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:18",
      "total_flops_so_far": 1698532321185792.0,
      "budget_used_percent": 1.6985323211857921
    },
    {
      "type": "training",
      "description": "Training step 1186",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:18",
      "total_flops_so_far": 1699964473227264.0,
      "budget_used_percent": 1.699964473227264
    },
    {
      "type": "training",
      "description": "Training step 1187",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:18",
      "total_flops_so_far": 1701396625268736.0,
      "budget_used_percent": 1.7013966252687358
    },
    {
      "type": "training",
      "description": "Training step 1188",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:18",
      "total_flops_so_far": 1702828777310208.0,
      "budget_used_percent": 1.7028287773102078
    },
    {
      "type": "training",
      "description": "Training step 1189",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:18",
      "total_flops_so_far": 1704260929351680.0,
      "budget_used_percent": 1.7042609293516802
    },
    {
      "type": "training",
      "description": "Training step 1190",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:18",
      "total_flops_so_far": 1705693081393152.0,
      "budget_used_percent": 1.7056930813931521
    },
    {
      "type": "training",
      "description": "Training step 1191",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:18",
      "total_flops_so_far": 1707125233434624.0,
      "budget_used_percent": 1.707125233434624
    },
    {
      "type": "training",
      "description": "Training step 1192",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:19",
      "total_flops_so_far": 1708557385476096.0,
      "budget_used_percent": 1.708557385476096
    },
    {
      "type": "training",
      "description": "Training step 1193",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:19",
      "total_flops_so_far": 1709989537517568.0,
      "budget_used_percent": 1.709989537517568
    },
    {
      "type": "training",
      "description": "Training step 1194",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:19",
      "total_flops_so_far": 1711421689559040.0,
      "budget_used_percent": 1.71142168955904
    },
    {
      "type": "training",
      "description": "Training step 1195",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:19",
      "total_flops_so_far": 1712853841600512.0,
      "budget_used_percent": 1.7128538416005121
    },
    {
      "type": "training",
      "description": "Training step 1196",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:19",
      "total_flops_so_far": 1714285993641984.0,
      "budget_used_percent": 1.714285993641984
    },
    {
      "type": "training",
      "description": "Training step 1197",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:19",
      "total_flops_so_far": 1715718145683456.0,
      "budget_used_percent": 1.715718145683456
    },
    {
      "type": "training",
      "description": "Training step 1198",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:20",
      "total_flops_so_far": 1717150297724928.0,
      "budget_used_percent": 1.717150297724928
    },
    {
      "type": "training",
      "description": "Training step 1199",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:20",
      "total_flops_so_far": 1718582449766400.0,
      "budget_used_percent": 1.7185824497664
    },
    {
      "type": "training",
      "description": "Training step 1200",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:20",
      "total_flops_so_far": 1720014601807872.0,
      "budget_used_percent": 1.720014601807872
    },
    {
      "type": "training",
      "description": "Training step 1201",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:20",
      "total_flops_so_far": 1721446753849344.0,
      "budget_used_percent": 1.721446753849344
    },
    {
      "type": "training",
      "description": "Training step 1202",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:20",
      "total_flops_so_far": 1722878905890816.0,
      "budget_used_percent": 1.722878905890816
    },
    {
      "type": "training",
      "description": "Training step 1203",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:20",
      "total_flops_so_far": 1724311057932288.0,
      "budget_used_percent": 1.724311057932288
    },
    {
      "type": "training",
      "description": "Training step 1204",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:20",
      "total_flops_so_far": 1725743209973760.0,
      "budget_used_percent": 1.72574320997376
    },
    {
      "type": "training",
      "description": "Training step 1205",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:21",
      "total_flops_so_far": 1727175362015232.0,
      "budget_used_percent": 1.727175362015232
    },
    {
      "type": "training",
      "description": "Training step 1206",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:21",
      "total_flops_so_far": 1728607514056704.0,
      "budget_used_percent": 1.7286075140567039
    },
    {
      "type": "training",
      "description": "Training step 1207",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:21",
      "total_flops_so_far": 1730039666098176.0,
      "budget_used_percent": 1.730039666098176
    },
    {
      "type": "training",
      "description": "Training step 1208",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:21",
      "total_flops_so_far": 1731471818139648.0,
      "budget_used_percent": 1.731471818139648
    },
    {
      "type": "training",
      "description": "Training step 1209",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:21",
      "total_flops_so_far": 1732903970181120.0,
      "budget_used_percent": 1.73290397018112
    },
    {
      "type": "training",
      "description": "Training step 1210",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:21",
      "total_flops_so_far": 1734336122222592.0,
      "budget_used_percent": 1.734336122222592
    },
    {
      "type": "training",
      "description": "Training step 1211",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:21",
      "total_flops_so_far": 1735768274264064.0,
      "budget_used_percent": 1.7357682742640639
    },
    {
      "type": "training",
      "description": "Training step 1212",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:22",
      "total_flops_so_far": 1737200426305536.0,
      "budget_used_percent": 1.7372004263055358
    },
    {
      "type": "training",
      "description": "Training step 1213",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:22",
      "total_flops_so_far": 1738632578347008.0,
      "budget_used_percent": 1.7386325783470082
    },
    {
      "type": "training",
      "description": "Training step 1214",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:22",
      "total_flops_so_far": 1740064730388480.0,
      "budget_used_percent": 1.7400647303884802
    },
    {
      "type": "training",
      "description": "Training step 1215",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:22",
      "total_flops_so_far": 1741496882429952.0,
      "budget_used_percent": 1.741496882429952
    },
    {
      "type": "training",
      "description": "Training step 1216",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:22",
      "total_flops_so_far": 1742929034471424.0,
      "budget_used_percent": 1.7429290344714239
    },
    {
      "type": "training",
      "description": "Training step 1217",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:22",
      "total_flops_so_far": 1744361186512896.0,
      "budget_used_percent": 1.7443611865128958
    },
    {
      "type": "training",
      "description": "Training step 1218",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:23",
      "total_flops_so_far": 1745793338554368.0,
      "budget_used_percent": 1.7457933385543678
    },
    {
      "type": "training",
      "description": "Training step 1219",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:23",
      "total_flops_so_far": 1747225490595840.0,
      "budget_used_percent": 1.7472254905958402
    },
    {
      "type": "training",
      "description": "Training step 1220",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:23",
      "total_flops_so_far": 1748657642637312.0,
      "budget_used_percent": 1.7486576426373122
    },
    {
      "type": "training",
      "description": "Training step 1221",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:23",
      "total_flops_so_far": 1750089794678784.0,
      "budget_used_percent": 1.7500897946787841
    },
    {
      "type": "training",
      "description": "Training step 1222",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:23",
      "total_flops_so_far": 1751521946720256.0,
      "budget_used_percent": 1.751521946720256
    },
    {
      "type": "training",
      "description": "Training step 1223",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:23",
      "total_flops_so_far": 1752954098761728.0,
      "budget_used_percent": 1.752954098761728
    },
    {
      "type": "training",
      "description": "Training step 1224",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:23",
      "total_flops_so_far": 1754386250803200.0,
      "budget_used_percent": 1.7543862508031998
    },
    {
      "type": "training",
      "description": "Training step 1225",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:24",
      "total_flops_so_far": 1755818402844672.0,
      "budget_used_percent": 1.7558184028446722
    },
    {
      "type": "training",
      "description": "Training step 1226",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:24",
      "total_flops_so_far": 1757250554886144.0,
      "budget_used_percent": 1.7572505548861441
    },
    {
      "type": "training",
      "description": "Training step 1227",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:24",
      "total_flops_so_far": 1758682706927616.0,
      "budget_used_percent": 1.758682706927616
    },
    {
      "type": "training",
      "description": "Training step 1228",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:24",
      "total_flops_so_far": 1760114858969088.0,
      "budget_used_percent": 1.760114858969088
    },
    {
      "type": "training",
      "description": "Training step 1229",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:24",
      "total_flops_so_far": 1761547011010560.0,
      "budget_used_percent": 1.76154701101056
    },
    {
      "type": "training",
      "description": "Training step 1230",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:24",
      "total_flops_so_far": 1762979163052032.0,
      "budget_used_percent": 1.762979163052032
    },
    {
      "type": "training",
      "description": "Training step 1231",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:24",
      "total_flops_so_far": 1764411315093504.0,
      "budget_used_percent": 1.7644113150935041
    },
    {
      "type": "training",
      "description": "Training step 1232",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:25",
      "total_flops_so_far": 1765843467134976.0,
      "budget_used_percent": 1.765843467134976
    },
    {
      "type": "training",
      "description": "Training step 1233",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:25",
      "total_flops_so_far": 1767275619176448.0,
      "budget_used_percent": 1.767275619176448
    },
    {
      "type": "training",
      "description": "Training step 1234",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:25",
      "total_flops_so_far": 1768707771217920.0,
      "budget_used_percent": 1.76870777121792
    },
    {
      "type": "training",
      "description": "Training step 1235",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:25",
      "total_flops_so_far": 1770139923259392.0,
      "budget_used_percent": 1.770139923259392
    },
    {
      "type": "training",
      "description": "Training step 1236",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:25",
      "total_flops_so_far": 1771572075300864.0,
      "budget_used_percent": 1.771572075300864
    },
    {
      "type": "training",
      "description": "Training step 1237",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:25",
      "total_flops_so_far": 1773004227342336.0,
      "budget_used_percent": 1.7730042273423359
    },
    {
      "type": "training",
      "description": "Training step 1238",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:26",
      "total_flops_so_far": 1774436379383808.0,
      "budget_used_percent": 1.774436379383808
    },
    {
      "type": "training",
      "description": "Training step 1239",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:26",
      "total_flops_so_far": 1775868531425280.0,
      "budget_used_percent": 1.77586853142528
    },
    {
      "type": "training",
      "description": "Training step 1240",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:26",
      "total_flops_so_far": 1777300683466752.0,
      "budget_used_percent": 1.777300683466752
    },
    {
      "type": "training",
      "description": "Training step 1241",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:26",
      "total_flops_so_far": 1778732835508224.0,
      "budget_used_percent": 1.778732835508224
    },
    {
      "type": "training",
      "description": "Training step 1242",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:26",
      "total_flops_so_far": 1780164987549696.0,
      "budget_used_percent": 1.7801649875496959
    },
    {
      "type": "training",
      "description": "Training step 1243",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:26",
      "total_flops_so_far": 1781597139591168.0,
      "budget_used_percent": 1.7815971395911678
    },
    {
      "type": "training",
      "description": "Training step 1244",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:26",
      "total_flops_so_far": 1783029291632640.0,
      "budget_used_percent": 1.7830292916326402
    },
    {
      "type": "training",
      "description": "Training step 1245",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:27",
      "total_flops_so_far": 1784461443674112.0,
      "budget_used_percent": 1.784461443674112
    },
    {
      "type": "training",
      "description": "Training step 1246",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:27",
      "total_flops_so_far": 1785893595715584.0,
      "budget_used_percent": 1.785893595715584
    },
    {
      "type": "training",
      "description": "Training step 1247",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:27",
      "total_flops_so_far": 1787325747757056.0,
      "budget_used_percent": 1.7873257477570559
    },
    {
      "type": "training",
      "description": "Training step 1248",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:27",
      "total_flops_so_far": 1788757899798528.0,
      "budget_used_percent": 1.7887578997985278
    },
    {
      "type": "training",
      "description": "Training step 1249",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:27",
      "total_flops_so_far": 1790190051840000.0,
      "budget_used_percent": 1.7901900518399998
    },
    {
      "type": "training",
      "description": "Training step 1250",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:27",
      "total_flops_so_far": 1791622203881472.0,
      "budget_used_percent": 1.7916222038814722
    },
    {
      "type": "training",
      "description": "Training step 1251",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:28",
      "total_flops_so_far": 1793054355922944.0,
      "budget_used_percent": 1.7930543559229442
    },
    {
      "type": "training",
      "description": "Training step 1252",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:28",
      "total_flops_so_far": 1794486507964416.0,
      "budget_used_percent": 1.794486507964416
    },
    {
      "type": "training",
      "description": "Training step 1253",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:28",
      "total_flops_so_far": 1795918660005888.0,
      "budget_used_percent": 1.795918660005888
    },
    {
      "type": "training",
      "description": "Training step 1254",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:28",
      "total_flops_so_far": 1797350812047360.0,
      "budget_used_percent": 1.7973508120473598
    },
    {
      "type": "training",
      "description": "Training step 1255",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:28",
      "total_flops_so_far": 1798782964088832.0,
      "budget_used_percent": 1.7987829640888318
    },
    {
      "type": "training",
      "description": "Training step 1256",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:28",
      "total_flops_so_far": 1800215116130304.0,
      "budget_used_percent": 1.8002151161303042
    },
    {
      "type": "training",
      "description": "Training step 1257",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:28",
      "total_flops_so_far": 1801647268171776.0,
      "budget_used_percent": 1.8016472681717761
    },
    {
      "type": "training",
      "description": "Training step 1258",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:29",
      "total_flops_so_far": 1803079420213248.0,
      "budget_used_percent": 1.803079420213248
    },
    {
      "type": "training",
      "description": "Training step 1259",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:29",
      "total_flops_so_far": 1804511572254720.0,
      "budget_used_percent": 1.80451157225472
    },
    {
      "type": "training",
      "description": "Training step 1260",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:29",
      "total_flops_so_far": 1805943724296192.0,
      "budget_used_percent": 1.805943724296192
    },
    {
      "type": "training",
      "description": "Training step 1261",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:29",
      "total_flops_so_far": 1807375876337664.0,
      "budget_used_percent": 1.807375876337664
    },
    {
      "type": "training",
      "description": "Training step 1262",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:29",
      "total_flops_so_far": 1808808028379136.0,
      "budget_used_percent": 1.8088080283791361
    },
    {
      "type": "training",
      "description": "Training step 1263",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:29",
      "total_flops_so_far": 1810240180420608.0,
      "budget_used_percent": 1.810240180420608
    },
    {
      "type": "training",
      "description": "Training step 1264",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:29",
      "total_flops_so_far": 1811672332462080.0,
      "budget_used_percent": 1.81167233246208
    },
    {
      "type": "training",
      "description": "Training step 1265",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:30",
      "total_flops_so_far": 1813104484503552.0,
      "budget_used_percent": 1.813104484503552
    },
    {
      "type": "training",
      "description": "Training step 1266",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:30",
      "total_flops_so_far": 1814536636545024.0,
      "budget_used_percent": 1.814536636545024
    },
    {
      "type": "training",
      "description": "Training step 1267",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:30",
      "total_flops_so_far": 1815968788586496.0,
      "budget_used_percent": 1.815968788586496
    },
    {
      "type": "training",
      "description": "Training step 1268",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:30",
      "total_flops_so_far": 1817400940627968.0,
      "budget_used_percent": 1.817400940627968
    },
    {
      "type": "training",
      "description": "Training step 1269",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:30",
      "total_flops_so_far": 1818833092669440.0,
      "budget_used_percent": 1.81883309266944
    },
    {
      "type": "training",
      "description": "Training step 1270",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:30",
      "total_flops_so_far": 1820265244710912.0,
      "budget_used_percent": 1.820265244710912
    },
    {
      "type": "training",
      "description": "Training step 1271",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:31",
      "total_flops_so_far": 1821697396752384.0,
      "budget_used_percent": 1.821697396752384
    },
    {
      "type": "training",
      "description": "Training step 1272",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:31",
      "total_flops_so_far": 1823129548793856.0,
      "budget_used_percent": 1.823129548793856
    },
    {
      "type": "training",
      "description": "Training step 1273",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:31",
      "total_flops_so_far": 1824561700835328.0,
      "budget_used_percent": 1.8245617008353279
    },
    {
      "type": "training",
      "description": "Training step 1274",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:31",
      "total_flops_so_far": 1825993852876800.0,
      "budget_used_percent": 1.8259938528768
    },
    {
      "type": "training",
      "description": "Training step 1275",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:31",
      "total_flops_so_far": 1827426004918272.0,
      "budget_used_percent": 1.827426004918272
    },
    {
      "type": "training",
      "description": "Training step 1276",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:31",
      "total_flops_so_far": 1828858156959744.0,
      "budget_used_percent": 1.828858156959744
    },
    {
      "type": "training",
      "description": "Training step 1277",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:31",
      "total_flops_so_far": 1830290309001216.0,
      "budget_used_percent": 1.830290309001216
    },
    {
      "type": "training",
      "description": "Training step 1278",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:32",
      "total_flops_so_far": 1831722461042688.0,
      "budget_used_percent": 1.8317224610426879
    },
    {
      "type": "training",
      "description": "Training step 1279",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:32",
      "total_flops_so_far": 1833154613084160.0,
      "budget_used_percent": 1.8331546130841598
    },
    {
      "type": "training",
      "description": "Training step 1280",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:32",
      "total_flops_so_far": 1834586765125632.0,
      "budget_used_percent": 1.8345867651256322
    },
    {
      "type": "training",
      "description": "Training step 1281",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:32",
      "total_flops_so_far": 1836018917167104.0,
      "budget_used_percent": 1.8360189171671042
    },
    {
      "type": "training",
      "description": "Training step 1282",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:32",
      "total_flops_so_far": 1837451069208576.0,
      "budget_used_percent": 1.837451069208576
    },
    {
      "type": "training",
      "description": "Training step 1283",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:32",
      "total_flops_so_far": 1838883221250048.0,
      "budget_used_percent": 1.8388832212500479
    },
    {
      "type": "training",
      "description": "Training step 1284",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:32",
      "total_flops_so_far": 1840315373291520.0,
      "budget_used_percent": 1.8403153732915198
    },
    {
      "type": "training",
      "description": "Training step 1285",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:33",
      "total_flops_so_far": 1841747525332992.0,
      "budget_used_percent": 1.8417475253329918
    },
    {
      "type": "training",
      "description": "Training step 1286",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:33",
      "total_flops_so_far": 1843179677374464.0,
      "budget_used_percent": 1.8431796773744642
    },
    {
      "type": "training",
      "description": "Training step 1287",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:33",
      "total_flops_so_far": 1844611829415936.0,
      "budget_used_percent": 1.8446118294159362
    },
    {
      "type": "training",
      "description": "Training step 1288",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:33",
      "total_flops_so_far": 1846043981457408.0,
      "budget_used_percent": 1.8460439814574081
    },
    {
      "type": "training",
      "description": "Training step 1289",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:33",
      "total_flops_so_far": 1847476133498880.0,
      "budget_used_percent": 1.84747613349888
    },
    {
      "type": "training",
      "description": "Training step 1290",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:33",
      "total_flops_so_far": 1848908285540352.0,
      "budget_used_percent": 1.848908285540352
    },
    {
      "type": "training",
      "description": "Training step 1291",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:34",
      "total_flops_so_far": 1850340437581824.0,
      "budget_used_percent": 1.8503404375818238
    },
    {
      "type": "training",
      "description": "Training step 1292",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:34",
      "total_flops_so_far": 1851772589623296.0,
      "budget_used_percent": 1.8517725896232962
    },
    {
      "type": "training",
      "description": "Training step 1293",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:34",
      "total_flops_so_far": 1853204741664768.0,
      "budget_used_percent": 1.8532047416647681
    },
    {
      "type": "training",
      "description": "Training step 1294",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:34",
      "total_flops_so_far": 1854636893706240.0,
      "budget_used_percent": 1.85463689370624
    },
    {
      "type": "training",
      "description": "Training step 1295",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:34",
      "total_flops_so_far": 1856069045747712.0,
      "budget_used_percent": 1.856069045747712
    },
    {
      "type": "training",
      "description": "Training step 1296",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:34",
      "total_flops_so_far": 1857501197789184.0,
      "budget_used_percent": 1.857501197789184
    },
    {
      "type": "training",
      "description": "Training step 1297",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:34",
      "total_flops_so_far": 1858933349830656.0,
      "budget_used_percent": 1.858933349830656
    },
    {
      "type": "training",
      "description": "Training step 1298",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:35",
      "total_flops_so_far": 1860365501872128.0,
      "budget_used_percent": 1.8603655018721281
    },
    {
      "type": "training",
      "description": "Training step 1299",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:35",
      "total_flops_so_far": 1861797653913600.0,
      "budget_used_percent": 1.8617976539136
    },
    {
      "type": "training",
      "description": "Training step 1300",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:35",
      "total_flops_so_far": 1863229805955072.0,
      "budget_used_percent": 1.863229805955072
    },
    {
      "type": "training",
      "description": "Training step 1301",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:35",
      "total_flops_so_far": 1864661957996544.0,
      "budget_used_percent": 1.864661957996544
    },
    {
      "type": "training",
      "description": "Training step 1302",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:35",
      "total_flops_so_far": 1866094110038016.0,
      "budget_used_percent": 1.866094110038016
    },
    {
      "type": "training",
      "description": "Training step 1303",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:35",
      "total_flops_so_far": 1867526262079488.0,
      "budget_used_percent": 1.867526262079488
    },
    {
      "type": "training",
      "description": "Training step 1304",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:35",
      "total_flops_so_far": 1868958414120960.0,
      "budget_used_percent": 1.86895841412096
    },
    {
      "type": "training",
      "description": "Training step 1305",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:36",
      "total_flops_so_far": 1870390566162432.0,
      "budget_used_percent": 1.870390566162432
    },
    {
      "type": "training",
      "description": "Training step 1306",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:36",
      "total_flops_so_far": 1871822718203904.0,
      "budget_used_percent": 1.871822718203904
    },
    {
      "type": "training",
      "description": "Training step 1307",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:36",
      "total_flops_so_far": 1873254870245376.0,
      "budget_used_percent": 1.873254870245376
    },
    {
      "type": "training",
      "description": "Training step 1308",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:36",
      "total_flops_so_far": 1874687022286848.0,
      "budget_used_percent": 1.874687022286848
    },
    {
      "type": "training",
      "description": "Training step 1309",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:36",
      "total_flops_so_far": 1876119174328320.0,
      "budget_used_percent": 1.8761191743283199
    },
    {
      "type": "training",
      "description": "Training step 1310",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:36",
      "total_flops_so_far": 1877551326369792.0,
      "budget_used_percent": 1.8775513263697918
    },
    {
      "type": "training",
      "description": "Training step 1311",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:37",
      "total_flops_so_far": 1878983478411264.0,
      "budget_used_percent": 1.8789834784112642
    },
    {
      "type": "training",
      "description": "Training step 1312",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:37",
      "total_flops_so_far": 1880415630452736.0,
      "budget_used_percent": 1.880415630452736
    },
    {
      "type": "training",
      "description": "Training step 1313",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:37",
      "total_flops_so_far": 1881847782494208.0,
      "budget_used_percent": 1.881847782494208
    },
    {
      "type": "training",
      "description": "Training step 1314",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:37",
      "total_flops_so_far": 1883279934535680.0,
      "budget_used_percent": 1.8832799345356799
    },
    {
      "type": "training",
      "description": "Training step 1315",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:37",
      "total_flops_so_far": 1884712086577152.0,
      "budget_used_percent": 1.8847120865771518
    },
    {
      "type": "training",
      "description": "Training step 1316",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:37",
      "total_flops_so_far": 1886144238618624.0,
      "budget_used_percent": 1.8861442386186238
    },
    {
      "type": "training",
      "description": "Training step 1317",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:37",
      "total_flops_so_far": 1887576390660096.0,
      "budget_used_percent": 1.8875763906600962
    },
    {
      "type": "training",
      "description": "Training step 1318",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:38",
      "total_flops_so_far": 1889008542701568.0,
      "budget_used_percent": 1.8890085427015681
    },
    {
      "type": "training",
      "description": "Training step 1319",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:38",
      "total_flops_so_far": 1890440694743040.0,
      "budget_used_percent": 1.89044069474304
    },
    {
      "type": "training",
      "description": "Training step 1320",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:38",
      "total_flops_so_far": 1891872846784512.0,
      "budget_used_percent": 1.891872846784512
    },
    {
      "type": "training",
      "description": "Training step 1321",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:38",
      "total_flops_so_far": 1893304998825984.0,
      "budget_used_percent": 1.8933049988259838
    },
    {
      "type": "training",
      "description": "Training step 1322",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:38",
      "total_flops_so_far": 1894737150867456.0,
      "budget_used_percent": 1.8947371508674558
    },
    {
      "type": "training",
      "description": "Training step 1323",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:38",
      "total_flops_so_far": 1896169302908928.0,
      "budget_used_percent": 1.8961693029089282
    },
    {
      "type": "training",
      "description": "Training step 1324",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:39",
      "total_flops_so_far": 1897601454950400.0,
      "budget_used_percent": 1.8976014549504001
    },
    {
      "type": "training",
      "description": "Training step 1325",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:39",
      "total_flops_so_far": 1899033606991872.0,
      "budget_used_percent": 1.899033606991872
    },
    {
      "type": "training",
      "description": "Training step 1326",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:39",
      "total_flops_so_far": 1900465759033344.0,
      "budget_used_percent": 1.900465759033344
    },
    {
      "type": "training",
      "description": "Training step 1327",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:39",
      "total_flops_so_far": 1901897911074816.0,
      "budget_used_percent": 1.901897911074816
    },
    {
      "type": "training",
      "description": "Training step 1328",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:39",
      "total_flops_so_far": 1903330063116288.0,
      "budget_used_percent": 1.903330063116288
    },
    {
      "type": "training",
      "description": "Training step 1329",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:39",
      "total_flops_so_far": 1904762215157760.0,
      "budget_used_percent": 1.9047622151577601
    },
    {
      "type": "training",
      "description": "Training step 1330",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:39",
      "total_flops_so_far": 1906194367199232.0,
      "budget_used_percent": 1.906194367199232
    },
    {
      "type": "training",
      "description": "Training step 1331",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:40",
      "total_flops_so_far": 1907626519240704.0,
      "budget_used_percent": 1.907626519240704
    },
    {
      "type": "training",
      "description": "Training step 1332",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:40",
      "total_flops_so_far": 1909058671282176.0,
      "budget_used_percent": 1.909058671282176
    },
    {
      "type": "training",
      "description": "Training step 1333",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:40",
      "total_flops_so_far": 1910490823323648.0,
      "budget_used_percent": 1.910490823323648
    },
    {
      "type": "training",
      "description": "Training step 1334",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:40",
      "total_flops_so_far": 1911922975365120.0,
      "budget_used_percent": 1.91192297536512
    },
    {
      "type": "training",
      "description": "Training step 1335",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:40",
      "total_flops_so_far": 1913355127406592.0,
      "budget_used_percent": 1.913355127406592
    },
    {
      "type": "training",
      "description": "Training step 1336",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:40",
      "total_flops_so_far": 1914787279448064.0,
      "budget_used_percent": 1.914787279448064
    },
    {
      "type": "training",
      "description": "Training step 1337",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:40",
      "total_flops_so_far": 1916219431489536.0,
      "budget_used_percent": 1.916219431489536
    },
    {
      "type": "training",
      "description": "Training step 1338",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:41",
      "total_flops_so_far": 1917651583531008.0,
      "budget_used_percent": 1.917651583531008
    },
    {
      "type": "training",
      "description": "Training step 1339",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:41",
      "total_flops_so_far": 1919083735572480.0,
      "budget_used_percent": 1.91908373557248
    },
    {
      "type": "training",
      "description": "Training step 1340",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:41",
      "total_flops_so_far": 1920515887613952.0,
      "budget_used_percent": 1.9205158876139519
    },
    {
      "type": "training",
      "description": "Training step 1341",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:41",
      "total_flops_so_far": 1921948039655424.0,
      "budget_used_percent": 1.921948039655424
    },
    {
      "type": "training",
      "description": "Training step 1342",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:41",
      "total_flops_so_far": 1923380191696896.0,
      "budget_used_percent": 1.923380191696896
    },
    {
      "type": "training",
      "description": "Training step 1343",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:41",
      "total_flops_so_far": 1924812343738368.0,
      "budget_used_percent": 1.924812343738368
    },
    {
      "type": "training",
      "description": "Training step 1344",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:42",
      "total_flops_so_far": 1926244495779840.0,
      "budget_used_percent": 1.92624449577984
    },
    {
      "type": "training",
      "description": "Training step 1345",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:42",
      "total_flops_so_far": 1927676647821312.0,
      "budget_used_percent": 1.9276766478213119
    },
    {
      "type": "training",
      "description": "Training step 1346",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:42",
      "total_flops_so_far": 1929108799862784.0,
      "budget_used_percent": 1.9291087998627838
    },
    {
      "type": "training",
      "description": "Training step 1347",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:42",
      "total_flops_so_far": 1930540951904256.0,
      "budget_used_percent": 1.9305409519042562
    },
    {
      "type": "training",
      "description": "Training step 1348",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:42",
      "total_flops_so_far": 1931973103945728.0,
      "budget_used_percent": 1.9319731039457282
    },
    {
      "type": "training",
      "description": "Training step 1349",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:42",
      "total_flops_so_far": 1933405255987200.0,
      "budget_used_percent": 1.9334052559872
    },
    {
      "type": "training",
      "description": "Training step 1350",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:42",
      "total_flops_so_far": 1934837408028672.0,
      "budget_used_percent": 1.9348374080286719
    },
    {
      "type": "training",
      "description": "Training step 1351",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:43",
      "total_flops_so_far": 1936269560070144.0,
      "budget_used_percent": 1.9362695600701438
    },
    {
      "type": "training",
      "description": "Training step 1352",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:43",
      "total_flops_so_far": 1937701712111616.0,
      "budget_used_percent": 1.9377017121116158
    },
    {
      "type": "training",
      "description": "Training step 1353",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:43",
      "total_flops_so_far": 1939133864153088.0,
      "budget_used_percent": 1.9391338641530882
    },
    {
      "type": "training",
      "description": "Training step 1354",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:43",
      "total_flops_so_far": 1940566016194560.0,
      "budget_used_percent": 1.9405660161945602
    },
    {
      "type": "training",
      "description": "Training step 1355",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:43",
      "total_flops_so_far": 1941998168236032.0,
      "budget_used_percent": 1.941998168236032
    },
    {
      "type": "training",
      "description": "Training step 1356",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:43",
      "total_flops_so_far": 1943430320277504.0,
      "budget_used_percent": 1.943430320277504
    },
    {
      "type": "training",
      "description": "Training step 1357",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:44",
      "total_flops_so_far": 1944862472318976.0,
      "budget_used_percent": 1.944862472318976
    },
    {
      "type": "training",
      "description": "Training step 1358",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:44",
      "total_flops_so_far": 1946294624360448.0,
      "budget_used_percent": 1.9462946243604478
    },
    {
      "type": "training",
      "description": "Training step 1359",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:44",
      "total_flops_so_far": 1947726776401920.0,
      "budget_used_percent": 1.9477267764019202
    },
    {
      "type": "training",
      "description": "Training step 1360",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:44",
      "total_flops_so_far": 1949158928443392.0,
      "budget_used_percent": 1.9491589284433921
    },
    {
      "type": "training",
      "description": "Training step 1361",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:44",
      "total_flops_so_far": 1950591080484864.0,
      "budget_used_percent": 1.950591080484864
    },
    {
      "type": "training",
      "description": "Training step 1362",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:44",
      "total_flops_so_far": 1952023232526336.0,
      "budget_used_percent": 1.952023232526336
    },
    {
      "type": "training",
      "description": "Training step 1363",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:44",
      "total_flops_so_far": 1953455384567808.0,
      "budget_used_percent": 1.953455384567808
    },
    {
      "type": "training",
      "description": "Training step 1364",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:45",
      "total_flops_so_far": 1954887536609280.0,
      "budget_used_percent": 1.95488753660928
    },
    {
      "type": "training",
      "description": "Training step 1365",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:45",
      "total_flops_so_far": 1956319688650752.0,
      "budget_used_percent": 1.9563196886507521
    },
    {
      "type": "training",
      "description": "Training step 1366",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:45",
      "total_flops_so_far": 1957751840692224.0,
      "budget_used_percent": 1.957751840692224
    },
    {
      "type": "training",
      "description": "Training step 1367",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:45",
      "total_flops_so_far": 1959183992733696.0,
      "budget_used_percent": 1.959183992733696
    },
    {
      "type": "training",
      "description": "Training step 1368",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:45",
      "total_flops_so_far": 1960616144775168.0,
      "budget_used_percent": 1.960616144775168
    },
    {
      "type": "training",
      "description": "Training step 1369",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:45",
      "total_flops_so_far": 1962048296816640.0,
      "budget_used_percent": 1.96204829681664
    },
    {
      "type": "training",
      "description": "Training step 1370",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:45",
      "total_flops_so_far": 1963480448858112.0,
      "budget_used_percent": 1.963480448858112
    },
    {
      "type": "training",
      "description": "Training step 1371",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:46",
      "total_flops_so_far": 1964912600899584.0,
      "budget_used_percent": 1.964912600899584
    },
    {
      "type": "training",
      "description": "Training step 1372",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:46",
      "total_flops_so_far": 1966344752941056.0,
      "budget_used_percent": 1.966344752941056
    },
    {
      "type": "training",
      "description": "Training step 1373",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:46",
      "total_flops_so_far": 1967776904982528.0,
      "budget_used_percent": 1.967776904982528
    },
    {
      "type": "training",
      "description": "Training step 1374",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:46",
      "total_flops_so_far": 1969209057024000.0,
      "budget_used_percent": 1.969209057024
    },
    {
      "type": "training",
      "description": "Training step 1375",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:46",
      "total_flops_so_far": 1970641209065472.0,
      "budget_used_percent": 1.970641209065472
    },
    {
      "type": "training",
      "description": "Training step 1376",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:46",
      "total_flops_so_far": 1972073361106944.0,
      "budget_used_percent": 1.9720733611069439
    },
    {
      "type": "training",
      "description": "Training step 1377",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:47",
      "total_flops_so_far": 1973505513148416.0,
      "budget_used_percent": 1.9735055131484163
    },
    {
      "type": "training",
      "description": "Training step 1378",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:47",
      "total_flops_so_far": 1974937665189888.0,
      "budget_used_percent": 1.9749376651898882
    },
    {
      "type": "training",
      "description": "Training step 1379",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:47",
      "total_flops_so_far": 1976369817231360.0,
      "budget_used_percent": 1.97636981723136
    },
    {
      "type": "training",
      "description": "Training step 1380",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:47",
      "total_flops_so_far": 1977801969272832.0,
      "budget_used_percent": 1.977801969272832
    },
    {
      "type": "training",
      "description": "Training step 1381",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:47",
      "total_flops_so_far": 1979234121314304.0,
      "budget_used_percent": 1.9792341213143039
    },
    {
      "type": "training",
      "description": "Training step 1382",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:47",
      "total_flops_so_far": 1980666273355776.0,
      "budget_used_percent": 1.9806662733557758
    },
    {
      "type": "training",
      "description": "Training step 1383",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:47",
      "total_flops_so_far": 1982098425397248.0,
      "budget_used_percent": 1.9820984253972478
    },
    {
      "type": "training",
      "description": "Training step 1384",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:48",
      "total_flops_so_far": 1983530577438720.0,
      "budget_used_percent": 1.9835305774387202
    },
    {
      "type": "training",
      "description": "Training step 1385",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:48",
      "total_flops_so_far": 1984962729480192.0,
      "budget_used_percent": 1.9849627294801921
    },
    {
      "type": "training",
      "description": "Training step 1386",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:48",
      "total_flops_so_far": 1986394881521664.0,
      "budget_used_percent": 1.986394881521664
    },
    {
      "type": "training",
      "description": "Training step 1387",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:48",
      "total_flops_so_far": 1987827033563136.0,
      "budget_used_percent": 1.987827033563136
    },
    {
      "type": "training",
      "description": "Training step 1388",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:48",
      "total_flops_so_far": 1989259185604608.0,
      "budget_used_percent": 1.9892591856046078
    },
    {
      "type": "training",
      "description": "Training step 1389",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:48",
      "total_flops_so_far": 1990691337646080.0,
      "budget_used_percent": 1.9906913376460798
    },
    {
      "type": "training",
      "description": "Training step 1390",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:49",
      "total_flops_so_far": 1992123489687552.0,
      "budget_used_percent": 1.9921234896875522
    },
    {
      "type": "training",
      "description": "Training step 1391",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:49",
      "total_flops_so_far": 1993555641729024.0,
      "budget_used_percent": 1.993555641729024
    },
    {
      "type": "training",
      "description": "Training step 1392",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:49",
      "total_flops_so_far": 1994987793770496.0,
      "budget_used_percent": 1.994987793770496
    },
    {
      "type": "training",
      "description": "Training step 1393",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:49",
      "total_flops_so_far": 1996419945811968.0,
      "budget_used_percent": 1.996419945811968
    },
    {
      "type": "training",
      "description": "Training step 1394",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:49",
      "total_flops_so_far": 1997852097853440.0,
      "budget_used_percent": 1.99785209785344
    },
    {
      "type": "training",
      "description": "Training step 1395",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:49",
      "total_flops_so_far": 1999284249894912.0,
      "budget_used_percent": 1.999284249894912
    },
    {
      "type": "training",
      "description": "Training step 1396",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:49",
      "total_flops_so_far": 2000716401936384.0,
      "budget_used_percent": 2.0007164019363843
    },
    {
      "type": "training",
      "description": "Training step 1397",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:50",
      "total_flops_so_far": 2002148553977856.0,
      "budget_used_percent": 2.002148553977856
    },
    {
      "type": "training",
      "description": "Training step 1398",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:50",
      "total_flops_so_far": 2003580706019328.0,
      "budget_used_percent": 2.003580706019328
    },
    {
      "type": "training",
      "description": "Training step 1399",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:50",
      "total_flops_so_far": 2005012858060800.0,
      "budget_used_percent": 2.0050128580608
    },
    {
      "type": "training",
      "description": "Training step 1400",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:50",
      "total_flops_so_far": 2006445010102272.0,
      "budget_used_percent": 2.0064450101022717
    },
    {
      "type": "training",
      "description": "Training step 1401",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:50",
      "total_flops_so_far": 2007877162143744.0,
      "budget_used_percent": 2.007877162143744
    },
    {
      "type": "training",
      "description": "Training step 1402",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:50",
      "total_flops_so_far": 2009309314185216.0,
      "budget_used_percent": 2.009309314185216
    },
    {
      "type": "training",
      "description": "Training step 1403",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:51",
      "total_flops_so_far": 2010741466226688.0,
      "budget_used_percent": 2.0107414662266883
    },
    {
      "type": "training",
      "description": "Training step 1404",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:51",
      "total_flops_so_far": 2012173618268160.0,
      "budget_used_percent": 2.01217361826816
    },
    {
      "type": "training",
      "description": "Training step 1405",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:51",
      "total_flops_so_far": 2013605770309632.0,
      "budget_used_percent": 2.013605770309632
    },
    {
      "type": "training",
      "description": "Training step 1406",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:51",
      "total_flops_so_far": 2015037922351104.0,
      "budget_used_percent": 2.015037922351104
    },
    {
      "type": "training",
      "description": "Training step 1407",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:51",
      "total_flops_so_far": 2016470074392576.0,
      "budget_used_percent": 2.0164700743925756
    },
    {
      "type": "training",
      "description": "Training step 1408",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:51",
      "total_flops_so_far": 2017902226434048.0,
      "budget_used_percent": 2.0179022264340483
    },
    {
      "type": "training",
      "description": "Training step 1409",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:51",
      "total_flops_so_far": 2019334378475520.0,
      "budget_used_percent": 2.01933437847552
    },
    {
      "type": "training",
      "description": "Training step 1410",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:52",
      "total_flops_so_far": 2020766530516992.0,
      "budget_used_percent": 2.020766530516992
    },
    {
      "type": "training",
      "description": "Training step 1411",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:52",
      "total_flops_so_far": 2022198682558464.0,
      "budget_used_percent": 2.022198682558464
    },
    {
      "type": "training",
      "description": "Training step 1412",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:52",
      "total_flops_so_far": 2023630834599936.0,
      "budget_used_percent": 2.023630834599936
    },
    {
      "type": "training",
      "description": "Training step 1413",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:52",
      "total_flops_so_far": 2025062986641408.0,
      "budget_used_percent": 2.025062986641408
    },
    {
      "type": "training",
      "description": "Training step 1414",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:52",
      "total_flops_so_far": 2026495138682880.0,
      "budget_used_percent": 2.02649513868288
    },
    {
      "type": "training",
      "description": "Training step 1415",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:52",
      "total_flops_so_far": 2027927290724352.0,
      "budget_used_percent": 2.027927290724352
    },
    {
      "type": "training",
      "description": "Training step 1416",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:53",
      "total_flops_so_far": 2029359442765824.0,
      "budget_used_percent": 2.029359442765824
    },
    {
      "type": "training",
      "description": "Training step 1417",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:53",
      "total_flops_so_far": 2030791594807296.0,
      "budget_used_percent": 2.030791594807296
    },
    {
      "type": "training",
      "description": "Training step 1418",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:53",
      "total_flops_so_far": 2032223746848768.0,
      "budget_used_percent": 2.032223746848768
    },
    {
      "type": "training",
      "description": "Training step 1419",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:53",
      "total_flops_so_far": 2033655898890240.0,
      "budget_used_percent": 2.03365589889024
    },
    {
      "type": "training",
      "description": "Training step 1420",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:53",
      "total_flops_so_far": 2035088050931712.0,
      "budget_used_percent": 2.035088050931712
    },
    {
      "type": "training",
      "description": "Training step 1421",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:53",
      "total_flops_so_far": 2036520202973184.0,
      "budget_used_percent": 2.036520202973184
    },
    {
      "type": "training",
      "description": "Training step 1422",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:53",
      "total_flops_so_far": 2037952355014656.0,
      "budget_used_percent": 2.037952355014656
    },
    {
      "type": "training",
      "description": "Training step 1423",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:54",
      "total_flops_so_far": 2039384507056128.0,
      "budget_used_percent": 2.039384507056128
    },
    {
      "type": "training",
      "description": "Training step 1424",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:54",
      "total_flops_so_far": 2040816659097600.0,
      "budget_used_percent": 2.0408166590976
    },
    {
      "type": "training",
      "description": "Training step 1425",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:54",
      "total_flops_so_far": 2042248811139072.0,
      "budget_used_percent": 2.0422488111390718
    },
    {
      "type": "training",
      "description": "Training step 1426",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:54",
      "total_flops_so_far": 2043680963180544.0,
      "budget_used_percent": 2.0436809631805444
    },
    {
      "type": "training",
      "description": "Training step 1427",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:54",
      "total_flops_so_far": 2045113115222016.0,
      "budget_used_percent": 2.045113115222016
    },
    {
      "type": "training",
      "description": "Training step 1428",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:54",
      "total_flops_so_far": 2046545267263488.0,
      "budget_used_percent": 2.046545267263488
    },
    {
      "type": "training",
      "description": "Training step 1429",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:55",
      "total_flops_so_far": 2047977419304960.0,
      "budget_used_percent": 2.04797741930496
    },
    {
      "type": "training",
      "description": "Training step 1430",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:55",
      "total_flops_so_far": 2049409571346432.0,
      "budget_used_percent": 2.0494095713464318
    },
    {
      "type": "training",
      "description": "Training step 1431",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:55",
      "total_flops_so_far": 2050841723387904.0,
      "budget_used_percent": 2.050841723387904
    },
    {
      "type": "training",
      "description": "Training step 1432",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:55",
      "total_flops_so_far": 2052273875429376.0,
      "budget_used_percent": 2.052273875429376
    },
    {
      "type": "training",
      "description": "Training step 1433",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:55",
      "total_flops_so_far": 2053706027470848.0,
      "budget_used_percent": 2.0537060274708483
    },
    {
      "type": "training",
      "description": "Training step 1434",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:55",
      "total_flops_so_far": 2055138179512320.0,
      "budget_used_percent": 2.05513817951232
    },
    {
      "type": "training",
      "description": "Training step 1435",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:55",
      "total_flops_so_far": 2056570331553792.0,
      "budget_used_percent": 2.056570331553792
    },
    {
      "type": "training",
      "description": "Training step 1436",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:56",
      "total_flops_so_far": 2058002483595264.0,
      "budget_used_percent": 2.058002483595264
    },
    {
      "type": "training",
      "description": "Training step 1437",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:56",
      "total_flops_so_far": 2059434635636736.0,
      "budget_used_percent": 2.0594346356367357
    },
    {
      "type": "training",
      "description": "Training step 1438",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:56",
      "total_flops_so_far": 2060866787678208.0,
      "budget_used_percent": 2.0608667876782083
    },
    {
      "type": "training",
      "description": "Training step 1439",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:56",
      "total_flops_so_far": 2062298939719680.0,
      "budget_used_percent": 2.06229893971968
    },
    {
      "type": "training",
      "description": "Training step 1440",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:56",
      "total_flops_so_far": 2063731091761152.0,
      "budget_used_percent": 2.063731091761152
    },
    {
      "type": "training",
      "description": "Training step 1441",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:56",
      "total_flops_so_far": 2065163243802624.0,
      "budget_used_percent": 2.065163243802624
    },
    {
      "type": "training",
      "description": "Training step 1442",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:57",
      "total_flops_so_far": 2066595395844096.0,
      "budget_used_percent": 2.066595395844096
    },
    {
      "type": "training",
      "description": "Training step 1443",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:57",
      "total_flops_so_far": 2068027547885568.0,
      "budget_used_percent": 2.068027547885568
    },
    {
      "type": "training",
      "description": "Training step 1444",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:57",
      "total_flops_so_far": 2069459699927040.0,
      "budget_used_percent": 2.06945969992704
    },
    {
      "type": "training",
      "description": "Training step 1445",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:57",
      "total_flops_so_far": 2070891851968512.0,
      "budget_used_percent": 2.070891851968512
    },
    {
      "type": "training",
      "description": "Training step 1446",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:57",
      "total_flops_so_far": 2072324004009984.0,
      "budget_used_percent": 2.072324004009984
    },
    {
      "type": "training",
      "description": "Training step 1447",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:57",
      "total_flops_so_far": 2073756156051456.0,
      "budget_used_percent": 2.073756156051456
    },
    {
      "type": "training",
      "description": "Training step 1448",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:57",
      "total_flops_so_far": 2075188308092928.0,
      "budget_used_percent": 2.075188308092928
    },
    {
      "type": "training",
      "description": "Training step 1449",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:58",
      "total_flops_so_far": 2076620460134400.0,
      "budget_used_percent": 2.0766204601344
    },
    {
      "type": "training",
      "description": "Training step 1450",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:58",
      "total_flops_so_far": 2078052612175872.0,
      "budget_used_percent": 2.0780526121758722
    },
    {
      "type": "training",
      "description": "Training step 1451",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:58",
      "total_flops_so_far": 2079484764217344.0,
      "budget_used_percent": 2.079484764217344
    },
    {
      "type": "training",
      "description": "Training step 1452",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:58",
      "total_flops_so_far": 2080916916258816.0,
      "budget_used_percent": 2.080916916258816
    },
    {
      "type": "training",
      "description": "Training step 1453",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:58",
      "total_flops_so_far": 2082349068300288.0,
      "budget_used_percent": 2.082349068300288
    },
    {
      "type": "training",
      "description": "Training step 1454",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:58",
      "total_flops_so_far": 2083781220341760.0,
      "budget_used_percent": 2.08378122034176
    },
    {
      "type": "training",
      "description": "Training step 1455",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:58",
      "total_flops_so_far": 2085213372383232.0,
      "budget_used_percent": 2.085213372383232
    },
    {
      "type": "training",
      "description": "Training step 1456",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:59",
      "total_flops_so_far": 2086645524424704.0,
      "budget_used_percent": 2.086645524424704
    },
    {
      "type": "training",
      "description": "Training step 1457",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:59",
      "total_flops_so_far": 2088077676466176.0,
      "budget_used_percent": 2.088077676466176
    },
    {
      "type": "training",
      "description": "Training step 1458",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:59",
      "total_flops_so_far": 2089509828507648.0,
      "budget_used_percent": 2.089509828507648
    },
    {
      "type": "training",
      "description": "Training step 1459",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:59",
      "total_flops_so_far": 2090941980549120.0,
      "budget_used_percent": 2.09094198054912
    },
    {
      "type": "training",
      "description": "Training step 1460",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:59",
      "total_flops_so_far": 2092374132590592.0,
      "budget_used_percent": 2.092374132590592
    },
    {
      "type": "training",
      "description": "Training step 1461",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:28:59",
      "total_flops_so_far": 2093806284632064.0,
      "budget_used_percent": 2.093806284632064
    },
    {
      "type": "training",
      "description": "Training step 1462",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:00",
      "total_flops_so_far": 2095238436673536.0,
      "budget_used_percent": 2.0952384366735357
    },
    {
      "type": "training",
      "description": "Training step 1463",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:00",
      "total_flops_so_far": 2096670588715008.0,
      "budget_used_percent": 2.0966705887150083
    },
    {
      "type": "training",
      "description": "Training step 1464",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:00",
      "total_flops_so_far": 2098102740756480.0,
      "budget_used_percent": 2.09810274075648
    },
    {
      "type": "training",
      "description": "Training step 1465",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:00",
      "total_flops_so_far": 2099534892797952.0,
      "budget_used_percent": 2.099534892797952
    },
    {
      "type": "training",
      "description": "Training step 1466",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:00",
      "total_flops_so_far": 2100967044839424.0,
      "budget_used_percent": 2.100967044839424
    },
    {
      "type": "training",
      "description": "Training step 1467",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:00",
      "total_flops_so_far": 2102399196880896.0,
      "budget_used_percent": 2.1023991968808957
    },
    {
      "type": "training",
      "description": "Training step 1468",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:01",
      "total_flops_so_far": 2103831348922368.0,
      "budget_used_percent": 2.103831348922368
    },
    {
      "type": "training",
      "description": "Training step 1469",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:01",
      "total_flops_so_far": 2105263500963840.0,
      "budget_used_percent": 2.10526350096384
    },
    {
      "type": "training",
      "description": "Training step 1470",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:01",
      "total_flops_so_far": 2106695653005312.0,
      "budget_used_percent": 2.1066956530053123
    },
    {
      "type": "training",
      "description": "Training step 1471",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:01",
      "total_flops_so_far": 2108127805046784.0,
      "budget_used_percent": 2.108127805046784
    },
    {
      "type": "training",
      "description": "Training step 1472",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:01",
      "total_flops_so_far": 2109559957088256.0,
      "budget_used_percent": 2.109559957088256
    },
    {
      "type": "training",
      "description": "Training step 1473",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:01",
      "total_flops_so_far": 2110992109129728.0,
      "budget_used_percent": 2.110992109129728
    },
    {
      "type": "training",
      "description": "Training step 1474",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:02",
      "total_flops_so_far": 2112424261171200.0,
      "budget_used_percent": 2.1124242611711996
    },
    {
      "type": "training",
      "description": "Training step 1475",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:02",
      "total_flops_so_far": 2113856413212672.0,
      "budget_used_percent": 2.1138564132126723
    },
    {
      "type": "training",
      "description": "Training step 1476",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:02",
      "total_flops_so_far": 2115288565254144.0,
      "budget_used_percent": 2.115288565254144
    },
    {
      "type": "training",
      "description": "Training step 1477",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:02",
      "total_flops_so_far": 2116720717295616.0,
      "budget_used_percent": 2.116720717295616
    },
    {
      "type": "training",
      "description": "Training step 1478",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:02",
      "total_flops_so_far": 2118152869337088.0,
      "budget_used_percent": 2.118152869337088
    },
    {
      "type": "training",
      "description": "Training step 1479",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:02",
      "total_flops_so_far": 2119585021378560.0,
      "budget_used_percent": 2.11958502137856
    },
    {
      "type": "training",
      "description": "Training step 1480",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:03",
      "total_flops_so_far": 2121017173420032.0,
      "budget_used_percent": 2.121017173420032
    },
    {
      "type": "training",
      "description": "Training step 1481",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:03",
      "total_flops_so_far": 2122449325461504.0,
      "budget_used_percent": 2.122449325461504
    },
    {
      "type": "training",
      "description": "Training step 1482",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:03",
      "total_flops_so_far": 2123881477502976.0,
      "budget_used_percent": 2.123881477502976
    },
    {
      "type": "training",
      "description": "Training step 1483",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:03",
      "total_flops_so_far": 2125313629544448.0,
      "budget_used_percent": 2.125313629544448
    },
    {
      "type": "training",
      "description": "Training step 1484",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:03",
      "total_flops_so_far": 2126745781585920.0,
      "budget_used_percent": 2.12674578158592
    },
    {
      "type": "training",
      "description": "Training step 1485",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:03",
      "total_flops_so_far": 2128177933627392.0,
      "budget_used_percent": 2.128177933627392
    },
    {
      "type": "training",
      "description": "Training step 1486",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:03",
      "total_flops_so_far": 2129610085668864.0,
      "budget_used_percent": 2.129610085668864
    },
    {
      "type": "training",
      "description": "Training step 1487",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:04",
      "total_flops_so_far": 2131042237710336.0,
      "budget_used_percent": 2.131042237710336
    },
    {
      "type": "training",
      "description": "Training step 1488",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:04",
      "total_flops_so_far": 2132474389751808.0,
      "budget_used_percent": 2.132474389751808
    },
    {
      "type": "training",
      "description": "Training step 1489",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:04",
      "total_flops_so_far": 2133906541793280.0,
      "budget_used_percent": 2.13390654179328
    },
    {
      "type": "training",
      "description": "Training step 1490",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:04",
      "total_flops_so_far": 2135338693834752.0,
      "budget_used_percent": 2.135338693834752
    },
    {
      "type": "training",
      "description": "Training step 1491",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:04",
      "total_flops_so_far": 2136770845876224.0,
      "budget_used_percent": 2.136770845876224
    },
    {
      "type": "training",
      "description": "Training step 1492",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:04",
      "total_flops_so_far": 2138202997917696.0,
      "budget_used_percent": 2.1382029979176957
    },
    {
      "type": "training",
      "description": "Training step 1493",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:05",
      "total_flops_so_far": 2139635149959168.0,
      "budget_used_percent": 2.139635149959168
    },
    {
      "type": "training",
      "description": "Training step 1494",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:05",
      "total_flops_so_far": 2141067302000640.0,
      "budget_used_percent": 2.14106730200064
    },
    {
      "type": "training",
      "description": "Training step 1495",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:05",
      "total_flops_so_far": 2142499454042112.0,
      "budget_used_percent": 2.142499454042112
    },
    {
      "type": "training",
      "description": "Training step 1496",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:05",
      "total_flops_so_far": 2143931606083584.0,
      "budget_used_percent": 2.143931606083584
    },
    {
      "type": "training",
      "description": "Training step 1497",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:05",
      "total_flops_so_far": 2145363758125056.0,
      "budget_used_percent": 2.1453637581250558
    },
    {
      "type": "training",
      "description": "Training step 1498",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:05",
      "total_flops_so_far": 2146795910166528.0,
      "budget_used_percent": 2.146795910166528
    },
    {
      "type": "training",
      "description": "Training step 1499",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:29:05",
      "total_flops_so_far": 2148228062208000.0,
      "budget_used_percent": 2.148228062208
    },
    {
      "type": "training",
      "description": "Training step 1500",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:27",
      "total_flops_so_far": 2149660214249472.0,
      "budget_used_percent": 2.1496602142494723
    },
    {
      "type": "training",
      "description": "Training step 1501",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:28",
      "total_flops_so_far": 2151092366290944.0,
      "budget_used_percent": 2.151092366290944
    },
    {
      "type": "training",
      "description": "Training step 1502",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:28",
      "total_flops_so_far": 2152524518332416.0,
      "budget_used_percent": 2.1525245183324158
    },
    {
      "type": "training",
      "description": "Training step 1503",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:28",
      "total_flops_so_far": 2153956670373888.0,
      "budget_used_percent": 2.153956670373888
    },
    {
      "type": "training",
      "description": "Training step 1504",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:28",
      "total_flops_so_far": 2155388822415360.0,
      "budget_used_percent": 2.1553888224153597
    },
    {
      "type": "training",
      "description": "Training step 1505",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:28",
      "total_flops_so_far": 2156820974456832.0,
      "budget_used_percent": 2.1568209744568323
    },
    {
      "type": "training",
      "description": "Training step 1506",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:28",
      "total_flops_so_far": 2158253126498304.0,
      "budget_used_percent": 2.158253126498304
    },
    {
      "type": "training",
      "description": "Training step 1507",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:29",
      "total_flops_so_far": 2159685278539776.0,
      "budget_used_percent": 2.159685278539776
    },
    {
      "type": "training",
      "description": "Training step 1508",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:29",
      "total_flops_so_far": 2161117430581248.0,
      "budget_used_percent": 2.161117430581248
    },
    {
      "type": "training",
      "description": "Training step 1509",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:29",
      "total_flops_so_far": 2162549582622720.0,
      "budget_used_percent": 2.16254958262272
    },
    {
      "type": "training",
      "description": "Training step 1510",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:29",
      "total_flops_so_far": 2163981734664192.0,
      "budget_used_percent": 2.163981734664192
    },
    {
      "type": "training",
      "description": "Training step 1511",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:29",
      "total_flops_so_far": 2165413886705664.0,
      "budget_used_percent": 2.165413886705664
    },
    {
      "type": "training",
      "description": "Training step 1512",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:29",
      "total_flops_so_far": 2166846038747136.0,
      "budget_used_percent": 2.166846038747136
    },
    {
      "type": "training",
      "description": "Training step 1513",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:29",
      "total_flops_so_far": 2168278190788608.0,
      "budget_used_percent": 2.168278190788608
    },
    {
      "type": "training",
      "description": "Training step 1514",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:30",
      "total_flops_so_far": 2169710342830080.0,
      "budget_used_percent": 2.16971034283008
    },
    {
      "type": "training",
      "description": "Training step 1515",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:30",
      "total_flops_so_far": 2171142494871552.0,
      "budget_used_percent": 2.171142494871552
    },
    {
      "type": "training",
      "description": "Training step 1516",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:30",
      "total_flops_so_far": 2172574646913024.0,
      "budget_used_percent": 2.172574646913024
    },
    {
      "type": "training",
      "description": "Training step 1517",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:30",
      "total_flops_so_far": 2174006798954496.0,
      "budget_used_percent": 2.1740067989544962
    },
    {
      "type": "training",
      "description": "Training step 1518",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:30",
      "total_flops_so_far": 2175438950995968.0,
      "budget_used_percent": 2.175438950995968
    },
    {
      "type": "training",
      "description": "Training step 1519",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:30",
      "total_flops_so_far": 2176871103037440.0,
      "budget_used_percent": 2.17687110303744
    },
    {
      "type": "training",
      "description": "Training step 1520",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:31",
      "total_flops_so_far": 2178303255078912.0,
      "budget_used_percent": 2.178303255078912
    },
    {
      "type": "training",
      "description": "Training step 1521",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:31",
      "total_flops_so_far": 2179735407120384.0,
      "budget_used_percent": 2.179735407120384
    },
    {
      "type": "training",
      "description": "Training step 1522",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:31",
      "total_flops_so_far": 2181167559161856.0,
      "budget_used_percent": 2.181167559161856
    },
    {
      "type": "training",
      "description": "Training step 1523",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:31",
      "total_flops_so_far": 2182599711203328.0,
      "budget_used_percent": 2.182599711203328
    },
    {
      "type": "training",
      "description": "Training step 1524",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:31",
      "total_flops_so_far": 2184031863244800.0,
      "budget_used_percent": 2.1840318632448
    },
    {
      "type": "training",
      "description": "Training step 1525",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:31",
      "total_flops_so_far": 2185464015286272.0,
      "budget_used_percent": 2.185464015286272
    },
    {
      "type": "training",
      "description": "Training step 1526",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:32",
      "total_flops_so_far": 2186896167327744.0,
      "budget_used_percent": 2.186896167327744
    },
    {
      "type": "training",
      "description": "Training step 1527",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:32",
      "total_flops_so_far": 2188328319369216.0,
      "budget_used_percent": 2.188328319369216
    },
    {
      "type": "training",
      "description": "Training step 1528",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:32",
      "total_flops_so_far": 2189760471410688.0,
      "budget_used_percent": 2.189760471410688
    },
    {
      "type": "training",
      "description": "Training step 1529",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:32",
      "total_flops_so_far": 2191192623452160.0,
      "budget_used_percent": 2.1911926234521597
    },
    {
      "type": "training",
      "description": "Training step 1530",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:32",
      "total_flops_so_far": 2192624775493632.0,
      "budget_used_percent": 2.1926247754936323
    },
    {
      "type": "training",
      "description": "Training step 1531",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:32",
      "total_flops_so_far": 2194056927535104.0,
      "budget_used_percent": 2.194056927535104
    },
    {
      "type": "training",
      "description": "Training step 1532",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:32",
      "total_flops_so_far": 2195489079576576.0,
      "budget_used_percent": 2.195489079576576
    },
    {
      "type": "training",
      "description": "Training step 1533",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:33",
      "total_flops_so_far": 2196921231618048.0,
      "budget_used_percent": 2.196921231618048
    },
    {
      "type": "training",
      "description": "Training step 1534",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:33",
      "total_flops_so_far": 2198353383659520.0,
      "budget_used_percent": 2.1983533836595197
    },
    {
      "type": "training",
      "description": "Training step 1535",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:33",
      "total_flops_so_far": 2199785535700992.0,
      "budget_used_percent": 2.199785535700992
    },
    {
      "type": "training",
      "description": "Training step 1536",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:33",
      "total_flops_so_far": 2201217687742464.0,
      "budget_used_percent": 2.201217687742464
    },
    {
      "type": "training",
      "description": "Training step 1537",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:33",
      "total_flops_so_far": 2202649839783936.0,
      "budget_used_percent": 2.2026498397839362
    },
    {
      "type": "training",
      "description": "Training step 1538",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:33",
      "total_flops_so_far": 2204081991825408.0,
      "budget_used_percent": 2.204081991825408
    },
    {
      "type": "training",
      "description": "Training step 1539",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:34",
      "total_flops_so_far": 2205514143866880.0,
      "budget_used_percent": 2.20551414386688
    },
    {
      "type": "training",
      "description": "Training step 1540",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:34",
      "total_flops_so_far": 2206946295908352.0,
      "budget_used_percent": 2.206946295908352
    },
    {
      "type": "training",
      "description": "Training step 1541",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:34",
      "total_flops_so_far": 2208378447949824.0,
      "budget_used_percent": 2.2083784479498236
    },
    {
      "type": "training",
      "description": "Training step 1542",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:34",
      "total_flops_so_far": 2209810599991296.0,
      "budget_used_percent": 2.2098105999912963
    },
    {
      "type": "training",
      "description": "Training step 1543",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:34",
      "total_flops_so_far": 2211242752032768.0,
      "budget_used_percent": 2.211242752032768
    },
    {
      "type": "training",
      "description": "Training step 1544",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:34",
      "total_flops_so_far": 2212674904074240.0,
      "budget_used_percent": 2.21267490407424
    },
    {
      "type": "training",
      "description": "Training step 1545",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:35",
      "total_flops_so_far": 2214107056115712.0,
      "budget_used_percent": 2.214107056115712
    },
    {
      "type": "training",
      "description": "Training step 1546",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:35",
      "total_flops_so_far": 2215539208157184.0,
      "budget_used_percent": 2.215539208157184
    },
    {
      "type": "training",
      "description": "Training step 1547",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:35",
      "total_flops_so_far": 2216971360198656.0,
      "budget_used_percent": 2.216971360198656
    },
    {
      "type": "training",
      "description": "Training step 1548",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:35",
      "total_flops_so_far": 2218403512240128.0,
      "budget_used_percent": 2.218403512240128
    },
    {
      "type": "training",
      "description": "Training step 1549",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:35",
      "total_flops_so_far": 2219835664281600.0,
      "budget_used_percent": 2.2198356642816
    },
    {
      "type": "training",
      "description": "Training step 1550",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:35",
      "total_flops_so_far": 2221267816323072.0,
      "budget_used_percent": 2.221267816323072
    },
    {
      "type": "training",
      "description": "Training step 1551",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:35",
      "total_flops_so_far": 2222699968364544.0,
      "budget_used_percent": 2.222699968364544
    },
    {
      "type": "training",
      "description": "Training step 1552",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:36",
      "total_flops_so_far": 2224132120406016.0,
      "budget_used_percent": 2.224132120406016
    },
    {
      "type": "training",
      "description": "Training step 1553",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:36",
      "total_flops_so_far": 2225564272447488.0,
      "budget_used_percent": 2.225564272447488
    },
    {
      "type": "training",
      "description": "Training step 1554",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:36",
      "total_flops_so_far": 2226996424488960.0,
      "budget_used_percent": 2.22699642448896
    },
    {
      "type": "training",
      "description": "Training step 1555",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:36",
      "total_flops_so_far": 2228428576530432.0,
      "budget_used_percent": 2.228428576530432
    },
    {
      "type": "training",
      "description": "Training step 1556",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:37",
      "total_flops_so_far": 2229860728571904.0,
      "budget_used_percent": 2.229860728571904
    },
    {
      "type": "training",
      "description": "Training step 1557",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:37",
      "total_flops_so_far": 2231292880613376.0,
      "budget_used_percent": 2.231292880613376
    },
    {
      "type": "training",
      "description": "Training step 1558",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:37",
      "total_flops_so_far": 2232725032654848.0,
      "budget_used_percent": 2.232725032654848
    },
    {
      "type": "training",
      "description": "Training step 1559",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:37",
      "total_flops_so_far": 2234157184696320.0,
      "budget_used_percent": 2.2341571846963197
    },
    {
      "type": "training",
      "description": "Training step 1560",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:37",
      "total_flops_so_far": 2235589336737792.0,
      "budget_used_percent": 2.2355893367377924
    },
    {
      "type": "training",
      "description": "Training step 1561",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:37",
      "total_flops_so_far": 2237021488779264.0,
      "budget_used_percent": 2.237021488779264
    },
    {
      "type": "training",
      "description": "Training step 1562",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:38",
      "total_flops_so_far": 2238453640820736.0,
      "budget_used_percent": 2.238453640820736
    },
    {
      "type": "training",
      "description": "Training step 1563",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:38",
      "total_flops_so_far": 2239885792862208.0,
      "budget_used_percent": 2.239885792862208
    },
    {
      "type": "training",
      "description": "Training step 1564",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:38",
      "total_flops_so_far": 2241317944903680.0,
      "budget_used_percent": 2.2413179449036797
    },
    {
      "type": "training",
      "description": "Training step 1565",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:38",
      "total_flops_so_far": 2242750096945152.0,
      "budget_used_percent": 2.242750096945152
    },
    {
      "type": "training",
      "description": "Training step 1566",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:38",
      "total_flops_so_far": 2244182248986624.0,
      "budget_used_percent": 2.244182248986624
    },
    {
      "type": "training",
      "description": "Training step 1567",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:38",
      "total_flops_so_far": 2245614401028096.0,
      "budget_used_percent": 2.2456144010280963
    },
    {
      "type": "training",
      "description": "Training step 1568",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:38",
      "total_flops_so_far": 2247046553069568.0,
      "budget_used_percent": 2.247046553069568
    },
    {
      "type": "training",
      "description": "Training step 1569",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:39",
      "total_flops_so_far": 2248478705111040.0,
      "budget_used_percent": 2.24847870511104
    },
    {
      "type": "training",
      "description": "Training step 1570",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:39",
      "total_flops_so_far": 2249910857152512.0,
      "budget_used_percent": 2.249910857152512
    },
    {
      "type": "training",
      "description": "Training step 1571",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:39",
      "total_flops_so_far": 2251343009193984.0,
      "budget_used_percent": 2.2513430091939837
    },
    {
      "type": "training",
      "description": "Training step 1572",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:39",
      "total_flops_so_far": 2252775161235456.0,
      "budget_used_percent": 2.2527751612354563
    },
    {
      "type": "training",
      "description": "Training step 1573",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:39",
      "total_flops_so_far": 2254207313276928.0,
      "budget_used_percent": 2.254207313276928
    },
    {
      "type": "training",
      "description": "Training step 1574",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:39",
      "total_flops_so_far": 2255639465318400.0,
      "budget_used_percent": 2.2556394653184
    },
    {
      "type": "training",
      "description": "Training step 1575",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:40",
      "total_flops_so_far": 2257071617359872.0,
      "budget_used_percent": 2.257071617359872
    },
    {
      "type": "training",
      "description": "Training step 1576",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:40",
      "total_flops_so_far": 2258503769401344.0,
      "budget_used_percent": 2.258503769401344
    },
    {
      "type": "training",
      "description": "Training step 1577",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:40",
      "total_flops_so_far": 2259935921442816.0,
      "budget_used_percent": 2.259935921442816
    },
    {
      "type": "training",
      "description": "Training step 1578",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:40",
      "total_flops_so_far": 2261368073484288.0,
      "budget_used_percent": 2.261368073484288
    },
    {
      "type": "training",
      "description": "Training step 1579",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:40",
      "total_flops_so_far": 2262800225525760.0,
      "budget_used_percent": 2.26280022552576
    },
    {
      "type": "training",
      "description": "Training step 1580",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:40",
      "total_flops_so_far": 2264232377567232.0,
      "budget_used_percent": 2.264232377567232
    },
    {
      "type": "training",
      "description": "Training step 1581",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:40",
      "total_flops_so_far": 2265664529608704.0,
      "budget_used_percent": 2.265664529608704
    },
    {
      "type": "training",
      "description": "Training step 1582",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:41",
      "total_flops_so_far": 2267096681650176.0,
      "budget_used_percent": 2.267096681650176
    },
    {
      "type": "training",
      "description": "Training step 1583",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:41",
      "total_flops_so_far": 2268528833691648.0,
      "budget_used_percent": 2.268528833691648
    },
    {
      "type": "training",
      "description": "Training step 1584",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:41",
      "total_flops_so_far": 2269960985733120.0,
      "budget_used_percent": 2.26996098573312
    },
    {
      "type": "training",
      "description": "Training step 1585",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:41",
      "total_flops_so_far": 2271393137774592.0,
      "budget_used_percent": 2.271393137774592
    },
    {
      "type": "training",
      "description": "Training step 1586",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:41",
      "total_flops_so_far": 2272825289816064.0,
      "budget_used_percent": 2.272825289816064
    },
    {
      "type": "training",
      "description": "Training step 1587",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:41",
      "total_flops_so_far": 2274257441857536.0,
      "budget_used_percent": 2.274257441857536
    },
    {
      "type": "training",
      "description": "Training step 1588",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:42",
      "total_flops_so_far": 2275689593899008.0,
      "budget_used_percent": 2.275689593899008
    },
    {
      "type": "training",
      "description": "Training step 1589",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:42",
      "total_flops_so_far": 2277121745940480.0,
      "budget_used_percent": 2.27712174594048
    },
    {
      "type": "training",
      "description": "Training step 1590",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:42",
      "total_flops_so_far": 2278553897981952.0,
      "budget_used_percent": 2.278553897981952
    },
    {
      "type": "training",
      "description": "Training step 1591",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:42",
      "total_flops_so_far": 2279986050023424.0,
      "budget_used_percent": 2.279986050023424
    },
    {
      "type": "training",
      "description": "Training step 1592",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:42",
      "total_flops_so_far": 2281418202064896.0,
      "budget_used_percent": 2.281418202064896
    },
    {
      "type": "training",
      "description": "Training step 1593",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:42",
      "total_flops_so_far": 2282850354106368.0,
      "budget_used_percent": 2.282850354106368
    },
    {
      "type": "training",
      "description": "Training step 1594",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:42",
      "total_flops_so_far": 2284282506147840.0,
      "budget_used_percent": 2.28428250614784
    },
    {
      "type": "training",
      "description": "Training step 1595",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:43",
      "total_flops_so_far": 2285714658189312.0,
      "budget_used_percent": 2.285714658189312
    },
    {
      "type": "training",
      "description": "Training step 1596",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:43",
      "total_flops_so_far": 2287146810230784.0,
      "budget_used_percent": 2.287146810230784
    },
    {
      "type": "training",
      "description": "Training step 1597",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:43",
      "total_flops_so_far": 2288578962272256.0,
      "budget_used_percent": 2.2885789622722563
    },
    {
      "type": "training",
      "description": "Training step 1598",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:43",
      "total_flops_so_far": 2290011114313728.0,
      "budget_used_percent": 2.290011114313728
    },
    {
      "type": "training",
      "description": "Training step 1599",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:43",
      "total_flops_so_far": 2291443266355200.0,
      "budget_used_percent": 2.2914432663552
    },
    {
      "type": "training",
      "description": "Training step 1600",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:43",
      "total_flops_so_far": 2292875418396672.0,
      "budget_used_percent": 2.292875418396672
    },
    {
      "type": "training",
      "description": "Training step 1601",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:44",
      "total_flops_so_far": 2294307570438144.0,
      "budget_used_percent": 2.2943075704381437
    },
    {
      "type": "training",
      "description": "Training step 1602",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:44",
      "total_flops_so_far": 2295739722479616.0,
      "budget_used_percent": 2.295739722479616
    },
    {
      "type": "training",
      "description": "Training step 1603",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:44",
      "total_flops_so_far": 2297171874521088.0,
      "budget_used_percent": 2.297171874521088
    },
    {
      "type": "training",
      "description": "Training step 1604",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:44",
      "total_flops_so_far": 2298604026562560.0,
      "budget_used_percent": 2.2986040265625602
    },
    {
      "type": "training",
      "description": "Training step 1605",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:44",
      "total_flops_so_far": 2300036178604032.0,
      "budget_used_percent": 2.300036178604032
    },
    {
      "type": "training",
      "description": "Training step 1606",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:44",
      "total_flops_so_far": 2301468330645504.0,
      "budget_used_percent": 2.301468330645504
    },
    {
      "type": "training",
      "description": "Training step 1607",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:45",
      "total_flops_so_far": 2302900482686976.0,
      "budget_used_percent": 2.302900482686976
    },
    {
      "type": "training",
      "description": "Training step 1608",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:45",
      "total_flops_so_far": 2304332634728448.0,
      "budget_used_percent": 2.3043326347284476
    },
    {
      "type": "training",
      "description": "Training step 1609",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:45",
      "total_flops_so_far": 2305764786769920.0,
      "budget_used_percent": 2.3057647867699202
    },
    {
      "type": "training",
      "description": "Training step 1610",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:45",
      "total_flops_so_far": 2307196938811392.0,
      "budget_used_percent": 2.307196938811392
    },
    {
      "type": "training",
      "description": "Training step 1611",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:45",
      "total_flops_so_far": 2308629090852864.0,
      "budget_used_percent": 2.308629090852864
    },
    {
      "type": "training",
      "description": "Training step 1612",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:45",
      "total_flops_so_far": 2310061242894336.0,
      "budget_used_percent": 2.310061242894336
    },
    {
      "type": "training",
      "description": "Training step 1613",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:45",
      "total_flops_so_far": 2311493394935808.0,
      "budget_used_percent": 2.311493394935808
    },
    {
      "type": "training",
      "description": "Training step 1614",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:46",
      "total_flops_so_far": 2312925546977280.0,
      "budget_used_percent": 2.31292554697728
    },
    {
      "type": "training",
      "description": "Training step 1615",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:46",
      "total_flops_so_far": 2314357699018752.0,
      "budget_used_percent": 2.314357699018752
    },
    {
      "type": "training",
      "description": "Training step 1616",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:46",
      "total_flops_so_far": 2315789851060224.0,
      "budget_used_percent": 2.315789851060224
    },
    {
      "type": "training",
      "description": "Training step 1617",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:46",
      "total_flops_so_far": 2317222003101696.0,
      "budget_used_percent": 2.317222003101696
    },
    {
      "type": "training",
      "description": "Training step 1618",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:46",
      "total_flops_so_far": 2318654155143168.0,
      "budget_used_percent": 2.318654155143168
    },
    {
      "type": "training",
      "description": "Training step 1619",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:46",
      "total_flops_so_far": 2320086307184640.0,
      "budget_used_percent": 2.32008630718464
    },
    {
      "type": "training",
      "description": "Training step 1620",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:47",
      "total_flops_so_far": 2321518459226112.0,
      "budget_used_percent": 2.321518459226112
    },
    {
      "type": "training",
      "description": "Training step 1621",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:47",
      "total_flops_so_far": 2322950611267584.0,
      "budget_used_percent": 2.322950611267584
    },
    {
      "type": "training",
      "description": "Training step 1622",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:47",
      "total_flops_so_far": 2324382763309056.0,
      "budget_used_percent": 2.324382763309056
    },
    {
      "type": "training",
      "description": "Training step 1623",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:47",
      "total_flops_so_far": 2325814915350528.0,
      "budget_used_percent": 2.325814915350528
    },
    {
      "type": "training",
      "description": "Training step 1624",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:47",
      "total_flops_so_far": 2327247067392000.0,
      "budget_used_percent": 2.327247067392
    },
    {
      "type": "training",
      "description": "Training step 1625",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:47",
      "total_flops_so_far": 2328679219433472.0,
      "budget_used_percent": 2.328679219433472
    },
    {
      "type": "training",
      "description": "Training step 1626",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:48",
      "total_flops_so_far": 2330111371474944.0,
      "budget_used_percent": 2.3301113714749437
    },
    {
      "type": "training",
      "description": "Training step 1627",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:48",
      "total_flops_so_far": 2331543523516416.0,
      "budget_used_percent": 2.331543523516416
    },
    {
      "type": "training",
      "description": "Training step 1628",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:48",
      "total_flops_so_far": 2332975675557888.0,
      "budget_used_percent": 2.332975675557888
    },
    {
      "type": "training",
      "description": "Training step 1629",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:48",
      "total_flops_so_far": 2334407827599360.0,
      "budget_used_percent": 2.33440782759936
    },
    {
      "type": "training",
      "description": "Training step 1630",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:48",
      "total_flops_so_far": 2335839979640832.0,
      "budget_used_percent": 2.335839979640832
    },
    {
      "type": "training",
      "description": "Training step 1631",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:48",
      "total_flops_so_far": 2337272131682304.0,
      "budget_used_percent": 2.3372721316823037
    },
    {
      "type": "training",
      "description": "Training step 1632",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:49",
      "total_flops_so_far": 2338704283723776.0,
      "budget_used_percent": 2.338704283723776
    },
    {
      "type": "training",
      "description": "Training step 1633",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:49",
      "total_flops_so_far": 2340136435765248.0,
      "budget_used_percent": 2.340136435765248
    },
    {
      "type": "training",
      "description": "Training step 1634",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:49",
      "total_flops_so_far": 2341568587806720.0,
      "budget_used_percent": 2.3415685878067203
    },
    {
      "type": "training",
      "description": "Training step 1635",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:49",
      "total_flops_so_far": 2343000739848192.0,
      "budget_used_percent": 2.343000739848192
    },
    {
      "type": "training",
      "description": "Training step 1636",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:49",
      "total_flops_so_far": 2344432891889664.0,
      "budget_used_percent": 2.3444328918896638
    },
    {
      "type": "training",
      "description": "Training step 1637",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:49",
      "total_flops_so_far": 2345865043931136.0,
      "budget_used_percent": 2.345865043931136
    },
    {
      "type": "training",
      "description": "Training step 1638",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:49",
      "total_flops_so_far": 2347297195972608.0,
      "budget_used_percent": 2.3472971959726077
    },
    {
      "type": "training",
      "description": "Training step 1639",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:50",
      "total_flops_so_far": 2348729348014080.0,
      "budget_used_percent": 2.3487293480140803
    },
    {
      "type": "training",
      "description": "Training step 1640",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:50",
      "total_flops_so_far": 2350161500055552.0,
      "budget_used_percent": 2.350161500055552
    },
    {
      "type": "training",
      "description": "Training step 1641",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:50",
      "total_flops_so_far": 2351593652097024.0,
      "budget_used_percent": 2.351593652097024
    },
    {
      "type": "training",
      "description": "Training step 1642",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:50",
      "total_flops_so_far": 2353025804138496.0,
      "budget_used_percent": 2.353025804138496
    },
    {
      "type": "training",
      "description": "Training step 1643",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:50",
      "total_flops_so_far": 2354457956179968.0,
      "budget_used_percent": 2.354457956179968
    },
    {
      "type": "training",
      "description": "Training step 1644",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:50",
      "total_flops_so_far": 2355890108221440.0,
      "budget_used_percent": 2.35589010822144
    },
    {
      "type": "training",
      "description": "Training step 1645",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:51",
      "total_flops_so_far": 2357322260262912.0,
      "budget_used_percent": 2.357322260262912
    },
    {
      "type": "training",
      "description": "Training step 1646",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:51",
      "total_flops_so_far": 2358754412304384.0,
      "budget_used_percent": 2.358754412304384
    },
    {
      "type": "training",
      "description": "Training step 1647",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:51",
      "total_flops_so_far": 2360186564345856.0,
      "budget_used_percent": 2.360186564345856
    },
    {
      "type": "training",
      "description": "Training step 1648",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:51",
      "total_flops_so_far": 2361618716387328.0,
      "budget_used_percent": 2.361618716387328
    },
    {
      "type": "training",
      "description": "Training step 1649",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:51",
      "total_flops_so_far": 2363050868428800.0,
      "budget_used_percent": 2.3630508684288
    },
    {
      "type": "training",
      "description": "Training step 1650",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:51",
      "total_flops_so_far": 2364483020470272.0,
      "budget_used_percent": 2.364483020470272
    },
    {
      "type": "training",
      "description": "Training step 1651",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:52",
      "total_flops_so_far": 2365915172511744.0,
      "budget_used_percent": 2.365915172511744
    },
    {
      "type": "training",
      "description": "Training step 1652",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:52",
      "total_flops_so_far": 2367347324553216.0,
      "budget_used_percent": 2.367347324553216
    },
    {
      "type": "training",
      "description": "Training step 1653",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:52",
      "total_flops_so_far": 2368779476594688.0,
      "budget_used_percent": 2.368779476594688
    },
    {
      "type": "training",
      "description": "Training step 1654",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:52",
      "total_flops_so_far": 2370211628636160.0,
      "budget_used_percent": 2.37021162863616
    },
    {
      "type": "training",
      "description": "Training step 1655",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:52",
      "total_flops_so_far": 2371643780677632.0,
      "budget_used_percent": 2.371643780677632
    },
    {
      "type": "training",
      "description": "Training step 1656",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:52",
      "total_flops_so_far": 2373075932719104.0,
      "budget_used_percent": 2.3730759327191038
    },
    {
      "type": "training",
      "description": "Training step 1657",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:52",
      "total_flops_so_far": 2374508084760576.0,
      "budget_used_percent": 2.374508084760576
    },
    {
      "type": "training",
      "description": "Training step 1658",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:53",
      "total_flops_so_far": 2375940236802048.0,
      "budget_used_percent": 2.375940236802048
    },
    {
      "type": "training",
      "description": "Training step 1659",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:53",
      "total_flops_so_far": 2377372388843520.0,
      "budget_used_percent": 2.37737238884352
    },
    {
      "type": "training",
      "description": "Training step 1660",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:53",
      "total_flops_so_far": 2378804540884992.0,
      "budget_used_percent": 2.378804540884992
    },
    {
      "type": "training",
      "description": "Training step 1661",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:53",
      "total_flops_so_far": 2380236692926464.0,
      "budget_used_percent": 2.380236692926464
    },
    {
      "type": "training",
      "description": "Training step 1662",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:53",
      "total_flops_so_far": 2381668844967936.0,
      "budget_used_percent": 2.381668844967936
    },
    {
      "type": "training",
      "description": "Training step 1663",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:53",
      "total_flops_so_far": 2383100997009408.0,
      "budget_used_percent": 2.383100997009408
    },
    {
      "type": "training",
      "description": "Training step 1664",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:54",
      "total_flops_so_far": 2384533149050880.0,
      "budget_used_percent": 2.3845331490508803
    },
    {
      "type": "training",
      "description": "Training step 1665",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:54",
      "total_flops_so_far": 2385965301092352.0,
      "budget_used_percent": 2.385965301092352
    },
    {
      "type": "training",
      "description": "Training step 1666",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:54",
      "total_flops_so_far": 2387397453133824.0,
      "budget_used_percent": 2.387397453133824
    },
    {
      "type": "training",
      "description": "Training step 1667",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:54",
      "total_flops_so_far": 2388829605175296.0,
      "budget_used_percent": 2.388829605175296
    },
    {
      "type": "training",
      "description": "Training step 1668",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:54",
      "total_flops_so_far": 2390261757216768.0,
      "budget_used_percent": 2.3902617572167677
    },
    {
      "type": "training",
      "description": "Training step 1669",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:54",
      "total_flops_so_far": 2391693909258240.0,
      "budget_used_percent": 2.3916939092582403
    },
    {
      "type": "training",
      "description": "Training step 1670",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:55",
      "total_flops_so_far": 2393126061299712.0,
      "budget_used_percent": 2.393126061299712
    },
    {
      "type": "training",
      "description": "Training step 1671",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:55",
      "total_flops_so_far": 2394558213341184.0,
      "budget_used_percent": 2.3945582133411842
    },
    {
      "type": "training",
      "description": "Training step 1672",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:55",
      "total_flops_so_far": 2395990365382656.0,
      "budget_used_percent": 2.395990365382656
    },
    {
      "type": "training",
      "description": "Training step 1673",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:55",
      "total_flops_so_far": 2397422517424128.0,
      "budget_used_percent": 2.397422517424128
    },
    {
      "type": "training",
      "description": "Training step 1674",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:55",
      "total_flops_so_far": 2398854669465600.0,
      "budget_used_percent": 2.3988546694656
    },
    {
      "type": "training",
      "description": "Training step 1675",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:55",
      "total_flops_so_far": 2400286821507072.0,
      "budget_used_percent": 2.4002868215070716
    },
    {
      "type": "training",
      "description": "Training step 1676",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:56",
      "total_flops_so_far": 2401718973548544.0,
      "budget_used_percent": 2.4017189735485442
    },
    {
      "type": "training",
      "description": "Training step 1677",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:56",
      "total_flops_so_far": 2403151125590016.0,
      "budget_used_percent": 2.403151125590016
    },
    {
      "type": "training",
      "description": "Training step 1678",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:56",
      "total_flops_so_far": 2404583277631488.0,
      "budget_used_percent": 2.404583277631488
    },
    {
      "type": "training",
      "description": "Training step 1679",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:56",
      "total_flops_so_far": 2406015429672960.0,
      "budget_used_percent": 2.40601542967296
    },
    {
      "type": "training",
      "description": "Training step 1680",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:56",
      "total_flops_so_far": 2407447581714432.0,
      "budget_used_percent": 2.407447581714432
    },
    {
      "type": "training",
      "description": "Training step 1681",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:56",
      "total_flops_so_far": 2408879733755904.0,
      "budget_used_percent": 2.408879733755904
    },
    {
      "type": "training",
      "description": "Training step 1682",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:56",
      "total_flops_so_far": 2410311885797376.0,
      "budget_used_percent": 2.410311885797376
    },
    {
      "type": "training",
      "description": "Training step 1683",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:57",
      "total_flops_so_far": 2411744037838848.0,
      "budget_used_percent": 2.411744037838848
    },
    {
      "type": "training",
      "description": "Training step 1684",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:57",
      "total_flops_so_far": 2413176189880320.0,
      "budget_used_percent": 2.41317618988032
    },
    {
      "type": "training",
      "description": "Training step 1685",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:57",
      "total_flops_so_far": 2414608341921792.0,
      "budget_used_percent": 2.414608341921792
    },
    {
      "type": "training",
      "description": "Training step 1686",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:57",
      "total_flops_so_far": 2416040493963264.0,
      "budget_used_percent": 2.416040493963264
    },
    {
      "type": "training",
      "description": "Training step 1687",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:57",
      "total_flops_so_far": 2417472646004736.0,
      "budget_used_percent": 2.417472646004736
    },
    {
      "type": "training",
      "description": "Training step 1688",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:57",
      "total_flops_so_far": 2418904798046208.0,
      "budget_used_percent": 2.418904798046208
    },
    {
      "type": "training",
      "description": "Training step 1689",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:58",
      "total_flops_so_far": 2420336950087680.0,
      "budget_used_percent": 2.42033695008768
    },
    {
      "type": "training",
      "description": "Training step 1690",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:58",
      "total_flops_so_far": 2421769102129152.0,
      "budget_used_percent": 2.421769102129152
    },
    {
      "type": "training",
      "description": "Training step 1691",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:58",
      "total_flops_so_far": 2423201254170624.0,
      "budget_used_percent": 2.423201254170624
    },
    {
      "type": "training",
      "description": "Training step 1692",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:58",
      "total_flops_so_far": 2424633406212096.0,
      "budget_used_percent": 2.424633406212096
    },
    {
      "type": "training",
      "description": "Training step 1693",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:58",
      "total_flops_so_far": 2426065558253568.0,
      "budget_used_percent": 2.4260655582535677
    },
    {
      "type": "training",
      "description": "Training step 1694",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:58",
      "total_flops_so_far": 2427497710295040.0,
      "budget_used_percent": 2.4274977102950404
    },
    {
      "type": "training",
      "description": "Training step 1695",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:59",
      "total_flops_so_far": 2428929862336512.0,
      "budget_used_percent": 2.428929862336512
    },
    {
      "type": "training",
      "description": "Training step 1696",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:59",
      "total_flops_so_far": 2430362014377984.0,
      "budget_used_percent": 2.430362014377984
    },
    {
      "type": "training",
      "description": "Training step 1697",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:59",
      "total_flops_so_far": 2431794166419456.0,
      "budget_used_percent": 2.431794166419456
    },
    {
      "type": "training",
      "description": "Training step 1698",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:59",
      "total_flops_so_far": 2433226318460928.0,
      "budget_used_percent": 2.4332263184609277
    },
    {
      "type": "training",
      "description": "Training step 1699",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:59",
      "total_flops_so_far": 2434658470502400.0,
      "budget_used_percent": 2.4346584705024
    },
    {
      "type": "training",
      "description": "Training step 1700",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:31:59",
      "total_flops_so_far": 2436090622543872.0,
      "budget_used_percent": 2.436090622543872
    },
    {
      "type": "training",
      "description": "Training step 1701",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:00",
      "total_flops_so_far": 2437522774585344.0,
      "budget_used_percent": 2.4375227745853443
    },
    {
      "type": "training",
      "description": "Training step 1702",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:00",
      "total_flops_so_far": 2438954926626816.0,
      "budget_used_percent": 2.438954926626816
    },
    {
      "type": "training",
      "description": "Training step 1703",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:00",
      "total_flops_so_far": 2440387078668288.0,
      "budget_used_percent": 2.440387078668288
    },
    {
      "type": "training",
      "description": "Training step 1704",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:00",
      "total_flops_so_far": 2441819230709760.0,
      "budget_used_percent": 2.44181923070976
    },
    {
      "type": "training",
      "description": "Training step 1705",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:00",
      "total_flops_so_far": 2443251382751232.0,
      "budget_used_percent": 2.4432513827512317
    },
    {
      "type": "training",
      "description": "Training step 1706",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:00",
      "total_flops_so_far": 2444683534792704.0,
      "budget_used_percent": 2.4446835347927043
    },
    {
      "type": "training",
      "description": "Training step 1707",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:01",
      "total_flops_so_far": 2446115686834176.0,
      "budget_used_percent": 2.446115686834176
    },
    {
      "type": "training",
      "description": "Training step 1708",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:01",
      "total_flops_so_far": 2447547838875648.0,
      "budget_used_percent": 2.447547838875648
    },
    {
      "type": "training",
      "description": "Training step 1709",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:01",
      "total_flops_so_far": 2448979990917120.0,
      "budget_used_percent": 2.44897999091712
    },
    {
      "type": "training",
      "description": "Training step 1710",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:01",
      "total_flops_so_far": 2450412142958592.0,
      "budget_used_percent": 2.450412142958592
    },
    {
      "type": "training",
      "description": "Training step 1711",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:01",
      "total_flops_so_far": 2451844295000064.0,
      "budget_used_percent": 2.451844295000064
    },
    {
      "type": "training",
      "description": "Training step 1712",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:01",
      "total_flops_so_far": 2453276447041536.0,
      "budget_used_percent": 2.453276447041536
    },
    {
      "type": "training",
      "description": "Training step 1713",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:02",
      "total_flops_so_far": 2454708599083008.0,
      "budget_used_percent": 2.454708599083008
    },
    {
      "type": "training",
      "description": "Training step 1714",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:02",
      "total_flops_so_far": 2456140751124480.0,
      "budget_used_percent": 2.45614075112448
    },
    {
      "type": "training",
      "description": "Training step 1715",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:02",
      "total_flops_so_far": 2457572903165952.0,
      "budget_used_percent": 2.457572903165952
    },
    {
      "type": "training",
      "description": "Training step 1716",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:02",
      "total_flops_so_far": 2459005055207424.0,
      "budget_used_percent": 2.459005055207424
    },
    {
      "type": "training",
      "description": "Training step 1717",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:02",
      "total_flops_so_far": 2460437207248896.0,
      "budget_used_percent": 2.460437207248896
    },
    {
      "type": "training",
      "description": "Training step 1718",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:02",
      "total_flops_so_far": 2461869359290368.0,
      "budget_used_percent": 2.461869359290368
    },
    {
      "type": "training",
      "description": "Training step 1719",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:03",
      "total_flops_so_far": 2463301511331840.0,
      "budget_used_percent": 2.46330151133184
    },
    {
      "type": "training",
      "description": "Training step 1720",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:03",
      "total_flops_so_far": 2464733663373312.0,
      "budget_used_percent": 2.464733663373312
    },
    {
      "type": "training",
      "description": "Training step 1721",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:03",
      "total_flops_so_far": 2466165815414784.0,
      "budget_used_percent": 2.466165815414784
    },
    {
      "type": "training",
      "description": "Training step 1722",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:03",
      "total_flops_so_far": 2467597967456256.0,
      "budget_used_percent": 2.467597967456256
    },
    {
      "type": "training",
      "description": "Training step 1723",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:03",
      "total_flops_so_far": 2469030119497728.0,
      "budget_used_percent": 2.4690301194977278
    },
    {
      "type": "training",
      "description": "Training step 1724",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:03",
      "total_flops_so_far": 2470462271539200.0,
      "budget_used_percent": 2.4704622715392
    },
    {
      "type": "training",
      "description": "Training step 1725",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:04",
      "total_flops_so_far": 2471894423580672.0,
      "budget_used_percent": 2.471894423580672
    },
    {
      "type": "training",
      "description": "Training step 1726",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:04",
      "total_flops_so_far": 2473326575622144.0,
      "budget_used_percent": 2.473326575622144
    },
    {
      "type": "training",
      "description": "Training step 1727",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:04",
      "total_flops_so_far": 2474758727663616.0,
      "budget_used_percent": 2.474758727663616
    },
    {
      "type": "training",
      "description": "Training step 1728",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:04",
      "total_flops_so_far": 2476190879705088.0,
      "budget_used_percent": 2.4761908797050878
    },
    {
      "type": "training",
      "description": "Training step 1729",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:04",
      "total_flops_so_far": 2477623031746560.0,
      "budget_used_percent": 2.47762303174656
    },
    {
      "type": "training",
      "description": "Training step 1730",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:04",
      "total_flops_so_far": 2479055183788032.0,
      "budget_used_percent": 2.479055183788032
    },
    {
      "type": "training",
      "description": "Training step 1731",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:04",
      "total_flops_so_far": 2480487335829504.0,
      "budget_used_percent": 2.4804873358295043
    },
    {
      "type": "training",
      "description": "Training step 1732",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:05",
      "total_flops_so_far": 2481919487870976.0,
      "budget_used_percent": 2.481919487870976
    },
    {
      "type": "training",
      "description": "Training step 1733",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:05",
      "total_flops_so_far": 2483351639912448.0,
      "budget_used_percent": 2.483351639912448
    },
    {
      "type": "training",
      "description": "Training step 1734",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:05",
      "total_flops_so_far": 2484783791953920.0,
      "budget_used_percent": 2.48478379195392
    },
    {
      "type": "training",
      "description": "Training step 1735",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:05",
      "total_flops_so_far": 2486215943995392.0,
      "budget_used_percent": 2.4862159439953917
    },
    {
      "type": "training",
      "description": "Training step 1736",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:05",
      "total_flops_so_far": 2487648096036864.0,
      "budget_used_percent": 2.4876480960368643
    },
    {
      "type": "training",
      "description": "Training step 1737",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:05",
      "total_flops_so_far": 2489080248078336.0,
      "budget_used_percent": 2.489080248078336
    },
    {
      "type": "training",
      "description": "Training step 1738",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:06",
      "total_flops_so_far": 2490512400119808.0,
      "budget_used_percent": 2.4905124001198082
    },
    {
      "type": "training",
      "description": "Training step 1739",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:06",
      "total_flops_so_far": 2491944552161280.0,
      "budget_used_percent": 2.49194455216128
    },
    {
      "type": "training",
      "description": "Training step 1740",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:06",
      "total_flops_so_far": 2493376704202752.0,
      "budget_used_percent": 2.493376704202752
    },
    {
      "type": "training",
      "description": "Training step 1741",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:06",
      "total_flops_so_far": 2494808856244224.0,
      "budget_used_percent": 2.494808856244224
    },
    {
      "type": "training",
      "description": "Training step 1742",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:06",
      "total_flops_so_far": 2496241008285696.0,
      "budget_used_percent": 2.496241008285696
    },
    {
      "type": "training",
      "description": "Training step 1743",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:06",
      "total_flops_so_far": 2497673160327168.0,
      "budget_used_percent": 2.4976731603271682
    },
    {
      "type": "training",
      "description": "Training step 1744",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:07",
      "total_flops_so_far": 2499105312368640.0,
      "budget_used_percent": 2.49910531236864
    },
    {
      "type": "training",
      "description": "Training step 1745",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:07",
      "total_flops_so_far": 2500537464410112.0,
      "budget_used_percent": 2.500537464410112
    },
    {
      "type": "training",
      "description": "Training step 1746",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:07",
      "total_flops_so_far": 2501969616451584.0,
      "budget_used_percent": 2.501969616451584
    },
    {
      "type": "training",
      "description": "Training step 1747",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:07",
      "total_flops_so_far": 2503401768493056.0,
      "budget_used_percent": 2.503401768493056
    },
    {
      "type": "training",
      "description": "Training step 1748",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:07",
      "total_flops_so_far": 2504833920534528.0,
      "budget_used_percent": 2.504833920534528
    },
    {
      "type": "training",
      "description": "Training step 1749",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:07",
      "total_flops_so_far": 2506266072576000.0,
      "budget_used_percent": 2.506266072576
    },
    {
      "type": "training",
      "description": "Training step 1750",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:08",
      "total_flops_so_far": 2507698224617472.0,
      "budget_used_percent": 2.507698224617472
    },
    {
      "type": "training",
      "description": "Training step 1751",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:08",
      "total_flops_so_far": 2509130376658944.0,
      "budget_used_percent": 2.509130376658944
    },
    {
      "type": "training",
      "description": "Training step 1752",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:08",
      "total_flops_so_far": 2510562528700416.0,
      "budget_used_percent": 2.510562528700416
    },
    {
      "type": "training",
      "description": "Training step 1753",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:08",
      "total_flops_so_far": 2511994680741888.0,
      "budget_used_percent": 2.511994680741888
    },
    {
      "type": "training",
      "description": "Training step 1754",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:08",
      "total_flops_so_far": 2513426832783360.0,
      "budget_used_percent": 2.51342683278336
    },
    {
      "type": "training",
      "description": "Training step 1755",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:08",
      "total_flops_so_far": 2514858984824832.0,
      "budget_used_percent": 2.514858984824832
    },
    {
      "type": "training",
      "description": "Training step 1756",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:08",
      "total_flops_so_far": 2516291136866304.0,
      "budget_used_percent": 2.516291136866304
    },
    {
      "type": "training",
      "description": "Training step 1757",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:09",
      "total_flops_so_far": 2517723288907776.0,
      "budget_used_percent": 2.517723288907776
    },
    {
      "type": "training",
      "description": "Training step 1758",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:09",
      "total_flops_so_far": 2519155440949248.0,
      "budget_used_percent": 2.519155440949248
    },
    {
      "type": "training",
      "description": "Training step 1759",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:09",
      "total_flops_so_far": 2520587592990720.0,
      "budget_used_percent": 2.52058759299072
    },
    {
      "type": "training",
      "description": "Training step 1760",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:09",
      "total_flops_so_far": 2522019745032192.0,
      "budget_used_percent": 2.5220197450321917
    },
    {
      "type": "training",
      "description": "Training step 1761",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:09",
      "total_flops_so_far": 2523451897073664.0,
      "budget_used_percent": 2.523451897073664
    },
    {
      "type": "training",
      "description": "Training step 1762",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:09",
      "total_flops_so_far": 2524884049115136.0,
      "budget_used_percent": 2.524884049115136
    },
    {
      "type": "training",
      "description": "Training step 1763",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:10",
      "total_flops_so_far": 2526316201156608.0,
      "budget_used_percent": 2.526316201156608
    },
    {
      "type": "training",
      "description": "Training step 1764",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:10",
      "total_flops_so_far": 2527748353198080.0,
      "budget_used_percent": 2.52774835319808
    },
    {
      "type": "training",
      "description": "Training step 1765",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:10",
      "total_flops_so_far": 2529180505239552.0,
      "budget_used_percent": 2.5291805052395517
    },
    {
      "type": "training",
      "description": "Training step 1766",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:10",
      "total_flops_so_far": 2530612657281024.0,
      "budget_used_percent": 2.530612657281024
    },
    {
      "type": "training",
      "description": "Training step 1767",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:10",
      "total_flops_so_far": 2532044809322496.0,
      "budget_used_percent": 2.532044809322496
    },
    {
      "type": "training",
      "description": "Training step 1768",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:10",
      "total_flops_so_far": 2533476961363968.0,
      "budget_used_percent": 2.5334769613639683
    },
    {
      "type": "training",
      "description": "Training step 1769",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:11",
      "total_flops_so_far": 2534909113405440.0,
      "budget_used_percent": 2.53490911340544
    },
    {
      "type": "training",
      "description": "Training step 1770",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:11",
      "total_flops_so_far": 2536341265446912.0,
      "budget_used_percent": 2.5363412654469117
    },
    {
      "type": "training",
      "description": "Training step 1771",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:11",
      "total_flops_so_far": 2537773417488384.0,
      "budget_used_percent": 2.537773417488384
    },
    {
      "type": "training",
      "description": "Training step 1772",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:11",
      "total_flops_so_far": 2539205569529856.0,
      "budget_used_percent": 2.5392055695298557
    },
    {
      "type": "training",
      "description": "Training step 1773",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:11",
      "total_flops_so_far": 2540637721571328.0,
      "budget_used_percent": 2.5406377215713283
    },
    {
      "type": "training",
      "description": "Training step 1774",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:11",
      "total_flops_so_far": 2542069873612800.0,
      "budget_used_percent": 2.5420698736128
    },
    {
      "type": "training",
      "description": "Training step 1775",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:12",
      "total_flops_so_far": 2543502025654272.0,
      "budget_used_percent": 2.543502025654272
    },
    {
      "type": "training",
      "description": "Training step 1776",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:12",
      "total_flops_so_far": 2544934177695744.0,
      "budget_used_percent": 2.544934177695744
    },
    {
      "type": "training",
      "description": "Training step 1777",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:12",
      "total_flops_so_far": 2546366329737216.0,
      "budget_used_percent": 2.546366329737216
    },
    {
      "type": "training",
      "description": "Training step 1778",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:12",
      "total_flops_so_far": 2547798481778688.0,
      "budget_used_percent": 2.547798481778688
    },
    {
      "type": "training",
      "description": "Training step 1779",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:12",
      "total_flops_so_far": 2549230633820160.0,
      "budget_used_percent": 2.54923063382016
    },
    {
      "type": "training",
      "description": "Training step 1780",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:12",
      "total_flops_so_far": 2550662785861632.0,
      "budget_used_percent": 2.550662785861632
    },
    {
      "type": "training",
      "description": "Training step 1781",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:13",
      "total_flops_so_far": 2552094937903104.0,
      "budget_used_percent": 2.552094937903104
    },
    {
      "type": "training",
      "description": "Training step 1782",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:13",
      "total_flops_so_far": 2553527089944576.0,
      "budget_used_percent": 2.553527089944576
    },
    {
      "type": "training",
      "description": "Training step 1783",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:13",
      "total_flops_so_far": 2554959241986048.0,
      "budget_used_percent": 2.554959241986048
    },
    {
      "type": "training",
      "description": "Training step 1784",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:13",
      "total_flops_so_far": 2556391394027520.0,
      "budget_used_percent": 2.55639139402752
    },
    {
      "type": "training",
      "description": "Training step 1785",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:13",
      "total_flops_so_far": 2557823546068992.0,
      "budget_used_percent": 2.557823546068992
    },
    {
      "type": "training",
      "description": "Training step 1786",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:13",
      "total_flops_so_far": 2559255698110464.0,
      "budget_used_percent": 2.559255698110464
    },
    {
      "type": "training",
      "description": "Training step 1787",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:14",
      "total_flops_so_far": 2560687850151936.0,
      "budget_used_percent": 2.560687850151936
    },
    {
      "type": "training",
      "description": "Training step 1788",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:14",
      "total_flops_so_far": 2562120002193408.0,
      "budget_used_percent": 2.562120002193408
    },
    {
      "type": "training",
      "description": "Training step 1789",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:14",
      "total_flops_so_far": 2563552154234880.0,
      "budget_used_percent": 2.56355215423488
    },
    {
      "type": "training",
      "description": "Training step 1790",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:14",
      "total_flops_so_far": 2564984306276352.0,
      "budget_used_percent": 2.5649843062763518
    },
    {
      "type": "training",
      "description": "Training step 1791",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:14",
      "total_flops_so_far": 2566416458317824.0,
      "budget_used_percent": 2.566416458317824
    },
    {
      "type": "training",
      "description": "Training step 1792",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:14",
      "total_flops_so_far": 2567848610359296.0,
      "budget_used_percent": 2.567848610359296
    },
    {
      "type": "training",
      "description": "Training step 1793",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:15",
      "total_flops_so_far": 2569280762400768.0,
      "budget_used_percent": 2.569280762400768
    },
    {
      "type": "training",
      "description": "Training step 1794",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:15",
      "total_flops_so_far": 2570712914442240.0,
      "budget_used_percent": 2.57071291444224
    },
    {
      "type": "training",
      "description": "Training step 1795",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:15",
      "total_flops_so_far": 2572145066483712.0,
      "budget_used_percent": 2.5721450664837118
    },
    {
      "type": "training",
      "description": "Training step 1796",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:15",
      "total_flops_so_far": 2573577218525184.0,
      "budget_used_percent": 2.573577218525184
    },
    {
      "type": "training",
      "description": "Training step 1797",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:15",
      "total_flops_so_far": 2575009370566656.0,
      "budget_used_percent": 2.575009370566656
    },
    {
      "type": "training",
      "description": "Training step 1798",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:15",
      "total_flops_so_far": 2576441522608128.0,
      "budget_used_percent": 2.5764415226081283
    },
    {
      "type": "training",
      "description": "Training step 1799",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:15",
      "total_flops_so_far": 2577873674649600.0,
      "budget_used_percent": 2.5778736746496
    },
    {
      "type": "training",
      "description": "Training step 1800",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:16",
      "total_flops_so_far": 2579305826691072.0,
      "budget_used_percent": 2.579305826691072
    },
    {
      "type": "training",
      "description": "Training step 1801",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:16",
      "total_flops_so_far": 2580737978732544.0,
      "budget_used_percent": 2.580737978732544
    },
    {
      "type": "training",
      "description": "Training step 1802",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:16",
      "total_flops_so_far": 2582170130774016.0,
      "budget_used_percent": 2.5821701307740157
    },
    {
      "type": "training",
      "description": "Training step 1803",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:16",
      "total_flops_so_far": 2583602282815488.0,
      "budget_used_percent": 2.5836022828154883
    },
    {
      "type": "training",
      "description": "Training step 1804",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:16",
      "total_flops_so_far": 2585034434856960.0,
      "budget_used_percent": 2.58503443485696
    },
    {
      "type": "training",
      "description": "Training step 1805",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:16",
      "total_flops_so_far": 2586466586898432.0,
      "budget_used_percent": 2.5864665868984322
    },
    {
      "type": "training",
      "description": "Training step 1806",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:17",
      "total_flops_so_far": 2587898738939904.0,
      "budget_used_percent": 2.587898738939904
    },
    {
      "type": "training",
      "description": "Training step 1807",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:17",
      "total_flops_so_far": 2589330890981376.0,
      "budget_used_percent": 2.589330890981376
    },
    {
      "type": "training",
      "description": "Training step 1808",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:17",
      "total_flops_so_far": 2590763043022848.0,
      "budget_used_percent": 2.590763043022848
    },
    {
      "type": "training",
      "description": "Training step 1809",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:17",
      "total_flops_so_far": 2592195195064320.0,
      "budget_used_percent": 2.59219519506432
    },
    {
      "type": "training",
      "description": "Training step 1810",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:17",
      "total_flops_so_far": 2593627347105792.0,
      "budget_used_percent": 2.5936273471057922
    },
    {
      "type": "training",
      "description": "Training step 1811",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:17",
      "total_flops_so_far": 2595059499147264.0,
      "budget_used_percent": 2.595059499147264
    },
    {
      "type": "training",
      "description": "Training step 1812",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:18",
      "total_flops_so_far": 2596491651188736.0,
      "budget_used_percent": 2.596491651188736
    },
    {
      "type": "training",
      "description": "Training step 1813",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:18",
      "total_flops_so_far": 2597923803230208.0,
      "budget_used_percent": 2.597923803230208
    },
    {
      "type": "training",
      "description": "Training step 1814",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:18",
      "total_flops_so_far": 2599355955271680.0,
      "budget_used_percent": 2.59935595527168
    },
    {
      "type": "training",
      "description": "Training step 1815",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:18",
      "total_flops_so_far": 2600788107313152.0,
      "budget_used_percent": 2.6007881073131522
    },
    {
      "type": "training",
      "description": "Training step 1816",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:18",
      "total_flops_so_far": 2602220259354624.0,
      "budget_used_percent": 2.602220259354624
    },
    {
      "type": "training",
      "description": "Training step 1817",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:18",
      "total_flops_so_far": 2603652411396096.0,
      "budget_used_percent": 2.603652411396096
    },
    {
      "type": "training",
      "description": "Training step 1818",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:19",
      "total_flops_so_far": 2605084563437568.0,
      "budget_used_percent": 2.605084563437568
    },
    {
      "type": "training",
      "description": "Training step 1819",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:19",
      "total_flops_so_far": 2606516715479040.0,
      "budget_used_percent": 2.60651671547904
    },
    {
      "type": "training",
      "description": "Training step 1820",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:19",
      "total_flops_so_far": 2607948867520512.0,
      "budget_used_percent": 2.607948867520512
    },
    {
      "type": "training",
      "description": "Training step 1821",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:19",
      "total_flops_so_far": 2609381019561984.0,
      "budget_used_percent": 2.609381019561984
    },
    {
      "type": "training",
      "description": "Training step 1822",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:19",
      "total_flops_so_far": 2610813171603456.0,
      "budget_used_percent": 2.610813171603456
    },
    {
      "type": "training",
      "description": "Training step 1823",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:19",
      "total_flops_so_far": 2612245323644928.0,
      "budget_used_percent": 2.612245323644928
    },
    {
      "type": "training",
      "description": "Training step 1824",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:20",
      "total_flops_so_far": 2613677475686400.0,
      "budget_used_percent": 2.6136774756864
    },
    {
      "type": "training",
      "description": "Training step 1825",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:20",
      "total_flops_so_far": 2615109627727872.0,
      "budget_used_percent": 2.615109627727872
    },
    {
      "type": "training",
      "description": "Training step 1826",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:20",
      "total_flops_so_far": 2616541779769344.0,
      "budget_used_percent": 2.616541779769344
    },
    {
      "type": "training",
      "description": "Training step 1827",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:20",
      "total_flops_so_far": 2617973931810816.0,
      "budget_used_percent": 2.6179739318108157
    },
    {
      "type": "training",
      "description": "Training step 1828",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:20",
      "total_flops_so_far": 2619406083852288.0,
      "budget_used_percent": 2.6194060838522883
    },
    {
      "type": "training",
      "description": "Training step 1829",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:20",
      "total_flops_so_far": 2620838235893760.0,
      "budget_used_percent": 2.62083823589376
    },
    {
      "type": "training",
      "description": "Training step 1830",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:21",
      "total_flops_so_far": 2622270387935232.0,
      "budget_used_percent": 2.622270387935232
    },
    {
      "type": "training",
      "description": "Training step 1831",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:21",
      "total_flops_so_far": 2623702539976704.0,
      "budget_used_percent": 2.623702539976704
    },
    {
      "type": "training",
      "description": "Training step 1832",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:21",
      "total_flops_so_far": 2625134692018176.0,
      "budget_used_percent": 2.6251346920181757
    },
    {
      "type": "training",
      "description": "Training step 1833",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:21",
      "total_flops_so_far": 2626566844059648.0,
      "budget_used_percent": 2.626566844059648
    },
    {
      "type": "training",
      "description": "Training step 1834",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:21",
      "total_flops_so_far": 2627998996101120.0,
      "budget_used_percent": 2.62799899610112
    },
    {
      "type": "training",
      "description": "Training step 1835",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:21",
      "total_flops_so_far": 2629431148142592.0,
      "budget_used_percent": 2.6294311481425923
    },
    {
      "type": "training",
      "description": "Training step 1836",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:22",
      "total_flops_so_far": 2630863300184064.0,
      "budget_used_percent": 2.630863300184064
    },
    {
      "type": "training",
      "description": "Training step 1837",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:22",
      "total_flops_so_far": 2632295452225536.0,
      "budget_used_percent": 2.632295452225536
    },
    {
      "type": "training",
      "description": "Training step 1838",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:22",
      "total_flops_so_far": 2633727604267008.0,
      "budget_used_percent": 2.633727604267008
    },
    {
      "type": "training",
      "description": "Training step 1839",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:22",
      "total_flops_so_far": 2635159756308480.0,
      "budget_used_percent": 2.6351597563084797
    },
    {
      "type": "training",
      "description": "Training step 1840",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:22",
      "total_flops_so_far": 2636591908349952.0,
      "budget_used_percent": 2.6365919083499523
    },
    {
      "type": "training",
      "description": "Training step 1841",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:22",
      "total_flops_so_far": 2638024060391424.0,
      "budget_used_percent": 2.638024060391424
    },
    {
      "type": "training",
      "description": "Training step 1842",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:23",
      "total_flops_so_far": 2639456212432896.0,
      "budget_used_percent": 2.639456212432896
    },
    {
      "type": "training",
      "description": "Training step 1843",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:23",
      "total_flops_so_far": 2640888364474368.0,
      "budget_used_percent": 2.640888364474368
    },
    {
      "type": "training",
      "description": "Training step 1844",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:23",
      "total_flops_so_far": 2642320516515840.0,
      "budget_used_percent": 2.64232051651584
    },
    {
      "type": "training",
      "description": "Training step 1845",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:23",
      "total_flops_so_far": 2643752668557312.0,
      "budget_used_percent": 2.643752668557312
    },
    {
      "type": "training",
      "description": "Training step 1846",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:23",
      "total_flops_so_far": 2645184820598784.0,
      "budget_used_percent": 2.645184820598784
    },
    {
      "type": "training",
      "description": "Training step 1847",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:23",
      "total_flops_so_far": 2646616972640256.0,
      "budget_used_percent": 2.646616972640256
    },
    {
      "type": "training",
      "description": "Training step 1848",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:24",
      "total_flops_so_far": 2648049124681728.0,
      "budget_used_percent": 2.648049124681728
    },
    {
      "type": "training",
      "description": "Training step 1849",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:24",
      "total_flops_so_far": 2649481276723200.0,
      "budget_used_percent": 2.6494812767232
    },
    {
      "type": "training",
      "description": "Training step 1850",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:24",
      "total_flops_so_far": 2650913428764672.0,
      "budget_used_percent": 2.650913428764672
    },
    {
      "type": "training",
      "description": "Training step 1851",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:24",
      "total_flops_so_far": 2652345580806144.0,
      "budget_used_percent": 2.652345580806144
    },
    {
      "type": "training",
      "description": "Training step 1852",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:24",
      "total_flops_so_far": 2653777732847616.0,
      "budget_used_percent": 2.653777732847616
    },
    {
      "type": "training",
      "description": "Training step 1853",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:24",
      "total_flops_so_far": 2655209884889088.0,
      "budget_used_percent": 2.655209884889088
    },
    {
      "type": "training",
      "description": "Training step 1854",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:25",
      "total_flops_so_far": 2656642036930560.0,
      "budget_used_percent": 2.65664203693056
    },
    {
      "type": "training",
      "description": "Training step 1855",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:25",
      "total_flops_so_far": 2658074188972032.0,
      "budget_used_percent": 2.658074188972032
    },
    {
      "type": "training",
      "description": "Training step 1856",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:25",
      "total_flops_so_far": 2659506341013504.0,
      "budget_used_percent": 2.659506341013504
    },
    {
      "type": "training",
      "description": "Training step 1857",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:25",
      "total_flops_so_far": 2660938493054976.0,
      "budget_used_percent": 2.6609384930549758
    },
    {
      "type": "training",
      "description": "Training step 1858",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:25",
      "total_flops_so_far": 2662370645096448.0,
      "budget_used_percent": 2.662370645096448
    },
    {
      "type": "training",
      "description": "Training step 1859",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:25",
      "total_flops_so_far": 2663802797137920.0,
      "budget_used_percent": 2.66380279713792
    },
    {
      "type": "training",
      "description": "Training step 1860",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:26",
      "total_flops_so_far": 2665234949179392.0,
      "budget_used_percent": 2.665234949179392
    },
    {
      "type": "training",
      "description": "Training step 1861",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:26",
      "total_flops_so_far": 2666667101220864.0,
      "budget_used_percent": 2.666667101220864
    },
    {
      "type": "training",
      "description": "Training step 1862",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:26",
      "total_flops_so_far": 2668099253262336.0,
      "budget_used_percent": 2.6680992532623358
    },
    {
      "type": "training",
      "description": "Training step 1863",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:26",
      "total_flops_so_far": 2669531405303808.0,
      "budget_used_percent": 2.669531405303808
    },
    {
      "type": "training",
      "description": "Training step 1864",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:26",
      "total_flops_so_far": 2670963557345280.0,
      "budget_used_percent": 2.67096355734528
    },
    {
      "type": "training",
      "description": "Training step 1865",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:26",
      "total_flops_so_far": 2672395709386752.0,
      "budget_used_percent": 2.6723957093867523
    },
    {
      "type": "training",
      "description": "Training step 1866",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:26",
      "total_flops_so_far": 2673827861428224.0,
      "budget_used_percent": 2.673827861428224
    },
    {
      "type": "training",
      "description": "Training step 1867",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:27",
      "total_flops_so_far": 2675260013469696.0,
      "budget_used_percent": 2.6752600134696958
    },
    {
      "type": "training",
      "description": "Training step 1868",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:27",
      "total_flops_so_far": 2676692165511168.0,
      "budget_used_percent": 2.676692165511168
    },
    {
      "type": "training",
      "description": "Training step 1869",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:27",
      "total_flops_so_far": 2678124317552640.0,
      "budget_used_percent": 2.6781243175526397
    },
    {
      "type": "training",
      "description": "Training step 1870",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:27",
      "total_flops_so_far": 2679556469594112.0,
      "budget_used_percent": 2.6795564695941123
    },
    {
      "type": "training",
      "description": "Training step 1871",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:27",
      "total_flops_so_far": 2680988621635584.0,
      "budget_used_percent": 2.680988621635584
    },
    {
      "type": "training",
      "description": "Training step 1872",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:27",
      "total_flops_so_far": 2682420773677056.0,
      "budget_used_percent": 2.6824207736770562
    },
    {
      "type": "training",
      "description": "Training step 1873",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:28",
      "total_flops_so_far": 2683852925718528.0,
      "budget_used_percent": 2.683852925718528
    },
    {
      "type": "training",
      "description": "Training step 1874",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:28",
      "total_flops_so_far": 2685285077760000.0,
      "budget_used_percent": 2.68528507776
    },
    {
      "type": "training",
      "description": "Training step 1875",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:28",
      "total_flops_so_far": 2686717229801472.0,
      "budget_used_percent": 2.686717229801472
    },
    {
      "type": "training",
      "description": "Training step 1876",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:28",
      "total_flops_so_far": 2688149381842944.0,
      "budget_used_percent": 2.688149381842944
    },
    {
      "type": "training",
      "description": "Training step 1877",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:28",
      "total_flops_so_far": 2689581533884416.0,
      "budget_used_percent": 2.6895815338844162
    },
    {
      "type": "training",
      "description": "Training step 1878",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:28",
      "total_flops_so_far": 2691013685925888.0,
      "budget_used_percent": 2.691013685925888
    },
    {
      "type": "training",
      "description": "Training step 1879",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:29",
      "total_flops_so_far": 2692445837967360.0,
      "budget_used_percent": 2.69244583796736
    },
    {
      "type": "training",
      "description": "Training step 1880",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:29",
      "total_flops_so_far": 2693877990008832.0,
      "budget_used_percent": 2.693877990008832
    },
    {
      "type": "training",
      "description": "Training step 1881",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:29",
      "total_flops_so_far": 2695310142050304.0,
      "budget_used_percent": 2.695310142050304
    },
    {
      "type": "training",
      "description": "Training step 1882",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:29",
      "total_flops_so_far": 2696742294091776.0,
      "budget_used_percent": 2.6967422940917762
    },
    {
      "type": "training",
      "description": "Training step 1883",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:29",
      "total_flops_so_far": 2698174446133248.0,
      "budget_used_percent": 2.698174446133248
    },
    {
      "type": "training",
      "description": "Training step 1884",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:29",
      "total_flops_so_far": 2699606598174720.0,
      "budget_used_percent": 2.69960659817472
    },
    {
      "type": "training",
      "description": "Training step 1885",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:30",
      "total_flops_so_far": 2701038750216192.0,
      "budget_used_percent": 2.701038750216192
    },
    {
      "type": "training",
      "description": "Training step 1886",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:30",
      "total_flops_so_far": 2702470902257664.0,
      "budget_used_percent": 2.702470902257664
    },
    {
      "type": "training",
      "description": "Training step 1887",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:30",
      "total_flops_so_far": 2703903054299136.0,
      "budget_used_percent": 2.703903054299136
    },
    {
      "type": "training",
      "description": "Training step 1888",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:30",
      "total_flops_so_far": 2705335206340608.0,
      "budget_used_percent": 2.705335206340608
    },
    {
      "type": "training",
      "description": "Training step 1889",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:30",
      "total_flops_so_far": 2706767358382080.0,
      "budget_used_percent": 2.70676735838208
    },
    {
      "type": "training",
      "description": "Training step 1890",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:30",
      "total_flops_so_far": 2708199510423552.0,
      "budget_used_percent": 2.708199510423552
    },
    {
      "type": "training",
      "description": "Training step 1891",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:31",
      "total_flops_so_far": 2709631662465024.0,
      "budget_used_percent": 2.709631662465024
    },
    {
      "type": "training",
      "description": "Training step 1892",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:31",
      "total_flops_so_far": 2711063814506496.0,
      "budget_used_percent": 2.711063814506496
    },
    {
      "type": "training",
      "description": "Training step 1893",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:31",
      "total_flops_so_far": 2712495966547968.0,
      "budget_used_percent": 2.712495966547968
    },
    {
      "type": "training",
      "description": "Training step 1894",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:31",
      "total_flops_so_far": 2713928118589440.0,
      "budget_used_percent": 2.7139281185894397
    },
    {
      "type": "training",
      "description": "Training step 1895",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:31",
      "total_flops_so_far": 2715360270630912.0,
      "budget_used_percent": 2.715360270630912
    },
    {
      "type": "training",
      "description": "Training step 1896",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:31",
      "total_flops_so_far": 2716792422672384.0,
      "budget_used_percent": 2.716792422672384
    },
    {
      "type": "training",
      "description": "Training step 1897",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:32",
      "total_flops_so_far": 2718224574713856.0,
      "budget_used_percent": 2.718224574713856
    },
    {
      "type": "training",
      "description": "Training step 1898",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:32",
      "total_flops_so_far": 2719656726755328.0,
      "budget_used_percent": 2.719656726755328
    },
    {
      "type": "training",
      "description": "Training step 1899",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:32",
      "total_flops_so_far": 2721088878796800.0,
      "budget_used_percent": 2.7210888787967997
    },
    {
      "type": "training",
      "description": "Training step 1900",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:32",
      "total_flops_so_far": 2722521030838272.0,
      "budget_used_percent": 2.722521030838272
    },
    {
      "type": "training",
      "description": "Training step 1901",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:33",
      "total_flops_so_far": 2723953182879744.0,
      "budget_used_percent": 2.723953182879744
    },
    {
      "type": "training",
      "description": "Training step 1902",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:33",
      "total_flops_so_far": 2725385334921216.0,
      "budget_used_percent": 2.7253853349212163
    },
    {
      "type": "training",
      "description": "Training step 1903",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:33",
      "total_flops_so_far": 2726817486962688.0,
      "budget_used_percent": 2.726817486962688
    },
    {
      "type": "training",
      "description": "Training step 1904",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:33",
      "total_flops_so_far": 2728249639004160.0,
      "budget_used_percent": 2.7282496390041597
    },
    {
      "type": "training",
      "description": "Training step 1905",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:33",
      "total_flops_so_far": 2729681791045632.0,
      "budget_used_percent": 2.729681791045632
    },
    {
      "type": "training",
      "description": "Training step 1906",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:33",
      "total_flops_so_far": 2731113943087104.0,
      "budget_used_percent": 2.7311139430871036
    },
    {
      "type": "training",
      "description": "Training step 1907",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:34",
      "total_flops_so_far": 2732546095128576.0,
      "budget_used_percent": 2.7325460951285763
    },
    {
      "type": "training",
      "description": "Training step 1908",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:34",
      "total_flops_so_far": 2733978247170048.0,
      "budget_used_percent": 2.733978247170048
    },
    {
      "type": "training",
      "description": "Training step 1909",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:34",
      "total_flops_so_far": 2735410399211520.0,
      "budget_used_percent": 2.73541039921152
    },
    {
      "type": "training",
      "description": "Training step 1910",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:34",
      "total_flops_so_far": 2736842551252992.0,
      "budget_used_percent": 2.736842551252992
    },
    {
      "type": "training",
      "description": "Training step 1911",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:34",
      "total_flops_so_far": 2738274703294464.0,
      "budget_used_percent": 2.738274703294464
    },
    {
      "type": "training",
      "description": "Training step 1912",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:34",
      "total_flops_so_far": 2739706855335936.0,
      "budget_used_percent": 2.739706855335936
    },
    {
      "type": "training",
      "description": "Training step 1913",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:35",
      "total_flops_so_far": 2741139007377408.0,
      "budget_used_percent": 2.741139007377408
    },
    {
      "type": "training",
      "description": "Training step 1914",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:35",
      "total_flops_so_far": 2742571159418880.0,
      "budget_used_percent": 2.74257115941888
    },
    {
      "type": "training",
      "description": "Training step 1915",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:35",
      "total_flops_so_far": 2744003311460352.0,
      "budget_used_percent": 2.744003311460352
    },
    {
      "type": "training",
      "description": "Training step 1916",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:35",
      "total_flops_so_far": 2745435463501824.0,
      "budget_used_percent": 2.745435463501824
    },
    {
      "type": "training",
      "description": "Training step 1917",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:35",
      "total_flops_so_far": 2746867615543296.0,
      "budget_used_percent": 2.746867615543296
    },
    {
      "type": "training",
      "description": "Training step 1918",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:35",
      "total_flops_so_far": 2748299767584768.0,
      "budget_used_percent": 2.748299767584768
    },
    {
      "type": "training",
      "description": "Training step 1919",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:36",
      "total_flops_so_far": 2749731919626240.0,
      "budget_used_percent": 2.74973191962624
    },
    {
      "type": "training",
      "description": "Training step 1920",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:36",
      "total_flops_so_far": 2751164071667712.0,
      "budget_used_percent": 2.751164071667712
    },
    {
      "type": "training",
      "description": "Training step 1921",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:36",
      "total_flops_so_far": 2752596223709184.0,
      "budget_used_percent": 2.752596223709184
    },
    {
      "type": "training",
      "description": "Training step 1922",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:36",
      "total_flops_so_far": 2754028375750656.0,
      "budget_used_percent": 2.754028375750656
    },
    {
      "type": "training",
      "description": "Training step 1923",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:36",
      "total_flops_so_far": 2755460527792128.0,
      "budget_used_percent": 2.755460527792128
    },
    {
      "type": "training",
      "description": "Training step 1924",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:36",
      "total_flops_so_far": 2756892679833600.0,
      "budget_used_percent": 2.7568926798335998
    },
    {
      "type": "training",
      "description": "Training step 1925",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:37",
      "total_flops_so_far": 2758324831875072.0,
      "budget_used_percent": 2.758324831875072
    },
    {
      "type": "training",
      "description": "Training step 1926",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:37",
      "total_flops_so_far": 2759756983916544.0,
      "budget_used_percent": 2.759756983916544
    },
    {
      "type": "training",
      "description": "Training step 1927",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:37",
      "total_flops_so_far": 2761189135958016.0,
      "budget_used_percent": 2.761189135958016
    },
    {
      "type": "training",
      "description": "Training step 1928",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:37",
      "total_flops_so_far": 2762621287999488.0,
      "budget_used_percent": 2.762621287999488
    },
    {
      "type": "training",
      "description": "Training step 1929",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:37",
      "total_flops_so_far": 2764053440040960.0,
      "budget_used_percent": 2.7640534400409598
    },
    {
      "type": "training",
      "description": "Training step 1930",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:37",
      "total_flops_so_far": 2765485592082432.0,
      "budget_used_percent": 2.765485592082432
    },
    {
      "type": "training",
      "description": "Training step 1931",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:38",
      "total_flops_so_far": 2766917744123904.0,
      "budget_used_percent": 2.766917744123904
    },
    {
      "type": "training",
      "description": "Training step 1932",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:38",
      "total_flops_so_far": 2768349896165376.0,
      "budget_used_percent": 2.7683498961653763
    },
    {
      "type": "training",
      "description": "Training step 1933",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:38",
      "total_flops_so_far": 2769782048206848.0,
      "budget_used_percent": 2.769782048206848
    },
    {
      "type": "training",
      "description": "Training step 1934",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:38",
      "total_flops_so_far": 2771214200248320.0,
      "budget_used_percent": 2.7712142002483198
    },
    {
      "type": "training",
      "description": "Training step 1935",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:38",
      "total_flops_so_far": 2772646352289792.0,
      "budget_used_percent": 2.772646352289792
    },
    {
      "type": "training",
      "description": "Training step 1936",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:38",
      "total_flops_so_far": 2774078504331264.0,
      "budget_used_percent": 2.7740785043312637
    },
    {
      "type": "training",
      "description": "Training step 1937",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:39",
      "total_flops_so_far": 2775510656372736.0,
      "budget_used_percent": 2.7755106563727363
    },
    {
      "type": "training",
      "description": "Training step 1938",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:39",
      "total_flops_so_far": 2776942808414208.0,
      "budget_used_percent": 2.776942808414208
    },
    {
      "type": "training",
      "description": "Training step 1939",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:39",
      "total_flops_so_far": 2778374960455680.0,
      "budget_used_percent": 2.77837496045568
    },
    {
      "type": "training",
      "description": "Training step 1940",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:39",
      "total_flops_so_far": 2779807112497152.0,
      "budget_used_percent": 2.779807112497152
    },
    {
      "type": "training",
      "description": "Training step 1941",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:39",
      "total_flops_so_far": 2781239264538624.0,
      "budget_used_percent": 2.781239264538624
    },
    {
      "type": "training",
      "description": "Training step 1942",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:39",
      "total_flops_so_far": 2782671416580096.0,
      "budget_used_percent": 2.782671416580096
    },
    {
      "type": "training",
      "description": "Training step 1943",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:40",
      "total_flops_so_far": 2784103568621568.0,
      "budget_used_percent": 2.784103568621568
    },
    {
      "type": "training",
      "description": "Training step 1944",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:40",
      "total_flops_so_far": 2785535720663040.0,
      "budget_used_percent": 2.7855357206630402
    },
    {
      "type": "training",
      "description": "Training step 1945",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:40",
      "total_flops_so_far": 2786967872704512.0,
      "budget_used_percent": 2.786967872704512
    },
    {
      "type": "training",
      "description": "Training step 1946",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:40",
      "total_flops_so_far": 2788400024745984.0,
      "budget_used_percent": 2.788400024745984
    },
    {
      "type": "training",
      "description": "Training step 1947",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:40",
      "total_flops_so_far": 2789832176787456.0,
      "budget_used_percent": 2.789832176787456
    },
    {
      "type": "training",
      "description": "Training step 1948",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:40",
      "total_flops_so_far": 2791264328828928.0,
      "budget_used_percent": 2.791264328828928
    },
    {
      "type": "training",
      "description": "Training step 1949",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:41",
      "total_flops_so_far": 2792696480870400.0,
      "budget_used_percent": 2.7926964808704002
    },
    {
      "type": "training",
      "description": "Training step 1950",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:41",
      "total_flops_so_far": 2794128632911872.0,
      "budget_used_percent": 2.794128632911872
    },
    {
      "type": "training",
      "description": "Training step 1951",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:41",
      "total_flops_so_far": 2795560784953344.0,
      "budget_used_percent": 2.795560784953344
    },
    {
      "type": "training",
      "description": "Training step 1952",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:41",
      "total_flops_so_far": 2796992936994816.0,
      "budget_used_percent": 2.796992936994816
    },
    {
      "type": "training",
      "description": "Training step 1953",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:41",
      "total_flops_so_far": 2798425089036288.0,
      "budget_used_percent": 2.798425089036288
    },
    {
      "type": "training",
      "description": "Training step 1954",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:41",
      "total_flops_so_far": 2799857241077760.0,
      "budget_used_percent": 2.79985724107776
    },
    {
      "type": "training",
      "description": "Training step 1955",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:42",
      "total_flops_so_far": 2801289393119232.0,
      "budget_used_percent": 2.801289393119232
    },
    {
      "type": "training",
      "description": "Training step 1956",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:42",
      "total_flops_so_far": 2802721545160704.0,
      "budget_used_percent": 2.802721545160704
    },
    {
      "type": "training",
      "description": "Training step 1957",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:42",
      "total_flops_so_far": 2804153697202176.0,
      "budget_used_percent": 2.804153697202176
    },
    {
      "type": "training",
      "description": "Training step 1958",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:42",
      "total_flops_so_far": 2805585849243648.0,
      "budget_used_percent": 2.805585849243648
    },
    {
      "type": "training",
      "description": "Training step 1959",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:42",
      "total_flops_so_far": 2807018001285120.0,
      "budget_used_percent": 2.80701800128512
    },
    {
      "type": "training",
      "description": "Training step 1960",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:42",
      "total_flops_so_far": 2808450153326592.0,
      "budget_used_percent": 2.808450153326592
    },
    {
      "type": "training",
      "description": "Training step 1961",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:43",
      "total_flops_so_far": 2809882305368064.0,
      "budget_used_percent": 2.809882305368064
    },
    {
      "type": "training",
      "description": "Training step 1962",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:43",
      "total_flops_so_far": 2811314457409536.0,
      "budget_used_percent": 2.8113144574095363
    },
    {
      "type": "training",
      "description": "Training step 1963",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:43",
      "total_flops_so_far": 2812746609451008.0,
      "budget_used_percent": 2.812746609451008
    },
    {
      "type": "training",
      "description": "Training step 1964",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:43",
      "total_flops_so_far": 2814178761492480.0,
      "budget_used_percent": 2.81417876149248
    },
    {
      "type": "training",
      "description": "Training step 1965",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:43",
      "total_flops_so_far": 2815610913533952.0,
      "budget_used_percent": 2.815610913533952
    },
    {
      "type": "training",
      "description": "Training step 1966",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:43",
      "total_flops_so_far": 2817043065575424.0,
      "budget_used_percent": 2.8170430655754237
    },
    {
      "type": "training",
      "description": "Training step 1967",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:44",
      "total_flops_so_far": 2818475217616896.0,
      "budget_used_percent": 2.818475217616896
    },
    {
      "type": "training",
      "description": "Training step 1968",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:44",
      "total_flops_so_far": 2819907369658368.0,
      "budget_used_percent": 2.819907369658368
    },
    {
      "type": "training",
      "description": "Training step 1969",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:44",
      "total_flops_so_far": 2821339521699840.0,
      "budget_used_percent": 2.8213395216998403
    },
    {
      "type": "training",
      "description": "Training step 1970",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:44",
      "total_flops_so_far": 2822771673741312.0,
      "budget_used_percent": 2.822771673741312
    },
    {
      "type": "training",
      "description": "Training step 1971",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:44",
      "total_flops_so_far": 2824203825782784.0,
      "budget_used_percent": 2.824203825782784
    },
    {
      "type": "training",
      "description": "Training step 1972",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:44",
      "total_flops_so_far": 2825635977824256.0,
      "budget_used_percent": 2.825635977824256
    },
    {
      "type": "training",
      "description": "Training step 1973",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:45",
      "total_flops_so_far": 2827068129865728.0,
      "budget_used_percent": 2.8270681298657276
    },
    {
      "type": "training",
      "description": "Training step 1974",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:45",
      "total_flops_so_far": 2828500281907200.0,
      "budget_used_percent": 2.8285002819072003
    },
    {
      "type": "training",
      "description": "Training step 1975",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:45",
      "total_flops_so_far": 2829932433948672.0,
      "budget_used_percent": 2.829932433948672
    },
    {
      "type": "training",
      "description": "Training step 1976",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:45",
      "total_flops_so_far": 2831364585990144.0,
      "budget_used_percent": 2.831364585990144
    },
    {
      "type": "training",
      "description": "Training step 1977",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:45",
      "total_flops_so_far": 2832796738031616.0,
      "budget_used_percent": 2.832796738031616
    },
    {
      "type": "training",
      "description": "Training step 1978",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:45",
      "total_flops_so_far": 2834228890073088.0,
      "budget_used_percent": 2.834228890073088
    },
    {
      "type": "training",
      "description": "Training step 1979",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:46",
      "total_flops_so_far": 2835661042114560.0,
      "budget_used_percent": 2.83566104211456
    },
    {
      "type": "training",
      "description": "Training step 1980",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:46",
      "total_flops_so_far": 2837093194156032.0,
      "budget_used_percent": 2.837093194156032
    },
    {
      "type": "training",
      "description": "Training step 1981",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:46",
      "total_flops_so_far": 2838525346197504.0,
      "budget_used_percent": 2.838525346197504
    },
    {
      "type": "training",
      "description": "Training step 1982",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:46",
      "total_flops_so_far": 2839957498238976.0,
      "budget_used_percent": 2.839957498238976
    },
    {
      "type": "training",
      "description": "Training step 1983",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:46",
      "total_flops_so_far": 2841389650280448.0,
      "budget_used_percent": 2.841389650280448
    },
    {
      "type": "training",
      "description": "Training step 1984",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:46",
      "total_flops_so_far": 2842821802321920.0,
      "budget_used_percent": 2.84282180232192
    },
    {
      "type": "training",
      "description": "Training step 1985",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:47",
      "total_flops_so_far": 2844253954363392.0,
      "budget_used_percent": 2.844253954363392
    },
    {
      "type": "training",
      "description": "Training step 1986",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:47",
      "total_flops_so_far": 2845686106404864.0,
      "budget_used_percent": 2.845686106404864
    },
    {
      "type": "training",
      "description": "Training step 1987",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:47",
      "total_flops_so_far": 2847118258446336.0,
      "budget_used_percent": 2.847118258446336
    },
    {
      "type": "training",
      "description": "Training step 1988",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:47",
      "total_flops_so_far": 2848550410487808.0,
      "budget_used_percent": 2.848550410487808
    },
    {
      "type": "training",
      "description": "Training step 1989",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:47",
      "total_flops_so_far": 2849982562529280.0,
      "budget_used_percent": 2.84998256252928
    },
    {
      "type": "training",
      "description": "Training step 1990",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:47",
      "total_flops_so_far": 2851414714570752.0,
      "budget_used_percent": 2.851414714570752
    },
    {
      "type": "training",
      "description": "Training step 1991",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:48",
      "total_flops_so_far": 2852846866612224.0,
      "budget_used_percent": 2.8528468666122238
    },
    {
      "type": "training",
      "description": "Training step 1992",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:48",
      "total_flops_so_far": 2854279018653696.0,
      "budget_used_percent": 2.854279018653696
    },
    {
      "type": "training",
      "description": "Training step 1993",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:48",
      "total_flops_so_far": 2855711170695168.0,
      "budget_used_percent": 2.855711170695168
    },
    {
      "type": "training",
      "description": "Training step 1994",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:48",
      "total_flops_so_far": 2857143322736640.0,
      "budget_used_percent": 2.85714332273664
    },
    {
      "type": "training",
      "description": "Training step 1995",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:48",
      "total_flops_so_far": 2858575474778112.0,
      "budget_used_percent": 2.858575474778112
    },
    {
      "type": "training",
      "description": "Training step 1996",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:48",
      "total_flops_so_far": 2860007626819584.0,
      "budget_used_percent": 2.8600076268195838
    },
    {
      "type": "training",
      "description": "Training step 1997",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:49",
      "total_flops_so_far": 2861439778861056.0,
      "budget_used_percent": 2.861439778861056
    },
    {
      "type": "training",
      "description": "Training step 1998",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:49",
      "total_flops_so_far": 2862871930902528.0,
      "budget_used_percent": 2.862871930902528
    },
    {
      "type": "training",
      "description": "Training step 1999",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-31 16:32:49",
      "total_flops_so_far": 2864304082944000.0,
      "budget_used_percent": 2.8643040829440003
    }
  ],
  "total_flops": 2864304082944000.0,
  "budget_used_percent": 2.8643040829440003
}