{
  "experiment_name": "continued_ctx128_lr1e-04_rank8_prec2",
  "model_config": {
    "hidden_size": 896,
    "num_attention_heads": 14,
    "num_hidden_layers": 24,
    "intermediate_size": 4864,
    "head_dim": 64,
    "vocab_size": 151936,
    "lora_r": 8,
    "lora_target_modules": [
      "q_proj",
      "v_proj"
    ]
  },
  "max_budget": 1e+17,
  "start_time": "2025-04-02 17:25:31",
  "operations": [
    {
      "type": "training",
      "description": "Training step 0",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:47",
      "total_flops_so_far": 1432152041472.0,
      "budget_used_percent": 0.001432152041472
    },
    {
      "type": "training",
      "description": "Training step 1",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:48",
      "total_flops_so_far": 2864304082944.0,
      "budget_used_percent": 0.002864304082944
    },
    {
      "type": "training",
      "description": "Training step 2",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:48",
      "total_flops_so_far": 4296456124416.0,
      "budget_used_percent": 0.004296456124416
    },
    {
      "type": "training",
      "description": "Training step 3",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:48",
      "total_flops_so_far": 5728608165888.0,
      "budget_used_percent": 0.005728608165888
    },
    {
      "type": "training",
      "description": "Training step 4",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:48",
      "total_flops_so_far": 7160760207360.0,
      "budget_used_percent": 0.007160760207359999
    },
    {
      "type": "training",
      "description": "Training step 5",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:49",
      "total_flops_so_far": 8592912248832.0,
      "budget_used_percent": 0.008592912248832
    },
    {
      "type": "training",
      "description": "Training step 6",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:49",
      "total_flops_so_far": 10025064290304.0,
      "budget_used_percent": 0.010025064290304
    },
    {
      "type": "training",
      "description": "Training step 7",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:49",
      "total_flops_so_far": 11457216331776.0,
      "budget_used_percent": 0.011457216331776
    },
    {
      "type": "training",
      "description": "Training step 8",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:49",
      "total_flops_so_far": 12889368373248.0,
      "budget_used_percent": 0.012889368373247998
    },
    {
      "type": "training",
      "description": "Training step 9",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:49",
      "total_flops_so_far": 14321520414720.0,
      "budget_used_percent": 0.014321520414719999
    },
    {
      "type": "training",
      "description": "Training step 10",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:49",
      "total_flops_so_far": 15753672456192.0,
      "budget_used_percent": 0.015753672456191997
    },
    {
      "type": "training",
      "description": "Training step 11",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:49",
      "total_flops_so_far": 17185824497664.0,
      "budget_used_percent": 0.017185824497664
    },
    {
      "type": "training",
      "description": "Training step 12",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:49",
      "total_flops_so_far": 18617976539136.0,
      "budget_used_percent": 0.018617976539136
    },
    {
      "type": "training",
      "description": "Training step 13",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:50",
      "total_flops_so_far": 20050128580608.0,
      "budget_used_percent": 0.020050128580608
    },
    {
      "type": "training",
      "description": "Training step 14",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:50",
      "total_flops_so_far": 21482280622080.0,
      "budget_used_percent": 0.02148228062208
    },
    {
      "type": "training",
      "description": "Training step 15",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:50",
      "total_flops_so_far": 22914432663552.0,
      "budget_used_percent": 0.022914432663552
    },
    {
      "type": "training",
      "description": "Training step 16",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:50",
      "total_flops_so_far": 24346584705024.0,
      "budget_used_percent": 0.024346584705024002
    },
    {
      "type": "training",
      "description": "Training step 17",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:50",
      "total_flops_so_far": 25778736746496.0,
      "budget_used_percent": 0.025778736746495997
    },
    {
      "type": "training",
      "description": "Training step 18",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:50",
      "total_flops_so_far": 27210888787968.0,
      "budget_used_percent": 0.027210888787968
    },
    {
      "type": "training",
      "description": "Training step 19",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:50",
      "total_flops_so_far": 28643040829440.0,
      "budget_used_percent": 0.028643040829439997
    },
    {
      "type": "training",
      "description": "Training step 20",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:50",
      "total_flops_so_far": 30075192870912.0,
      "budget_used_percent": 0.030075192870912
    },
    {
      "type": "training",
      "description": "Training step 21",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:50",
      "total_flops_so_far": 31507344912384.0,
      "budget_used_percent": 0.031507344912383994
    },
    {
      "type": "training",
      "description": "Training step 22",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:51",
      "total_flops_so_far": 32939496953856.0,
      "budget_used_percent": 0.032939496953856
    },
    {
      "type": "training",
      "description": "Training step 23",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:51",
      "total_flops_so_far": 34371648995328.0,
      "budget_used_percent": 0.034371648995328
    },
    {
      "type": "training",
      "description": "Training step 24",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:51",
      "total_flops_so_far": 35803801036800.0,
      "budget_used_percent": 0.0358038010368
    },
    {
      "type": "training",
      "description": "Training step 25",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:51",
      "total_flops_so_far": 37235953078272.0,
      "budget_used_percent": 0.037235953078272
    },
    {
      "type": "training",
      "description": "Training step 26",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:51",
      "total_flops_so_far": 38668105119744.0,
      "budget_used_percent": 0.038668105119744
    },
    {
      "type": "training",
      "description": "Training step 27",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:51",
      "total_flops_so_far": 40100257161216.0,
      "budget_used_percent": 0.040100257161216
    },
    {
      "type": "training",
      "description": "Training step 28",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:51",
      "total_flops_so_far": 41532409202688.0,
      "budget_used_percent": 0.041532409202688
    },
    {
      "type": "training",
      "description": "Training step 29",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:51",
      "total_flops_so_far": 42964561244160.0,
      "budget_used_percent": 0.04296456124416
    },
    {
      "type": "training",
      "description": "Training step 30",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:52",
      "total_flops_so_far": 44396713285632.0,
      "budget_used_percent": 0.044396713285632
    },
    {
      "type": "training",
      "description": "Training step 31",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:52",
      "total_flops_so_far": 45828865327104.0,
      "budget_used_percent": 0.045828865327104
    },
    {
      "type": "training",
      "description": "Training step 32",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:52",
      "total_flops_so_far": 47261017368576.0,
      "budget_used_percent": 0.047261017368576
    },
    {
      "type": "training",
      "description": "Training step 33",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:52",
      "total_flops_so_far": 48693169410048.0,
      "budget_used_percent": 0.048693169410048004
    },
    {
      "type": "training",
      "description": "Training step 34",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:52",
      "total_flops_so_far": 50125321451520.0,
      "budget_used_percent": 0.05012532145152
    },
    {
      "type": "training",
      "description": "Training step 35",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:52",
      "total_flops_so_far": 51557473492992.0,
      "budget_used_percent": 0.051557473492991994
    },
    {
      "type": "training",
      "description": "Training step 36",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:52",
      "total_flops_so_far": 52989625534464.0,
      "budget_used_percent": 0.052989625534464006
    },
    {
      "type": "training",
      "description": "Training step 37",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:52",
      "total_flops_so_far": 54421777575936.0,
      "budget_used_percent": 0.054421777575936
    },
    {
      "type": "training",
      "description": "Training step 38",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:52",
      "total_flops_so_far": 55853929617408.0,
      "budget_used_percent": 0.055853929617407996
    },
    {
      "type": "training",
      "description": "Training step 39",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:53",
      "total_flops_so_far": 57286081658880.0,
      "budget_used_percent": 0.057286081658879995
    },
    {
      "type": "training",
      "description": "Training step 40",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:53",
      "total_flops_so_far": 58718233700352.0,
      "budget_used_percent": 0.05871823370035201
    },
    {
      "type": "training",
      "description": "Training step 41",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:53",
      "total_flops_so_far": 60150385741824.0,
      "budget_used_percent": 0.060150385741824
    },
    {
      "type": "training",
      "description": "Training step 42",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:53",
      "total_flops_so_far": 61582537783296.0,
      "budget_used_percent": 0.061582537783296
    },
    {
      "type": "training",
      "description": "Training step 43",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:53",
      "total_flops_so_far": 63014689824768.0,
      "budget_used_percent": 0.06301468982476799
    },
    {
      "type": "training",
      "description": "Training step 44",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:53",
      "total_flops_so_far": 64446841866240.0,
      "budget_used_percent": 0.06444684186624
    },
    {
      "type": "training",
      "description": "Training step 45",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:53",
      "total_flops_so_far": 65878993907712.0,
      "budget_used_percent": 0.065878993907712
    },
    {
      "type": "training",
      "description": "Training step 46",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:53",
      "total_flops_so_far": 67311145949184.0,
      "budget_used_percent": 0.067311145949184
    },
    {
      "type": "training",
      "description": "Training step 47",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:54",
      "total_flops_so_far": 68743297990656.0,
      "budget_used_percent": 0.068743297990656
    },
    {
      "type": "training",
      "description": "Training step 48",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:54",
      "total_flops_so_far": 70175450032128.0,
      "budget_used_percent": 0.07017545003212801
    },
    {
      "type": "training",
      "description": "Training step 49",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:54",
      "total_flops_so_far": 71607602073600.0,
      "budget_used_percent": 0.0716076020736
    },
    {
      "type": "training",
      "description": "Training step 50",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:54",
      "total_flops_so_far": 73039754115072.0,
      "budget_used_percent": 0.07303975411507199
    },
    {
      "type": "training",
      "description": "Training step 51",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:54",
      "total_flops_so_far": 74471906156544.0,
      "budget_used_percent": 0.074471906156544
    },
    {
      "type": "training",
      "description": "Training step 52",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:54",
      "total_flops_so_far": 75904058198016.0,
      "budget_used_percent": 0.075904058198016
    },
    {
      "type": "training",
      "description": "Training step 53",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:54",
      "total_flops_so_far": 77336210239488.0,
      "budget_used_percent": 0.077336210239488
    },
    {
      "type": "training",
      "description": "Training step 54",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:54",
      "total_flops_so_far": 78768362280960.0,
      "budget_used_percent": 0.07876836228096
    },
    {
      "type": "training",
      "description": "Training step 55",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:54",
      "total_flops_so_far": 80200514322432.0,
      "budget_used_percent": 0.080200514322432
    },
    {
      "type": "training",
      "description": "Training step 56",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:55",
      "total_flops_so_far": 81632666363904.0,
      "budget_used_percent": 0.081632666363904
    },
    {
      "type": "training",
      "description": "Training step 57",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:55",
      "total_flops_so_far": 83064818405376.0,
      "budget_used_percent": 0.083064818405376
    },
    {
      "type": "training",
      "description": "Training step 58",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:55",
      "total_flops_so_far": 84496970446848.0,
      "budget_used_percent": 0.084496970446848
    },
    {
      "type": "training",
      "description": "Training step 59",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:55",
      "total_flops_so_far": 85929122488320.0,
      "budget_used_percent": 0.08592912248832
    },
    {
      "type": "training",
      "description": "Training step 60",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:55",
      "total_flops_so_far": 87361274529792.0,
      "budget_used_percent": 0.087361274529792
    },
    {
      "type": "training",
      "description": "Training step 61",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:55",
      "total_flops_so_far": 88793426571264.0,
      "budget_used_percent": 0.088793426571264
    },
    {
      "type": "training",
      "description": "Training step 62",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:55",
      "total_flops_so_far": 90225578612736.0,
      "budget_used_percent": 0.090225578612736
    },
    {
      "type": "training",
      "description": "Training step 63",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:55",
      "total_flops_so_far": 91657730654208.0,
      "budget_used_percent": 0.091657730654208
    },
    {
      "type": "training",
      "description": "Training step 64",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:56",
      "total_flops_so_far": 93089882695680.0,
      "budget_used_percent": 0.09308988269568
    },
    {
      "type": "training",
      "description": "Training step 65",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:56",
      "total_flops_so_far": 94522034737152.0,
      "budget_used_percent": 0.094522034737152
    },
    {
      "type": "training",
      "description": "Training step 66",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:56",
      "total_flops_so_far": 95954186778624.0,
      "budget_used_percent": 0.095954186778624
    },
    {
      "type": "training",
      "description": "Training step 67",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:56",
      "total_flops_so_far": 97386338820096.0,
      "budget_used_percent": 0.09738633882009601
    },
    {
      "type": "training",
      "description": "Training step 68",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:56",
      "total_flops_so_far": 98818490861568.0,
      "budget_used_percent": 0.09881849086156799
    },
    {
      "type": "training",
      "description": "Training step 69",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:56",
      "total_flops_so_far": 100250642903040.0,
      "budget_used_percent": 0.10025064290304
    },
    {
      "type": "training",
      "description": "Training step 70",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:56",
      "total_flops_so_far": 101682794944512.0,
      "budget_used_percent": 0.101682794944512
    },
    {
      "type": "training",
      "description": "Training step 71",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:56",
      "total_flops_so_far": 103114946985984.0,
      "budget_used_percent": 0.10311494698598399
    },
    {
      "type": "training",
      "description": "Training step 72",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:56",
      "total_flops_so_far": 104547099027456.0,
      "budget_used_percent": 0.104547099027456
    },
    {
      "type": "training",
      "description": "Training step 73",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:57",
      "total_flops_so_far": 105979251068928.0,
      "budget_used_percent": 0.10597925106892801
    },
    {
      "type": "training",
      "description": "Training step 74",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:57",
      "total_flops_so_far": 107411403110400.0,
      "budget_used_percent": 0.1074114031104
    },
    {
      "type": "training",
      "description": "Training step 75",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:57",
      "total_flops_so_far": 108843555151872.0,
      "budget_used_percent": 0.108843555151872
    },
    {
      "type": "training",
      "description": "Training step 76",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:57",
      "total_flops_so_far": 110275707193344.0,
      "budget_used_percent": 0.11027570719334401
    },
    {
      "type": "training",
      "description": "Training step 77",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:57",
      "total_flops_so_far": 111707859234816.0,
      "budget_used_percent": 0.11170785923481599
    },
    {
      "type": "training",
      "description": "Training step 78",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:57",
      "total_flops_so_far": 113140011276288.0,
      "budget_used_percent": 0.113140011276288
    },
    {
      "type": "training",
      "description": "Training step 79",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:57",
      "total_flops_so_far": 114572163317760.0,
      "budget_used_percent": 0.11457216331775999
    },
    {
      "type": "training",
      "description": "Training step 80",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:57",
      "total_flops_so_far": 116004315359232.0,
      "budget_used_percent": 0.116004315359232
    },
    {
      "type": "training",
      "description": "Training step 81",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:58",
      "total_flops_so_far": 117436467400704.0,
      "budget_used_percent": 0.11743646740070401
    },
    {
      "type": "training",
      "description": "Training step 82",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:58",
      "total_flops_so_far": 118868619442176.0,
      "budget_used_percent": 0.118868619442176
    },
    {
      "type": "training",
      "description": "Training step 83",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:58",
      "total_flops_so_far": 120300771483648.0,
      "budget_used_percent": 0.120300771483648
    },
    {
      "type": "training",
      "description": "Training step 84",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:58",
      "total_flops_so_far": 121732923525120.0,
      "budget_used_percent": 0.12173292352512001
    },
    {
      "type": "training",
      "description": "Training step 85",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:58",
      "total_flops_so_far": 123165075566592.0,
      "budget_used_percent": 0.123165075566592
    },
    {
      "type": "training",
      "description": "Training step 86",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:58",
      "total_flops_so_far": 124597227608064.0,
      "budget_used_percent": 0.124597227608064
    },
    {
      "type": "training",
      "description": "Training step 87",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:58",
      "total_flops_so_far": 126029379649536.0,
      "budget_used_percent": 0.12602937964953598
    },
    {
      "type": "training",
      "description": "Training step 88",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:58",
      "total_flops_so_far": 127461531691008.0,
      "budget_used_percent": 0.127461531691008
    },
    {
      "type": "training",
      "description": "Training step 89",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:59",
      "total_flops_so_far": 128893683732480.0,
      "budget_used_percent": 0.12889368373248
    },
    {
      "type": "training",
      "description": "Training step 90",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:59",
      "total_flops_so_far": 130325835773952.0,
      "budget_used_percent": 0.130325835773952
    },
    {
      "type": "training",
      "description": "Training step 91",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:59",
      "total_flops_so_far": 131757987815424.0,
      "budget_used_percent": 0.131757987815424
    },
    {
      "type": "training",
      "description": "Training step 92",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:59",
      "total_flops_so_far": 133190139856896.0,
      "budget_used_percent": 0.133190139856896
    },
    {
      "type": "training",
      "description": "Training step 93",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:59",
      "total_flops_so_far": 134622291898368.0,
      "budget_used_percent": 0.134622291898368
    },
    {
      "type": "training",
      "description": "Training step 94",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:59",
      "total_flops_so_far": 136054443939840.0,
      "budget_used_percent": 0.13605444393984
    },
    {
      "type": "training",
      "description": "Training step 95",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:59",
      "total_flops_so_far": 137486595981312.0,
      "budget_used_percent": 0.137486595981312
    },
    {
      "type": "training",
      "description": "Training step 96",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:59",
      "total_flops_so_far": 138918748022784.0,
      "budget_used_percent": 0.138918748022784
    },
    {
      "type": "training",
      "description": "Training step 97",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:25:59",
      "total_flops_so_far": 140350900064256.0,
      "budget_used_percent": 0.14035090006425602
    },
    {
      "type": "training",
      "description": "Training step 98",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:00",
      "total_flops_so_far": 141783052105728.0,
      "budget_used_percent": 0.141783052105728
    },
    {
      "type": "training",
      "description": "Training step 99",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:00",
      "total_flops_so_far": 143215204147200.0,
      "budget_used_percent": 0.1432152041472
    },
    {
      "type": "training",
      "description": "Training step 100",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:00",
      "total_flops_so_far": 144647356188672.0,
      "budget_used_percent": 0.144647356188672
    },
    {
      "type": "training",
      "description": "Training step 101",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:00",
      "total_flops_so_far": 146079508230144.0,
      "budget_used_percent": 0.14607950823014398
    },
    {
      "type": "training",
      "description": "Training step 102",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:00",
      "total_flops_so_far": 147511660271616.0,
      "budget_used_percent": 0.147511660271616
    },
    {
      "type": "training",
      "description": "Training step 103",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:00",
      "total_flops_so_far": 148943812313088.0,
      "budget_used_percent": 0.148943812313088
    },
    {
      "type": "training",
      "description": "Training step 104",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:00",
      "total_flops_so_far": 150375964354560.0,
      "budget_used_percent": 0.15037596435456
    },
    {
      "type": "training",
      "description": "Training step 105",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:00",
      "total_flops_so_far": 151808116396032.0,
      "budget_used_percent": 0.151808116396032
    },
    {
      "type": "training",
      "description": "Training step 106",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:01",
      "total_flops_so_far": 153240268437504.0,
      "budget_used_percent": 0.153240268437504
    },
    {
      "type": "training",
      "description": "Training step 107",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:01",
      "total_flops_so_far": 154672420478976.0,
      "budget_used_percent": 0.154672420478976
    },
    {
      "type": "training",
      "description": "Training step 108",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:01",
      "total_flops_so_far": 156104572520448.0,
      "budget_used_percent": 0.15610457252044802
    },
    {
      "type": "training",
      "description": "Training step 109",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:01",
      "total_flops_so_far": 157536724561920.0,
      "budget_used_percent": 0.15753672456192
    },
    {
      "type": "training",
      "description": "Training step 110",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:01",
      "total_flops_so_far": 158968876603392.0,
      "budget_used_percent": 0.158968876603392
    },
    {
      "type": "training",
      "description": "Training step 111",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:01",
      "total_flops_so_far": 160401028644864.0,
      "budget_used_percent": 0.160401028644864
    },
    {
      "type": "training",
      "description": "Training step 112",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:01",
      "total_flops_so_far": 161833180686336.0,
      "budget_used_percent": 0.161833180686336
    },
    {
      "type": "training",
      "description": "Training step 113",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:01",
      "total_flops_so_far": 163265332727808.0,
      "budget_used_percent": 0.163265332727808
    },
    {
      "type": "training",
      "description": "Training step 114",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:01",
      "total_flops_so_far": 164697484769280.0,
      "budget_used_percent": 0.16469748476927998
    },
    {
      "type": "training",
      "description": "Training step 115",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:02",
      "total_flops_so_far": 166129636810752.0,
      "budget_used_percent": 0.166129636810752
    },
    {
      "type": "training",
      "description": "Training step 116",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:02",
      "total_flops_so_far": 167561788852224.0,
      "budget_used_percent": 0.167561788852224
    },
    {
      "type": "training",
      "description": "Training step 117",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:02",
      "total_flops_so_far": 168993940893696.0,
      "budget_used_percent": 0.168993940893696
    },
    {
      "type": "training",
      "description": "Training step 118",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:02",
      "total_flops_so_far": 170426092935168.0,
      "budget_used_percent": 0.170426092935168
    },
    {
      "type": "training",
      "description": "Training step 119",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:02",
      "total_flops_so_far": 171858244976640.0,
      "budget_used_percent": 0.17185824497664
    },
    {
      "type": "training",
      "description": "Training step 120",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:02",
      "total_flops_so_far": 173290397018112.0,
      "budget_used_percent": 0.173290397018112
    },
    {
      "type": "training",
      "description": "Training step 121",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:02",
      "total_flops_so_far": 174722549059584.0,
      "budget_used_percent": 0.174722549059584
    },
    {
      "type": "training",
      "description": "Training step 122",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:02",
      "total_flops_so_far": 176154701101056.0,
      "budget_used_percent": 0.176154701101056
    },
    {
      "type": "training",
      "description": "Training step 123",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:03",
      "total_flops_so_far": 177586853142528.0,
      "budget_used_percent": 0.177586853142528
    },
    {
      "type": "training",
      "description": "Training step 124",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:03",
      "total_flops_so_far": 179019005184000.0,
      "budget_used_percent": 0.17901900518400002
    },
    {
      "type": "training",
      "description": "Training step 125",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:03",
      "total_flops_so_far": 180451157225472.0,
      "budget_used_percent": 0.180451157225472
    },
    {
      "type": "training",
      "description": "Training step 126",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:03",
      "total_flops_so_far": 181883309266944.0,
      "budget_used_percent": 0.181883309266944
    },
    {
      "type": "training",
      "description": "Training step 127",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:03",
      "total_flops_so_far": 183315461308416.0,
      "budget_used_percent": 0.183315461308416
    },
    {
      "type": "training",
      "description": "Training step 128",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:03",
      "total_flops_so_far": 184747613349888.0,
      "budget_used_percent": 0.18474761334988798
    },
    {
      "type": "training",
      "description": "Training step 129",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:03",
      "total_flops_so_far": 186179765391360.0,
      "budget_used_percent": 0.18617976539136
    },
    {
      "type": "training",
      "description": "Training step 130",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:03",
      "total_flops_so_far": 187611917432832.0,
      "budget_used_percent": 0.187611917432832
    },
    {
      "type": "training",
      "description": "Training step 131",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:03",
      "total_flops_so_far": 189044069474304.0,
      "budget_used_percent": 0.189044069474304
    },
    {
      "type": "training",
      "description": "Training step 132",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:04",
      "total_flops_so_far": 190476221515776.0,
      "budget_used_percent": 0.190476221515776
    },
    {
      "type": "training",
      "description": "Training step 133",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:04",
      "total_flops_so_far": 191908373557248.0,
      "budget_used_percent": 0.191908373557248
    },
    {
      "type": "training",
      "description": "Training step 134",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:04",
      "total_flops_so_far": 193340525598720.0,
      "budget_used_percent": 0.19334052559872
    },
    {
      "type": "training",
      "description": "Training step 135",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:04",
      "total_flops_so_far": 194772677640192.0,
      "budget_used_percent": 0.19477267764019202
    },
    {
      "type": "training",
      "description": "Training step 136",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:04",
      "total_flops_so_far": 196204829681664.0,
      "budget_used_percent": 0.196204829681664
    },
    {
      "type": "training",
      "description": "Training step 137",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:04",
      "total_flops_so_far": 197636981723136.0,
      "budget_used_percent": 0.19763698172313598
    },
    {
      "type": "training",
      "description": "Training step 138",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:04",
      "total_flops_so_far": 199069133764608.0,
      "budget_used_percent": 0.199069133764608
    },
    {
      "type": "training",
      "description": "Training step 139",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:04",
      "total_flops_so_far": 200501285806080.0,
      "budget_used_percent": 0.20050128580608
    },
    {
      "type": "training",
      "description": "Training step 140",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:05",
      "total_flops_so_far": 201933437847552.0,
      "budget_used_percent": 0.201933437847552
    },
    {
      "type": "training",
      "description": "Training step 141",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:05",
      "total_flops_so_far": 203365589889024.0,
      "budget_used_percent": 0.203365589889024
    },
    {
      "type": "training",
      "description": "Training step 142",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:05",
      "total_flops_so_far": 204797741930496.0,
      "budget_used_percent": 0.204797741930496
    },
    {
      "type": "training",
      "description": "Training step 143",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:05",
      "total_flops_so_far": 206229893971968.0,
      "budget_used_percent": 0.20622989397196798
    },
    {
      "type": "training",
      "description": "Training step 144",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:05",
      "total_flops_so_far": 207662046013440.0,
      "budget_used_percent": 0.20766204601344002
    },
    {
      "type": "training",
      "description": "Training step 145",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:05",
      "total_flops_so_far": 209094198054912.0,
      "budget_used_percent": 0.209094198054912
    },
    {
      "type": "training",
      "description": "Training step 146",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:05",
      "total_flops_so_far": 210526350096384.0,
      "budget_used_percent": 0.21052635009638399
    },
    {
      "type": "training",
      "description": "Training step 147",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:05",
      "total_flops_so_far": 211958502137856.0,
      "budget_used_percent": 0.21195850213785603
    },
    {
      "type": "training",
      "description": "Training step 148",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:06",
      "total_flops_so_far": 213390654179328.0,
      "budget_used_percent": 0.213390654179328
    },
    {
      "type": "training",
      "description": "Training step 149",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:06",
      "total_flops_so_far": 214822806220800.0,
      "budget_used_percent": 0.2148228062208
    },
    {
      "type": "training",
      "description": "Training step 150",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:06",
      "total_flops_so_far": 216254958262272.0,
      "budget_used_percent": 0.216254958262272
    },
    {
      "type": "training",
      "description": "Training step 151",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:06",
      "total_flops_so_far": 217687110303744.0,
      "budget_used_percent": 0.217687110303744
    },
    {
      "type": "training",
      "description": "Training step 152",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:06",
      "total_flops_so_far": 219119262345216.0,
      "budget_used_percent": 0.219119262345216
    },
    {
      "type": "training",
      "description": "Training step 153",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:06",
      "total_flops_so_far": 220551414386688.0,
      "budget_used_percent": 0.22055141438668802
    },
    {
      "type": "training",
      "description": "Training step 154",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:06",
      "total_flops_so_far": 221983566428160.0,
      "budget_used_percent": 0.22198356642816
    },
    {
      "type": "training",
      "description": "Training step 155",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:06",
      "total_flops_so_far": 223415718469632.0,
      "budget_used_percent": 0.22341571846963199
    },
    {
      "type": "training",
      "description": "Training step 156",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:07",
      "total_flops_so_far": 224847870511104.0,
      "budget_used_percent": 0.22484787051110397
    },
    {
      "type": "training",
      "description": "Training step 157",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:07",
      "total_flops_so_far": 226280022552576.0,
      "budget_used_percent": 0.226280022552576
    },
    {
      "type": "training",
      "description": "Training step 158",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:07",
      "total_flops_so_far": 227712174594048.0,
      "budget_used_percent": 0.227712174594048
    },
    {
      "type": "training",
      "description": "Training step 159",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:07",
      "total_flops_so_far": 229144326635520.0,
      "budget_used_percent": 0.22914432663551998
    },
    {
      "type": "training",
      "description": "Training step 160",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:07",
      "total_flops_so_far": 230576478676992.0,
      "budget_used_percent": 0.23057647867699202
    },
    {
      "type": "training",
      "description": "Training step 161",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:07",
      "total_flops_so_far": 232008630718464.0,
      "budget_used_percent": 0.232008630718464
    },
    {
      "type": "training",
      "description": "Training step 162",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:07",
      "total_flops_so_far": 233440782759936.0,
      "budget_used_percent": 0.233440782759936
    },
    {
      "type": "training",
      "description": "Training step 163",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:07",
      "total_flops_so_far": 234872934801408.0,
      "budget_used_percent": 0.23487293480140803
    },
    {
      "type": "training",
      "description": "Training step 164",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:07",
      "total_flops_so_far": 236305086842880.0,
      "budget_used_percent": 0.23630508684288
    },
    {
      "type": "training",
      "description": "Training step 165",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:08",
      "total_flops_so_far": 237737238884352.0,
      "budget_used_percent": 0.237737238884352
    },
    {
      "type": "training",
      "description": "Training step 166",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:08",
      "total_flops_so_far": 239169390925824.0,
      "budget_used_percent": 0.239169390925824
    },
    {
      "type": "training",
      "description": "Training step 167",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:08",
      "total_flops_so_far": 240601542967296.0,
      "budget_used_percent": 0.240601542967296
    },
    {
      "type": "training",
      "description": "Training step 168",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:08",
      "total_flops_so_far": 242033695008768.0,
      "budget_used_percent": 0.24203369500876798
    },
    {
      "type": "training",
      "description": "Training step 169",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:08",
      "total_flops_so_far": 243465847050240.0,
      "budget_used_percent": 0.24346584705024002
    },
    {
      "type": "training",
      "description": "Training step 170",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:08",
      "total_flops_so_far": 244897999091712.0,
      "budget_used_percent": 0.244897999091712
    },
    {
      "type": "training",
      "description": "Training step 171",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:08",
      "total_flops_so_far": 246330151133184.0,
      "budget_used_percent": 0.246330151133184
    },
    {
      "type": "training",
      "description": "Training step 172",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:08",
      "total_flops_so_far": 247762303174656.0,
      "budget_used_percent": 0.24776230317465597
    },
    {
      "type": "training",
      "description": "Training step 173",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:09",
      "total_flops_so_far": 249194455216128.0,
      "budget_used_percent": 0.249194455216128
    },
    {
      "type": "training",
      "description": "Training step 174",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:09",
      "total_flops_so_far": 250626607257600.0,
      "budget_used_percent": 0.2506266072576
    },
    {
      "type": "training",
      "description": "Training step 175",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:09",
      "total_flops_so_far": 252058759299072.0,
      "budget_used_percent": 0.25205875929907195
    },
    {
      "type": "training",
      "description": "Training step 176",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:09",
      "total_flops_so_far": 253490911340544.0,
      "budget_used_percent": 0.253490911340544
    },
    {
      "type": "training",
      "description": "Training step 177",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:09",
      "total_flops_so_far": 254923063382016.0,
      "budget_used_percent": 0.254923063382016
    },
    {
      "type": "training",
      "description": "Training step 178",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:09",
      "total_flops_so_far": 256355215423488.0,
      "budget_used_percent": 0.256355215423488
    },
    {
      "type": "training",
      "description": "Training step 179",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:09",
      "total_flops_so_far": 257787367464960.0,
      "budget_used_percent": 0.25778736746496
    },
    {
      "type": "training",
      "description": "Training step 180",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:09",
      "total_flops_so_far": 259219519506432.0,
      "budget_used_percent": 0.259219519506432
    },
    {
      "type": "training",
      "description": "Training step 181",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:10",
      "total_flops_so_far": 260651671547904.0,
      "budget_used_percent": 0.260651671547904
    },
    {
      "type": "training",
      "description": "Training step 182",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:10",
      "total_flops_so_far": 262083823589376.0,
      "budget_used_percent": 0.26208382358937604
    },
    {
      "type": "training",
      "description": "Training step 183",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:10",
      "total_flops_so_far": 263515975630848.0,
      "budget_used_percent": 0.263515975630848
    },
    {
      "type": "training",
      "description": "Training step 184",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:10",
      "total_flops_so_far": 264948127672320.0,
      "budget_used_percent": 0.26494812767232
    },
    {
      "type": "training",
      "description": "Training step 185",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:10",
      "total_flops_so_far": 266380279713792.0,
      "budget_used_percent": 0.266380279713792
    },
    {
      "type": "training",
      "description": "Training step 186",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:10",
      "total_flops_so_far": 267812431755264.0,
      "budget_used_percent": 0.267812431755264
    },
    {
      "type": "training",
      "description": "Training step 187",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:10",
      "total_flops_so_far": 269244583796736.0,
      "budget_used_percent": 0.269244583796736
    },
    {
      "type": "training",
      "description": "Training step 188",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:10",
      "total_flops_so_far": 270676735838208.0,
      "budget_used_percent": 0.270676735838208
    },
    {
      "type": "training",
      "description": "Training step 189",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:11",
      "total_flops_so_far": 272108887879680.0,
      "budget_used_percent": 0.27210888787968
    },
    {
      "type": "training",
      "description": "Training step 190",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:11",
      "total_flops_so_far": 273541039921152.0,
      "budget_used_percent": 0.273541039921152
    },
    {
      "type": "training",
      "description": "Training step 191",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:11",
      "total_flops_so_far": 274973191962624.0,
      "budget_used_percent": 0.274973191962624
    },
    {
      "type": "training",
      "description": "Training step 192",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:11",
      "total_flops_so_far": 276405344004096.0,
      "budget_used_percent": 0.276405344004096
    },
    {
      "type": "training",
      "description": "Training step 193",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:11",
      "total_flops_so_far": 277837496045568.0,
      "budget_used_percent": 0.277837496045568
    },
    {
      "type": "training",
      "description": "Training step 194",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:11",
      "total_flops_so_far": 279269648087040.0,
      "budget_used_percent": 0.27926964808703997
    },
    {
      "type": "training",
      "description": "Training step 195",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:11",
      "total_flops_so_far": 280701800128512.0,
      "budget_used_percent": 0.28070180012851204
    },
    {
      "type": "training",
      "description": "Training step 196",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:11",
      "total_flops_so_far": 282133952169984.0,
      "budget_used_percent": 0.282133952169984
    },
    {
      "type": "training",
      "description": "Training step 197",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:11",
      "total_flops_so_far": 283566104211456.0,
      "budget_used_percent": 0.283566104211456
    },
    {
      "type": "training",
      "description": "Training step 198",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:12",
      "total_flops_so_far": 284998256252928.0,
      "budget_used_percent": 0.284998256252928
    },
    {
      "type": "training",
      "description": "Training step 199",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:12",
      "total_flops_so_far": 286430408294400.0,
      "budget_used_percent": 0.2864304082944
    },
    {
      "type": "training",
      "description": "Training step 200",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:12",
      "total_flops_so_far": 287862560335872.0,
      "budget_used_percent": 0.287862560335872
    },
    {
      "type": "training",
      "description": "Training step 201",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:12",
      "total_flops_so_far": 289294712377344.0,
      "budget_used_percent": 0.289294712377344
    },
    {
      "type": "training",
      "description": "Training step 202",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:12",
      "total_flops_so_far": 290726864418816.0,
      "budget_used_percent": 0.290726864418816
    },
    {
      "type": "training",
      "description": "Training step 203",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:12",
      "total_flops_so_far": 292159016460288.0,
      "budget_used_percent": 0.29215901646028797
    },
    {
      "type": "training",
      "description": "Training step 204",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:12",
      "total_flops_so_far": 293591168501760.0,
      "budget_used_percent": 0.29359116850176004
    },
    {
      "type": "training",
      "description": "Training step 205",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:12",
      "total_flops_so_far": 295023320543232.0,
      "budget_used_percent": 0.295023320543232
    },
    {
      "type": "training",
      "description": "Training step 206",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:13",
      "total_flops_so_far": 296455472584704.0,
      "budget_used_percent": 0.296455472584704
    },
    {
      "type": "training",
      "description": "Training step 207",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:13",
      "total_flops_so_far": 297887624626176.0,
      "budget_used_percent": 0.297887624626176
    },
    {
      "type": "training",
      "description": "Training step 208",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:13",
      "total_flops_so_far": 299319776667648.0,
      "budget_used_percent": 0.29931977666764803
    },
    {
      "type": "training",
      "description": "Training step 209",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:13",
      "total_flops_so_far": 300751928709120.0,
      "budget_used_percent": 0.30075192870912
    },
    {
      "type": "training",
      "description": "Training step 210",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:13",
      "total_flops_so_far": 302184080750592.0,
      "budget_used_percent": 0.302184080750592
    },
    {
      "type": "training",
      "description": "Training step 211",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:13",
      "total_flops_so_far": 303616232792064.0,
      "budget_used_percent": 0.303616232792064
    },
    {
      "type": "training",
      "description": "Training step 212",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:13",
      "total_flops_so_far": 305048384833536.0,
      "budget_used_percent": 0.305048384833536
    },
    {
      "type": "training",
      "description": "Training step 213",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:13",
      "total_flops_so_far": 306480536875008.0,
      "budget_used_percent": 0.306480536875008
    },
    {
      "type": "training",
      "description": "Training step 214",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:14",
      "total_flops_so_far": 307912688916480.0,
      "budget_used_percent": 0.30791268891648
    },
    {
      "type": "training",
      "description": "Training step 215",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:14",
      "total_flops_so_far": 309344840957952.0,
      "budget_used_percent": 0.309344840957952
    },
    {
      "type": "training",
      "description": "Training step 216",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:14",
      "total_flops_so_far": 310776992999424.0,
      "budget_used_percent": 0.31077699299942396
    },
    {
      "type": "training",
      "description": "Training step 217",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:14",
      "total_flops_so_far": 312209145040896.0,
      "budget_used_percent": 0.31220914504089603
    },
    {
      "type": "training",
      "description": "Training step 218",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:14",
      "total_flops_so_far": 313641297082368.0,
      "budget_used_percent": 0.313641297082368
    },
    {
      "type": "training",
      "description": "Training step 219",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:14",
      "total_flops_so_far": 315073449123840.0,
      "budget_used_percent": 0.31507344912384
    },
    {
      "type": "training",
      "description": "Training step 220",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:14",
      "total_flops_so_far": 316505601165312.0,
      "budget_used_percent": 0.316505601165312
    },
    {
      "type": "training",
      "description": "Training step 221",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:14",
      "total_flops_so_far": 317937753206784.0,
      "budget_used_percent": 0.317937753206784
    },
    {
      "type": "training",
      "description": "Training step 222",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:14",
      "total_flops_so_far": 319369905248256.0,
      "budget_used_percent": 0.319369905248256
    },
    {
      "type": "training",
      "description": "Training step 223",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:15",
      "total_flops_so_far": 320802057289728.0,
      "budget_used_percent": 0.320802057289728
    },
    {
      "type": "training",
      "description": "Training step 224",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:15",
      "total_flops_so_far": 322234209331200.0,
      "budget_used_percent": 0.3222342093312
    },
    {
      "type": "training",
      "description": "Training step 225",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:15",
      "total_flops_so_far": 323666361372672.0,
      "budget_used_percent": 0.323666361372672
    },
    {
      "type": "training",
      "description": "Training step 226",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:15",
      "total_flops_so_far": 325098513414144.0,
      "budget_used_percent": 0.32509851341414403
    },
    {
      "type": "training",
      "description": "Training step 227",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:15",
      "total_flops_so_far": 326530665455616.0,
      "budget_used_percent": 0.326530665455616
    },
    {
      "type": "training",
      "description": "Training step 228",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:15",
      "total_flops_so_far": 327962817497088.0,
      "budget_used_percent": 0.327962817497088
    },
    {
      "type": "training",
      "description": "Training step 229",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:15",
      "total_flops_so_far": 329394969538560.0,
      "budget_used_percent": 0.32939496953855996
    },
    {
      "type": "training",
      "description": "Training step 230",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:15",
      "total_flops_so_far": 330827121580032.0,
      "budget_used_percent": 0.330827121580032
    },
    {
      "type": "training",
      "description": "Training step 231",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:16",
      "total_flops_so_far": 332259273621504.0,
      "budget_used_percent": 0.332259273621504
    },
    {
      "type": "training",
      "description": "Training step 232",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:16",
      "total_flops_so_far": 333691425662976.0,
      "budget_used_percent": 0.333691425662976
    },
    {
      "type": "training",
      "description": "Training step 233",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:16",
      "total_flops_so_far": 335123577704448.0,
      "budget_used_percent": 0.335123577704448
    },
    {
      "type": "training",
      "description": "Training step 234",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:16",
      "total_flops_so_far": 336555729745920.0,
      "budget_used_percent": 0.33655572974592
    },
    {
      "type": "training",
      "description": "Training step 235",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:16",
      "total_flops_so_far": 337987881787392.0,
      "budget_used_percent": 0.337987881787392
    },
    {
      "type": "training",
      "description": "Training step 236",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:16",
      "total_flops_so_far": 339420033828864.0,
      "budget_used_percent": 0.339420033828864
    },
    {
      "type": "training",
      "description": "Training step 237",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:16",
      "total_flops_so_far": 340852185870336.0,
      "budget_used_percent": 0.340852185870336
    },
    {
      "type": "training",
      "description": "Training step 238",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:16",
      "total_flops_so_far": 342284337911808.0,
      "budget_used_percent": 0.342284337911808
    },
    {
      "type": "training",
      "description": "Training step 239",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:17",
      "total_flops_so_far": 343716489953280.0,
      "budget_used_percent": 0.34371648995328
    },
    {
      "type": "training",
      "description": "Training step 240",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:17",
      "total_flops_so_far": 345148641994752.0,
      "budget_used_percent": 0.345148641994752
    },
    {
      "type": "training",
      "description": "Training step 241",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:17",
      "total_flops_so_far": 346580794036224.0,
      "budget_used_percent": 0.346580794036224
    },
    {
      "type": "training",
      "description": "Training step 242",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:17",
      "total_flops_so_far": 348012946077696.0,
      "budget_used_percent": 0.348012946077696
    },
    {
      "type": "training",
      "description": "Training step 243",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:17",
      "total_flops_so_far": 349445098119168.0,
      "budget_used_percent": 0.349445098119168
    },
    {
      "type": "training",
      "description": "Training step 244",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:17",
      "total_flops_so_far": 350877250160640.0,
      "budget_used_percent": 0.35087725016064
    },
    {
      "type": "training",
      "description": "Training step 245",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:17",
      "total_flops_so_far": 352309402202112.0,
      "budget_used_percent": 0.352309402202112
    },
    {
      "type": "training",
      "description": "Training step 246",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:17",
      "total_flops_so_far": 353741554243584.0,
      "budget_used_percent": 0.353741554243584
    },
    {
      "type": "training",
      "description": "Training step 247",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:18",
      "total_flops_so_far": 355173706285056.0,
      "budget_used_percent": 0.355173706285056
    },
    {
      "type": "training",
      "description": "Training step 248",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:18",
      "total_flops_so_far": 356605858326528.0,
      "budget_used_percent": 0.35660585832652797
    },
    {
      "type": "training",
      "description": "Training step 249",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:18",
      "total_flops_so_far": 358038010368000.0,
      "budget_used_percent": 0.35803801036800004
    },
    {
      "type": "training",
      "description": "Training step 250",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:18",
      "total_flops_so_far": 359470162409472.0,
      "budget_used_percent": 0.359470162409472
    },
    {
      "type": "training",
      "description": "Training step 251",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:18",
      "total_flops_so_far": 360902314450944.0,
      "budget_used_percent": 0.360902314450944
    },
    {
      "type": "training",
      "description": "Training step 252",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:18",
      "total_flops_so_far": 362334466492416.0,
      "budget_used_percent": 0.362334466492416
    },
    {
      "type": "training",
      "description": "Training step 253",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:18",
      "total_flops_so_far": 363766618533888.0,
      "budget_used_percent": 0.363766618533888
    },
    {
      "type": "training",
      "description": "Training step 254",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:18",
      "total_flops_so_far": 365198770575360.0,
      "budget_used_percent": 0.36519877057536
    },
    {
      "type": "training",
      "description": "Training step 255",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:19",
      "total_flops_so_far": 366630922616832.0,
      "budget_used_percent": 0.366630922616832
    },
    {
      "type": "training",
      "description": "Training step 256",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:19",
      "total_flops_so_far": 368063074658304.0,
      "budget_used_percent": 0.368063074658304
    },
    {
      "type": "training",
      "description": "Training step 257",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:19",
      "total_flops_so_far": 369495226699776.0,
      "budget_used_percent": 0.36949522669977597
    },
    {
      "type": "training",
      "description": "Training step 258",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:19",
      "total_flops_so_far": 370927378741248.0,
      "budget_used_percent": 0.37092737874124804
    },
    {
      "type": "training",
      "description": "Training step 259",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:19",
      "total_flops_so_far": 372359530782720.0,
      "budget_used_percent": 0.37235953078272
    },
    {
      "type": "training",
      "description": "Training step 260",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:19",
      "total_flops_so_far": 373791682824192.0,
      "budget_used_percent": 0.373791682824192
    },
    {
      "type": "training",
      "description": "Training step 261",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:19",
      "total_flops_so_far": 375223834865664.0,
      "budget_used_percent": 0.375223834865664
    },
    {
      "type": "training",
      "description": "Training step 262",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:19",
      "total_flops_so_far": 376655986907136.0,
      "budget_used_percent": 0.37665598690713603
    },
    {
      "type": "training",
      "description": "Training step 263",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:20",
      "total_flops_so_far": 378088138948608.0,
      "budget_used_percent": 0.378088138948608
    },
    {
      "type": "training",
      "description": "Training step 264",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:20",
      "total_flops_so_far": 379520290990080.0,
      "budget_used_percent": 0.37952029099008
    },
    {
      "type": "training",
      "description": "Training step 265",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:20",
      "total_flops_so_far": 380952443031552.0,
      "budget_used_percent": 0.380952443031552
    },
    {
      "type": "training",
      "description": "Training step 266",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:20",
      "total_flops_so_far": 382384595073024.0,
      "budget_used_percent": 0.38238459507302397
    },
    {
      "type": "training",
      "description": "Training step 267",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:20",
      "total_flops_so_far": 383816747114496.0,
      "budget_used_percent": 0.383816747114496
    },
    {
      "type": "training",
      "description": "Training step 268",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:20",
      "total_flops_so_far": 385248899155968.0,
      "budget_used_percent": 0.385248899155968
    },
    {
      "type": "training",
      "description": "Training step 269",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:20",
      "total_flops_so_far": 386681051197440.0,
      "budget_used_percent": 0.38668105119744
    },
    {
      "type": "training",
      "description": "Training step 270",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:20",
      "total_flops_so_far": 388113203238912.0,
      "budget_used_percent": 0.38811320323891196
    },
    {
      "type": "training",
      "description": "Training step 271",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:21",
      "total_flops_so_far": 389545355280384.0,
      "budget_used_percent": 0.38954535528038403
    },
    {
      "type": "training",
      "description": "Training step 272",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:21",
      "total_flops_so_far": 390977507321856.0,
      "budget_used_percent": 0.39097750732185593
    },
    {
      "type": "training",
      "description": "Training step 273",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:21",
      "total_flops_so_far": 392409659363328.0,
      "budget_used_percent": 0.392409659363328
    },
    {
      "type": "training",
      "description": "Training step 274",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:21",
      "total_flops_so_far": 393841811404800.0,
      "budget_used_percent": 0.3938418114048
    },
    {
      "type": "training",
      "description": "Training step 275",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:21",
      "total_flops_so_far": 395273963446272.0,
      "budget_used_percent": 0.39527396344627197
    },
    {
      "type": "training",
      "description": "Training step 276",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:21",
      "total_flops_so_far": 396706115487744.0,
      "budget_used_percent": 0.396706115487744
    },
    {
      "type": "training",
      "description": "Training step 277",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:21",
      "total_flops_so_far": 398138267529216.0,
      "budget_used_percent": 0.398138267529216
    },
    {
      "type": "training",
      "description": "Training step 278",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:21",
      "total_flops_so_far": 399570419570688.0,
      "budget_used_percent": 0.39957041957068795
    },
    {
      "type": "training",
      "description": "Training step 279",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:22",
      "total_flops_so_far": 401002571612160.0,
      "budget_used_percent": 0.40100257161216
    },
    {
      "type": "training",
      "description": "Training step 280",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:22",
      "total_flops_so_far": 402434723653632.0,
      "budget_used_percent": 0.40243472365363203
    },
    {
      "type": "training",
      "description": "Training step 281",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:22",
      "total_flops_so_far": 403866875695104.0,
      "budget_used_percent": 0.403866875695104
    },
    {
      "type": "training",
      "description": "Training step 282",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:22",
      "total_flops_so_far": 405299027736576.0,
      "budget_used_percent": 0.405299027736576
    },
    {
      "type": "training",
      "description": "Training step 283",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:22",
      "total_flops_so_far": 406731179778048.0,
      "budget_used_percent": 0.406731179778048
    },
    {
      "type": "training",
      "description": "Training step 284",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:22",
      "total_flops_so_far": 408163331819520.0,
      "budget_used_percent": 0.40816333181951997
    },
    {
      "type": "training",
      "description": "Training step 285",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:22",
      "total_flops_so_far": 409595483860992.0,
      "budget_used_percent": 0.409595483860992
    },
    {
      "type": "training",
      "description": "Training step 286",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:22",
      "total_flops_so_far": 411027635902464.0,
      "budget_used_percent": 0.41102763590246405
    },
    {
      "type": "training",
      "description": "Training step 287",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:23",
      "total_flops_so_far": 412459787943936.0,
      "budget_used_percent": 0.41245978794393595
    },
    {
      "type": "training",
      "description": "Training step 288",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:23",
      "total_flops_so_far": 413891939985408.0,
      "budget_used_percent": 0.413891939985408
    },
    {
      "type": "training",
      "description": "Training step 289",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:23",
      "total_flops_so_far": 415324092026880.0,
      "budget_used_percent": 0.41532409202688003
    },
    {
      "type": "training",
      "description": "Training step 290",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:23",
      "total_flops_so_far": 416756244068352.0,
      "budget_used_percent": 0.416756244068352
    },
    {
      "type": "training",
      "description": "Training step 291",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:23",
      "total_flops_so_far": 418188396109824.0,
      "budget_used_percent": 0.418188396109824
    },
    {
      "type": "training",
      "description": "Training step 292",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:23",
      "total_flops_so_far": 419620548151296.0,
      "budget_used_percent": 0.419620548151296
    },
    {
      "type": "training",
      "description": "Training step 293",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:23",
      "total_flops_so_far": 421052700192768.0,
      "budget_used_percent": 0.42105270019276797
    },
    {
      "type": "training",
      "description": "Training step 294",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:23",
      "total_flops_so_far": 422484852234240.0,
      "budget_used_percent": 0.42248485223424
    },
    {
      "type": "training",
      "description": "Training step 295",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:23",
      "total_flops_so_far": 423917004275712.0,
      "budget_used_percent": 0.42391700427571205
    },
    {
      "type": "training",
      "description": "Training step 296",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:24",
      "total_flops_so_far": 425349156317184.0,
      "budget_used_percent": 0.42534915631718395
    },
    {
      "type": "training",
      "description": "Training step 297",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:24",
      "total_flops_so_far": 426781308358656.0,
      "budget_used_percent": 0.426781308358656
    },
    {
      "type": "training",
      "description": "Training step 298",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:24",
      "total_flops_so_far": 428213460400128.0,
      "budget_used_percent": 0.42821346040012803
    },
    {
      "type": "training",
      "description": "Training step 299",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:24",
      "total_flops_so_far": 429645612441600.0,
      "budget_used_percent": 0.4296456124416
    },
    {
      "type": "training",
      "description": "Training step 300",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:24",
      "total_flops_so_far": 431077764483072.0,
      "budget_used_percent": 0.431077764483072
    },
    {
      "type": "training",
      "description": "Training step 301",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:24",
      "total_flops_so_far": 432509916524544.0,
      "budget_used_percent": 0.432509916524544
    },
    {
      "type": "training",
      "description": "Training step 302",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:24",
      "total_flops_so_far": 433942068566016.0,
      "budget_used_percent": 0.43394206856601597
    },
    {
      "type": "training",
      "description": "Training step 303",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:24",
      "total_flops_so_far": 435374220607488.0,
      "budget_used_percent": 0.435374220607488
    },
    {
      "type": "training",
      "description": "Training step 304",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:25",
      "total_flops_so_far": 436806372648960.0,
      "budget_used_percent": 0.43680637264896005
    },
    {
      "type": "training",
      "description": "Training step 305",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:25",
      "total_flops_so_far": 438238524690432.0,
      "budget_used_percent": 0.438238524690432
    },
    {
      "type": "training",
      "description": "Training step 306",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:25",
      "total_flops_so_far": 439670676731904.0,
      "budget_used_percent": 0.439670676731904
    },
    {
      "type": "training",
      "description": "Training step 307",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:25",
      "total_flops_so_far": 441102828773376.0,
      "budget_used_percent": 0.44110282877337603
    },
    {
      "type": "training",
      "description": "Training step 308",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:25",
      "total_flops_so_far": 442534980814848.0,
      "budget_used_percent": 0.442534980814848
    },
    {
      "type": "training",
      "description": "Training step 309",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:25",
      "total_flops_so_far": 443967132856320.0,
      "budget_used_percent": 0.44396713285632
    },
    {
      "type": "training",
      "description": "Training step 310",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:25",
      "total_flops_so_far": 445399284897792.0,
      "budget_used_percent": 0.44539928489779196
    },
    {
      "type": "training",
      "description": "Training step 311",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:25",
      "total_flops_so_far": 446831436939264.0,
      "budget_used_percent": 0.44683143693926397
    },
    {
      "type": "training",
      "description": "Training step 312",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:26",
      "total_flops_so_far": 448263588980736.0,
      "budget_used_percent": 0.44826358898073604
    },
    {
      "type": "training",
      "description": "Training step 313",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:26",
      "total_flops_so_far": 449695741022208.0,
      "budget_used_percent": 0.44969574102220794
    },
    {
      "type": "training",
      "description": "Training step 314",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:26",
      "total_flops_so_far": 451127893063680.0,
      "budget_used_percent": 0.45112789306368
    },
    {
      "type": "training",
      "description": "Training step 315",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:26",
      "total_flops_so_far": 452560045105152.0,
      "budget_used_percent": 0.452560045105152
    },
    {
      "type": "training",
      "description": "Training step 316",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:26",
      "total_flops_so_far": 453992197146624.0,
      "budget_used_percent": 0.453992197146624
    },
    {
      "type": "training",
      "description": "Training step 317",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:26",
      "total_flops_so_far": 455424349188096.0,
      "budget_used_percent": 0.455424349188096
    },
    {
      "type": "training",
      "description": "Training step 318",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:26",
      "total_flops_so_far": 456856501229568.0,
      "budget_used_percent": 0.456856501229568
    },
    {
      "type": "training",
      "description": "Training step 319",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:26",
      "total_flops_so_far": 458288653271040.0,
      "budget_used_percent": 0.45828865327103996
    },
    {
      "type": "training",
      "description": "Training step 320",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:27",
      "total_flops_so_far": 459720805312512.0,
      "budget_used_percent": 0.45972080531251197
    },
    {
      "type": "training",
      "description": "Training step 321",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:27",
      "total_flops_so_far": 461152957353984.0,
      "budget_used_percent": 0.46115295735398404
    },
    {
      "type": "training",
      "description": "Training step 322",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:27",
      "total_flops_so_far": 462585109395456.0,
      "budget_used_percent": 0.46258510939545594
    },
    {
      "type": "training",
      "description": "Training step 323",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:27",
      "total_flops_so_far": 464017261436928.0,
      "budget_used_percent": 0.464017261436928
    },
    {
      "type": "training",
      "description": "Training step 324",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:27",
      "total_flops_so_far": 465449413478400.0,
      "budget_used_percent": 0.4654494134784
    },
    {
      "type": "training",
      "description": "Training step 325",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:27",
      "total_flops_so_far": 466881565519872.0,
      "budget_used_percent": 0.466881565519872
    },
    {
      "type": "training",
      "description": "Training step 326",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:27",
      "total_flops_so_far": 468313717561344.0,
      "budget_used_percent": 0.468313717561344
    },
    {
      "type": "training",
      "description": "Training step 327",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:27",
      "total_flops_so_far": 469745869602816.0,
      "budget_used_percent": 0.46974586960281606
    },
    {
      "type": "training",
      "description": "Training step 328",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:28",
      "total_flops_so_far": 471178021644288.0,
      "budget_used_percent": 0.47117802164428796
    },
    {
      "type": "training",
      "description": "Training step 329",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:28",
      "total_flops_so_far": 472610173685760.0,
      "budget_used_percent": 0.47261017368576
    },
    {
      "type": "training",
      "description": "Training step 330",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:28",
      "total_flops_so_far": 474042325727232.0,
      "budget_used_percent": 0.47404232572723204
    },
    {
      "type": "training",
      "description": "Training step 331",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:28",
      "total_flops_so_far": 475474477768704.0,
      "budget_used_percent": 0.475474477768704
    },
    {
      "type": "training",
      "description": "Training step 332",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:28",
      "total_flops_so_far": 476906629810176.0,
      "budget_used_percent": 0.476906629810176
    },
    {
      "type": "training",
      "description": "Training step 333",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:28",
      "total_flops_so_far": 478338781851648.0,
      "budget_used_percent": 0.478338781851648
    },
    {
      "type": "training",
      "description": "Training step 334",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:28",
      "total_flops_so_far": 479770933893120.0,
      "budget_used_percent": 0.47977093389312
    },
    {
      "type": "training",
      "description": "Training step 335",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:28",
      "total_flops_so_far": 481203085934592.0,
      "budget_used_percent": 0.481203085934592
    },
    {
      "type": "training",
      "description": "Training step 336",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:29",
      "total_flops_so_far": 482635237976064.0,
      "budget_used_percent": 0.48263523797606406
    },
    {
      "type": "training",
      "description": "Training step 337",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:29",
      "total_flops_so_far": 484067390017536.0,
      "budget_used_percent": 0.48406739001753596
    },
    {
      "type": "training",
      "description": "Training step 338",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:29",
      "total_flops_so_far": 485499542059008.0,
      "budget_used_percent": 0.485499542059008
    },
    {
      "type": "training",
      "description": "Training step 339",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:29",
      "total_flops_so_far": 486931694100480.0,
      "budget_used_percent": 0.48693169410048004
    },
    {
      "type": "training",
      "description": "Training step 340",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:29",
      "total_flops_so_far": 488363846141952.0,
      "budget_used_percent": 0.488363846141952
    },
    {
      "type": "training",
      "description": "Training step 341",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:29",
      "total_flops_so_far": 489795998183424.0,
      "budget_used_percent": 0.489795998183424
    },
    {
      "type": "training",
      "description": "Training step 342",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:29",
      "total_flops_so_far": 491228150224896.0,
      "budget_used_percent": 0.491228150224896
    },
    {
      "type": "training",
      "description": "Training step 343",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:29",
      "total_flops_so_far": 492660302266368.0,
      "budget_used_percent": 0.492660302266368
    },
    {
      "type": "training",
      "description": "Training step 344",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:30",
      "total_flops_so_far": 494092454307840.0,
      "budget_used_percent": 0.49409245430784
    },
    {
      "type": "training",
      "description": "Training step 345",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:30",
      "total_flops_so_far": 495524606349312.0,
      "budget_used_percent": 0.49552460634931195
    },
    {
      "type": "training",
      "description": "Training step 346",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:30",
      "total_flops_so_far": 496956758390784.0,
      "budget_used_percent": 0.496956758390784
    },
    {
      "type": "training",
      "description": "Training step 347",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:30",
      "total_flops_so_far": 498388910432256.0,
      "budget_used_percent": 0.498388910432256
    },
    {
      "type": "training",
      "description": "Training step 348",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:30",
      "total_flops_so_far": 499821062473728.0,
      "budget_used_percent": 0.499821062473728
    },
    {
      "type": "training",
      "description": "Training step 349",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:30",
      "total_flops_so_far": 501253214515200.0,
      "budget_used_percent": 0.5012532145152
    },
    {
      "type": "training",
      "description": "Training step 350",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:30",
      "total_flops_so_far": 502685366556672.0,
      "budget_used_percent": 0.5026853665566721
    },
    {
      "type": "training",
      "description": "Training step 351",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:30",
      "total_flops_so_far": 504117518598144.0,
      "budget_used_percent": 0.5041175185981439
    },
    {
      "type": "training",
      "description": "Training step 352",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:31",
      "total_flops_so_far": 505549670639616.0,
      "budget_used_percent": 0.505549670639616
    },
    {
      "type": "training",
      "description": "Training step 353",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:31",
      "total_flops_so_far": 506981822681088.0,
      "budget_used_percent": 0.506981822681088
    },
    {
      "type": "training",
      "description": "Training step 354",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:31",
      "total_flops_so_far": 508413974722560.0,
      "budget_used_percent": 0.50841397472256
    },
    {
      "type": "training",
      "description": "Training step 355",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:31",
      "total_flops_so_far": 509846126764032.0,
      "budget_used_percent": 0.509846126764032
    },
    {
      "type": "training",
      "description": "Training step 356",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:31",
      "total_flops_so_far": 511278278805504.0,
      "budget_used_percent": 0.511278278805504
    },
    {
      "type": "training",
      "description": "Training step 357",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:31",
      "total_flops_so_far": 512710430846976.0,
      "budget_used_percent": 0.512710430846976
    },
    {
      "type": "training",
      "description": "Training step 358",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:31",
      "total_flops_so_far": 514142582888448.0,
      "budget_used_percent": 0.514142582888448
    },
    {
      "type": "training",
      "description": "Training step 359",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:31",
      "total_flops_so_far": 515574734929920.0,
      "budget_used_percent": 0.51557473492992
    },
    {
      "type": "training",
      "description": "Training step 360",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:32",
      "total_flops_so_far": 517006886971392.0,
      "budget_used_percent": 0.517006886971392
    },
    {
      "type": "training",
      "description": "Training step 361",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:32",
      "total_flops_so_far": 518439039012864.0,
      "budget_used_percent": 0.518439039012864
    },
    {
      "type": "training",
      "description": "Training step 362",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:32",
      "total_flops_so_far": 519871191054336.0,
      "budget_used_percent": 0.519871191054336
    },
    {
      "type": "training",
      "description": "Training step 363",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:32",
      "total_flops_so_far": 521303343095808.0,
      "budget_used_percent": 0.521303343095808
    },
    {
      "type": "training",
      "description": "Training step 364",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:32",
      "total_flops_so_far": 522735495137280.0,
      "budget_used_percent": 0.52273549513728
    },
    {
      "type": "training",
      "description": "Training step 365",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:32",
      "total_flops_so_far": 524167647178752.0,
      "budget_used_percent": 0.5241676471787521
    },
    {
      "type": "training",
      "description": "Training step 366",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:32",
      "total_flops_so_far": 525599799220224.0,
      "budget_used_percent": 0.5255997992202239
    },
    {
      "type": "training",
      "description": "Training step 367",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:32",
      "total_flops_so_far": 527031951261696.0,
      "budget_used_percent": 0.527031951261696
    },
    {
      "type": "training",
      "description": "Training step 368",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:33",
      "total_flops_so_far": 528464103303168.0,
      "budget_used_percent": 0.5284641033031681
    },
    {
      "type": "training",
      "description": "Training step 369",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:33",
      "total_flops_so_far": 529896255344640.0,
      "budget_used_percent": 0.52989625534464
    },
    {
      "type": "training",
      "description": "Training step 370",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:33",
      "total_flops_so_far": 531328407386112.0,
      "budget_used_percent": 0.531328407386112
    },
    {
      "type": "training",
      "description": "Training step 371",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:33",
      "total_flops_so_far": 532760559427584.0,
      "budget_used_percent": 0.532760559427584
    },
    {
      "type": "training",
      "description": "Training step 372",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:33",
      "total_flops_so_far": 534192711469056.0,
      "budget_used_percent": 0.534192711469056
    },
    {
      "type": "training",
      "description": "Training step 373",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:33",
      "total_flops_so_far": 535624863510528.0,
      "budget_used_percent": 0.535624863510528
    },
    {
      "type": "training",
      "description": "Training step 374",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:33",
      "total_flops_so_far": 537057015552000.0,
      "budget_used_percent": 0.537057015552
    },
    {
      "type": "training",
      "description": "Training step 375",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:33",
      "total_flops_so_far": 538489167593472.0,
      "budget_used_percent": 0.538489167593472
    },
    {
      "type": "training",
      "description": "Training step 376",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:34",
      "total_flops_so_far": 539921319634944.0,
      "budget_used_percent": 0.539921319634944
    },
    {
      "type": "training",
      "description": "Training step 377",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:34",
      "total_flops_so_far": 541353471676416.0,
      "budget_used_percent": 0.541353471676416
    },
    {
      "type": "training",
      "description": "Training step 378",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:34",
      "total_flops_so_far": 542785623717888.0,
      "budget_used_percent": 0.542785623717888
    },
    {
      "type": "training",
      "description": "Training step 379",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:34",
      "total_flops_so_far": 544217775759360.0,
      "budget_used_percent": 0.54421777575936
    },
    {
      "type": "training",
      "description": "Training step 380",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:34",
      "total_flops_so_far": 545649927800832.0,
      "budget_used_percent": 0.545649927800832
    },
    {
      "type": "training",
      "description": "Training step 381",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:34",
      "total_flops_so_far": 547082079842304.0,
      "budget_used_percent": 0.547082079842304
    },
    {
      "type": "training",
      "description": "Training step 382",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:34",
      "total_flops_so_far": 548514231883776.0,
      "budget_used_percent": 0.548514231883776
    },
    {
      "type": "training",
      "description": "Training step 383",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:34",
      "total_flops_so_far": 549946383925248.0,
      "budget_used_percent": 0.549946383925248
    },
    {
      "type": "training",
      "description": "Training step 384",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:35",
      "total_flops_so_far": 551378535966720.0,
      "budget_used_percent": 0.55137853596672
    },
    {
      "type": "training",
      "description": "Training step 385",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:35",
      "total_flops_so_far": 552810688008192.0,
      "budget_used_percent": 0.552810688008192
    },
    {
      "type": "training",
      "description": "Training step 386",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:35",
      "total_flops_so_far": 554242840049664.0,
      "budget_used_percent": 0.554242840049664
    },
    {
      "type": "training",
      "description": "Training step 387",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:35",
      "total_flops_so_far": 555674992091136.0,
      "budget_used_percent": 0.555674992091136
    },
    {
      "type": "training",
      "description": "Training step 388",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:35",
      "total_flops_so_far": 557107144132608.0,
      "budget_used_percent": 0.557107144132608
    },
    {
      "type": "training",
      "description": "Training step 389",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:35",
      "total_flops_so_far": 558539296174080.0,
      "budget_used_percent": 0.5585392961740799
    },
    {
      "type": "training",
      "description": "Training step 390",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:35",
      "total_flops_so_far": 559971448215552.0,
      "budget_used_percent": 0.559971448215552
    },
    {
      "type": "training",
      "description": "Training step 391",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:35",
      "total_flops_so_far": 561403600257024.0,
      "budget_used_percent": 0.5614036002570241
    },
    {
      "type": "training",
      "description": "Training step 392",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:36",
      "total_flops_so_far": 562835752298496.0,
      "budget_used_percent": 0.5628357522984959
    },
    {
      "type": "training",
      "description": "Training step 393",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:36",
      "total_flops_so_far": 564267904339968.0,
      "budget_used_percent": 0.564267904339968
    },
    {
      "type": "training",
      "description": "Training step 394",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:36",
      "total_flops_so_far": 565700056381440.0,
      "budget_used_percent": 0.56570005638144
    },
    {
      "type": "training",
      "description": "Training step 395",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:36",
      "total_flops_so_far": 567132208422912.0,
      "budget_used_percent": 0.567132208422912
    },
    {
      "type": "training",
      "description": "Training step 396",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:36",
      "total_flops_so_far": 568564360464384.0,
      "budget_used_percent": 0.568564360464384
    },
    {
      "type": "training",
      "description": "Training step 397",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:36",
      "total_flops_so_far": 569996512505856.0,
      "budget_used_percent": 0.569996512505856
    },
    {
      "type": "training",
      "description": "Training step 398",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:36",
      "total_flops_so_far": 571428664547328.0,
      "budget_used_percent": 0.571428664547328
    },
    {
      "type": "training",
      "description": "Training step 399",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:36",
      "total_flops_so_far": 572860816588800.0,
      "budget_used_percent": 0.5728608165888
    },
    {
      "type": "training",
      "description": "Training step 400",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:37",
      "total_flops_so_far": 574292968630272.0,
      "budget_used_percent": 0.574292968630272
    },
    {
      "type": "training",
      "description": "Training step 401",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:37",
      "total_flops_so_far": 575725120671744.0,
      "budget_used_percent": 0.575725120671744
    },
    {
      "type": "training",
      "description": "Training step 402",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:37",
      "total_flops_so_far": 577157272713216.0,
      "budget_used_percent": 0.577157272713216
    },
    {
      "type": "training",
      "description": "Training step 403",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:37",
      "total_flops_so_far": 578589424754688.0,
      "budget_used_percent": 0.578589424754688
    },
    {
      "type": "training",
      "description": "Training step 404",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:37",
      "total_flops_so_far": 580021576796160.0,
      "budget_used_percent": 0.58002157679616
    },
    {
      "type": "training",
      "description": "Training step 405",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:37",
      "total_flops_so_far": 581453728837632.0,
      "budget_used_percent": 0.581453728837632
    },
    {
      "type": "training",
      "description": "Training step 406",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:37",
      "total_flops_so_far": 582885880879104.0,
      "budget_used_percent": 0.582885880879104
    },
    {
      "type": "training",
      "description": "Training step 407",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:37",
      "total_flops_so_far": 584318032920576.0,
      "budget_used_percent": 0.5843180329205759
    },
    {
      "type": "training",
      "description": "Training step 408",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:38",
      "total_flops_so_far": 585750184962048.0,
      "budget_used_percent": 0.585750184962048
    },
    {
      "type": "training",
      "description": "Training step 409",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:38",
      "total_flops_so_far": 587182337003520.0,
      "budget_used_percent": 0.5871823370035201
    },
    {
      "type": "training",
      "description": "Training step 410",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:38",
      "total_flops_so_far": 588614489044992.0,
      "budget_used_percent": 0.588614489044992
    },
    {
      "type": "training",
      "description": "Training step 411",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:38",
      "total_flops_so_far": 590046641086464.0,
      "budget_used_percent": 0.590046641086464
    },
    {
      "type": "training",
      "description": "Training step 412",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:38",
      "total_flops_so_far": 591478793127936.0,
      "budget_used_percent": 0.591478793127936
    },
    {
      "type": "training",
      "description": "Training step 413",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:38",
      "total_flops_so_far": 592910945169408.0,
      "budget_used_percent": 0.592910945169408
    },
    {
      "type": "training",
      "description": "Training step 414",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:38",
      "total_flops_so_far": 594343097210880.0,
      "budget_used_percent": 0.59434309721088
    },
    {
      "type": "training",
      "description": "Training step 415",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:38",
      "total_flops_so_far": 595775249252352.0,
      "budget_used_percent": 0.595775249252352
    },
    {
      "type": "training",
      "description": "Training step 416",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:39",
      "total_flops_so_far": 597207401293824.0,
      "budget_used_percent": 0.597207401293824
    },
    {
      "type": "training",
      "description": "Training step 417",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:39",
      "total_flops_so_far": 598639553335296.0,
      "budget_used_percent": 0.5986395533352961
    },
    {
      "type": "training",
      "description": "Training step 418",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:39",
      "total_flops_so_far": 600071705376768.0,
      "budget_used_percent": 0.6000717053767679
    },
    {
      "type": "training",
      "description": "Training step 419",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:39",
      "total_flops_so_far": 601503857418240.0,
      "budget_used_percent": 0.60150385741824
    },
    {
      "type": "training",
      "description": "Training step 420",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:39",
      "total_flops_so_far": 602936009459712.0,
      "budget_used_percent": 0.602936009459712
    },
    {
      "type": "training",
      "description": "Training step 421",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:39",
      "total_flops_so_far": 604368161501184.0,
      "budget_used_percent": 0.604368161501184
    },
    {
      "type": "training",
      "description": "Training step 422",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:39",
      "total_flops_so_far": 605800313542656.0,
      "budget_used_percent": 0.605800313542656
    },
    {
      "type": "training",
      "description": "Training step 423",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:39",
      "total_flops_so_far": 607232465584128.0,
      "budget_used_percent": 0.607232465584128
    },
    {
      "type": "training",
      "description": "Training step 424",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:40",
      "total_flops_so_far": 608664617625600.0,
      "budget_used_percent": 0.6086646176256
    },
    {
      "type": "training",
      "description": "Training step 425",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:40",
      "total_flops_so_far": 610096769667072.0,
      "budget_used_percent": 0.610096769667072
    },
    {
      "type": "training",
      "description": "Training step 426",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:40",
      "total_flops_so_far": 611528921708544.0,
      "budget_used_percent": 0.611528921708544
    },
    {
      "type": "training",
      "description": "Training step 427",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:40",
      "total_flops_so_far": 612961073750016.0,
      "budget_used_percent": 0.612961073750016
    },
    {
      "type": "training",
      "description": "Training step 428",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:40",
      "total_flops_so_far": 614393225791488.0,
      "budget_used_percent": 0.614393225791488
    },
    {
      "type": "training",
      "description": "Training step 429",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:40",
      "total_flops_so_far": 615825377832960.0,
      "budget_used_percent": 0.61582537783296
    },
    {
      "type": "training",
      "description": "Training step 430",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:40",
      "total_flops_so_far": 617257529874432.0,
      "budget_used_percent": 0.6172575298744319
    },
    {
      "type": "training",
      "description": "Training step 431",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:41",
      "total_flops_so_far": 618689681915904.0,
      "budget_used_percent": 0.618689681915904
    },
    {
      "type": "training",
      "description": "Training step 432",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:41",
      "total_flops_so_far": 620121833957376.0,
      "budget_used_percent": 0.6201218339573761
    },
    {
      "type": "training",
      "description": "Training step 433",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:41",
      "total_flops_so_far": 621553985998848.0,
      "budget_used_percent": 0.6215539859988479
    },
    {
      "type": "training",
      "description": "Training step 434",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:41",
      "total_flops_so_far": 622986138040320.0,
      "budget_used_percent": 0.62298613804032
    },
    {
      "type": "training",
      "description": "Training step 435",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:41",
      "total_flops_so_far": 624418290081792.0,
      "budget_used_percent": 0.6244182900817921
    },
    {
      "type": "training",
      "description": "Training step 436",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:41",
      "total_flops_so_far": 625850442123264.0,
      "budget_used_percent": 0.625850442123264
    },
    {
      "type": "training",
      "description": "Training step 437",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:41",
      "total_flops_so_far": 627282594164736.0,
      "budget_used_percent": 0.627282594164736
    },
    {
      "type": "training",
      "description": "Training step 438",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:41",
      "total_flops_so_far": 628714746206208.0,
      "budget_used_percent": 0.628714746206208
    },
    {
      "type": "training",
      "description": "Training step 439",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:42",
      "total_flops_so_far": 630146898247680.0,
      "budget_used_percent": 0.63014689824768
    },
    {
      "type": "training",
      "description": "Training step 440",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:42",
      "total_flops_so_far": 631579050289152.0,
      "budget_used_percent": 0.631579050289152
    },
    {
      "type": "training",
      "description": "Training step 441",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:42",
      "total_flops_so_far": 633011202330624.0,
      "budget_used_percent": 0.633011202330624
    },
    {
      "type": "training",
      "description": "Training step 442",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:42",
      "total_flops_so_far": 634443354372096.0,
      "budget_used_percent": 0.634443354372096
    },
    {
      "type": "training",
      "description": "Training step 443",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:42",
      "total_flops_so_far": 635875506413568.0,
      "budget_used_percent": 0.635875506413568
    },
    {
      "type": "training",
      "description": "Training step 444",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:42",
      "total_flops_so_far": 637307658455040.0,
      "budget_used_percent": 0.63730765845504
    },
    {
      "type": "training",
      "description": "Training step 445",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:42",
      "total_flops_so_far": 638739810496512.0,
      "budget_used_percent": 0.638739810496512
    },
    {
      "type": "training",
      "description": "Training step 446",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:42",
      "total_flops_so_far": 640171962537984.0,
      "budget_used_percent": 0.640171962537984
    },
    {
      "type": "training",
      "description": "Training step 447",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:43",
      "total_flops_so_far": 641604114579456.0,
      "budget_used_percent": 0.641604114579456
    },
    {
      "type": "training",
      "description": "Training step 448",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:43",
      "total_flops_so_far": 643036266620928.0,
      "budget_used_percent": 0.6430362666209279
    },
    {
      "type": "training",
      "description": "Training step 449",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:43",
      "total_flops_so_far": 644468418662400.0,
      "budget_used_percent": 0.6444684186624
    },
    {
      "type": "training",
      "description": "Training step 450",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:43",
      "total_flops_so_far": 645900570703872.0,
      "budget_used_percent": 0.6459005707038721
    },
    {
      "type": "training",
      "description": "Training step 451",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:43",
      "total_flops_so_far": 647332722745344.0,
      "budget_used_percent": 0.647332722745344
    },
    {
      "type": "training",
      "description": "Training step 452",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:43",
      "total_flops_so_far": 648764874786816.0,
      "budget_used_percent": 0.648764874786816
    },
    {
      "type": "training",
      "description": "Training step 453",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:43",
      "total_flops_so_far": 650197026828288.0,
      "budget_used_percent": 0.6501970268282881
    },
    {
      "type": "training",
      "description": "Training step 454",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:43",
      "total_flops_so_far": 651629178869760.0,
      "budget_used_percent": 0.65162917886976
    },
    {
      "type": "training",
      "description": "Training step 455",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:44",
      "total_flops_so_far": 653061330911232.0,
      "budget_used_percent": 0.653061330911232
    },
    {
      "type": "training",
      "description": "Training step 456",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:44",
      "total_flops_so_far": 654493482952704.0,
      "budget_used_percent": 0.6544934829527039
    },
    {
      "type": "training",
      "description": "Training step 457",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:44",
      "total_flops_so_far": 655925634994176.0,
      "budget_used_percent": 0.655925634994176
    },
    {
      "type": "training",
      "description": "Training step 458",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:44",
      "total_flops_so_far": 657357787035648.0,
      "budget_used_percent": 0.6573577870356481
    },
    {
      "type": "training",
      "description": "Training step 459",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:44",
      "total_flops_so_far": 658789939077120.0,
      "budget_used_percent": 0.6587899390771199
    },
    {
      "type": "training",
      "description": "Training step 460",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:44",
      "total_flops_so_far": 660222091118592.0,
      "budget_used_percent": 0.660222091118592
    },
    {
      "type": "training",
      "description": "Training step 461",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:44",
      "total_flops_so_far": 661654243160064.0,
      "budget_used_percent": 0.661654243160064
    },
    {
      "type": "training",
      "description": "Training step 462",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:44",
      "total_flops_so_far": 663086395201536.0,
      "budget_used_percent": 0.663086395201536
    },
    {
      "type": "training",
      "description": "Training step 463",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:45",
      "total_flops_so_far": 664518547243008.0,
      "budget_used_percent": 0.664518547243008
    },
    {
      "type": "training",
      "description": "Training step 464",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:45",
      "total_flops_so_far": 665950699284480.0,
      "budget_used_percent": 0.66595069928448
    },
    {
      "type": "training",
      "description": "Training step 465",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:45",
      "total_flops_so_far": 667382851325952.0,
      "budget_used_percent": 0.667382851325952
    },
    {
      "type": "training",
      "description": "Training step 466",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:45",
      "total_flops_so_far": 668815003367424.0,
      "budget_used_percent": 0.6688150033674239
    },
    {
      "type": "training",
      "description": "Training step 467",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:45",
      "total_flops_so_far": 670247155408896.0,
      "budget_used_percent": 0.670247155408896
    },
    {
      "type": "training",
      "description": "Training step 468",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:45",
      "total_flops_so_far": 671679307450368.0,
      "budget_used_percent": 0.671679307450368
    },
    {
      "type": "training",
      "description": "Training step 469",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:45",
      "total_flops_so_far": 673111459491840.0,
      "budget_used_percent": 0.67311145949184
    },
    {
      "type": "training",
      "description": "Training step 470",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:45",
      "total_flops_so_far": 674543611533312.0,
      "budget_used_percent": 0.674543611533312
    },
    {
      "type": "training",
      "description": "Training step 471",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:46",
      "total_flops_so_far": 675975763574784.0,
      "budget_used_percent": 0.675975763574784
    },
    {
      "type": "training",
      "description": "Training step 472",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:46",
      "total_flops_so_far": 677407915616256.0,
      "budget_used_percent": 0.677407915616256
    },
    {
      "type": "training",
      "description": "Training step 473",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:46",
      "total_flops_so_far": 678840067657728.0,
      "budget_used_percent": 0.678840067657728
    },
    {
      "type": "training",
      "description": "Training step 474",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:46",
      "total_flops_so_far": 680272219699200.0,
      "budget_used_percent": 0.6802722196991999
    },
    {
      "type": "training",
      "description": "Training step 475",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:46",
      "total_flops_so_far": 681704371740672.0,
      "budget_used_percent": 0.681704371740672
    },
    {
      "type": "training",
      "description": "Training step 476",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:46",
      "total_flops_so_far": 683136523782144.0,
      "budget_used_percent": 0.6831365237821441
    },
    {
      "type": "training",
      "description": "Training step 477",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:46",
      "total_flops_so_far": 684568675823616.0,
      "budget_used_percent": 0.684568675823616
    },
    {
      "type": "training",
      "description": "Training step 478",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:46",
      "total_flops_so_far": 686000827865088.0,
      "budget_used_percent": 0.686000827865088
    },
    {
      "type": "training",
      "description": "Training step 479",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:47",
      "total_flops_so_far": 687432979906560.0,
      "budget_used_percent": 0.68743297990656
    },
    {
      "type": "training",
      "description": "Training step 480",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:47",
      "total_flops_so_far": 688865131948032.0,
      "budget_used_percent": 0.688865131948032
    },
    {
      "type": "training",
      "description": "Training step 481",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:47",
      "total_flops_so_far": 690297283989504.0,
      "budget_used_percent": 0.690297283989504
    },
    {
      "type": "training",
      "description": "Training step 482",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:47",
      "total_flops_so_far": 691729436030976.0,
      "budget_used_percent": 0.691729436030976
    },
    {
      "type": "training",
      "description": "Training step 483",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:47",
      "total_flops_so_far": 693161588072448.0,
      "budget_used_percent": 0.693161588072448
    },
    {
      "type": "training",
      "description": "Training step 484",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:47",
      "total_flops_so_far": 694593740113920.0,
      "budget_used_percent": 0.69459374011392
    },
    {
      "type": "training",
      "description": "Training step 485",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:47",
      "total_flops_so_far": 696025892155392.0,
      "budget_used_percent": 0.696025892155392
    },
    {
      "type": "training",
      "description": "Training step 486",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:47",
      "total_flops_so_far": 697458044196864.0,
      "budget_used_percent": 0.697458044196864
    },
    {
      "type": "training",
      "description": "Training step 487",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:48",
      "total_flops_so_far": 698890196238336.0,
      "budget_used_percent": 0.698890196238336
    },
    {
      "type": "training",
      "description": "Training step 488",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:48",
      "total_flops_so_far": 700322348279808.0,
      "budget_used_percent": 0.700322348279808
    },
    {
      "type": "training",
      "description": "Training step 489",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:48",
      "total_flops_so_far": 701754500321280.0,
      "budget_used_percent": 0.70175450032128
    },
    {
      "type": "training",
      "description": "Training step 490",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:48",
      "total_flops_so_far": 703186652362752.0,
      "budget_used_percent": 0.703186652362752
    },
    {
      "type": "training",
      "description": "Training step 491",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:48",
      "total_flops_so_far": 704618804404224.0,
      "budget_used_percent": 0.704618804404224
    },
    {
      "type": "training",
      "description": "Training step 492",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:48",
      "total_flops_so_far": 706050956445696.0,
      "budget_used_percent": 0.706050956445696
    },
    {
      "type": "training",
      "description": "Training step 493",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:48",
      "total_flops_so_far": 707483108487168.0,
      "budget_used_percent": 0.707483108487168
    },
    {
      "type": "training",
      "description": "Training step 494",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:48",
      "total_flops_so_far": 708915260528640.0,
      "budget_used_percent": 0.70891526052864
    },
    {
      "type": "training",
      "description": "Training step 495",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:49",
      "total_flops_so_far": 710347412570112.0,
      "budget_used_percent": 0.710347412570112
    },
    {
      "type": "training",
      "description": "Training step 496",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:49",
      "total_flops_so_far": 711779564611584.0,
      "budget_used_percent": 0.711779564611584
    },
    {
      "type": "training",
      "description": "Training step 497",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:49",
      "total_flops_so_far": 713211716653056.0,
      "budget_used_percent": 0.7132117166530559
    },
    {
      "type": "training",
      "description": "Training step 498",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:49",
      "total_flops_so_far": 714643868694528.0,
      "budget_used_percent": 0.714643868694528
    },
    {
      "type": "training",
      "description": "Training step 499",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:26:49",
      "total_flops_so_far": 716076020736000.0,
      "budget_used_percent": 0.7160760207360001
    },
    {
      "type": "training",
      "description": "Training step 500",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:12",
      "total_flops_so_far": 717508172777472.0,
      "budget_used_percent": 0.7175081727774719
    },
    {
      "type": "training",
      "description": "Training step 501",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:12",
      "total_flops_so_far": 718940324818944.0,
      "budget_used_percent": 0.718940324818944
    },
    {
      "type": "training",
      "description": "Training step 502",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:12",
      "total_flops_so_far": 720372476860416.0,
      "budget_used_percent": 0.7203724768604161
    },
    {
      "type": "training",
      "description": "Training step 503",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:12",
      "total_flops_so_far": 721804628901888.0,
      "budget_used_percent": 0.721804628901888
    },
    {
      "type": "training",
      "description": "Training step 504",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:12",
      "total_flops_so_far": 723236780943360.0,
      "budget_used_percent": 0.72323678094336
    },
    {
      "type": "training",
      "description": "Training step 505",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:12",
      "total_flops_so_far": 724668932984832.0,
      "budget_used_percent": 0.724668932984832
    },
    {
      "type": "training",
      "description": "Training step 506",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:12",
      "total_flops_so_far": 726101085026304.0,
      "budget_used_percent": 0.726101085026304
    },
    {
      "type": "training",
      "description": "Training step 507",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:13",
      "total_flops_so_far": 727533237067776.0,
      "budget_used_percent": 0.727533237067776
    },
    {
      "type": "training",
      "description": "Training step 508",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:13",
      "total_flops_so_far": 728965389109248.0,
      "budget_used_percent": 0.728965389109248
    },
    {
      "type": "training",
      "description": "Training step 509",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:13",
      "total_flops_so_far": 730397541150720.0,
      "budget_used_percent": 0.73039754115072
    },
    {
      "type": "training",
      "description": "Training step 510",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:13",
      "total_flops_so_far": 731829693192192.0,
      "budget_used_percent": 0.731829693192192
    },
    {
      "type": "training",
      "description": "Training step 511",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:13",
      "total_flops_so_far": 733261845233664.0,
      "budget_used_percent": 0.733261845233664
    },
    {
      "type": "training",
      "description": "Training step 512",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:13",
      "total_flops_so_far": 734693997275136.0,
      "budget_used_percent": 0.734693997275136
    },
    {
      "type": "training",
      "description": "Training step 513",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:13",
      "total_flops_so_far": 736126149316608.0,
      "budget_used_percent": 0.736126149316608
    },
    {
      "type": "training",
      "description": "Training step 514",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:14",
      "total_flops_so_far": 737558301358080.0,
      "budget_used_percent": 0.73755830135808
    },
    {
      "type": "training",
      "description": "Training step 515",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:14",
      "total_flops_so_far": 738990453399552.0,
      "budget_used_percent": 0.7389904533995519
    },
    {
      "type": "training",
      "description": "Training step 516",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:14",
      "total_flops_so_far": 740422605441024.0,
      "budget_used_percent": 0.740422605441024
    },
    {
      "type": "training",
      "description": "Training step 517",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:14",
      "total_flops_so_far": 741854757482496.0,
      "budget_used_percent": 0.7418547574824961
    },
    {
      "type": "training",
      "description": "Training step 518",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:14",
      "total_flops_so_far": 743286909523968.0,
      "budget_used_percent": 0.743286909523968
    },
    {
      "type": "training",
      "description": "Training step 519",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:14",
      "total_flops_so_far": 744719061565440.0,
      "budget_used_percent": 0.74471906156544
    },
    {
      "type": "training",
      "description": "Training step 520",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:14",
      "total_flops_so_far": 746151213606912.0,
      "budget_used_percent": 0.7461512136069121
    },
    {
      "type": "training",
      "description": "Training step 521",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:14",
      "total_flops_so_far": 747583365648384.0,
      "budget_used_percent": 0.747583365648384
    },
    {
      "type": "training",
      "description": "Training step 522",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:15",
      "total_flops_so_far": 749015517689856.0,
      "budget_used_percent": 0.749015517689856
    },
    {
      "type": "training",
      "description": "Training step 523",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:15",
      "total_flops_so_far": 750447669731328.0,
      "budget_used_percent": 0.750447669731328
    },
    {
      "type": "training",
      "description": "Training step 524",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:15",
      "total_flops_so_far": 751879821772800.0,
      "budget_used_percent": 0.7518798217728
    },
    {
      "type": "training",
      "description": "Training step 525",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:15",
      "total_flops_so_far": 753311973814272.0,
      "budget_used_percent": 0.7533119738142721
    },
    {
      "type": "training",
      "description": "Training step 526",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:15",
      "total_flops_so_far": 754744125855744.0,
      "budget_used_percent": 0.7547441258557439
    },
    {
      "type": "training",
      "description": "Training step 527",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:15",
      "total_flops_so_far": 756176277897216.0,
      "budget_used_percent": 0.756176277897216
    },
    {
      "type": "training",
      "description": "Training step 528",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:15",
      "total_flops_so_far": 757608429938688.0,
      "budget_used_percent": 0.757608429938688
    },
    {
      "type": "training",
      "description": "Training step 529",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:15",
      "total_flops_so_far": 759040581980160.0,
      "budget_used_percent": 0.75904058198016
    },
    {
      "type": "training",
      "description": "Training step 530",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:16",
      "total_flops_so_far": 760472734021632.0,
      "budget_used_percent": 0.760472734021632
    },
    {
      "type": "training",
      "description": "Training step 531",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:16",
      "total_flops_so_far": 761904886063104.0,
      "budget_used_percent": 0.761904886063104
    },
    {
      "type": "training",
      "description": "Training step 532",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:16",
      "total_flops_so_far": 763337038104576.0,
      "budget_used_percent": 0.763337038104576
    },
    {
      "type": "training",
      "description": "Training step 533",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:16",
      "total_flops_so_far": 764769190146048.0,
      "budget_used_percent": 0.7647691901460479
    },
    {
      "type": "training",
      "description": "Training step 534",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:16",
      "total_flops_so_far": 766201342187520.0,
      "budget_used_percent": 0.76620134218752
    },
    {
      "type": "training",
      "description": "Training step 535",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:16",
      "total_flops_so_far": 767633494228992.0,
      "budget_used_percent": 0.767633494228992
    },
    {
      "type": "training",
      "description": "Training step 536",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:16",
      "total_flops_so_far": 769065646270464.0,
      "budget_used_percent": 0.769065646270464
    },
    {
      "type": "training",
      "description": "Training step 537",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:17",
      "total_flops_so_far": 770497798311936.0,
      "budget_used_percent": 0.770497798311936
    },
    {
      "type": "training",
      "description": "Training step 538",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:17",
      "total_flops_so_far": 771929950353408.0,
      "budget_used_percent": 0.771929950353408
    },
    {
      "type": "training",
      "description": "Training step 539",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:17",
      "total_flops_so_far": 773362102394880.0,
      "budget_used_percent": 0.77336210239488
    },
    {
      "type": "training",
      "description": "Training step 540",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:17",
      "total_flops_so_far": 774794254436352.0,
      "budget_used_percent": 0.774794254436352
    },
    {
      "type": "training",
      "description": "Training step 541",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:17",
      "total_flops_so_far": 776226406477824.0,
      "budget_used_percent": 0.7762264064778239
    },
    {
      "type": "training",
      "description": "Training step 542",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:17",
      "total_flops_so_far": 777658558519296.0,
      "budget_used_percent": 0.777658558519296
    },
    {
      "type": "training",
      "description": "Training step 543",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:17",
      "total_flops_so_far": 779090710560768.0,
      "budget_used_percent": 0.7790907105607681
    },
    {
      "type": "training",
      "description": "Training step 544",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:17",
      "total_flops_so_far": 780522862602240.0,
      "budget_used_percent": 0.78052286260224
    },
    {
      "type": "training",
      "description": "Training step 545",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:18",
      "total_flops_so_far": 781955014643712.0,
      "budget_used_percent": 0.7819550146437119
    },
    {
      "type": "training",
      "description": "Training step 546",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:18",
      "total_flops_so_far": 783387166685184.0,
      "budget_used_percent": 0.783387166685184
    },
    {
      "type": "training",
      "description": "Training step 547",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:18",
      "total_flops_so_far": 784819318726656.0,
      "budget_used_percent": 0.784819318726656
    },
    {
      "type": "training",
      "description": "Training step 548",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:18",
      "total_flops_so_far": 786251470768128.0,
      "budget_used_percent": 0.786251470768128
    },
    {
      "type": "training",
      "description": "Training step 549",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:18",
      "total_flops_so_far": 787683622809600.0,
      "budget_used_percent": 0.7876836228096
    },
    {
      "type": "training",
      "description": "Training step 550",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:18",
      "total_flops_so_far": 789115774851072.0,
      "budget_used_percent": 0.789115774851072
    },
    {
      "type": "training",
      "description": "Training step 551",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:18",
      "total_flops_so_far": 790547926892544.0,
      "budget_used_percent": 0.7905479268925439
    },
    {
      "type": "training",
      "description": "Training step 552",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:18",
      "total_flops_so_far": 791980078934016.0,
      "budget_used_percent": 0.791980078934016
    },
    {
      "type": "training",
      "description": "Training step 553",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:19",
      "total_flops_so_far": 793412230975488.0,
      "budget_used_percent": 0.793412230975488
    },
    {
      "type": "training",
      "description": "Training step 554",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:19",
      "total_flops_so_far": 794844383016960.0,
      "budget_used_percent": 0.7948443830169599
    },
    {
      "type": "training",
      "description": "Training step 555",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:19",
      "total_flops_so_far": 796276535058432.0,
      "budget_used_percent": 0.796276535058432
    },
    {
      "type": "training",
      "description": "Training step 556",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:19",
      "total_flops_so_far": 797708687099904.0,
      "budget_used_percent": 0.797708687099904
    },
    {
      "type": "training",
      "description": "Training step 557",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:19",
      "total_flops_so_far": 799140839141376.0,
      "budget_used_percent": 0.7991408391413759
    },
    {
      "type": "training",
      "description": "Training step 558",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:19",
      "total_flops_so_far": 800572991182848.0,
      "budget_used_percent": 0.8005729911828481
    },
    {
      "type": "training",
      "description": "Training step 559",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:19",
      "total_flops_so_far": 802005143224320.0,
      "budget_used_percent": 0.80200514322432
    },
    {
      "type": "training",
      "description": "Training step 560",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:20",
      "total_flops_so_far": 803437295265792.0,
      "budget_used_percent": 0.8034372952657919
    },
    {
      "type": "training",
      "description": "Training step 561",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:20",
      "total_flops_so_far": 804869447307264.0,
      "budget_used_percent": 0.8048694473072641
    },
    {
      "type": "training",
      "description": "Training step 562",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:20",
      "total_flops_so_far": 806301599348736.0,
      "budget_used_percent": 0.806301599348736
    },
    {
      "type": "training",
      "description": "Training step 563",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:20",
      "total_flops_so_far": 807733751390208.0,
      "budget_used_percent": 0.807733751390208
    },
    {
      "type": "training",
      "description": "Training step 564",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:20",
      "total_flops_so_far": 809165903431680.0,
      "budget_used_percent": 0.80916590343168
    },
    {
      "type": "training",
      "description": "Training step 565",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:20",
      "total_flops_so_far": 810598055473152.0,
      "budget_used_percent": 0.810598055473152
    },
    {
      "type": "training",
      "description": "Training step 566",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:20",
      "total_flops_so_far": 812030207514624.0,
      "budget_used_percent": 0.812030207514624
    },
    {
      "type": "training",
      "description": "Training step 567",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:20",
      "total_flops_so_far": 813462359556096.0,
      "budget_used_percent": 0.813462359556096
    },
    {
      "type": "training",
      "description": "Training step 568",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:21",
      "total_flops_so_far": 814894511597568.0,
      "budget_used_percent": 0.814894511597568
    },
    {
      "type": "training",
      "description": "Training step 569",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:21",
      "total_flops_so_far": 816326663639040.0,
      "budget_used_percent": 0.8163266636390399
    },
    {
      "type": "training",
      "description": "Training step 570",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:21",
      "total_flops_so_far": 817758815680512.0,
      "budget_used_percent": 0.817758815680512
    },
    {
      "type": "training",
      "description": "Training step 571",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:21",
      "total_flops_so_far": 819190967721984.0,
      "budget_used_percent": 0.819190967721984
    },
    {
      "type": "training",
      "description": "Training step 572",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:21",
      "total_flops_so_far": 820623119763456.0,
      "budget_used_percent": 0.8206231197634559
    },
    {
      "type": "training",
      "description": "Training step 573",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:21",
      "total_flops_so_far": 822055271804928.0,
      "budget_used_percent": 0.8220552718049281
    },
    {
      "type": "training",
      "description": "Training step 574",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:21",
      "total_flops_so_far": 823487423846400.0,
      "budget_used_percent": 0.8234874238464
    },
    {
      "type": "training",
      "description": "Training step 575",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:21",
      "total_flops_so_far": 824919575887872.0,
      "budget_used_percent": 0.8249195758878719
    },
    {
      "type": "training",
      "description": "Training step 576",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:22",
      "total_flops_so_far": 826351727929344.0,
      "budget_used_percent": 0.8263517279293441
    },
    {
      "type": "training",
      "description": "Training step 577",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:22",
      "total_flops_so_far": 827783879970816.0,
      "budget_used_percent": 0.827783879970816
    },
    {
      "type": "training",
      "description": "Training step 578",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:22",
      "total_flops_so_far": 829216032012288.0,
      "budget_used_percent": 0.8292160320122879
    },
    {
      "type": "training",
      "description": "Training step 579",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:22",
      "total_flops_so_far": 830648184053760.0,
      "budget_used_percent": 0.8306481840537601
    },
    {
      "type": "training",
      "description": "Training step 580",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:22",
      "total_flops_so_far": 832080336095232.0,
      "budget_used_percent": 0.832080336095232
    },
    {
      "type": "training",
      "description": "Training step 581",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:22",
      "total_flops_so_far": 833512488136704.0,
      "budget_used_percent": 0.833512488136704
    },
    {
      "type": "training",
      "description": "Training step 582",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:22",
      "total_flops_so_far": 834944640178176.0,
      "budget_used_percent": 0.834944640178176
    },
    {
      "type": "training",
      "description": "Training step 583",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:23",
      "total_flops_so_far": 836376792219648.0,
      "budget_used_percent": 0.836376792219648
    },
    {
      "type": "training",
      "description": "Training step 584",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:23",
      "total_flops_so_far": 837808944261120.0,
      "budget_used_percent": 0.83780894426112
    },
    {
      "type": "training",
      "description": "Training step 585",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:23",
      "total_flops_so_far": 839241096302592.0,
      "budget_used_percent": 0.839241096302592
    },
    {
      "type": "training",
      "description": "Training step 586",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:23",
      "total_flops_so_far": 840673248344064.0,
      "budget_used_percent": 0.840673248344064
    },
    {
      "type": "training",
      "description": "Training step 587",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:23",
      "total_flops_so_far": 842105400385536.0,
      "budget_used_percent": 0.8421054003855359
    },
    {
      "type": "training",
      "description": "Training step 588",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:23",
      "total_flops_so_far": 843537552427008.0,
      "budget_used_percent": 0.8435375524270081
    },
    {
      "type": "training",
      "description": "Training step 589",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:23",
      "total_flops_so_far": 844969704468480.0,
      "budget_used_percent": 0.84496970446848
    },
    {
      "type": "training",
      "description": "Training step 590",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:23",
      "total_flops_so_far": 846401856509952.0,
      "budget_used_percent": 0.8464018565099519
    },
    {
      "type": "training",
      "description": "Training step 591",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:24",
      "total_flops_so_far": 847834008551424.0,
      "budget_used_percent": 0.8478340085514241
    },
    {
      "type": "training",
      "description": "Training step 592",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:24",
      "total_flops_so_far": 849266160592896.0,
      "budget_used_percent": 0.8492661605928961
    },
    {
      "type": "training",
      "description": "Training step 593",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:24",
      "total_flops_so_far": 850698312634368.0,
      "budget_used_percent": 0.8506983126343679
    },
    {
      "type": "training",
      "description": "Training step 594",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:24",
      "total_flops_so_far": 852130464675840.0,
      "budget_used_percent": 0.8521304646758401
    },
    {
      "type": "training",
      "description": "Training step 595",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:24",
      "total_flops_so_far": 853562616717312.0,
      "budget_used_percent": 0.853562616717312
    },
    {
      "type": "training",
      "description": "Training step 596",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:24",
      "total_flops_so_far": 854994768758784.0,
      "budget_used_percent": 0.854994768758784
    },
    {
      "type": "training",
      "description": "Training step 597",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:24",
      "total_flops_so_far": 856426920800256.0,
      "budget_used_percent": 0.8564269208002561
    },
    {
      "type": "training",
      "description": "Training step 598",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:24",
      "total_flops_so_far": 857859072841728.0,
      "budget_used_percent": 0.857859072841728
    },
    {
      "type": "training",
      "description": "Training step 599",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:25",
      "total_flops_so_far": 859291224883200.0,
      "budget_used_percent": 0.8592912248832
    },
    {
      "type": "training",
      "description": "Training step 600",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:25",
      "total_flops_so_far": 860723376924672.0,
      "budget_used_percent": 0.860723376924672
    },
    {
      "type": "training",
      "description": "Training step 601",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:25",
      "total_flops_so_far": 862155528966144.0,
      "budget_used_percent": 0.862155528966144
    },
    {
      "type": "training",
      "description": "Training step 602",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:25",
      "total_flops_so_far": 863587681007616.0,
      "budget_used_percent": 0.863587681007616
    },
    {
      "type": "training",
      "description": "Training step 603",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:25",
      "total_flops_so_far": 865019833049088.0,
      "budget_used_percent": 0.865019833049088
    },
    {
      "type": "training",
      "description": "Training step 604",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:25",
      "total_flops_so_far": 866451985090560.0,
      "budget_used_percent": 0.86645198509056
    },
    {
      "type": "training",
      "description": "Training step 605",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:25",
      "total_flops_so_far": 867884137132032.0,
      "budget_used_percent": 0.8678841371320319
    },
    {
      "type": "training",
      "description": "Training step 606",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:26",
      "total_flops_so_far": 869316289173504.0,
      "budget_used_percent": 0.8693162891735041
    },
    {
      "type": "training",
      "description": "Training step 607",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:26",
      "total_flops_so_far": 870748441214976.0,
      "budget_used_percent": 0.870748441214976
    },
    {
      "type": "training",
      "description": "Training step 608",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:26",
      "total_flops_so_far": 872180593256448.0,
      "budget_used_percent": 0.8721805932564479
    },
    {
      "type": "training",
      "description": "Training step 609",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:26",
      "total_flops_so_far": 873612745297920.0,
      "budget_used_percent": 0.8736127452979201
    },
    {
      "type": "training",
      "description": "Training step 610",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:26",
      "total_flops_so_far": 875044897339392.0,
      "budget_used_percent": 0.8750448973393921
    },
    {
      "type": "training",
      "description": "Training step 611",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:26",
      "total_flops_so_far": 876477049380864.0,
      "budget_used_percent": 0.876477049380864
    },
    {
      "type": "training",
      "description": "Training step 612",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:26",
      "total_flops_so_far": 877909201422336.0,
      "budget_used_percent": 0.8779092014223361
    },
    {
      "type": "training",
      "description": "Training step 613",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:26",
      "total_flops_so_far": 879341353463808.0,
      "budget_used_percent": 0.879341353463808
    },
    {
      "type": "training",
      "description": "Training step 614",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:27",
      "total_flops_so_far": 880773505505280.0,
      "budget_used_percent": 0.88077350550528
    },
    {
      "type": "training",
      "description": "Training step 615",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:27",
      "total_flops_so_far": 882205657546752.0,
      "budget_used_percent": 0.8822056575467521
    },
    {
      "type": "training",
      "description": "Training step 616",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:27",
      "total_flops_so_far": 883637809588224.0,
      "budget_used_percent": 0.883637809588224
    },
    {
      "type": "training",
      "description": "Training step 617",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:27",
      "total_flops_so_far": 885069961629696.0,
      "budget_used_percent": 0.885069961629696
    },
    {
      "type": "training",
      "description": "Training step 618",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:27",
      "total_flops_so_far": 886502113671168.0,
      "budget_used_percent": 0.8865021136711679
    },
    {
      "type": "training",
      "description": "Training step 619",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:27",
      "total_flops_so_far": 887934265712640.0,
      "budget_used_percent": 0.88793426571264
    },
    {
      "type": "training",
      "description": "Training step 620",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:27",
      "total_flops_so_far": 889366417754112.0,
      "budget_used_percent": 0.889366417754112
    },
    {
      "type": "training",
      "description": "Training step 621",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:28",
      "total_flops_so_far": 890798569795584.0,
      "budget_used_percent": 0.8907985697955839
    },
    {
      "type": "training",
      "description": "Training step 622",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:28",
      "total_flops_so_far": 892230721837056.0,
      "budget_used_percent": 0.892230721837056
    },
    {
      "type": "training",
      "description": "Training step 623",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:28",
      "total_flops_so_far": 893662873878528.0,
      "budget_used_percent": 0.8936628738785279
    },
    {
      "type": "training",
      "description": "Training step 624",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:28",
      "total_flops_so_far": 895095025920000.0,
      "budget_used_percent": 0.8950950259199999
    },
    {
      "type": "training",
      "description": "Training step 625",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:28",
      "total_flops_so_far": 896527177961472.0,
      "budget_used_percent": 0.8965271779614721
    },
    {
      "type": "training",
      "description": "Training step 626",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:28",
      "total_flops_so_far": 897959330002944.0,
      "budget_used_percent": 0.897959330002944
    },
    {
      "type": "training",
      "description": "Training step 627",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:28",
      "total_flops_so_far": 899391482044416.0,
      "budget_used_percent": 0.8993914820444159
    },
    {
      "type": "training",
      "description": "Training step 628",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:28",
      "total_flops_so_far": 900823634085888.0,
      "budget_used_percent": 0.9008236340858881
    },
    {
      "type": "training",
      "description": "Training step 629",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:29",
      "total_flops_so_far": 902255786127360.0,
      "budget_used_percent": 0.90225578612736
    },
    {
      "type": "training",
      "description": "Training step 630",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:29",
      "total_flops_so_far": 903687938168832.0,
      "budget_used_percent": 0.903687938168832
    },
    {
      "type": "training",
      "description": "Training step 631",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:29",
      "total_flops_so_far": 905120090210304.0,
      "budget_used_percent": 0.905120090210304
    },
    {
      "type": "training",
      "description": "Training step 632",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:29",
      "total_flops_so_far": 906552242251776.0,
      "budget_used_percent": 0.906552242251776
    },
    {
      "type": "training",
      "description": "Training step 633",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:29",
      "total_flops_so_far": 907984394293248.0,
      "budget_used_percent": 0.907984394293248
    },
    {
      "type": "training",
      "description": "Training step 634",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:29",
      "total_flops_so_far": 909416546334720.0,
      "budget_used_percent": 0.90941654633472
    },
    {
      "type": "training",
      "description": "Training step 635",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:29",
      "total_flops_so_far": 910848698376192.0,
      "budget_used_percent": 0.910848698376192
    },
    {
      "type": "training",
      "description": "Training step 636",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:30",
      "total_flops_so_far": 912280850417664.0,
      "budget_used_percent": 0.9122808504176639
    },
    {
      "type": "training",
      "description": "Training step 637",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:30",
      "total_flops_so_far": 913713002459136.0,
      "budget_used_percent": 0.913713002459136
    },
    {
      "type": "training",
      "description": "Training step 638",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:30",
      "total_flops_so_far": 915145154500608.0,
      "budget_used_percent": 0.915145154500608
    },
    {
      "type": "training",
      "description": "Training step 639",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:30",
      "total_flops_so_far": 916577306542080.0,
      "budget_used_percent": 0.9165773065420799
    },
    {
      "type": "training",
      "description": "Training step 640",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:30",
      "total_flops_so_far": 918009458583552.0,
      "budget_used_percent": 0.9180094585835521
    },
    {
      "type": "training",
      "description": "Training step 641",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:30",
      "total_flops_so_far": 919441610625024.0,
      "budget_used_percent": 0.9194416106250239
    },
    {
      "type": "training",
      "description": "Training step 642",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:30",
      "total_flops_so_far": 920873762666496.0,
      "budget_used_percent": 0.9208737626664959
    },
    {
      "type": "training",
      "description": "Training step 643",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:30",
      "total_flops_so_far": 922305914707968.0,
      "budget_used_percent": 0.9223059147079681
    },
    {
      "type": "training",
      "description": "Training step 644",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:31",
      "total_flops_so_far": 923738066749440.0,
      "budget_used_percent": 0.92373806674944
    },
    {
      "type": "training",
      "description": "Training step 645",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:31",
      "total_flops_so_far": 925170218790912.0,
      "budget_used_percent": 0.9251702187909119
    },
    {
      "type": "training",
      "description": "Training step 646",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:31",
      "total_flops_so_far": 926602370832384.0,
      "budget_used_percent": 0.9266023708323841
    },
    {
      "type": "training",
      "description": "Training step 647",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:31",
      "total_flops_so_far": 928034522873856.0,
      "budget_used_percent": 0.928034522873856
    },
    {
      "type": "training",
      "description": "Training step 648",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:31",
      "total_flops_so_far": 929466674915328.0,
      "budget_used_percent": 0.929466674915328
    },
    {
      "type": "training",
      "description": "Training step 649",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:31",
      "total_flops_so_far": 930898826956800.0,
      "budget_used_percent": 0.9308988269568
    },
    {
      "type": "training",
      "description": "Training step 650",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:31",
      "total_flops_so_far": 932330978998272.0,
      "budget_used_percent": 0.932330978998272
    },
    {
      "type": "training",
      "description": "Training step 651",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:32",
      "total_flops_so_far": 933763131039744.0,
      "budget_used_percent": 0.933763131039744
    },
    {
      "type": "training",
      "description": "Training step 652",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:32",
      "total_flops_so_far": 935195283081216.0,
      "budget_used_percent": 0.935195283081216
    },
    {
      "type": "training",
      "description": "Training step 653",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:32",
      "total_flops_so_far": 936627435122688.0,
      "budget_used_percent": 0.936627435122688
    },
    {
      "type": "training",
      "description": "Training step 654",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:32",
      "total_flops_so_far": 938059587164160.0,
      "budget_used_percent": 0.9380595871641599
    },
    {
      "type": "training",
      "description": "Training step 655",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:32",
      "total_flops_so_far": 939491739205632.0,
      "budget_used_percent": 0.9394917392056321
    },
    {
      "type": "training",
      "description": "Training step 656",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:32",
      "total_flops_so_far": 940923891247104.0,
      "budget_used_percent": 0.940923891247104
    },
    {
      "type": "training",
      "description": "Training step 657",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:32",
      "total_flops_so_far": 942356043288576.0,
      "budget_used_percent": 0.9423560432885759
    },
    {
      "type": "training",
      "description": "Training step 658",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:32",
      "total_flops_so_far": 943788195330048.0,
      "budget_used_percent": 0.9437881953300481
    },
    {
      "type": "training",
      "description": "Training step 659",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:33",
      "total_flops_so_far": 945220347371520.0,
      "budget_used_percent": 0.94522034737152
    },
    {
      "type": "training",
      "description": "Training step 660",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:33",
      "total_flops_so_far": 946652499412992.0,
      "budget_used_percent": 0.9466524994129919
    },
    {
      "type": "training",
      "description": "Training step 661",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:33",
      "total_flops_so_far": 948084651454464.0,
      "budget_used_percent": 0.9480846514544641
    },
    {
      "type": "training",
      "description": "Training step 662",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:33",
      "total_flops_so_far": 949516803495936.0,
      "budget_used_percent": 0.949516803495936
    },
    {
      "type": "training",
      "description": "Training step 663",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:33",
      "total_flops_so_far": 950948955537408.0,
      "budget_used_percent": 0.950948955537408
    },
    {
      "type": "training",
      "description": "Training step 664",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:33",
      "total_flops_so_far": 952381107578880.0,
      "budget_used_percent": 0.9523811075788801
    },
    {
      "type": "training",
      "description": "Training step 665",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:33",
      "total_flops_so_far": 953813259620352.0,
      "budget_used_percent": 0.953813259620352
    },
    {
      "type": "training",
      "description": "Training step 666",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:33",
      "total_flops_so_far": 955245411661824.0,
      "budget_used_percent": 0.955245411661824
    },
    {
      "type": "training",
      "description": "Training step 667",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:34",
      "total_flops_so_far": 956677563703296.0,
      "budget_used_percent": 0.956677563703296
    },
    {
      "type": "training",
      "description": "Training step 668",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:34",
      "total_flops_so_far": 958109715744768.0,
      "budget_used_percent": 0.958109715744768
    },
    {
      "type": "training",
      "description": "Training step 669",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:34",
      "total_flops_so_far": 959541867786240.0,
      "budget_used_percent": 0.95954186778624
    },
    {
      "type": "training",
      "description": "Training step 670",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:34",
      "total_flops_so_far": 960974019827712.0,
      "budget_used_percent": 0.960974019827712
    },
    {
      "type": "training",
      "description": "Training step 671",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:34",
      "total_flops_so_far": 962406171869184.0,
      "budget_used_percent": 0.962406171869184
    },
    {
      "type": "training",
      "description": "Training step 672",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:34",
      "total_flops_so_far": 963838323910656.0,
      "budget_used_percent": 0.9638383239106559
    },
    {
      "type": "training",
      "description": "Training step 673",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:34",
      "total_flops_so_far": 965270475952128.0,
      "budget_used_percent": 0.9652704759521281
    },
    {
      "type": "training",
      "description": "Training step 674",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:35",
      "total_flops_so_far": 966702627993600.0,
      "budget_used_percent": 0.9667026279936
    },
    {
      "type": "training",
      "description": "Training step 675",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:35",
      "total_flops_so_far": 968134780035072.0,
      "budget_used_percent": 0.9681347800350719
    },
    {
      "type": "training",
      "description": "Training step 676",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:35",
      "total_flops_so_far": 969566932076544.0,
      "budget_used_percent": 0.9695669320765441
    },
    {
      "type": "training",
      "description": "Training step 677",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:35",
      "total_flops_so_far": 970999084118016.0,
      "budget_used_percent": 0.970999084118016
    },
    {
      "type": "training",
      "description": "Training step 678",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:35",
      "total_flops_so_far": 972431236159488.0,
      "budget_used_percent": 0.972431236159488
    },
    {
      "type": "training",
      "description": "Training step 679",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:35",
      "total_flops_so_far": 973863388200960.0,
      "budget_used_percent": 0.9738633882009601
    },
    {
      "type": "training",
      "description": "Training step 680",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:35",
      "total_flops_so_far": 975295540242432.0,
      "budget_used_percent": 0.975295540242432
    },
    {
      "type": "training",
      "description": "Training step 681",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:35",
      "total_flops_so_far": 976727692283904.0,
      "budget_used_percent": 0.976727692283904
    },
    {
      "type": "training",
      "description": "Training step 682",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:36",
      "total_flops_so_far": 978159844325376.0,
      "budget_used_percent": 0.9781598443253761
    },
    {
      "type": "training",
      "description": "Training step 683",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:36",
      "total_flops_so_far": 979591996366848.0,
      "budget_used_percent": 0.979591996366848
    },
    {
      "type": "training",
      "description": "Training step 684",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:36",
      "total_flops_so_far": 981024148408320.0,
      "budget_used_percent": 0.98102414840832
    },
    {
      "type": "training",
      "description": "Training step 685",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:36",
      "total_flops_so_far": 982456300449792.0,
      "budget_used_percent": 0.982456300449792
    },
    {
      "type": "training",
      "description": "Training step 686",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:36",
      "total_flops_so_far": 983888452491264.0,
      "budget_used_percent": 0.983888452491264
    },
    {
      "type": "training",
      "description": "Training step 687",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:36",
      "total_flops_so_far": 985320604532736.0,
      "budget_used_percent": 0.985320604532736
    },
    {
      "type": "training",
      "description": "Training step 688",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:36",
      "total_flops_so_far": 986752756574208.0,
      "budget_used_percent": 0.9867527565742081
    },
    {
      "type": "training",
      "description": "Training step 689",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:37",
      "total_flops_so_far": 988184908615680.0,
      "budget_used_percent": 0.98818490861568
    },
    {
      "type": "training",
      "description": "Training step 690",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:37",
      "total_flops_so_far": 989617060657152.0,
      "budget_used_percent": 0.9896170606571519
    },
    {
      "type": "training",
      "description": "Training step 691",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:37",
      "total_flops_so_far": 991049212698624.0,
      "budget_used_percent": 0.9910492126986239
    },
    {
      "type": "training",
      "description": "Training step 692",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:37",
      "total_flops_so_far": 992481364740096.0,
      "budget_used_percent": 0.9924813647400961
    },
    {
      "type": "training",
      "description": "Training step 693",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:37",
      "total_flops_so_far": 993913516781568.0,
      "budget_used_percent": 0.993913516781568
    },
    {
      "type": "training",
      "description": "Training step 694",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:37",
      "total_flops_so_far": 995345668823040.0,
      "budget_used_percent": 0.9953456688230399
    },
    {
      "type": "training",
      "description": "Training step 695",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:37",
      "total_flops_so_far": 996777820864512.0,
      "budget_used_percent": 0.996777820864512
    },
    {
      "type": "training",
      "description": "Training step 696",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:37",
      "total_flops_so_far": 998209972905984.0,
      "budget_used_percent": 0.998209972905984
    },
    {
      "type": "training",
      "description": "Training step 697",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:38",
      "total_flops_so_far": 999642124947456.0,
      "budget_used_percent": 0.999642124947456
    },
    {
      "type": "training",
      "description": "Training step 698",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:38",
      "total_flops_so_far": 1001074276988928.0,
      "budget_used_percent": 1.001074276988928
    },
    {
      "type": "training",
      "description": "Training step 699",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:38",
      "total_flops_so_far": 1002506429030400.0,
      "budget_used_percent": 1.0025064290304
    },
    {
      "type": "training",
      "description": "Training step 700",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:38",
      "total_flops_so_far": 1003938581071872.0,
      "budget_used_percent": 1.003938581071872
    },
    {
      "type": "training",
      "description": "Training step 701",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:38",
      "total_flops_so_far": 1005370733113344.0,
      "budget_used_percent": 1.0053707331133441
    },
    {
      "type": "training",
      "description": "Training step 702",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:38",
      "total_flops_so_far": 1006802885154816.0,
      "budget_used_percent": 1.006802885154816
    },
    {
      "type": "training",
      "description": "Training step 703",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:38",
      "total_flops_so_far": 1008235037196288.0,
      "budget_used_percent": 1.0082350371962878
    },
    {
      "type": "training",
      "description": "Training step 704",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:39",
      "total_flops_so_far": 1009667189237760.0,
      "budget_used_percent": 1.00966718923776
    },
    {
      "type": "training",
      "description": "Training step 705",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:39",
      "total_flops_so_far": 1011099341279232.0,
      "budget_used_percent": 1.011099341279232
    },
    {
      "type": "training",
      "description": "Training step 706",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:39",
      "total_flops_so_far": 1012531493320704.0,
      "budget_used_percent": 1.012531493320704
    },
    {
      "type": "training",
      "description": "Training step 707",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:39",
      "total_flops_so_far": 1013963645362176.0,
      "budget_used_percent": 1.013963645362176
    },
    {
      "type": "training",
      "description": "Training step 708",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:39",
      "total_flops_so_far": 1015395797403648.0,
      "budget_used_percent": 1.015395797403648
    },
    {
      "type": "training",
      "description": "Training step 709",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:39",
      "total_flops_so_far": 1016827949445120.0,
      "budget_used_percent": 1.01682794944512
    },
    {
      "type": "training",
      "description": "Training step 710",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:39",
      "total_flops_so_far": 1018260101486592.0,
      "budget_used_percent": 1.018260101486592
    },
    {
      "type": "training",
      "description": "Training step 711",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:39",
      "total_flops_so_far": 1019692253528064.0,
      "budget_used_percent": 1.019692253528064
    },
    {
      "type": "training",
      "description": "Training step 712",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:40",
      "total_flops_so_far": 1021124405569536.0,
      "budget_used_percent": 1.0211244055695359
    },
    {
      "type": "training",
      "description": "Training step 713",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:40",
      "total_flops_so_far": 1022556557611008.0,
      "budget_used_percent": 1.022556557611008
    },
    {
      "type": "training",
      "description": "Training step 714",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:40",
      "total_flops_so_far": 1023988709652480.0,
      "budget_used_percent": 1.02398870965248
    },
    {
      "type": "training",
      "description": "Training step 715",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:40",
      "total_flops_so_far": 1025420861693952.0,
      "budget_used_percent": 1.025420861693952
    },
    {
      "type": "training",
      "description": "Training step 716",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:40",
      "total_flops_so_far": 1026853013735424.0,
      "budget_used_percent": 1.0268530137354241
    },
    {
      "type": "training",
      "description": "Training step 717",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:40",
      "total_flops_so_far": 1028285165776896.0,
      "budget_used_percent": 1.028285165776896
    },
    {
      "type": "training",
      "description": "Training step 718",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:40",
      "total_flops_so_far": 1029717317818368.0,
      "budget_used_percent": 1.0297173178183678
    },
    {
      "type": "training",
      "description": "Training step 719",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:41",
      "total_flops_so_far": 1031149469859840.0,
      "budget_used_percent": 1.03114946985984
    },
    {
      "type": "training",
      "description": "Training step 720",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:41",
      "total_flops_so_far": 1032581621901312.0,
      "budget_used_percent": 1.032581621901312
    },
    {
      "type": "training",
      "description": "Training step 721",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:41",
      "total_flops_so_far": 1034013773942784.0,
      "budget_used_percent": 1.034013773942784
    },
    {
      "type": "training",
      "description": "Training step 722",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:41",
      "total_flops_so_far": 1035445925984256.0,
      "budget_used_percent": 1.035445925984256
    },
    {
      "type": "training",
      "description": "Training step 723",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:41",
      "total_flops_so_far": 1036878078025728.0,
      "budget_used_percent": 1.036878078025728
    },
    {
      "type": "training",
      "description": "Training step 724",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:41",
      "total_flops_so_far": 1038310230067200.0,
      "budget_used_percent": 1.0383102300672
    },
    {
      "type": "training",
      "description": "Training step 725",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:41",
      "total_flops_so_far": 1039742382108672.0,
      "budget_used_percent": 1.039742382108672
    },
    {
      "type": "training",
      "description": "Training step 726",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:42",
      "total_flops_so_far": 1041174534150144.0,
      "budget_used_percent": 1.041174534150144
    },
    {
      "type": "training",
      "description": "Training step 727",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:42",
      "total_flops_so_far": 1042606686191616.0,
      "budget_used_percent": 1.042606686191616
    },
    {
      "type": "training",
      "description": "Training step 728",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:42",
      "total_flops_so_far": 1044038838233088.0,
      "budget_used_percent": 1.044038838233088
    },
    {
      "type": "training",
      "description": "Training step 729",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:42",
      "total_flops_so_far": 1045470990274560.0,
      "budget_used_percent": 1.04547099027456
    },
    {
      "type": "training",
      "description": "Training step 730",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:42",
      "total_flops_so_far": 1046903142316032.0,
      "budget_used_percent": 1.046903142316032
    },
    {
      "type": "training",
      "description": "Training step 731",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:42",
      "total_flops_so_far": 1048335294357504.0,
      "budget_used_percent": 1.0483352943575042
    },
    {
      "type": "training",
      "description": "Training step 732",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:42",
      "total_flops_so_far": 1049767446398976.0,
      "budget_used_percent": 1.049767446398976
    },
    {
      "type": "training",
      "description": "Training step 733",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:42",
      "total_flops_so_far": 1051199598440448.0,
      "budget_used_percent": 1.0511995984404479
    },
    {
      "type": "training",
      "description": "Training step 734",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:43",
      "total_flops_so_far": 1052631750481920.0,
      "budget_used_percent": 1.05263175048192
    },
    {
      "type": "training",
      "description": "Training step 735",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:43",
      "total_flops_so_far": 1054063902523392.0,
      "budget_used_percent": 1.054063902523392
    },
    {
      "type": "training",
      "description": "Training step 736",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:43",
      "total_flops_so_far": 1055496054564864.0,
      "budget_used_percent": 1.055496054564864
    },
    {
      "type": "training",
      "description": "Training step 737",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:43",
      "total_flops_so_far": 1056928206606336.0,
      "budget_used_percent": 1.0569282066063361
    },
    {
      "type": "training",
      "description": "Training step 738",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:43",
      "total_flops_so_far": 1058360358647808.0,
      "budget_used_percent": 1.058360358647808
    },
    {
      "type": "training",
      "description": "Training step 739",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:43",
      "total_flops_so_far": 1059792510689280.0,
      "budget_used_percent": 1.05979251068928
    },
    {
      "type": "training",
      "description": "Training step 740",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:43",
      "total_flops_so_far": 1061224662730752.0,
      "budget_used_percent": 1.061224662730752
    },
    {
      "type": "training",
      "description": "Training step 741",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:44",
      "total_flops_so_far": 1062656814772224.0,
      "budget_used_percent": 1.062656814772224
    },
    {
      "type": "training",
      "description": "Training step 742",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:44",
      "total_flops_so_far": 1064088966813696.0,
      "budget_used_percent": 1.064088966813696
    },
    {
      "type": "training",
      "description": "Training step 743",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:44",
      "total_flops_so_far": 1065521118855168.0,
      "budget_used_percent": 1.065521118855168
    },
    {
      "type": "training",
      "description": "Training step 744",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:44",
      "total_flops_so_far": 1066953270896640.0,
      "budget_used_percent": 1.06695327089664
    },
    {
      "type": "training",
      "description": "Training step 745",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:44",
      "total_flops_so_far": 1068385422938112.0,
      "budget_used_percent": 1.068385422938112
    },
    {
      "type": "training",
      "description": "Training step 746",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:44",
      "total_flops_so_far": 1069817574979584.0,
      "budget_used_percent": 1.069817574979584
    },
    {
      "type": "training",
      "description": "Training step 747",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:44",
      "total_flops_so_far": 1071249727021056.0,
      "budget_used_percent": 1.071249727021056
    },
    {
      "type": "training",
      "description": "Training step 748",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:44",
      "total_flops_so_far": 1072681879062528.0,
      "budget_used_percent": 1.0726818790625279
    },
    {
      "type": "training",
      "description": "Training step 749",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:45",
      "total_flops_so_far": 1074114031104000.0,
      "budget_used_percent": 1.074114031104
    },
    {
      "type": "training",
      "description": "Training step 750",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:45",
      "total_flops_so_far": 1075546183145472.0,
      "budget_used_percent": 1.075546183145472
    },
    {
      "type": "training",
      "description": "Training step 751",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:45",
      "total_flops_so_far": 1076978335186944.0,
      "budget_used_percent": 1.076978335186944
    },
    {
      "type": "training",
      "description": "Training step 752",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:45",
      "total_flops_so_far": 1078410487228416.0,
      "budget_used_percent": 1.0784104872284161
    },
    {
      "type": "training",
      "description": "Training step 753",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:45",
      "total_flops_so_far": 1079842639269888.0,
      "budget_used_percent": 1.079842639269888
    },
    {
      "type": "training",
      "description": "Training step 754",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:45",
      "total_flops_so_far": 1081274791311360.0,
      "budget_used_percent": 1.08127479131136
    },
    {
      "type": "training",
      "description": "Training step 755",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:45",
      "total_flops_so_far": 1082706943352832.0,
      "budget_used_percent": 1.082706943352832
    },
    {
      "type": "training",
      "description": "Training step 756",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:46",
      "total_flops_so_far": 1084139095394304.0,
      "budget_used_percent": 1.084139095394304
    },
    {
      "type": "training",
      "description": "Training step 757",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:46",
      "total_flops_so_far": 1085571247435776.0,
      "budget_used_percent": 1.085571247435776
    },
    {
      "type": "training",
      "description": "Training step 758",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:46",
      "total_flops_so_far": 1087003399477248.0,
      "budget_used_percent": 1.0870033994772481
    },
    {
      "type": "training",
      "description": "Training step 759",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:46",
      "total_flops_so_far": 1088435551518720.0,
      "budget_used_percent": 1.08843555151872
    },
    {
      "type": "training",
      "description": "Training step 760",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:46",
      "total_flops_so_far": 1089867703560192.0,
      "budget_used_percent": 1.089867703560192
    },
    {
      "type": "training",
      "description": "Training step 761",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:46",
      "total_flops_so_far": 1091299855601664.0,
      "budget_used_percent": 1.091299855601664
    },
    {
      "type": "training",
      "description": "Training step 762",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:46",
      "total_flops_so_far": 1092732007643136.0,
      "budget_used_percent": 1.092732007643136
    },
    {
      "type": "training",
      "description": "Training step 763",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:47",
      "total_flops_so_far": 1094164159684608.0,
      "budget_used_percent": 1.094164159684608
    },
    {
      "type": "training",
      "description": "Training step 764",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:47",
      "total_flops_so_far": 1095596311726080.0,
      "budget_used_percent": 1.0955963117260799
    },
    {
      "type": "training",
      "description": "Training step 765",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:47",
      "total_flops_so_far": 1097028463767552.0,
      "budget_used_percent": 1.097028463767552
    },
    {
      "type": "training",
      "description": "Training step 766",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:47",
      "total_flops_so_far": 1098460615809024.0,
      "budget_used_percent": 1.098460615809024
    },
    {
      "type": "training",
      "description": "Training step 767",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:47",
      "total_flops_so_far": 1099892767850496.0,
      "budget_used_percent": 1.099892767850496
    },
    {
      "type": "training",
      "description": "Training step 768",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:47",
      "total_flops_so_far": 1101324919891968.0,
      "budget_used_percent": 1.1013249198919681
    },
    {
      "type": "training",
      "description": "Training step 769",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:47",
      "total_flops_so_far": 1102757071933440.0,
      "budget_used_percent": 1.10275707193344
    },
    {
      "type": "training",
      "description": "Training step 770",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:47",
      "total_flops_so_far": 1104189223974912.0,
      "budget_used_percent": 1.1041892239749118
    },
    {
      "type": "training",
      "description": "Training step 771",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:48",
      "total_flops_so_far": 1105621376016384.0,
      "budget_used_percent": 1.105621376016384
    },
    {
      "type": "training",
      "description": "Training step 772",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:48",
      "total_flops_so_far": 1107053528057856.0,
      "budget_used_percent": 1.107053528057856
    },
    {
      "type": "training",
      "description": "Training step 773",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:48",
      "total_flops_so_far": 1108485680099328.0,
      "budget_used_percent": 1.108485680099328
    },
    {
      "type": "training",
      "description": "Training step 774",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:48",
      "total_flops_so_far": 1109917832140800.0,
      "budget_used_percent": 1.1099178321408
    },
    {
      "type": "training",
      "description": "Training step 775",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:48",
      "total_flops_so_far": 1111349984182272.0,
      "budget_used_percent": 1.111349984182272
    },
    {
      "type": "training",
      "description": "Training step 776",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:48",
      "total_flops_so_far": 1112782136223744.0,
      "budget_used_percent": 1.112782136223744
    },
    {
      "type": "training",
      "description": "Training step 777",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:48",
      "total_flops_so_far": 1114214288265216.0,
      "budget_used_percent": 1.114214288265216
    },
    {
      "type": "training",
      "description": "Training step 778",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:49",
      "total_flops_so_far": 1115646440306688.0,
      "budget_used_percent": 1.115646440306688
    },
    {
      "type": "training",
      "description": "Training step 779",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:49",
      "total_flops_so_far": 1117078592348160.0,
      "budget_used_percent": 1.1170785923481599
    },
    {
      "type": "training",
      "description": "Training step 780",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:49",
      "total_flops_so_far": 1118510744389632.0,
      "budget_used_percent": 1.118510744389632
    },
    {
      "type": "training",
      "description": "Training step 781",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:49",
      "total_flops_so_far": 1119942896431104.0,
      "budget_used_percent": 1.119942896431104
    },
    {
      "type": "training",
      "description": "Training step 782",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:49",
      "total_flops_so_far": 1121375048472576.0,
      "budget_used_percent": 1.121375048472576
    },
    {
      "type": "training",
      "description": "Training step 783",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:49",
      "total_flops_so_far": 1122807200514048.0,
      "budget_used_percent": 1.1228072005140481
    },
    {
      "type": "training",
      "description": "Training step 784",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:49",
      "total_flops_so_far": 1124239352555520.0,
      "budget_used_percent": 1.12423935255552
    },
    {
      "type": "training",
      "description": "Training step 785",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:50",
      "total_flops_so_far": 1125671504596992.0,
      "budget_used_percent": 1.1256715045969918
    },
    {
      "type": "training",
      "description": "Training step 786",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:50",
      "total_flops_so_far": 1127103656638464.0,
      "budget_used_percent": 1.127103656638464
    },
    {
      "type": "training",
      "description": "Training step 787",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:50",
      "total_flops_so_far": 1128535808679936.0,
      "budget_used_percent": 1.128535808679936
    },
    {
      "type": "training",
      "description": "Training step 788",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:50",
      "total_flops_so_far": 1129967960721408.0,
      "budget_used_percent": 1.129967960721408
    },
    {
      "type": "training",
      "description": "Training step 789",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:50",
      "total_flops_so_far": 1131400112762880.0,
      "budget_used_percent": 1.13140011276288
    },
    {
      "type": "training",
      "description": "Training step 790",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:50",
      "total_flops_so_far": 1132832264804352.0,
      "budget_used_percent": 1.132832264804352
    },
    {
      "type": "training",
      "description": "Training step 791",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:50",
      "total_flops_so_far": 1134264416845824.0,
      "budget_used_percent": 1.134264416845824
    },
    {
      "type": "training",
      "description": "Training step 792",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:50",
      "total_flops_so_far": 1135696568887296.0,
      "budget_used_percent": 1.135696568887296
    },
    {
      "type": "training",
      "description": "Training step 793",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:51",
      "total_flops_so_far": 1137128720928768.0,
      "budget_used_percent": 1.137128720928768
    },
    {
      "type": "training",
      "description": "Training step 794",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:51",
      "total_flops_so_far": 1138560872970240.0,
      "budget_used_percent": 1.13856087297024
    },
    {
      "type": "training",
      "description": "Training step 795",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:51",
      "total_flops_so_far": 1139993025011712.0,
      "budget_used_percent": 1.139993025011712
    },
    {
      "type": "training",
      "description": "Training step 796",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:51",
      "total_flops_so_far": 1141425177053184.0,
      "budget_used_percent": 1.141425177053184
    },
    {
      "type": "training",
      "description": "Training step 797",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:51",
      "total_flops_so_far": 1142857329094656.0,
      "budget_used_percent": 1.142857329094656
    },
    {
      "type": "training",
      "description": "Training step 798",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:51",
      "total_flops_so_far": 1144289481136128.0,
      "budget_used_percent": 1.1442894811361282
    },
    {
      "type": "training",
      "description": "Training step 799",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:51",
      "total_flops_so_far": 1145721633177600.0,
      "budget_used_percent": 1.1457216331776
    },
    {
      "type": "training",
      "description": "Training step 800",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:52",
      "total_flops_so_far": 1147153785219072.0,
      "budget_used_percent": 1.1471537852190719
    },
    {
      "type": "training",
      "description": "Training step 801",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:52",
      "total_flops_so_far": 1148585937260544.0,
      "budget_used_percent": 1.148585937260544
    },
    {
      "type": "training",
      "description": "Training step 802",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:52",
      "total_flops_so_far": 1150018089302016.0,
      "budget_used_percent": 1.150018089302016
    },
    {
      "type": "training",
      "description": "Training step 803",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:52",
      "total_flops_so_far": 1151450241343488.0,
      "budget_used_percent": 1.151450241343488
    },
    {
      "type": "training",
      "description": "Training step 804",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:52",
      "total_flops_so_far": 1152882393384960.0,
      "budget_used_percent": 1.1528823933849601
    },
    {
      "type": "training",
      "description": "Training step 805",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:52",
      "total_flops_so_far": 1154314545426432.0,
      "budget_used_percent": 1.154314545426432
    },
    {
      "type": "training",
      "description": "Training step 806",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:52",
      "total_flops_so_far": 1155746697467904.0,
      "budget_used_percent": 1.155746697467904
    },
    {
      "type": "training",
      "description": "Training step 807",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:53",
      "total_flops_so_far": 1157178849509376.0,
      "budget_used_percent": 1.157178849509376
    },
    {
      "type": "training",
      "description": "Training step 808",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:53",
      "total_flops_so_far": 1158611001550848.0,
      "budget_used_percent": 1.158611001550848
    },
    {
      "type": "training",
      "description": "Training step 809",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:53",
      "total_flops_so_far": 1160043153592320.0,
      "budget_used_percent": 1.16004315359232
    },
    {
      "type": "training",
      "description": "Training step 810",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:53",
      "total_flops_so_far": 1161475305633792.0,
      "budget_used_percent": 1.161475305633792
    },
    {
      "type": "training",
      "description": "Training step 811",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:53",
      "total_flops_so_far": 1162907457675264.0,
      "budget_used_percent": 1.162907457675264
    },
    {
      "type": "training",
      "description": "Training step 812",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:53",
      "total_flops_so_far": 1164339609716736.0,
      "budget_used_percent": 1.164339609716736
    },
    {
      "type": "training",
      "description": "Training step 813",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:53",
      "total_flops_so_far": 1165771761758208.0,
      "budget_used_percent": 1.165771761758208
    },
    {
      "type": "training",
      "description": "Training step 814",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:53",
      "total_flops_so_far": 1167203913799680.0,
      "budget_used_percent": 1.16720391379968
    },
    {
      "type": "training",
      "description": "Training step 815",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:54",
      "total_flops_so_far": 1168636065841152.0,
      "budget_used_percent": 1.1686360658411519
    },
    {
      "type": "training",
      "description": "Training step 816",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:54",
      "total_flops_so_far": 1170068217882624.0,
      "budget_used_percent": 1.170068217882624
    },
    {
      "type": "training",
      "description": "Training step 817",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:54",
      "total_flops_so_far": 1171500369924096.0,
      "budget_used_percent": 1.171500369924096
    },
    {
      "type": "training",
      "description": "Training step 818",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:54",
      "total_flops_so_far": 1172932521965568.0,
      "budget_used_percent": 1.172932521965568
    },
    {
      "type": "training",
      "description": "Training step 819",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:54",
      "total_flops_so_far": 1174364674007040.0,
      "budget_used_percent": 1.1743646740070401
    },
    {
      "type": "training",
      "description": "Training step 820",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:54",
      "total_flops_so_far": 1175796826048512.0,
      "budget_used_percent": 1.175796826048512
    },
    {
      "type": "training",
      "description": "Training step 821",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:54",
      "total_flops_so_far": 1177228978089984.0,
      "budget_used_percent": 1.177228978089984
    },
    {
      "type": "training",
      "description": "Training step 822",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:55",
      "total_flops_so_far": 1178661130131456.0,
      "budget_used_percent": 1.178661130131456
    },
    {
      "type": "training",
      "description": "Training step 823",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:55",
      "total_flops_so_far": 1180093282172928.0,
      "budget_used_percent": 1.180093282172928
    },
    {
      "type": "training",
      "description": "Training step 824",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:55",
      "total_flops_so_far": 1181525434214400.0,
      "budget_used_percent": 1.1815254342144
    },
    {
      "type": "training",
      "description": "Training step 825",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:55",
      "total_flops_so_far": 1182957586255872.0,
      "budget_used_percent": 1.182957586255872
    },
    {
      "type": "training",
      "description": "Training step 826",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:55",
      "total_flops_so_far": 1184389738297344.0,
      "budget_used_percent": 1.184389738297344
    },
    {
      "type": "training",
      "description": "Training step 827",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:55",
      "total_flops_so_far": 1185821890338816.0,
      "budget_used_percent": 1.185821890338816
    },
    {
      "type": "training",
      "description": "Training step 828",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:55",
      "total_flops_so_far": 1187254042380288.0,
      "budget_used_percent": 1.187254042380288
    },
    {
      "type": "training",
      "description": "Training step 829",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:56",
      "total_flops_so_far": 1188686194421760.0,
      "budget_used_percent": 1.18868619442176
    },
    {
      "type": "training",
      "description": "Training step 830",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:56",
      "total_flops_so_far": 1190118346463232.0,
      "budget_used_percent": 1.190118346463232
    },
    {
      "type": "training",
      "description": "Training step 831",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:56",
      "total_flops_so_far": 1191550498504704.0,
      "budget_used_percent": 1.191550498504704
    },
    {
      "type": "training",
      "description": "Training step 832",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:56",
      "total_flops_so_far": 1192982650546176.0,
      "budget_used_percent": 1.192982650546176
    },
    {
      "type": "training",
      "description": "Training step 833",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:56",
      "total_flops_so_far": 1194414802587648.0,
      "budget_used_percent": 1.194414802587648
    },
    {
      "type": "training",
      "description": "Training step 834",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:56",
      "total_flops_so_far": 1195846954629120.0,
      "budget_used_percent": 1.1958469546291202
    },
    {
      "type": "training",
      "description": "Training step 835",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:56",
      "total_flops_so_far": 1197279106670592.0,
      "budget_used_percent": 1.1972791066705921
    },
    {
      "type": "training",
      "description": "Training step 836",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:56",
      "total_flops_so_far": 1198711258712064.0,
      "budget_used_percent": 1.198711258712064
    },
    {
      "type": "training",
      "description": "Training step 837",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:57",
      "total_flops_so_far": 1200143410753536.0,
      "budget_used_percent": 1.2001434107535358
    },
    {
      "type": "training",
      "description": "Training step 838",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:57",
      "total_flops_so_far": 1201575562795008.0,
      "budget_used_percent": 1.201575562795008
    },
    {
      "type": "training",
      "description": "Training step 839",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:57",
      "total_flops_so_far": 1203007714836480.0,
      "budget_used_percent": 1.20300771483648
    },
    {
      "type": "training",
      "description": "Training step 840",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:57",
      "total_flops_so_far": 1204439866877952.0,
      "budget_used_percent": 1.204439866877952
    },
    {
      "type": "training",
      "description": "Training step 841",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:57",
      "total_flops_so_far": 1205872018919424.0,
      "budget_used_percent": 1.205872018919424
    },
    {
      "type": "training",
      "description": "Training step 842",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:57",
      "total_flops_so_far": 1207304170960896.0,
      "budget_used_percent": 1.207304170960896
    },
    {
      "type": "training",
      "description": "Training step 843",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:57",
      "total_flops_so_far": 1208736323002368.0,
      "budget_used_percent": 1.208736323002368
    },
    {
      "type": "training",
      "description": "Training step 844",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:58",
      "total_flops_so_far": 1210168475043840.0,
      "budget_used_percent": 1.21016847504384
    },
    {
      "type": "training",
      "description": "Training step 845",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:58",
      "total_flops_so_far": 1211600627085312.0,
      "budget_used_percent": 1.211600627085312
    },
    {
      "type": "training",
      "description": "Training step 846",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:58",
      "total_flops_so_far": 1213032779126784.0,
      "budget_used_percent": 1.2130327791267839
    },
    {
      "type": "training",
      "description": "Training step 847",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:58",
      "total_flops_so_far": 1214464931168256.0,
      "budget_used_percent": 1.214464931168256
    },
    {
      "type": "training",
      "description": "Training step 848",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:58",
      "total_flops_so_far": 1215897083209728.0,
      "budget_used_percent": 1.215897083209728
    },
    {
      "type": "training",
      "description": "Training step 849",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:58",
      "total_flops_so_far": 1217329235251200.0,
      "budget_used_percent": 1.2173292352512
    },
    {
      "type": "training",
      "description": "Training step 850",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:58",
      "total_flops_so_far": 1218761387292672.0,
      "budget_used_percent": 1.2187613872926721
    },
    {
      "type": "training",
      "description": "Training step 851",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:58",
      "total_flops_so_far": 1220193539334144.0,
      "budget_used_percent": 1.220193539334144
    },
    {
      "type": "training",
      "description": "Training step 852",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:59",
      "total_flops_so_far": 1221625691375616.0,
      "budget_used_percent": 1.2216256913756158
    },
    {
      "type": "training",
      "description": "Training step 853",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:59",
      "total_flops_so_far": 1223057843417088.0,
      "budget_used_percent": 1.223057843417088
    },
    {
      "type": "training",
      "description": "Training step 854",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:59",
      "total_flops_so_far": 1224489995458560.0,
      "budget_used_percent": 1.22448999545856
    },
    {
      "type": "training",
      "description": "Training step 855",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:59",
      "total_flops_so_far": 1225922147500032.0,
      "budget_used_percent": 1.225922147500032
    },
    {
      "type": "training",
      "description": "Training step 856",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:59",
      "total_flops_so_far": 1227354299541504.0,
      "budget_used_percent": 1.227354299541504
    },
    {
      "type": "training",
      "description": "Training step 857",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:59",
      "total_flops_so_far": 1228786451582976.0,
      "budget_used_percent": 1.228786451582976
    },
    {
      "type": "training",
      "description": "Training step 858",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:29:59",
      "total_flops_so_far": 1230218603624448.0,
      "budget_used_percent": 1.230218603624448
    },
    {
      "type": "training",
      "description": "Training step 859",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:00",
      "total_flops_so_far": 1231650755665920.0,
      "budget_used_percent": 1.23165075566592
    },
    {
      "type": "training",
      "description": "Training step 860",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:00",
      "total_flops_so_far": 1233082907707392.0,
      "budget_used_percent": 1.233082907707392
    },
    {
      "type": "training",
      "description": "Training step 861",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:00",
      "total_flops_so_far": 1234515059748864.0,
      "budget_used_percent": 1.2345150597488639
    },
    {
      "type": "training",
      "description": "Training step 862",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:00",
      "total_flops_so_far": 1235947211790336.0,
      "budget_used_percent": 1.235947211790336
    },
    {
      "type": "training",
      "description": "Training step 863",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:00",
      "total_flops_so_far": 1237379363831808.0,
      "budget_used_percent": 1.237379363831808
    },
    {
      "type": "training",
      "description": "Training step 864",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:00",
      "total_flops_so_far": 1238811515873280.0,
      "budget_used_percent": 1.23881151587328
    },
    {
      "type": "training",
      "description": "Training step 865",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:00",
      "total_flops_so_far": 1240243667914752.0,
      "budget_used_percent": 1.2402436679147522
    },
    {
      "type": "training",
      "description": "Training step 866",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:01",
      "total_flops_so_far": 1241675819956224.0,
      "budget_used_percent": 1.241675819956224
    },
    {
      "type": "training",
      "description": "Training step 867",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:01",
      "total_flops_so_far": 1243107971997696.0,
      "budget_used_percent": 1.2431079719976958
    },
    {
      "type": "training",
      "description": "Training step 868",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:01",
      "total_flops_so_far": 1244540124039168.0,
      "budget_used_percent": 1.244540124039168
    },
    {
      "type": "training",
      "description": "Training step 869",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:01",
      "total_flops_so_far": 1245972276080640.0,
      "budget_used_percent": 1.24597227608064
    },
    {
      "type": "training",
      "description": "Training step 870",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:01",
      "total_flops_so_far": 1247404428122112.0,
      "budget_used_percent": 1.247404428122112
    },
    {
      "type": "training",
      "description": "Training step 871",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:01",
      "total_flops_so_far": 1248836580163584.0,
      "budget_used_percent": 1.2488365801635841
    },
    {
      "type": "training",
      "description": "Training step 872",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:01",
      "total_flops_so_far": 1250268732205056.0,
      "budget_used_percent": 1.250268732205056
    },
    {
      "type": "training",
      "description": "Training step 873",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:02",
      "total_flops_so_far": 1251700884246528.0,
      "budget_used_percent": 1.251700884246528
    },
    {
      "type": "training",
      "description": "Training step 874",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:02",
      "total_flops_so_far": 1253133036288000.0,
      "budget_used_percent": 1.253133036288
    },
    {
      "type": "training",
      "description": "Training step 875",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:02",
      "total_flops_so_far": 1254565188329472.0,
      "budget_used_percent": 1.254565188329472
    },
    {
      "type": "training",
      "description": "Training step 876",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:02",
      "total_flops_so_far": 1255997340370944.0,
      "budget_used_percent": 1.255997340370944
    },
    {
      "type": "training",
      "description": "Training step 877",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:02",
      "total_flops_so_far": 1257429492412416.0,
      "budget_used_percent": 1.257429492412416
    },
    {
      "type": "training",
      "description": "Training step 878",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:02",
      "total_flops_so_far": 1258861644453888.0,
      "budget_used_percent": 1.258861644453888
    },
    {
      "type": "training",
      "description": "Training step 879",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:02",
      "total_flops_so_far": 1260293796495360.0,
      "budget_used_percent": 1.26029379649536
    },
    {
      "type": "training",
      "description": "Training step 880",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:02",
      "total_flops_so_far": 1261725948536832.0,
      "budget_used_percent": 1.261725948536832
    },
    {
      "type": "training",
      "description": "Training step 881",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:03",
      "total_flops_so_far": 1263158100578304.0,
      "budget_used_percent": 1.263158100578304
    },
    {
      "type": "training",
      "description": "Training step 882",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:03",
      "total_flops_so_far": 1264590252619776.0,
      "budget_used_percent": 1.2645902526197759
    },
    {
      "type": "training",
      "description": "Training step 883",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:03",
      "total_flops_so_far": 1266022404661248.0,
      "budget_used_percent": 1.266022404661248
    },
    {
      "type": "training",
      "description": "Training step 884",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:03",
      "total_flops_so_far": 1267454556702720.0,
      "budget_used_percent": 1.26745455670272
    },
    {
      "type": "training",
      "description": "Training step 885",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:03",
      "total_flops_so_far": 1268886708744192.0,
      "budget_used_percent": 1.268886708744192
    },
    {
      "type": "training",
      "description": "Training step 886",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:03",
      "total_flops_so_far": 1270318860785664.0,
      "budget_used_percent": 1.2703188607856641
    },
    {
      "type": "training",
      "description": "Training step 887",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:03",
      "total_flops_so_far": 1271751012827136.0,
      "budget_used_percent": 1.271751012827136
    },
    {
      "type": "training",
      "description": "Training step 888",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:04",
      "total_flops_so_far": 1273183164868608.0,
      "budget_used_percent": 1.273183164868608
    },
    {
      "type": "training",
      "description": "Training step 889",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:04",
      "total_flops_so_far": 1274615316910080.0,
      "budget_used_percent": 1.27461531691008
    },
    {
      "type": "training",
      "description": "Training step 890",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:04",
      "total_flops_so_far": 1276047468951552.0,
      "budget_used_percent": 1.276047468951552
    },
    {
      "type": "training",
      "description": "Training step 891",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:04",
      "total_flops_so_far": 1277479620993024.0,
      "budget_used_percent": 1.277479620993024
    },
    {
      "type": "training",
      "description": "Training step 892",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:04",
      "total_flops_so_far": 1278911773034496.0,
      "budget_used_percent": 1.278911773034496
    },
    {
      "type": "training",
      "description": "Training step 893",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:04",
      "total_flops_so_far": 1280343925075968.0,
      "budget_used_percent": 1.280343925075968
    },
    {
      "type": "training",
      "description": "Training step 894",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:04",
      "total_flops_so_far": 1281776077117440.0,
      "budget_used_percent": 1.28177607711744
    },
    {
      "type": "training",
      "description": "Training step 895",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:05",
      "total_flops_so_far": 1283208229158912.0,
      "budget_used_percent": 1.283208229158912
    },
    {
      "type": "training",
      "description": "Training step 896",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:05",
      "total_flops_so_far": 1284640381200384.0,
      "budget_used_percent": 1.284640381200384
    },
    {
      "type": "training",
      "description": "Training step 897",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:05",
      "total_flops_so_far": 1286072533241856.0,
      "budget_used_percent": 1.2860725332418559
    },
    {
      "type": "training",
      "description": "Training step 898",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:05",
      "total_flops_so_far": 1287504685283328.0,
      "budget_used_percent": 1.287504685283328
    },
    {
      "type": "training",
      "description": "Training step 899",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:05",
      "total_flops_so_far": 1288936837324800.0,
      "budget_used_percent": 1.2889368373248
    },
    {
      "type": "training",
      "description": "Training step 900",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:05",
      "total_flops_so_far": 1290368989366272.0,
      "budget_used_percent": 1.290368989366272
    },
    {
      "type": "training",
      "description": "Training step 901",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:05",
      "total_flops_so_far": 1291801141407744.0,
      "budget_used_percent": 1.2918011414077442
    },
    {
      "type": "training",
      "description": "Training step 902",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:06",
      "total_flops_so_far": 1293233293449216.0,
      "budget_used_percent": 1.2932332934492161
    },
    {
      "type": "training",
      "description": "Training step 903",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:06",
      "total_flops_so_far": 1294665445490688.0,
      "budget_used_percent": 1.294665445490688
    },
    {
      "type": "training",
      "description": "Training step 904",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:06",
      "total_flops_so_far": 1296097597532160.0,
      "budget_used_percent": 1.29609759753216
    },
    {
      "type": "training",
      "description": "Training step 905",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:06",
      "total_flops_so_far": 1297529749573632.0,
      "budget_used_percent": 1.297529749573632
    },
    {
      "type": "training",
      "description": "Training step 906",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:06",
      "total_flops_so_far": 1298961901615104.0,
      "budget_used_percent": 1.298961901615104
    },
    {
      "type": "training",
      "description": "Training step 907",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:06",
      "total_flops_so_far": 1300394053656576.0,
      "budget_used_percent": 1.3003940536565761
    },
    {
      "type": "training",
      "description": "Training step 908",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:06",
      "total_flops_so_far": 1301826205698048.0,
      "budget_used_percent": 1.301826205698048
    },
    {
      "type": "training",
      "description": "Training step 909",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:07",
      "total_flops_so_far": 1303258357739520.0,
      "budget_used_percent": 1.30325835773952
    },
    {
      "type": "training",
      "description": "Training step 910",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:07",
      "total_flops_so_far": 1304690509780992.0,
      "budget_used_percent": 1.304690509780992
    },
    {
      "type": "training",
      "description": "Training step 911",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:07",
      "total_flops_so_far": 1306122661822464.0,
      "budget_used_percent": 1.306122661822464
    },
    {
      "type": "training",
      "description": "Training step 912",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:07",
      "total_flops_so_far": 1307554813863936.0,
      "budget_used_percent": 1.307554813863936
    },
    {
      "type": "training",
      "description": "Training step 913",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:07",
      "total_flops_so_far": 1308986965905408.0,
      "budget_used_percent": 1.3089869659054079
    },
    {
      "type": "training",
      "description": "Training step 914",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:07",
      "total_flops_so_far": 1310419117946880.0,
      "budget_used_percent": 1.31041911794688
    },
    {
      "type": "training",
      "description": "Training step 915",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:07",
      "total_flops_so_far": 1311851269988352.0,
      "budget_used_percent": 1.311851269988352
    },
    {
      "type": "training",
      "description": "Training step 916",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:07",
      "total_flops_so_far": 1313283422029824.0,
      "budget_used_percent": 1.313283422029824
    },
    {
      "type": "training",
      "description": "Training step 917",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:08",
      "total_flops_so_far": 1314715574071296.0,
      "budget_used_percent": 1.3147155740712961
    },
    {
      "type": "training",
      "description": "Training step 918",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:08",
      "total_flops_so_far": 1316147726112768.0,
      "budget_used_percent": 1.316147726112768
    },
    {
      "type": "training",
      "description": "Training step 919",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:08",
      "total_flops_so_far": 1317579878154240.0,
      "budget_used_percent": 1.3175798781542398
    },
    {
      "type": "training",
      "description": "Training step 920",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:08",
      "total_flops_so_far": 1319012030195712.0,
      "budget_used_percent": 1.319012030195712
    },
    {
      "type": "training",
      "description": "Training step 921",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:08",
      "total_flops_so_far": 1320444182237184.0,
      "budget_used_percent": 1.320444182237184
    },
    {
      "type": "training",
      "description": "Training step 922",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:08",
      "total_flops_so_far": 1321876334278656.0,
      "budget_used_percent": 1.321876334278656
    },
    {
      "type": "training",
      "description": "Training step 923",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:08",
      "total_flops_so_far": 1323308486320128.0,
      "budget_used_percent": 1.323308486320128
    },
    {
      "type": "training",
      "description": "Training step 924",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:09",
      "total_flops_so_far": 1324740638361600.0,
      "budget_used_percent": 1.3247406383616
    },
    {
      "type": "training",
      "description": "Training step 925",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:09",
      "total_flops_so_far": 1326172790403072.0,
      "budget_used_percent": 1.326172790403072
    },
    {
      "type": "training",
      "description": "Training step 926",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:09",
      "total_flops_so_far": 1327604942444544.0,
      "budget_used_percent": 1.327604942444544
    },
    {
      "type": "training",
      "description": "Training step 927",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:09",
      "total_flops_so_far": 1329037094486016.0,
      "budget_used_percent": 1.329037094486016
    },
    {
      "type": "training",
      "description": "Training step 928",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:09",
      "total_flops_so_far": 1330469246527488.0,
      "budget_used_percent": 1.3304692465274879
    },
    {
      "type": "training",
      "description": "Training step 929",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:09",
      "total_flops_so_far": 1331901398568960.0,
      "budget_used_percent": 1.33190139856896
    },
    {
      "type": "training",
      "description": "Training step 930",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:09",
      "total_flops_so_far": 1333333550610432.0,
      "budget_used_percent": 1.333333550610432
    },
    {
      "type": "training",
      "description": "Training step 931",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:10",
      "total_flops_so_far": 1334765702651904.0,
      "budget_used_percent": 1.334765702651904
    },
    {
      "type": "training",
      "description": "Training step 932",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:10",
      "total_flops_so_far": 1336197854693376.0,
      "budget_used_percent": 1.3361978546933762
    },
    {
      "type": "training",
      "description": "Training step 933",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:10",
      "total_flops_so_far": 1337630006734848.0,
      "budget_used_percent": 1.3376300067348479
    },
    {
      "type": "training",
      "description": "Training step 934",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:10",
      "total_flops_so_far": 1339062158776320.0,
      "budget_used_percent": 1.3390621587763198
    },
    {
      "type": "training",
      "description": "Training step 935",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:10",
      "total_flops_so_far": 1340494310817792.0,
      "budget_used_percent": 1.340494310817792
    },
    {
      "type": "training",
      "description": "Training step 936",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:10",
      "total_flops_so_far": 1341926462859264.0,
      "budget_used_percent": 1.341926462859264
    },
    {
      "type": "training",
      "description": "Training step 937",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:10",
      "total_flops_so_far": 1343358614900736.0,
      "budget_used_percent": 1.343358614900736
    },
    {
      "type": "training",
      "description": "Training step 938",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:11",
      "total_flops_so_far": 1344790766942208.0,
      "budget_used_percent": 1.3447907669422081
    },
    {
      "type": "training",
      "description": "Training step 939",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:11",
      "total_flops_so_far": 1346222918983680.0,
      "budget_used_percent": 1.34622291898368
    },
    {
      "type": "training",
      "description": "Training step 940",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:11",
      "total_flops_so_far": 1347655071025152.0,
      "budget_used_percent": 1.347655071025152
    },
    {
      "type": "training",
      "description": "Training step 941",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:11",
      "total_flops_so_far": 1349087223066624.0,
      "budget_used_percent": 1.349087223066624
    },
    {
      "type": "training",
      "description": "Training step 942",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:11",
      "total_flops_so_far": 1350519375108096.0,
      "budget_used_percent": 1.350519375108096
    },
    {
      "type": "training",
      "description": "Training step 943",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:11",
      "total_flops_so_far": 1351951527149568.0,
      "budget_used_percent": 1.351951527149568
    },
    {
      "type": "training",
      "description": "Training step 944",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:11",
      "total_flops_so_far": 1353383679191040.0,
      "budget_used_percent": 1.35338367919104
    },
    {
      "type": "training",
      "description": "Training step 945",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:11",
      "total_flops_so_far": 1354815831232512.0,
      "budget_used_percent": 1.354815831232512
    },
    {
      "type": "training",
      "description": "Training step 946",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:12",
      "total_flops_so_far": 1356247983273984.0,
      "budget_used_percent": 1.356247983273984
    },
    {
      "type": "training",
      "description": "Training step 947",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:12",
      "total_flops_so_far": 1357680135315456.0,
      "budget_used_percent": 1.357680135315456
    },
    {
      "type": "training",
      "description": "Training step 948",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:12",
      "total_flops_so_far": 1359112287356928.0,
      "budget_used_percent": 1.359112287356928
    },
    {
      "type": "training",
      "description": "Training step 949",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:12",
      "total_flops_so_far": 1360544439398400.0,
      "budget_used_percent": 1.3605444393983999
    },
    {
      "type": "training",
      "description": "Training step 950",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:12",
      "total_flops_so_far": 1361976591439872.0,
      "budget_used_percent": 1.361976591439872
    },
    {
      "type": "training",
      "description": "Training step 951",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:12",
      "total_flops_so_far": 1363408743481344.0,
      "budget_used_percent": 1.363408743481344
    },
    {
      "type": "training",
      "description": "Training step 952",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:12",
      "total_flops_so_far": 1364840895522816.0,
      "budget_used_percent": 1.364840895522816
    },
    {
      "type": "training",
      "description": "Training step 953",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:13",
      "total_flops_so_far": 1366273047564288.0,
      "budget_used_percent": 1.3662730475642881
    },
    {
      "type": "training",
      "description": "Training step 954",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:13",
      "total_flops_so_far": 1367705199605760.0,
      "budget_used_percent": 1.36770519960576
    },
    {
      "type": "training",
      "description": "Training step 955",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:13",
      "total_flops_so_far": 1369137351647232.0,
      "budget_used_percent": 1.369137351647232
    },
    {
      "type": "training",
      "description": "Training step 956",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:13",
      "total_flops_so_far": 1370569503688704.0,
      "budget_used_percent": 1.370569503688704
    },
    {
      "type": "training",
      "description": "Training step 957",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:13",
      "total_flops_so_far": 1372001655730176.0,
      "budget_used_percent": 1.372001655730176
    },
    {
      "type": "training",
      "description": "Training step 958",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:13",
      "total_flops_so_far": 1373433807771648.0,
      "budget_used_percent": 1.373433807771648
    },
    {
      "type": "training",
      "description": "Training step 959",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:13",
      "total_flops_so_far": 1374865959813120.0,
      "budget_used_percent": 1.37486595981312
    },
    {
      "type": "training",
      "description": "Training step 960",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:14",
      "total_flops_so_far": 1376298111854592.0,
      "budget_used_percent": 1.376298111854592
    },
    {
      "type": "training",
      "description": "Training step 961",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:14",
      "total_flops_so_far": 1377730263896064.0,
      "budget_used_percent": 1.377730263896064
    },
    {
      "type": "training",
      "description": "Training step 962",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:14",
      "total_flops_so_far": 1379162415937536.0,
      "budget_used_percent": 1.379162415937536
    },
    {
      "type": "training",
      "description": "Training step 963",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:14",
      "total_flops_so_far": 1380594567979008.0,
      "budget_used_percent": 1.380594567979008
    },
    {
      "type": "training",
      "description": "Training step 964",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:14",
      "total_flops_so_far": 1382026720020480.0,
      "budget_used_percent": 1.3820267200204799
    },
    {
      "type": "training",
      "description": "Training step 965",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:14",
      "total_flops_so_far": 1383458872061952.0,
      "budget_used_percent": 1.383458872061952
    },
    {
      "type": "training",
      "description": "Training step 966",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:14",
      "total_flops_so_far": 1384891024103424.0,
      "budget_used_percent": 1.384891024103424
    },
    {
      "type": "training",
      "description": "Training step 967",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:15",
      "total_flops_so_far": 1386323176144896.0,
      "budget_used_percent": 1.386323176144896
    },
    {
      "type": "training",
      "description": "Training step 968",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:15",
      "total_flops_so_far": 1387755328186368.0,
      "budget_used_percent": 1.3877553281863682
    },
    {
      "type": "training",
      "description": "Training step 969",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:15",
      "total_flops_so_far": 1389187480227840.0,
      "budget_used_percent": 1.38918748022784
    },
    {
      "type": "training",
      "description": "Training step 970",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:15",
      "total_flops_so_far": 1390619632269312.0,
      "budget_used_percent": 1.390619632269312
    },
    {
      "type": "training",
      "description": "Training step 971",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:15",
      "total_flops_so_far": 1392051784310784.0,
      "budget_used_percent": 1.392051784310784
    },
    {
      "type": "training",
      "description": "Training step 972",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:15",
      "total_flops_so_far": 1393483936352256.0,
      "budget_used_percent": 1.393483936352256
    },
    {
      "type": "training",
      "description": "Training step 973",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:15",
      "total_flops_so_far": 1394916088393728.0,
      "budget_used_percent": 1.394916088393728
    },
    {
      "type": "training",
      "description": "Training step 974",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:16",
      "total_flops_so_far": 1396348240435200.0,
      "budget_used_percent": 1.3963482404352001
    },
    {
      "type": "training",
      "description": "Training step 975",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:16",
      "total_flops_so_far": 1397780392476672.0,
      "budget_used_percent": 1.397780392476672
    },
    {
      "type": "training",
      "description": "Training step 976",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:16",
      "total_flops_so_far": 1399212544518144.0,
      "budget_used_percent": 1.399212544518144
    },
    {
      "type": "training",
      "description": "Training step 977",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:16",
      "total_flops_so_far": 1400644696559616.0,
      "budget_used_percent": 1.400644696559616
    },
    {
      "type": "training",
      "description": "Training step 978",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:16",
      "total_flops_so_far": 1402076848601088.0,
      "budget_used_percent": 1.402076848601088
    },
    {
      "type": "training",
      "description": "Training step 979",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:16",
      "total_flops_so_far": 1403509000642560.0,
      "budget_used_percent": 1.40350900064256
    },
    {
      "type": "training",
      "description": "Training step 980",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:16",
      "total_flops_so_far": 1404941152684032.0,
      "budget_used_percent": 1.404941152684032
    },
    {
      "type": "training",
      "description": "Training step 981",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:17",
      "total_flops_so_far": 1406373304725504.0,
      "budget_used_percent": 1.406373304725504
    },
    {
      "type": "training",
      "description": "Training step 982",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:17",
      "total_flops_so_far": 1407805456766976.0,
      "budget_used_percent": 1.407805456766976
    },
    {
      "type": "training",
      "description": "Training step 983",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:17",
      "total_flops_so_far": 1409237608808448.0,
      "budget_used_percent": 1.409237608808448
    },
    {
      "type": "training",
      "description": "Training step 984",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:17",
      "total_flops_so_far": 1410669760849920.0,
      "budget_used_percent": 1.4106697608499201
    },
    {
      "type": "training",
      "description": "Training step 985",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:17",
      "total_flops_so_far": 1412101912891392.0,
      "budget_used_percent": 1.412101912891392
    },
    {
      "type": "training",
      "description": "Training step 986",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:17",
      "total_flops_so_far": 1413534064932864.0,
      "budget_used_percent": 1.4135340649328638
    },
    {
      "type": "training",
      "description": "Training step 987",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:17",
      "total_flops_so_far": 1414966216974336.0,
      "budget_used_percent": 1.414966216974336
    },
    {
      "type": "training",
      "description": "Training step 988",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:18",
      "total_flops_so_far": 1416398369015808.0,
      "budget_used_percent": 1.416398369015808
    },
    {
      "type": "training",
      "description": "Training step 989",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:18",
      "total_flops_so_far": 1417830521057280.0,
      "budget_used_percent": 1.41783052105728
    },
    {
      "type": "training",
      "description": "Training step 990",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:18",
      "total_flops_so_far": 1419262673098752.0,
      "budget_used_percent": 1.419262673098752
    },
    {
      "type": "training",
      "description": "Training step 991",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:18",
      "total_flops_so_far": 1420694825140224.0,
      "budget_used_percent": 1.420694825140224
    },
    {
      "type": "training",
      "description": "Training step 992",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:18",
      "total_flops_so_far": 1422126977181696.0,
      "budget_used_percent": 1.422126977181696
    },
    {
      "type": "training",
      "description": "Training step 993",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:18",
      "total_flops_so_far": 1423559129223168.0,
      "budget_used_percent": 1.423559129223168
    },
    {
      "type": "training",
      "description": "Training step 994",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:18",
      "total_flops_so_far": 1424991281264640.0,
      "budget_used_percent": 1.42499128126464
    },
    {
      "type": "training",
      "description": "Training step 995",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:19",
      "total_flops_so_far": 1426423433306112.0,
      "budget_used_percent": 1.4264234333061119
    },
    {
      "type": "training",
      "description": "Training step 996",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:19",
      "total_flops_so_far": 1427855585347584.0,
      "budget_used_percent": 1.427855585347584
    },
    {
      "type": "training",
      "description": "Training step 997",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:19",
      "total_flops_so_far": 1429287737389056.0,
      "budget_used_percent": 1.429287737389056
    },
    {
      "type": "training",
      "description": "Training step 998",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:19",
      "total_flops_so_far": 1430719889430528.0,
      "budget_used_percent": 1.430719889430528
    },
    {
      "type": "training",
      "description": "Training step 999",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-04-02 17:30:19",
      "total_flops_so_far": 1432152041472000.0,
      "budget_used_percent": 1.4321520414720001
    }
  ],
  "total_flops": 1432152041472000.0,
  "budget_used_percent": 1.4321520414720001
}