{
  "experiment_name": "lr1e-04_rank8",
  "model_config": {
    "hidden_size": 896,
    "num_attention_heads": 14,
    "num_hidden_layers": 24,
    "intermediate_size": 4864,
    "head_dim": 64,
    "vocab_size": 151936,
    "lora_r": 8,
    "lora_target_modules": [
      "q_proj",
      "v_proj"
    ]
  },
  "max_budget": 1e+17,
  "start_time": "2025-03-23 14:43:24",
  "operations": [
    {
      "type": "training",
      "description": "Training step 0",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:26",
      "total_flops_so_far": 1432152041472.0,
      "budget_used_percent": 0.001432152041472
    },
    {
      "type": "training",
      "description": "Training step 1",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:27",
      "total_flops_so_far": 2864304082944.0,
      "budget_used_percent": 0.002864304082944
    },
    {
      "type": "training",
      "description": "Training step 2",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:27",
      "total_flops_so_far": 4296456124416.0,
      "budget_used_percent": 0.004296456124416
    },
    {
      "type": "training",
      "description": "Training step 3",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:27",
      "total_flops_so_far": 5728608165888.0,
      "budget_used_percent": 0.005728608165888
    },
    {
      "type": "training",
      "description": "Training step 4",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:27",
      "total_flops_so_far": 7160760207360.0,
      "budget_used_percent": 0.007160760207359999
    },
    {
      "type": "training",
      "description": "Training step 5",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:27",
      "total_flops_so_far": 8592912248832.0,
      "budget_used_percent": 0.008592912248832
    },
    {
      "type": "training",
      "description": "Training step 6",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:27",
      "total_flops_so_far": 10025064290304.0,
      "budget_used_percent": 0.010025064290304
    },
    {
      "type": "training",
      "description": "Training step 7",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:27",
      "total_flops_so_far": 11457216331776.0,
      "budget_used_percent": 0.011457216331776
    },
    {
      "type": "training",
      "description": "Training step 8",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:27",
      "total_flops_so_far": 12889368373248.0,
      "budget_used_percent": 0.012889368373247998
    },
    {
      "type": "training",
      "description": "Training step 9",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:27",
      "total_flops_so_far": 14321520414720.0,
      "budget_used_percent": 0.014321520414719999
    },
    {
      "type": "training",
      "description": "Training step 10",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:28",
      "total_flops_so_far": 15753672456192.0,
      "budget_used_percent": 0.015753672456191997
    },
    {
      "type": "training",
      "description": "Training step 11",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:28",
      "total_flops_so_far": 17185824497664.0,
      "budget_used_percent": 0.017185824497664
    },
    {
      "type": "training",
      "description": "Training step 12",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:28",
      "total_flops_so_far": 18617976539136.0,
      "budget_used_percent": 0.018617976539136
    },
    {
      "type": "training",
      "description": "Training step 13",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:28",
      "total_flops_so_far": 20050128580608.0,
      "budget_used_percent": 0.020050128580608
    },
    {
      "type": "training",
      "description": "Training step 14",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:28",
      "total_flops_so_far": 21482280622080.0,
      "budget_used_percent": 0.02148228062208
    },
    {
      "type": "training",
      "description": "Training step 15",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:28",
      "total_flops_so_far": 22914432663552.0,
      "budget_used_percent": 0.022914432663552
    },
    {
      "type": "training",
      "description": "Training step 16",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:28",
      "total_flops_so_far": 24346584705024.0,
      "budget_used_percent": 0.024346584705024002
    },
    {
      "type": "training",
      "description": "Training step 17",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:28",
      "total_flops_so_far": 25778736746496.0,
      "budget_used_percent": 0.025778736746495997
    },
    {
      "type": "training",
      "description": "Training step 18",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:29",
      "total_flops_so_far": 27210888787968.0,
      "budget_used_percent": 0.027210888787968
    },
    {
      "type": "training",
      "description": "Training step 19",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:29",
      "total_flops_so_far": 28643040829440.0,
      "budget_used_percent": 0.028643040829439997
    },
    {
      "type": "training",
      "description": "Training step 20",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:29",
      "total_flops_so_far": 30075192870912.0,
      "budget_used_percent": 0.030075192870912
    },
    {
      "type": "training",
      "description": "Training step 21",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:29",
      "total_flops_so_far": 31507344912384.0,
      "budget_used_percent": 0.031507344912383994
    },
    {
      "type": "training",
      "description": "Training step 22",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:29",
      "total_flops_so_far": 32939496953856.0,
      "budget_used_percent": 0.032939496953856
    },
    {
      "type": "training",
      "description": "Training step 23",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:29",
      "total_flops_so_far": 34371648995328.0,
      "budget_used_percent": 0.034371648995328
    },
    {
      "type": "training",
      "description": "Training step 24",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:29",
      "total_flops_so_far": 35803801036800.0,
      "budget_used_percent": 0.0358038010368
    },
    {
      "type": "training",
      "description": "Training step 25",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:29",
      "total_flops_so_far": 37235953078272.0,
      "budget_used_percent": 0.037235953078272
    },
    {
      "type": "training",
      "description": "Training step 26",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:29",
      "total_flops_so_far": 38668105119744.0,
      "budget_used_percent": 0.038668105119744
    },
    {
      "type": "training",
      "description": "Training step 27",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:30",
      "total_flops_so_far": 40100257161216.0,
      "budget_used_percent": 0.040100257161216
    },
    {
      "type": "training",
      "description": "Training step 28",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:30",
      "total_flops_so_far": 41532409202688.0,
      "budget_used_percent": 0.041532409202688
    },
    {
      "type": "training",
      "description": "Training step 29",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:30",
      "total_flops_so_far": 42964561244160.0,
      "budget_used_percent": 0.04296456124416
    },
    {
      "type": "training",
      "description": "Training step 30",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:30",
      "total_flops_so_far": 44396713285632.0,
      "budget_used_percent": 0.044396713285632
    },
    {
      "type": "training",
      "description": "Training step 31",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:30",
      "total_flops_so_far": 45828865327104.0,
      "budget_used_percent": 0.045828865327104
    },
    {
      "type": "training",
      "description": "Training step 32",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:30",
      "total_flops_so_far": 47261017368576.0,
      "budget_used_percent": 0.047261017368576
    },
    {
      "type": "training",
      "description": "Training step 33",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:30",
      "total_flops_so_far": 48693169410048.0,
      "budget_used_percent": 0.048693169410048004
    },
    {
      "type": "training",
      "description": "Training step 34",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:30",
      "total_flops_so_far": 50125321451520.0,
      "budget_used_percent": 0.05012532145152
    },
    {
      "type": "training",
      "description": "Training step 35",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:31",
      "total_flops_so_far": 51557473492992.0,
      "budget_used_percent": 0.051557473492991994
    },
    {
      "type": "training",
      "description": "Training step 36",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:31",
      "total_flops_so_far": 52989625534464.0,
      "budget_used_percent": 0.052989625534464006
    },
    {
      "type": "training",
      "description": "Training step 37",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:31",
      "total_flops_so_far": 54421777575936.0,
      "budget_used_percent": 0.054421777575936
    },
    {
      "type": "training",
      "description": "Training step 38",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:31",
      "total_flops_so_far": 55853929617408.0,
      "budget_used_percent": 0.055853929617407996
    },
    {
      "type": "training",
      "description": "Training step 39",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:31",
      "total_flops_so_far": 57286081658880.0,
      "budget_used_percent": 0.057286081658879995
    },
    {
      "type": "training",
      "description": "Training step 40",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:31",
      "total_flops_so_far": 58718233700352.0,
      "budget_used_percent": 0.05871823370035201
    },
    {
      "type": "training",
      "description": "Training step 41",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:31",
      "total_flops_so_far": 60150385741824.0,
      "budget_used_percent": 0.060150385741824
    },
    {
      "type": "training",
      "description": "Training step 42",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:31",
      "total_flops_so_far": 61582537783296.0,
      "budget_used_percent": 0.061582537783296
    },
    {
      "type": "training",
      "description": "Training step 43",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:31",
      "total_flops_so_far": 63014689824768.0,
      "budget_used_percent": 0.06301468982476799
    },
    {
      "type": "training",
      "description": "Training step 44",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:32",
      "total_flops_so_far": 64446841866240.0,
      "budget_used_percent": 0.06444684186624
    },
    {
      "type": "training",
      "description": "Training step 45",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:32",
      "total_flops_so_far": 65878993907712.0,
      "budget_used_percent": 0.065878993907712
    },
    {
      "type": "training",
      "description": "Training step 46",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:32",
      "total_flops_so_far": 67311145949184.0,
      "budget_used_percent": 0.067311145949184
    },
    {
      "type": "training",
      "description": "Training step 47",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:32",
      "total_flops_so_far": 68743297990656.0,
      "budget_used_percent": 0.068743297990656
    },
    {
      "type": "training",
      "description": "Training step 48",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:32",
      "total_flops_so_far": 70175450032128.0,
      "budget_used_percent": 0.07017545003212801
    },
    {
      "type": "training",
      "description": "Training step 49",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:32",
      "total_flops_so_far": 71607602073600.0,
      "budget_used_percent": 0.0716076020736
    },
    {
      "type": "training",
      "description": "Training step 50",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:32",
      "total_flops_so_far": 73039754115072.0,
      "budget_used_percent": 0.07303975411507199
    },
    {
      "type": "training",
      "description": "Training step 51",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:32",
      "total_flops_so_far": 74471906156544.0,
      "budget_used_percent": 0.074471906156544
    },
    {
      "type": "training",
      "description": "Training step 52",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:32",
      "total_flops_so_far": 75904058198016.0,
      "budget_used_percent": 0.075904058198016
    },
    {
      "type": "training",
      "description": "Training step 53",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:33",
      "total_flops_so_far": 77336210239488.0,
      "budget_used_percent": 0.077336210239488
    },
    {
      "type": "training",
      "description": "Training step 54",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:33",
      "total_flops_so_far": 78768362280960.0,
      "budget_used_percent": 0.07876836228096
    },
    {
      "type": "training",
      "description": "Training step 55",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:33",
      "total_flops_so_far": 80200514322432.0,
      "budget_used_percent": 0.080200514322432
    },
    {
      "type": "training",
      "description": "Training step 56",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:33",
      "total_flops_so_far": 81632666363904.0,
      "budget_used_percent": 0.081632666363904
    },
    {
      "type": "training",
      "description": "Training step 57",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:33",
      "total_flops_so_far": 83064818405376.0,
      "budget_used_percent": 0.083064818405376
    },
    {
      "type": "training",
      "description": "Training step 58",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:33",
      "total_flops_so_far": 84496970446848.0,
      "budget_used_percent": 0.084496970446848
    },
    {
      "type": "training",
      "description": "Training step 59",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:33",
      "total_flops_so_far": 85929122488320.0,
      "budget_used_percent": 0.08592912248832
    },
    {
      "type": "training",
      "description": "Training step 60",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:33",
      "total_flops_so_far": 87361274529792.0,
      "budget_used_percent": 0.087361274529792
    },
    {
      "type": "training",
      "description": "Training step 61",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:34",
      "total_flops_so_far": 88793426571264.0,
      "budget_used_percent": 0.088793426571264
    },
    {
      "type": "training",
      "description": "Training step 62",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:34",
      "total_flops_so_far": 90225578612736.0,
      "budget_used_percent": 0.090225578612736
    },
    {
      "type": "training",
      "description": "Training step 63",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:34",
      "total_flops_so_far": 91657730654208.0,
      "budget_used_percent": 0.091657730654208
    },
    {
      "type": "training",
      "description": "Training step 64",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:34",
      "total_flops_so_far": 93089882695680.0,
      "budget_used_percent": 0.09308988269568
    },
    {
      "type": "training",
      "description": "Training step 65",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:34",
      "total_flops_so_far": 94522034737152.0,
      "budget_used_percent": 0.094522034737152
    },
    {
      "type": "training",
      "description": "Training step 66",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:34",
      "total_flops_so_far": 95954186778624.0,
      "budget_used_percent": 0.095954186778624
    },
    {
      "type": "training",
      "description": "Training step 67",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:34",
      "total_flops_so_far": 97386338820096.0,
      "budget_used_percent": 0.09738633882009601
    },
    {
      "type": "training",
      "description": "Training step 68",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:34",
      "total_flops_so_far": 98818490861568.0,
      "budget_used_percent": 0.09881849086156799
    },
    {
      "type": "training",
      "description": "Training step 69",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:34",
      "total_flops_so_far": 100250642903040.0,
      "budget_used_percent": 0.10025064290304
    },
    {
      "type": "training",
      "description": "Training step 70",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:35",
      "total_flops_so_far": 101682794944512.0,
      "budget_used_percent": 0.101682794944512
    },
    {
      "type": "training",
      "description": "Training step 71",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:35",
      "total_flops_so_far": 103114946985984.0,
      "budget_used_percent": 0.10311494698598399
    },
    {
      "type": "training",
      "description": "Training step 72",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:35",
      "total_flops_so_far": 104547099027456.0,
      "budget_used_percent": 0.104547099027456
    },
    {
      "type": "training",
      "description": "Training step 73",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:35",
      "total_flops_so_far": 105979251068928.0,
      "budget_used_percent": 0.10597925106892801
    },
    {
      "type": "training",
      "description": "Training step 74",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:35",
      "total_flops_so_far": 107411403110400.0,
      "budget_used_percent": 0.1074114031104
    },
    {
      "type": "training",
      "description": "Training step 75",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:35",
      "total_flops_so_far": 108843555151872.0,
      "budget_used_percent": 0.108843555151872
    },
    {
      "type": "training",
      "description": "Training step 76",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:35",
      "total_flops_so_far": 110275707193344.0,
      "budget_used_percent": 0.11027570719334401
    },
    {
      "type": "training",
      "description": "Training step 77",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:35",
      "total_flops_so_far": 111707859234816.0,
      "budget_used_percent": 0.11170785923481599
    },
    {
      "type": "training",
      "description": "Training step 78",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:36",
      "total_flops_so_far": 113140011276288.0,
      "budget_used_percent": 0.113140011276288
    },
    {
      "type": "training",
      "description": "Training step 79",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:36",
      "total_flops_so_far": 114572163317760.0,
      "budget_used_percent": 0.11457216331775999
    },
    {
      "type": "training",
      "description": "Training step 80",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:36",
      "total_flops_so_far": 116004315359232.0,
      "budget_used_percent": 0.116004315359232
    },
    {
      "type": "training",
      "description": "Training step 81",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:36",
      "total_flops_so_far": 117436467400704.0,
      "budget_used_percent": 0.11743646740070401
    },
    {
      "type": "training",
      "description": "Training step 82",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:36",
      "total_flops_so_far": 118868619442176.0,
      "budget_used_percent": 0.118868619442176
    },
    {
      "type": "training",
      "description": "Training step 83",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:36",
      "total_flops_so_far": 120300771483648.0,
      "budget_used_percent": 0.120300771483648
    },
    {
      "type": "training",
      "description": "Training step 84",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:36",
      "total_flops_so_far": 121732923525120.0,
      "budget_used_percent": 0.12173292352512001
    },
    {
      "type": "training",
      "description": "Training step 85",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:36",
      "total_flops_so_far": 123165075566592.0,
      "budget_used_percent": 0.123165075566592
    },
    {
      "type": "training",
      "description": "Training step 86",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:36",
      "total_flops_so_far": 124597227608064.0,
      "budget_used_percent": 0.124597227608064
    },
    {
      "type": "training",
      "description": "Training step 87",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:37",
      "total_flops_so_far": 126029379649536.0,
      "budget_used_percent": 0.12602937964953598
    },
    {
      "type": "training",
      "description": "Training step 88",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:37",
      "total_flops_so_far": 127461531691008.0,
      "budget_used_percent": 0.127461531691008
    },
    {
      "type": "training",
      "description": "Training step 89",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:37",
      "total_flops_so_far": 128893683732480.0,
      "budget_used_percent": 0.12889368373248
    },
    {
      "type": "training",
      "description": "Training step 90",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:37",
      "total_flops_so_far": 130325835773952.0,
      "budget_used_percent": 0.130325835773952
    },
    {
      "type": "training",
      "description": "Training step 91",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:37",
      "total_flops_so_far": 131757987815424.0,
      "budget_used_percent": 0.131757987815424
    },
    {
      "type": "training",
      "description": "Training step 92",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:37",
      "total_flops_so_far": 133190139856896.0,
      "budget_used_percent": 0.133190139856896
    },
    {
      "type": "training",
      "description": "Training step 93",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:37",
      "total_flops_so_far": 134622291898368.0,
      "budget_used_percent": 0.134622291898368
    },
    {
      "type": "training",
      "description": "Training step 94",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:37",
      "total_flops_so_far": 136054443939840.0,
      "budget_used_percent": 0.13605444393984
    },
    {
      "type": "training",
      "description": "Training step 95",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:38",
      "total_flops_so_far": 137486595981312.0,
      "budget_used_percent": 0.137486595981312
    },
    {
      "type": "training",
      "description": "Training step 96",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:38",
      "total_flops_so_far": 138918748022784.0,
      "budget_used_percent": 0.138918748022784
    },
    {
      "type": "training",
      "description": "Training step 97",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:38",
      "total_flops_so_far": 140350900064256.0,
      "budget_used_percent": 0.14035090006425602
    },
    {
      "type": "training",
      "description": "Training step 98",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:38",
      "total_flops_so_far": 141783052105728.0,
      "budget_used_percent": 0.141783052105728
    },
    {
      "type": "training",
      "description": "Training step 99",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:38",
      "total_flops_so_far": 143215204147200.0,
      "budget_used_percent": 0.1432152041472
    },
    {
      "type": "training",
      "description": "Training step 100",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:38",
      "total_flops_so_far": 144647356188672.0,
      "budget_used_percent": 0.144647356188672
    },
    {
      "type": "training",
      "description": "Training step 101",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:38",
      "total_flops_so_far": 146079508230144.0,
      "budget_used_percent": 0.14607950823014398
    },
    {
      "type": "training",
      "description": "Training step 102",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:38",
      "total_flops_so_far": 147511660271616.0,
      "budget_used_percent": 0.147511660271616
    },
    {
      "type": "training",
      "description": "Training step 103",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:38",
      "total_flops_so_far": 148943812313088.0,
      "budget_used_percent": 0.148943812313088
    },
    {
      "type": "training",
      "description": "Training step 104",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:39",
      "total_flops_so_far": 150375964354560.0,
      "budget_used_percent": 0.15037596435456
    },
    {
      "type": "training",
      "description": "Training step 105",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:39",
      "total_flops_so_far": 151808116396032.0,
      "budget_used_percent": 0.151808116396032
    },
    {
      "type": "training",
      "description": "Training step 106",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:39",
      "total_flops_so_far": 153240268437504.0,
      "budget_used_percent": 0.153240268437504
    },
    {
      "type": "training",
      "description": "Training step 107",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:39",
      "total_flops_so_far": 154672420478976.0,
      "budget_used_percent": 0.154672420478976
    },
    {
      "type": "training",
      "description": "Training step 108",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:39",
      "total_flops_so_far": 156104572520448.0,
      "budget_used_percent": 0.15610457252044802
    },
    {
      "type": "training",
      "description": "Training step 109",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:39",
      "total_flops_so_far": 157536724561920.0,
      "budget_used_percent": 0.15753672456192
    },
    {
      "type": "training",
      "description": "Training step 110",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:39",
      "total_flops_so_far": 158968876603392.0,
      "budget_used_percent": 0.158968876603392
    },
    {
      "type": "training",
      "description": "Training step 111",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:39",
      "total_flops_so_far": 160401028644864.0,
      "budget_used_percent": 0.160401028644864
    },
    {
      "type": "training",
      "description": "Training step 112",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:40",
      "total_flops_so_far": 161833180686336.0,
      "budget_used_percent": 0.161833180686336
    },
    {
      "type": "training",
      "description": "Training step 113",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:40",
      "total_flops_so_far": 163265332727808.0,
      "budget_used_percent": 0.163265332727808
    },
    {
      "type": "training",
      "description": "Training step 114",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:40",
      "total_flops_so_far": 164697484769280.0,
      "budget_used_percent": 0.16469748476927998
    },
    {
      "type": "training",
      "description": "Training step 115",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:40",
      "total_flops_so_far": 166129636810752.0,
      "budget_used_percent": 0.166129636810752
    },
    {
      "type": "training",
      "description": "Training step 116",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:40",
      "total_flops_so_far": 167561788852224.0,
      "budget_used_percent": 0.167561788852224
    },
    {
      "type": "training",
      "description": "Training step 117",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:40",
      "total_flops_so_far": 168993940893696.0,
      "budget_used_percent": 0.168993940893696
    },
    {
      "type": "training",
      "description": "Training step 118",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:40",
      "total_flops_so_far": 170426092935168.0,
      "budget_used_percent": 0.170426092935168
    },
    {
      "type": "training",
      "description": "Training step 119",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:40",
      "total_flops_so_far": 171858244976640.0,
      "budget_used_percent": 0.17185824497664
    },
    {
      "type": "training",
      "description": "Training step 120",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:40",
      "total_flops_so_far": 173290397018112.0,
      "budget_used_percent": 0.173290397018112
    },
    {
      "type": "training",
      "description": "Training step 121",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:41",
      "total_flops_so_far": 174722549059584.0,
      "budget_used_percent": 0.174722549059584
    },
    {
      "type": "training",
      "description": "Training step 122",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:41",
      "total_flops_so_far": 176154701101056.0,
      "budget_used_percent": 0.176154701101056
    },
    {
      "type": "training",
      "description": "Training step 123",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:41",
      "total_flops_so_far": 177586853142528.0,
      "budget_used_percent": 0.177586853142528
    },
    {
      "type": "training",
      "description": "Training step 124",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:41",
      "total_flops_so_far": 179019005184000.0,
      "budget_used_percent": 0.17901900518400002
    },
    {
      "type": "training",
      "description": "Training step 125",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:41",
      "total_flops_so_far": 180451157225472.0,
      "budget_used_percent": 0.180451157225472
    },
    {
      "type": "training",
      "description": "Training step 126",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:41",
      "total_flops_so_far": 181883309266944.0,
      "budget_used_percent": 0.181883309266944
    },
    {
      "type": "training",
      "description": "Training step 127",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:41",
      "total_flops_so_far": 183315461308416.0,
      "budget_used_percent": 0.183315461308416
    },
    {
      "type": "training",
      "description": "Training step 128",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:41",
      "total_flops_so_far": 184747613349888.0,
      "budget_used_percent": 0.18474761334988798
    },
    {
      "type": "training",
      "description": "Training step 129",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:42",
      "total_flops_so_far": 186179765391360.0,
      "budget_used_percent": 0.18617976539136
    },
    {
      "type": "training",
      "description": "Training step 130",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:42",
      "total_flops_so_far": 187611917432832.0,
      "budget_used_percent": 0.187611917432832
    },
    {
      "type": "training",
      "description": "Training step 131",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:42",
      "total_flops_so_far": 189044069474304.0,
      "budget_used_percent": 0.189044069474304
    },
    {
      "type": "training",
      "description": "Training step 132",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:42",
      "total_flops_so_far": 190476221515776.0,
      "budget_used_percent": 0.190476221515776
    },
    {
      "type": "training",
      "description": "Training step 133",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:42",
      "total_flops_so_far": 191908373557248.0,
      "budget_used_percent": 0.191908373557248
    },
    {
      "type": "training",
      "description": "Training step 134",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:42",
      "total_flops_so_far": 193340525598720.0,
      "budget_used_percent": 0.19334052559872
    },
    {
      "type": "training",
      "description": "Training step 135",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:42",
      "total_flops_so_far": 194772677640192.0,
      "budget_used_percent": 0.19477267764019202
    },
    {
      "type": "training",
      "description": "Training step 136",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:42",
      "total_flops_so_far": 196204829681664.0,
      "budget_used_percent": 0.196204829681664
    },
    {
      "type": "training",
      "description": "Training step 137",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:43",
      "total_flops_so_far": 197636981723136.0,
      "budget_used_percent": 0.19763698172313598
    },
    {
      "type": "training",
      "description": "Training step 138",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:43",
      "total_flops_so_far": 199069133764608.0,
      "budget_used_percent": 0.199069133764608
    },
    {
      "type": "training",
      "description": "Training step 139",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:43",
      "total_flops_so_far": 200501285806080.0,
      "budget_used_percent": 0.20050128580608
    },
    {
      "type": "training",
      "description": "Training step 140",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:43",
      "total_flops_so_far": 201933437847552.0,
      "budget_used_percent": 0.201933437847552
    },
    {
      "type": "training",
      "description": "Training step 141",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:43",
      "total_flops_so_far": 203365589889024.0,
      "budget_used_percent": 0.203365589889024
    },
    {
      "type": "training",
      "description": "Training step 142",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:43",
      "total_flops_so_far": 204797741930496.0,
      "budget_used_percent": 0.204797741930496
    },
    {
      "type": "training",
      "description": "Training step 143",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:43",
      "total_flops_so_far": 206229893971968.0,
      "budget_used_percent": 0.20622989397196798
    },
    {
      "type": "training",
      "description": "Training step 144",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:43",
      "total_flops_so_far": 207662046013440.0,
      "budget_used_percent": 0.20766204601344002
    },
    {
      "type": "training",
      "description": "Training step 145",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:43",
      "total_flops_so_far": 209094198054912.0,
      "budget_used_percent": 0.209094198054912
    },
    {
      "type": "training",
      "description": "Training step 146",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:44",
      "total_flops_so_far": 210526350096384.0,
      "budget_used_percent": 0.21052635009638399
    },
    {
      "type": "training",
      "description": "Training step 147",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:45",
      "total_flops_so_far": 211958502137856.0,
      "budget_used_percent": 0.21195850213785603
    },
    {
      "type": "training",
      "description": "Training step 148",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:45",
      "total_flops_so_far": 213390654179328.0,
      "budget_used_percent": 0.213390654179328
    },
    {
      "type": "training",
      "description": "Training step 149",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:45",
      "total_flops_so_far": 214822806220800.0,
      "budget_used_percent": 0.2148228062208
    },
    {
      "type": "training",
      "description": "Training step 150",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:45",
      "total_flops_so_far": 216254958262272.0,
      "budget_used_percent": 0.216254958262272
    },
    {
      "type": "training",
      "description": "Training step 151",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:45",
      "total_flops_so_far": 217687110303744.0,
      "budget_used_percent": 0.217687110303744
    },
    {
      "type": "training",
      "description": "Training step 152",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:45",
      "total_flops_so_far": 219119262345216.0,
      "budget_used_percent": 0.219119262345216
    },
    {
      "type": "training",
      "description": "Training step 153",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:46",
      "total_flops_so_far": 220551414386688.0,
      "budget_used_percent": 0.22055141438668802
    },
    {
      "type": "training",
      "description": "Training step 154",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:46",
      "total_flops_so_far": 221983566428160.0,
      "budget_used_percent": 0.22198356642816
    },
    {
      "type": "training",
      "description": "Training step 155",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:46",
      "total_flops_so_far": 223415718469632.0,
      "budget_used_percent": 0.22341571846963199
    },
    {
      "type": "training",
      "description": "Training step 156",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:46",
      "total_flops_so_far": 224847870511104.0,
      "budget_used_percent": 0.22484787051110397
    },
    {
      "type": "training",
      "description": "Training step 157",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:46",
      "total_flops_so_far": 226280022552576.0,
      "budget_used_percent": 0.226280022552576
    },
    {
      "type": "training",
      "description": "Training step 158",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:46",
      "total_flops_so_far": 227712174594048.0,
      "budget_used_percent": 0.227712174594048
    },
    {
      "type": "training",
      "description": "Training step 159",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:46",
      "total_flops_so_far": 229144326635520.0,
      "budget_used_percent": 0.22914432663551998
    },
    {
      "type": "training",
      "description": "Training step 160",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:46",
      "total_flops_so_far": 230576478676992.0,
      "budget_used_percent": 0.23057647867699202
    },
    {
      "type": "training",
      "description": "Training step 161",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:47",
      "total_flops_so_far": 232008630718464.0,
      "budget_used_percent": 0.232008630718464
    },
    {
      "type": "training",
      "description": "Training step 162",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:47",
      "total_flops_so_far": 233440782759936.0,
      "budget_used_percent": 0.233440782759936
    },
    {
      "type": "training",
      "description": "Training step 163",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:47",
      "total_flops_so_far": 234872934801408.0,
      "budget_used_percent": 0.23487293480140803
    },
    {
      "type": "training",
      "description": "Training step 164",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:47",
      "total_flops_so_far": 236305086842880.0,
      "budget_used_percent": 0.23630508684288
    },
    {
      "type": "training",
      "description": "Training step 165",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:47",
      "total_flops_so_far": 237737238884352.0,
      "budget_used_percent": 0.237737238884352
    },
    {
      "type": "training",
      "description": "Training step 166",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:47",
      "total_flops_so_far": 239169390925824.0,
      "budget_used_percent": 0.239169390925824
    },
    {
      "type": "training",
      "description": "Training step 167",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:47",
      "total_flops_so_far": 240601542967296.0,
      "budget_used_percent": 0.240601542967296
    },
    {
      "type": "training",
      "description": "Training step 168",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:47",
      "total_flops_so_far": 242033695008768.0,
      "budget_used_percent": 0.24203369500876798
    },
    {
      "type": "training",
      "description": "Training step 169",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:47",
      "total_flops_so_far": 243465847050240.0,
      "budget_used_percent": 0.24346584705024002
    },
    {
      "type": "training",
      "description": "Training step 170",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:48",
      "total_flops_so_far": 244897999091712.0,
      "budget_used_percent": 0.244897999091712
    },
    {
      "type": "training",
      "description": "Training step 171",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:48",
      "total_flops_so_far": 246330151133184.0,
      "budget_used_percent": 0.246330151133184
    },
    {
      "type": "training",
      "description": "Training step 172",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:48",
      "total_flops_so_far": 247762303174656.0,
      "budget_used_percent": 0.24776230317465597
    },
    {
      "type": "training",
      "description": "Training step 173",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:48",
      "total_flops_so_far": 249194455216128.0,
      "budget_used_percent": 0.249194455216128
    },
    {
      "type": "training",
      "description": "Training step 174",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:48",
      "total_flops_so_far": 250626607257600.0,
      "budget_used_percent": 0.2506266072576
    },
    {
      "type": "training",
      "description": "Training step 175",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:48",
      "total_flops_so_far": 252058759299072.0,
      "budget_used_percent": 0.25205875929907195
    },
    {
      "type": "training",
      "description": "Training step 176",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:48",
      "total_flops_so_far": 253490911340544.0,
      "budget_used_percent": 0.253490911340544
    },
    {
      "type": "training",
      "description": "Training step 177",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:48",
      "total_flops_so_far": 254923063382016.0,
      "budget_used_percent": 0.254923063382016
    },
    {
      "type": "training",
      "description": "Training step 178",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:49",
      "total_flops_so_far": 256355215423488.0,
      "budget_used_percent": 0.256355215423488
    },
    {
      "type": "training",
      "description": "Training step 179",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:49",
      "total_flops_so_far": 257787367464960.0,
      "budget_used_percent": 0.25778736746496
    },
    {
      "type": "training",
      "description": "Training step 180",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:49",
      "total_flops_so_far": 259219519506432.0,
      "budget_used_percent": 0.259219519506432
    },
    {
      "type": "training",
      "description": "Training step 181",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:49",
      "total_flops_so_far": 260651671547904.0,
      "budget_used_percent": 0.260651671547904
    },
    {
      "type": "training",
      "description": "Training step 182",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:49",
      "total_flops_so_far": 262083823589376.0,
      "budget_used_percent": 0.26208382358937604
    },
    {
      "type": "training",
      "description": "Training step 183",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:49",
      "total_flops_so_far": 263515975630848.0,
      "budget_used_percent": 0.263515975630848
    },
    {
      "type": "training",
      "description": "Training step 184",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:49",
      "total_flops_so_far": 264948127672320.0,
      "budget_used_percent": 0.26494812767232
    },
    {
      "type": "training",
      "description": "Training step 185",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:49",
      "total_flops_so_far": 266380279713792.0,
      "budget_used_percent": 0.266380279713792
    },
    {
      "type": "training",
      "description": "Training step 186",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:50",
      "total_flops_so_far": 267812431755264.0,
      "budget_used_percent": 0.267812431755264
    },
    {
      "type": "training",
      "description": "Training step 187",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:50",
      "total_flops_so_far": 269244583796736.0,
      "budget_used_percent": 0.269244583796736
    },
    {
      "type": "training",
      "description": "Training step 188",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:50",
      "total_flops_so_far": 270676735838208.0,
      "budget_used_percent": 0.270676735838208
    },
    {
      "type": "training",
      "description": "Training step 189",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:50",
      "total_flops_so_far": 272108887879680.0,
      "budget_used_percent": 0.27210888787968
    },
    {
      "type": "training",
      "description": "Training step 190",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:50",
      "total_flops_so_far": 273541039921152.0,
      "budget_used_percent": 0.273541039921152
    },
    {
      "type": "training",
      "description": "Training step 191",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:50",
      "total_flops_so_far": 274973191962624.0,
      "budget_used_percent": 0.274973191962624
    },
    {
      "type": "training",
      "description": "Training step 192",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:50",
      "total_flops_so_far": 276405344004096.0,
      "budget_used_percent": 0.276405344004096
    },
    {
      "type": "training",
      "description": "Training step 193",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:50",
      "total_flops_so_far": 277837496045568.0,
      "budget_used_percent": 0.277837496045568
    },
    {
      "type": "training",
      "description": "Training step 194",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:51",
      "total_flops_so_far": 279269648087040.0,
      "budget_used_percent": 0.27926964808703997
    },
    {
      "type": "training",
      "description": "Training step 195",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:51",
      "total_flops_so_far": 280701800128512.0,
      "budget_used_percent": 0.28070180012851204
    },
    {
      "type": "training",
      "description": "Training step 196",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:51",
      "total_flops_so_far": 282133952169984.0,
      "budget_used_percent": 0.282133952169984
    },
    {
      "type": "training",
      "description": "Training step 197",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:51",
      "total_flops_so_far": 283566104211456.0,
      "budget_used_percent": 0.283566104211456
    },
    {
      "type": "training",
      "description": "Training step 198",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:51",
      "total_flops_so_far": 284998256252928.0,
      "budget_used_percent": 0.284998256252928
    },
    {
      "type": "training",
      "description": "Training step 199",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:51",
      "total_flops_so_far": 286430408294400.0,
      "budget_used_percent": 0.2864304082944
    },
    {
      "type": "training",
      "description": "Training step 200",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:51",
      "total_flops_so_far": 287862560335872.0,
      "budget_used_percent": 0.287862560335872
    },
    {
      "type": "training",
      "description": "Training step 201",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:51",
      "total_flops_so_far": 289294712377344.0,
      "budget_used_percent": 0.289294712377344
    },
    {
      "type": "training",
      "description": "Training step 202",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:51",
      "total_flops_so_far": 290726864418816.0,
      "budget_used_percent": 0.290726864418816
    },
    {
      "type": "training",
      "description": "Training step 203",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:52",
      "total_flops_so_far": 292159016460288.0,
      "budget_used_percent": 0.29215901646028797
    },
    {
      "type": "training",
      "description": "Training step 204",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:52",
      "total_flops_so_far": 293591168501760.0,
      "budget_used_percent": 0.29359116850176004
    },
    {
      "type": "training",
      "description": "Training step 205",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:52",
      "total_flops_so_far": 295023320543232.0,
      "budget_used_percent": 0.295023320543232
    },
    {
      "type": "training",
      "description": "Training step 206",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:52",
      "total_flops_so_far": 296455472584704.0,
      "budget_used_percent": 0.296455472584704
    },
    {
      "type": "training",
      "description": "Training step 207",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:52",
      "total_flops_so_far": 297887624626176.0,
      "budget_used_percent": 0.297887624626176
    },
    {
      "type": "training",
      "description": "Training step 208",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:52",
      "total_flops_so_far": 299319776667648.0,
      "budget_used_percent": 0.29931977666764803
    },
    {
      "type": "training",
      "description": "Training step 209",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:52",
      "total_flops_so_far": 300751928709120.0,
      "budget_used_percent": 0.30075192870912
    },
    {
      "type": "training",
      "description": "Training step 210",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:52",
      "total_flops_so_far": 302184080750592.0,
      "budget_used_percent": 0.302184080750592
    },
    {
      "type": "training",
      "description": "Training step 211",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:53",
      "total_flops_so_far": 303616232792064.0,
      "budget_used_percent": 0.303616232792064
    },
    {
      "type": "training",
      "description": "Training step 212",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:53",
      "total_flops_so_far": 305048384833536.0,
      "budget_used_percent": 0.305048384833536
    },
    {
      "type": "training",
      "description": "Training step 213",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:53",
      "total_flops_so_far": 306480536875008.0,
      "budget_used_percent": 0.306480536875008
    },
    {
      "type": "training",
      "description": "Training step 214",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:53",
      "total_flops_so_far": 307912688916480.0,
      "budget_used_percent": 0.30791268891648
    },
    {
      "type": "training",
      "description": "Training step 215",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:53",
      "total_flops_so_far": 309344840957952.0,
      "budget_used_percent": 0.309344840957952
    },
    {
      "type": "training",
      "description": "Training step 216",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:53",
      "total_flops_so_far": 310776992999424.0,
      "budget_used_percent": 0.31077699299942396
    },
    {
      "type": "training",
      "description": "Training step 217",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:53",
      "total_flops_so_far": 312209145040896.0,
      "budget_used_percent": 0.31220914504089603
    },
    {
      "type": "training",
      "description": "Training step 218",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:53",
      "total_flops_so_far": 313641297082368.0,
      "budget_used_percent": 0.313641297082368
    },
    {
      "type": "training",
      "description": "Training step 219",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:54",
      "total_flops_so_far": 315073449123840.0,
      "budget_used_percent": 0.31507344912384
    },
    {
      "type": "training",
      "description": "Training step 220",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:54",
      "total_flops_so_far": 316505601165312.0,
      "budget_used_percent": 0.316505601165312
    },
    {
      "type": "training",
      "description": "Training step 221",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:54",
      "total_flops_so_far": 317937753206784.0,
      "budget_used_percent": 0.317937753206784
    },
    {
      "type": "training",
      "description": "Training step 222",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:54",
      "total_flops_so_far": 319369905248256.0,
      "budget_used_percent": 0.319369905248256
    },
    {
      "type": "training",
      "description": "Training step 223",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:54",
      "total_flops_so_far": 320802057289728.0,
      "budget_used_percent": 0.320802057289728
    },
    {
      "type": "training",
      "description": "Training step 224",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:54",
      "total_flops_so_far": 322234209331200.0,
      "budget_used_percent": 0.3222342093312
    },
    {
      "type": "training",
      "description": "Training step 225",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:54",
      "total_flops_so_far": 323666361372672.0,
      "budget_used_percent": 0.323666361372672
    },
    {
      "type": "training",
      "description": "Training step 226",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:54",
      "total_flops_so_far": 325098513414144.0,
      "budget_used_percent": 0.32509851341414403
    },
    {
      "type": "training",
      "description": "Training step 227",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:54",
      "total_flops_so_far": 326530665455616.0,
      "budget_used_percent": 0.326530665455616
    },
    {
      "type": "training",
      "description": "Training step 228",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:55",
      "total_flops_so_far": 327962817497088.0,
      "budget_used_percent": 0.327962817497088
    },
    {
      "type": "training",
      "description": "Training step 229",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:55",
      "total_flops_so_far": 329394969538560.0,
      "budget_used_percent": 0.32939496953855996
    },
    {
      "type": "training",
      "description": "Training step 230",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:55",
      "total_flops_so_far": 330827121580032.0,
      "budget_used_percent": 0.330827121580032
    },
    {
      "type": "training",
      "description": "Training step 231",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:55",
      "total_flops_so_far": 332259273621504.0,
      "budget_used_percent": 0.332259273621504
    },
    {
      "type": "training",
      "description": "Training step 232",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:55",
      "total_flops_so_far": 333691425662976.0,
      "budget_used_percent": 0.333691425662976
    },
    {
      "type": "training",
      "description": "Training step 233",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:55",
      "total_flops_so_far": 335123577704448.0,
      "budget_used_percent": 0.335123577704448
    },
    {
      "type": "training",
      "description": "Training step 234",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:55",
      "total_flops_so_far": 336555729745920.0,
      "budget_used_percent": 0.33655572974592
    },
    {
      "type": "training",
      "description": "Training step 235",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:55",
      "total_flops_so_far": 337987881787392.0,
      "budget_used_percent": 0.337987881787392
    },
    {
      "type": "training",
      "description": "Training step 236",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:56",
      "total_flops_so_far": 339420033828864.0,
      "budget_used_percent": 0.339420033828864
    },
    {
      "type": "training",
      "description": "Training step 237",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:56",
      "total_flops_so_far": 340852185870336.0,
      "budget_used_percent": 0.340852185870336
    },
    {
      "type": "training",
      "description": "Training step 238",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:56",
      "total_flops_so_far": 342284337911808.0,
      "budget_used_percent": 0.342284337911808
    },
    {
      "type": "training",
      "description": "Training step 239",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:56",
      "total_flops_so_far": 343716489953280.0,
      "budget_used_percent": 0.34371648995328
    },
    {
      "type": "training",
      "description": "Training step 240",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:56",
      "total_flops_so_far": 345148641994752.0,
      "budget_used_percent": 0.345148641994752
    },
    {
      "type": "training",
      "description": "Training step 241",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:56",
      "total_flops_so_far": 346580794036224.0,
      "budget_used_percent": 0.346580794036224
    },
    {
      "type": "training",
      "description": "Training step 242",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:56",
      "total_flops_so_far": 348012946077696.0,
      "budget_used_percent": 0.348012946077696
    },
    {
      "type": "training",
      "description": "Training step 243",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:56",
      "total_flops_so_far": 349445098119168.0,
      "budget_used_percent": 0.349445098119168
    },
    {
      "type": "training",
      "description": "Training step 244",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:57",
      "total_flops_so_far": 350877250160640.0,
      "budget_used_percent": 0.35087725016064
    },
    {
      "type": "training",
      "description": "Training step 245",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:57",
      "total_flops_so_far": 352309402202112.0,
      "budget_used_percent": 0.352309402202112
    },
    {
      "type": "training",
      "description": "Training step 246",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:57",
      "total_flops_so_far": 353741554243584.0,
      "budget_used_percent": 0.353741554243584
    },
    {
      "type": "training",
      "description": "Training step 247",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:57",
      "total_flops_so_far": 355173706285056.0,
      "budget_used_percent": 0.355173706285056
    },
    {
      "type": "training",
      "description": "Training step 248",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:57",
      "total_flops_so_far": 356605858326528.0,
      "budget_used_percent": 0.35660585832652797
    },
    {
      "type": "training",
      "description": "Training step 249",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:57",
      "total_flops_so_far": 358038010368000.0,
      "budget_used_percent": 0.35803801036800004
    },
    {
      "type": "training",
      "description": "Training step 250",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:57",
      "total_flops_so_far": 359470162409472.0,
      "budget_used_percent": 0.359470162409472
    },
    {
      "type": "training",
      "description": "Training step 251",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:57",
      "total_flops_so_far": 360902314450944.0,
      "budget_used_percent": 0.360902314450944
    },
    {
      "type": "training",
      "description": "Training step 252",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:58",
      "total_flops_so_far": 362334466492416.0,
      "budget_used_percent": 0.362334466492416
    },
    {
      "type": "training",
      "description": "Training step 253",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:58",
      "total_flops_so_far": 363766618533888.0,
      "budget_used_percent": 0.363766618533888
    },
    {
      "type": "training",
      "description": "Training step 254",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:58",
      "total_flops_so_far": 365198770575360.0,
      "budget_used_percent": 0.36519877057536
    },
    {
      "type": "training",
      "description": "Training step 255",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:58",
      "total_flops_so_far": 366630922616832.0,
      "budget_used_percent": 0.366630922616832
    },
    {
      "type": "training",
      "description": "Training step 256",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:58",
      "total_flops_so_far": 368063074658304.0,
      "budget_used_percent": 0.368063074658304
    },
    {
      "type": "training",
      "description": "Training step 257",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:58",
      "total_flops_so_far": 369495226699776.0,
      "budget_used_percent": 0.36949522669977597
    },
    {
      "type": "training",
      "description": "Training step 258",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:58",
      "total_flops_so_far": 370927378741248.0,
      "budget_used_percent": 0.37092737874124804
    },
    {
      "type": "training",
      "description": "Training step 259",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:58",
      "total_flops_so_far": 372359530782720.0,
      "budget_used_percent": 0.37235953078272
    },
    {
      "type": "training",
      "description": "Training step 260",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:59",
      "total_flops_so_far": 373791682824192.0,
      "budget_used_percent": 0.373791682824192
    },
    {
      "type": "training",
      "description": "Training step 261",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:59",
      "total_flops_so_far": 375223834865664.0,
      "budget_used_percent": 0.375223834865664
    },
    {
      "type": "training",
      "description": "Training step 262",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:59",
      "total_flops_so_far": 376655986907136.0,
      "budget_used_percent": 0.37665598690713603
    },
    {
      "type": "training",
      "description": "Training step 263",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:59",
      "total_flops_so_far": 378088138948608.0,
      "budget_used_percent": 0.378088138948608
    },
    {
      "type": "training",
      "description": "Training step 264",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:59",
      "total_flops_so_far": 379520290990080.0,
      "budget_used_percent": 0.37952029099008
    },
    {
      "type": "training",
      "description": "Training step 265",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:59",
      "total_flops_so_far": 380952443031552.0,
      "budget_used_percent": 0.380952443031552
    },
    {
      "type": "training",
      "description": "Training step 266",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:59",
      "total_flops_so_far": 382384595073024.0,
      "budget_used_percent": 0.38238459507302397
    },
    {
      "type": "training",
      "description": "Training step 267",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:59",
      "total_flops_so_far": 383816747114496.0,
      "budget_used_percent": 0.383816747114496
    },
    {
      "type": "training",
      "description": "Training step 268",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:59",
      "total_flops_so_far": 385248899155968.0,
      "budget_used_percent": 0.385248899155968
    },
    {
      "type": "training",
      "description": "Training step 269",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:00",
      "total_flops_so_far": 386681051197440.0,
      "budget_used_percent": 0.38668105119744
    },
    {
      "type": "training",
      "description": "Training step 270",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:00",
      "total_flops_so_far": 388113203238912.0,
      "budget_used_percent": 0.38811320323891196
    },
    {
      "type": "training",
      "description": "Training step 271",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:00",
      "total_flops_so_far": 389545355280384.0,
      "budget_used_percent": 0.38954535528038403
    },
    {
      "type": "training",
      "description": "Training step 272",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:00",
      "total_flops_so_far": 390977507321856.0,
      "budget_used_percent": 0.39097750732185593
    },
    {
      "type": "training",
      "description": "Training step 273",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:00",
      "total_flops_so_far": 392409659363328.0,
      "budget_used_percent": 0.392409659363328
    },
    {
      "type": "training",
      "description": "Training step 274",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:00",
      "total_flops_so_far": 393841811404800.0,
      "budget_used_percent": 0.3938418114048
    },
    {
      "type": "training",
      "description": "Training step 275",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:00",
      "total_flops_so_far": 395273963446272.0,
      "budget_used_percent": 0.39527396344627197
    },
    {
      "type": "training",
      "description": "Training step 276",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:00",
      "total_flops_so_far": 396706115487744.0,
      "budget_used_percent": 0.396706115487744
    },
    {
      "type": "training",
      "description": "Training step 277",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:01",
      "total_flops_so_far": 398138267529216.0,
      "budget_used_percent": 0.398138267529216
    },
    {
      "type": "training",
      "description": "Training step 278",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:01",
      "total_flops_so_far": 399570419570688.0,
      "budget_used_percent": 0.39957041957068795
    },
    {
      "type": "training",
      "description": "Training step 279",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:01",
      "total_flops_so_far": 401002571612160.0,
      "budget_used_percent": 0.40100257161216
    },
    {
      "type": "training",
      "description": "Training step 280",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:01",
      "total_flops_so_far": 402434723653632.0,
      "budget_used_percent": 0.40243472365363203
    },
    {
      "type": "training",
      "description": "Training step 281",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:01",
      "total_flops_so_far": 403866875695104.0,
      "budget_used_percent": 0.403866875695104
    },
    {
      "type": "training",
      "description": "Training step 282",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:01",
      "total_flops_so_far": 405299027736576.0,
      "budget_used_percent": 0.405299027736576
    },
    {
      "type": "training",
      "description": "Training step 283",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:01",
      "total_flops_so_far": 406731179778048.0,
      "budget_used_percent": 0.406731179778048
    },
    {
      "type": "training",
      "description": "Training step 284",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:01",
      "total_flops_so_far": 408163331819520.0,
      "budget_used_percent": 0.40816333181951997
    },
    {
      "type": "training",
      "description": "Training step 285",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:02",
      "total_flops_so_far": 409595483860992.0,
      "budget_used_percent": 0.409595483860992
    },
    {
      "type": "training",
      "description": "Training step 286",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:02",
      "total_flops_so_far": 411027635902464.0,
      "budget_used_percent": 0.41102763590246405
    },
    {
      "type": "training",
      "description": "Training step 287",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:02",
      "total_flops_so_far": 412459787943936.0,
      "budget_used_percent": 0.41245978794393595
    },
    {
      "type": "training",
      "description": "Training step 288",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:02",
      "total_flops_so_far": 413891939985408.0,
      "budget_used_percent": 0.413891939985408
    },
    {
      "type": "training",
      "description": "Training step 289",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:02",
      "total_flops_so_far": 415324092026880.0,
      "budget_used_percent": 0.41532409202688003
    },
    {
      "type": "training",
      "description": "Training step 290",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:02",
      "total_flops_so_far": 416756244068352.0,
      "budget_used_percent": 0.416756244068352
    },
    {
      "type": "training",
      "description": "Training step 291",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:02",
      "total_flops_so_far": 418188396109824.0,
      "budget_used_percent": 0.418188396109824
    },
    {
      "type": "training",
      "description": "Training step 292",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:02",
      "total_flops_so_far": 419620548151296.0,
      "budget_used_percent": 0.419620548151296
    },
    {
      "type": "training",
      "description": "Training step 293",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:03",
      "total_flops_so_far": 421052700192768.0,
      "budget_used_percent": 0.42105270019276797
    },
    {
      "type": "training",
      "description": "Training step 294",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:03",
      "total_flops_so_far": 422484852234240.0,
      "budget_used_percent": 0.42248485223424
    },
    {
      "type": "training",
      "description": "Training step 295",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:03",
      "total_flops_so_far": 423917004275712.0,
      "budget_used_percent": 0.42391700427571205
    },
    {
      "type": "training",
      "description": "Training step 296",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:03",
      "total_flops_so_far": 425349156317184.0,
      "budget_used_percent": 0.42534915631718395
    },
    {
      "type": "training",
      "description": "Training step 297",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:03",
      "total_flops_so_far": 426781308358656.0,
      "budget_used_percent": 0.426781308358656
    },
    {
      "type": "training",
      "description": "Training step 298",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:03",
      "total_flops_so_far": 428213460400128.0,
      "budget_used_percent": 0.42821346040012803
    },
    {
      "type": "training",
      "description": "Training step 299",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:03",
      "total_flops_so_far": 429645612441600.0,
      "budget_used_percent": 0.4296456124416
    },
    {
      "type": "training",
      "description": "Training step 300",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:03",
      "total_flops_so_far": 431077764483072.0,
      "budget_used_percent": 0.431077764483072
    },
    {
      "type": "training",
      "description": "Training step 301",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:04",
      "total_flops_so_far": 432509916524544.0,
      "budget_used_percent": 0.432509916524544
    },
    {
      "type": "training",
      "description": "Training step 302",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:04",
      "total_flops_so_far": 433942068566016.0,
      "budget_used_percent": 0.43394206856601597
    },
    {
      "type": "training",
      "description": "Training step 303",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:04",
      "total_flops_so_far": 435374220607488.0,
      "budget_used_percent": 0.435374220607488
    },
    {
      "type": "training",
      "description": "Training step 304",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:04",
      "total_flops_so_far": 436806372648960.0,
      "budget_used_percent": 0.43680637264896005
    },
    {
      "type": "training",
      "description": "Training step 305",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:04",
      "total_flops_so_far": 438238524690432.0,
      "budget_used_percent": 0.438238524690432
    },
    {
      "type": "training",
      "description": "Training step 306",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:04",
      "total_flops_so_far": 439670676731904.0,
      "budget_used_percent": 0.439670676731904
    },
    {
      "type": "training",
      "description": "Training step 307",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:04",
      "total_flops_so_far": 441102828773376.0,
      "budget_used_percent": 0.44110282877337603
    },
    {
      "type": "training",
      "description": "Training step 308",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:04",
      "total_flops_so_far": 442534980814848.0,
      "budget_used_percent": 0.442534980814848
    },
    {
      "type": "training",
      "description": "Training step 309",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:05",
      "total_flops_so_far": 443967132856320.0,
      "budget_used_percent": 0.44396713285632
    },
    {
      "type": "training",
      "description": "Training step 310",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:05",
      "total_flops_so_far": 445399284897792.0,
      "budget_used_percent": 0.44539928489779196
    },
    {
      "type": "training",
      "description": "Training step 311",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:05",
      "total_flops_so_far": 446831436939264.0,
      "budget_used_percent": 0.44683143693926397
    },
    {
      "type": "training",
      "description": "Training step 312",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:05",
      "total_flops_so_far": 448263588980736.0,
      "budget_used_percent": 0.44826358898073604
    },
    {
      "type": "training",
      "description": "Training step 313",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:05",
      "total_flops_so_far": 449695741022208.0,
      "budget_used_percent": 0.44969574102220794
    },
    {
      "type": "training",
      "description": "Training step 314",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:05",
      "total_flops_so_far": 451127893063680.0,
      "budget_used_percent": 0.45112789306368
    },
    {
      "type": "training",
      "description": "Training step 315",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:05",
      "total_flops_so_far": 452560045105152.0,
      "budget_used_percent": 0.452560045105152
    },
    {
      "type": "training",
      "description": "Training step 316",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:05",
      "total_flops_so_far": 453992197146624.0,
      "budget_used_percent": 0.453992197146624
    },
    {
      "type": "training",
      "description": "Training step 317",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:06",
      "total_flops_so_far": 455424349188096.0,
      "budget_used_percent": 0.455424349188096
    },
    {
      "type": "training",
      "description": "Training step 318",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:06",
      "total_flops_so_far": 456856501229568.0,
      "budget_used_percent": 0.456856501229568
    },
    {
      "type": "training",
      "description": "Training step 319",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:06",
      "total_flops_so_far": 458288653271040.0,
      "budget_used_percent": 0.45828865327103996
    },
    {
      "type": "training",
      "description": "Training step 320",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:06",
      "total_flops_so_far": 459720805312512.0,
      "budget_used_percent": 0.45972080531251197
    },
    {
      "type": "training",
      "description": "Training step 321",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:06",
      "total_flops_so_far": 461152957353984.0,
      "budget_used_percent": 0.46115295735398404
    },
    {
      "type": "training",
      "description": "Training step 322",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:06",
      "total_flops_so_far": 462585109395456.0,
      "budget_used_percent": 0.46258510939545594
    },
    {
      "type": "training",
      "description": "Training step 323",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:06",
      "total_flops_so_far": 464017261436928.0,
      "budget_used_percent": 0.464017261436928
    },
    {
      "type": "training",
      "description": "Training step 324",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:06",
      "total_flops_so_far": 465449413478400.0,
      "budget_used_percent": 0.4654494134784
    },
    {
      "type": "training",
      "description": "Training step 325",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:07",
      "total_flops_so_far": 466881565519872.0,
      "budget_used_percent": 0.466881565519872
    },
    {
      "type": "training",
      "description": "Training step 326",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:07",
      "total_flops_so_far": 468313717561344.0,
      "budget_used_percent": 0.468313717561344
    },
    {
      "type": "training",
      "description": "Training step 327",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:07",
      "total_flops_so_far": 469745869602816.0,
      "budget_used_percent": 0.46974586960281606
    },
    {
      "type": "training",
      "description": "Training step 328",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:07",
      "total_flops_so_far": 471178021644288.0,
      "budget_used_percent": 0.47117802164428796
    },
    {
      "type": "training",
      "description": "Training step 329",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:07",
      "total_flops_so_far": 472610173685760.0,
      "budget_used_percent": 0.47261017368576
    },
    {
      "type": "training",
      "description": "Training step 330",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:07",
      "total_flops_so_far": 474042325727232.0,
      "budget_used_percent": 0.47404232572723204
    },
    {
      "type": "training",
      "description": "Training step 331",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:07",
      "total_flops_so_far": 475474477768704.0,
      "budget_used_percent": 0.475474477768704
    },
    {
      "type": "training",
      "description": "Training step 332",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:07",
      "total_flops_so_far": 476906629810176.0,
      "budget_used_percent": 0.476906629810176
    },
    {
      "type": "training",
      "description": "Training step 333",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:07",
      "total_flops_so_far": 478338781851648.0,
      "budget_used_percent": 0.478338781851648
    },
    {
      "type": "training",
      "description": "Training step 334",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:08",
      "total_flops_so_far": 479770933893120.0,
      "budget_used_percent": 0.47977093389312
    },
    {
      "type": "training",
      "description": "Training step 335",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:08",
      "total_flops_so_far": 481203085934592.0,
      "budget_used_percent": 0.481203085934592
    },
    {
      "type": "training",
      "description": "Training step 336",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:08",
      "total_flops_so_far": 482635237976064.0,
      "budget_used_percent": 0.48263523797606406
    },
    {
      "type": "training",
      "description": "Training step 337",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:08",
      "total_flops_so_far": 484067390017536.0,
      "budget_used_percent": 0.48406739001753596
    },
    {
      "type": "training",
      "description": "Training step 338",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:08",
      "total_flops_so_far": 485499542059008.0,
      "budget_used_percent": 0.485499542059008
    },
    {
      "type": "training",
      "description": "Training step 339",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:08",
      "total_flops_so_far": 486931694100480.0,
      "budget_used_percent": 0.48693169410048004
    },
    {
      "type": "training",
      "description": "Training step 340",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:08",
      "total_flops_so_far": 488363846141952.0,
      "budget_used_percent": 0.488363846141952
    },
    {
      "type": "training",
      "description": "Training step 341",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:08",
      "total_flops_so_far": 489795998183424.0,
      "budget_used_percent": 0.489795998183424
    },
    {
      "type": "training",
      "description": "Training step 342",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:09",
      "total_flops_so_far": 491228150224896.0,
      "budget_used_percent": 0.491228150224896
    },
    {
      "type": "training",
      "description": "Training step 343",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:09",
      "total_flops_so_far": 492660302266368.0,
      "budget_used_percent": 0.492660302266368
    },
    {
      "type": "training",
      "description": "Training step 344",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:09",
      "total_flops_so_far": 494092454307840.0,
      "budget_used_percent": 0.49409245430784
    },
    {
      "type": "training",
      "description": "Training step 345",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:09",
      "total_flops_so_far": 495524606349312.0,
      "budget_used_percent": 0.49552460634931195
    },
    {
      "type": "training",
      "description": "Training step 346",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:09",
      "total_flops_so_far": 496956758390784.0,
      "budget_used_percent": 0.496956758390784
    },
    {
      "type": "training",
      "description": "Training step 347",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:09",
      "total_flops_so_far": 498388910432256.0,
      "budget_used_percent": 0.498388910432256
    },
    {
      "type": "training",
      "description": "Training step 348",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:09",
      "total_flops_so_far": 499821062473728.0,
      "budget_used_percent": 0.499821062473728
    },
    {
      "type": "training",
      "description": "Training step 349",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:09",
      "total_flops_so_far": 501253214515200.0,
      "budget_used_percent": 0.5012532145152
    },
    {
      "type": "training",
      "description": "Training step 350",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:10",
      "total_flops_so_far": 502685366556672.0,
      "budget_used_percent": 0.5026853665566721
    },
    {
      "type": "training",
      "description": "Training step 351",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:10",
      "total_flops_so_far": 504117518598144.0,
      "budget_used_percent": 0.5041175185981439
    },
    {
      "type": "training",
      "description": "Training step 352",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:10",
      "total_flops_so_far": 505549670639616.0,
      "budget_used_percent": 0.505549670639616
    },
    {
      "type": "training",
      "description": "Training step 353",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:10",
      "total_flops_so_far": 506981822681088.0,
      "budget_used_percent": 0.506981822681088
    },
    {
      "type": "training",
      "description": "Training step 354",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:10",
      "total_flops_so_far": 508413974722560.0,
      "budget_used_percent": 0.50841397472256
    },
    {
      "type": "training",
      "description": "Training step 355",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:10",
      "total_flops_so_far": 509846126764032.0,
      "budget_used_percent": 0.509846126764032
    },
    {
      "type": "training",
      "description": "Training step 356",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:10",
      "total_flops_so_far": 511278278805504.0,
      "budget_used_percent": 0.511278278805504
    },
    {
      "type": "training",
      "description": "Training step 357",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:10",
      "total_flops_so_far": 512710430846976.0,
      "budget_used_percent": 0.512710430846976
    },
    {
      "type": "training",
      "description": "Training step 358",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:11",
      "total_flops_so_far": 514142582888448.0,
      "budget_used_percent": 0.514142582888448
    },
    {
      "type": "training",
      "description": "Training step 359",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:11",
      "total_flops_so_far": 515574734929920.0,
      "budget_used_percent": 0.51557473492992
    },
    {
      "type": "training",
      "description": "Training step 360",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:11",
      "total_flops_so_far": 517006886971392.0,
      "budget_used_percent": 0.517006886971392
    },
    {
      "type": "training",
      "description": "Training step 361",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:11",
      "total_flops_so_far": 518439039012864.0,
      "budget_used_percent": 0.518439039012864
    },
    {
      "type": "training",
      "description": "Training step 362",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:11",
      "total_flops_so_far": 519871191054336.0,
      "budget_used_percent": 0.519871191054336
    },
    {
      "type": "training",
      "description": "Training step 363",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:11",
      "total_flops_so_far": 521303343095808.0,
      "budget_used_percent": 0.521303343095808
    },
    {
      "type": "training",
      "description": "Training step 364",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:11",
      "total_flops_so_far": 522735495137280.0,
      "budget_used_percent": 0.52273549513728
    },
    {
      "type": "training",
      "description": "Training step 365",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:11",
      "total_flops_so_far": 524167647178752.0,
      "budget_used_percent": 0.5241676471787521
    },
    {
      "type": "training",
      "description": "Training step 366",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:12",
      "total_flops_so_far": 525599799220224.0,
      "budget_used_percent": 0.5255997992202239
    },
    {
      "type": "training",
      "description": "Training step 367",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:12",
      "total_flops_so_far": 527031951261696.0,
      "budget_used_percent": 0.527031951261696
    },
    {
      "type": "training",
      "description": "Training step 368",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:12",
      "total_flops_so_far": 528464103303168.0,
      "budget_used_percent": 0.5284641033031681
    },
    {
      "type": "training",
      "description": "Training step 369",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:12",
      "total_flops_so_far": 529896255344640.0,
      "budget_used_percent": 0.52989625534464
    },
    {
      "type": "training",
      "description": "Training step 370",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:12",
      "total_flops_so_far": 531328407386112.0,
      "budget_used_percent": 0.531328407386112
    },
    {
      "type": "training",
      "description": "Training step 371",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:12",
      "total_flops_so_far": 532760559427584.0,
      "budget_used_percent": 0.532760559427584
    },
    {
      "type": "training",
      "description": "Training step 372",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:12",
      "total_flops_so_far": 534192711469056.0,
      "budget_used_percent": 0.534192711469056
    },
    {
      "type": "training",
      "description": "Training step 373",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:12",
      "total_flops_so_far": 535624863510528.0,
      "budget_used_percent": 0.535624863510528
    },
    {
      "type": "training",
      "description": "Training step 374",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:13",
      "total_flops_so_far": 537057015552000.0,
      "budget_used_percent": 0.537057015552
    },
    {
      "type": "training",
      "description": "Training step 375",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:13",
      "total_flops_so_far": 538489167593472.0,
      "budget_used_percent": 0.538489167593472
    },
    {
      "type": "training",
      "description": "Training step 376",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:13",
      "total_flops_so_far": 539921319634944.0,
      "budget_used_percent": 0.539921319634944
    },
    {
      "type": "training",
      "description": "Training step 377",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:13",
      "total_flops_so_far": 541353471676416.0,
      "budget_used_percent": 0.541353471676416
    },
    {
      "type": "training",
      "description": "Training step 378",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:13",
      "total_flops_so_far": 542785623717888.0,
      "budget_used_percent": 0.542785623717888
    },
    {
      "type": "training",
      "description": "Training step 379",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:13",
      "total_flops_so_far": 544217775759360.0,
      "budget_used_percent": 0.54421777575936
    },
    {
      "type": "training",
      "description": "Training step 380",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:13",
      "total_flops_so_far": 545649927800832.0,
      "budget_used_percent": 0.545649927800832
    },
    {
      "type": "training",
      "description": "Training step 381",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:13",
      "total_flops_so_far": 547082079842304.0,
      "budget_used_percent": 0.547082079842304
    },
    {
      "type": "training",
      "description": "Training step 382",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:14",
      "total_flops_so_far": 548514231883776.0,
      "budget_used_percent": 0.548514231883776
    },
    {
      "type": "training",
      "description": "Training step 383",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:14",
      "total_flops_so_far": 549946383925248.0,
      "budget_used_percent": 0.549946383925248
    },
    {
      "type": "training",
      "description": "Training step 384",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:14",
      "total_flops_so_far": 551378535966720.0,
      "budget_used_percent": 0.55137853596672
    },
    {
      "type": "training",
      "description": "Training step 385",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:14",
      "total_flops_so_far": 552810688008192.0,
      "budget_used_percent": 0.552810688008192
    },
    {
      "type": "training",
      "description": "Training step 386",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:14",
      "total_flops_so_far": 554242840049664.0,
      "budget_used_percent": 0.554242840049664
    },
    {
      "type": "training",
      "description": "Training step 387",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:14",
      "total_flops_so_far": 555674992091136.0,
      "budget_used_percent": 0.555674992091136
    },
    {
      "type": "training",
      "description": "Training step 388",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:14",
      "total_flops_so_far": 557107144132608.0,
      "budget_used_percent": 0.557107144132608
    },
    {
      "type": "training",
      "description": "Training step 389",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:14",
      "total_flops_so_far": 558539296174080.0,
      "budget_used_percent": 0.5585392961740799
    },
    {
      "type": "training",
      "description": "Training step 390",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:15",
      "total_flops_so_far": 559971448215552.0,
      "budget_used_percent": 0.559971448215552
    },
    {
      "type": "training",
      "description": "Training step 391",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:15",
      "total_flops_so_far": 561403600257024.0,
      "budget_used_percent": 0.5614036002570241
    },
    {
      "type": "training",
      "description": "Training step 392",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:15",
      "total_flops_so_far": 562835752298496.0,
      "budget_used_percent": 0.5628357522984959
    },
    {
      "type": "training",
      "description": "Training step 393",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:15",
      "total_flops_so_far": 564267904339968.0,
      "budget_used_percent": 0.564267904339968
    },
    {
      "type": "training",
      "description": "Training step 394",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:15",
      "total_flops_so_far": 565700056381440.0,
      "budget_used_percent": 0.56570005638144
    },
    {
      "type": "training",
      "description": "Training step 395",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:15",
      "total_flops_so_far": 567132208422912.0,
      "budget_used_percent": 0.567132208422912
    },
    {
      "type": "training",
      "description": "Training step 396",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:15",
      "total_flops_so_far": 568564360464384.0,
      "budget_used_percent": 0.568564360464384
    },
    {
      "type": "training",
      "description": "Training step 397",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:15",
      "total_flops_so_far": 569996512505856.0,
      "budget_used_percent": 0.569996512505856
    },
    {
      "type": "training",
      "description": "Training step 398",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:16",
      "total_flops_so_far": 571428664547328.0,
      "budget_used_percent": 0.571428664547328
    },
    {
      "type": "training",
      "description": "Training step 399",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:16",
      "total_flops_so_far": 572860816588800.0,
      "budget_used_percent": 0.5728608165888
    },
    {
      "type": "training",
      "description": "Training step 400",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:16",
      "total_flops_so_far": 574292968630272.0,
      "budget_used_percent": 0.574292968630272
    },
    {
      "type": "training",
      "description": "Training step 401",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:16",
      "total_flops_so_far": 575725120671744.0,
      "budget_used_percent": 0.575725120671744
    },
    {
      "type": "training",
      "description": "Training step 402",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:16",
      "total_flops_so_far": 577157272713216.0,
      "budget_used_percent": 0.577157272713216
    },
    {
      "type": "training",
      "description": "Training step 403",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:16",
      "total_flops_so_far": 578589424754688.0,
      "budget_used_percent": 0.578589424754688
    },
    {
      "type": "training",
      "description": "Training step 404",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:16",
      "total_flops_so_far": 580021576796160.0,
      "budget_used_percent": 0.58002157679616
    },
    {
      "type": "training",
      "description": "Training step 405",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:16",
      "total_flops_so_far": 581453728837632.0,
      "budget_used_percent": 0.581453728837632
    },
    {
      "type": "training",
      "description": "Training step 406",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:17",
      "total_flops_so_far": 582885880879104.0,
      "budget_used_percent": 0.582885880879104
    },
    {
      "type": "training",
      "description": "Training step 407",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:17",
      "total_flops_so_far": 584318032920576.0,
      "budget_used_percent": 0.5843180329205759
    },
    {
      "type": "training",
      "description": "Training step 408",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:17",
      "total_flops_so_far": 585750184962048.0,
      "budget_used_percent": 0.585750184962048
    },
    {
      "type": "training",
      "description": "Training step 409",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:17",
      "total_flops_so_far": 587182337003520.0,
      "budget_used_percent": 0.5871823370035201
    },
    {
      "type": "training",
      "description": "Training step 410",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:17",
      "total_flops_so_far": 588614489044992.0,
      "budget_used_percent": 0.588614489044992
    },
    {
      "type": "training",
      "description": "Training step 411",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:17",
      "total_flops_so_far": 590046641086464.0,
      "budget_used_percent": 0.590046641086464
    },
    {
      "type": "training",
      "description": "Training step 412",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:17",
      "total_flops_so_far": 591478793127936.0,
      "budget_used_percent": 0.591478793127936
    },
    {
      "type": "training",
      "description": "Training step 413",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:17",
      "total_flops_so_far": 592910945169408.0,
      "budget_used_percent": 0.592910945169408
    },
    {
      "type": "training",
      "description": "Training step 414",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:18",
      "total_flops_so_far": 594343097210880.0,
      "budget_used_percent": 0.59434309721088
    },
    {
      "type": "training",
      "description": "Training step 415",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:18",
      "total_flops_so_far": 595775249252352.0,
      "budget_used_percent": 0.595775249252352
    },
    {
      "type": "training",
      "description": "Training step 416",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:18",
      "total_flops_so_far": 597207401293824.0,
      "budget_used_percent": 0.597207401293824
    },
    {
      "type": "training",
      "description": "Training step 417",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:18",
      "total_flops_so_far": 598639553335296.0,
      "budget_used_percent": 0.5986395533352961
    },
    {
      "type": "training",
      "description": "Training step 418",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:18",
      "total_flops_so_far": 600071705376768.0,
      "budget_used_percent": 0.6000717053767679
    },
    {
      "type": "training",
      "description": "Training step 419",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:18",
      "total_flops_so_far": 601503857418240.0,
      "budget_used_percent": 0.60150385741824
    },
    {
      "type": "training",
      "description": "Training step 420",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:18",
      "total_flops_so_far": 602936009459712.0,
      "budget_used_percent": 0.602936009459712
    },
    {
      "type": "training",
      "description": "Training step 421",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:18",
      "total_flops_so_far": 604368161501184.0,
      "budget_used_percent": 0.604368161501184
    },
    {
      "type": "training",
      "description": "Training step 422",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:19",
      "total_flops_so_far": 605800313542656.0,
      "budget_used_percent": 0.605800313542656
    },
    {
      "type": "training",
      "description": "Training step 423",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:19",
      "total_flops_so_far": 607232465584128.0,
      "budget_used_percent": 0.607232465584128
    },
    {
      "type": "training",
      "description": "Training step 424",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:19",
      "total_flops_so_far": 608664617625600.0,
      "budget_used_percent": 0.6086646176256
    },
    {
      "type": "training",
      "description": "Training step 425",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:19",
      "total_flops_so_far": 610096769667072.0,
      "budget_used_percent": 0.610096769667072
    },
    {
      "type": "training",
      "description": "Training step 426",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:19",
      "total_flops_so_far": 611528921708544.0,
      "budget_used_percent": 0.611528921708544
    },
    {
      "type": "training",
      "description": "Training step 427",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:19",
      "total_flops_so_far": 612961073750016.0,
      "budget_used_percent": 0.612961073750016
    },
    {
      "type": "training",
      "description": "Training step 428",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:19",
      "total_flops_so_far": 614393225791488.0,
      "budget_used_percent": 0.614393225791488
    },
    {
      "type": "training",
      "description": "Training step 429",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:19",
      "total_flops_so_far": 615825377832960.0,
      "budget_used_percent": 0.61582537783296
    },
    {
      "type": "training",
      "description": "Training step 430",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:20",
      "total_flops_so_far": 617257529874432.0,
      "budget_used_percent": 0.6172575298744319
    },
    {
      "type": "training",
      "description": "Training step 431",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:20",
      "total_flops_so_far": 618689681915904.0,
      "budget_used_percent": 0.618689681915904
    },
    {
      "type": "training",
      "description": "Training step 432",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:20",
      "total_flops_so_far": 620121833957376.0,
      "budget_used_percent": 0.6201218339573761
    },
    {
      "type": "training",
      "description": "Training step 433",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:20",
      "total_flops_so_far": 621553985998848.0,
      "budget_used_percent": 0.6215539859988479
    },
    {
      "type": "training",
      "description": "Training step 434",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:20",
      "total_flops_so_far": 622986138040320.0,
      "budget_used_percent": 0.62298613804032
    },
    {
      "type": "training",
      "description": "Training step 435",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:20",
      "total_flops_so_far": 624418290081792.0,
      "budget_used_percent": 0.6244182900817921
    },
    {
      "type": "training",
      "description": "Training step 436",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:20",
      "total_flops_so_far": 625850442123264.0,
      "budget_used_percent": 0.625850442123264
    },
    {
      "type": "training",
      "description": "Training step 437",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:21",
      "total_flops_so_far": 627282594164736.0,
      "budget_used_percent": 0.627282594164736
    },
    {
      "type": "training",
      "description": "Training step 438",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:21",
      "total_flops_so_far": 628714746206208.0,
      "budget_used_percent": 0.628714746206208
    },
    {
      "type": "training",
      "description": "Training step 439",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:21",
      "total_flops_so_far": 630146898247680.0,
      "budget_used_percent": 0.63014689824768
    },
    {
      "type": "training",
      "description": "Training step 440",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:21",
      "total_flops_so_far": 631579050289152.0,
      "budget_used_percent": 0.631579050289152
    },
    {
      "type": "training",
      "description": "Training step 441",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:21",
      "total_flops_so_far": 633011202330624.0,
      "budget_used_percent": 0.633011202330624
    },
    {
      "type": "training",
      "description": "Training step 442",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:21",
      "total_flops_so_far": 634443354372096.0,
      "budget_used_percent": 0.634443354372096
    },
    {
      "type": "training",
      "description": "Training step 443",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:21",
      "total_flops_so_far": 635875506413568.0,
      "budget_used_percent": 0.635875506413568
    },
    {
      "type": "training",
      "description": "Training step 444",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:21",
      "total_flops_so_far": 637307658455040.0,
      "budget_used_percent": 0.63730765845504
    },
    {
      "type": "training",
      "description": "Training step 445",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:22",
      "total_flops_so_far": 638739810496512.0,
      "budget_used_percent": 0.638739810496512
    },
    {
      "type": "training",
      "description": "Training step 446",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:22",
      "total_flops_so_far": 640171962537984.0,
      "budget_used_percent": 0.640171962537984
    },
    {
      "type": "training",
      "description": "Training step 447",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:22",
      "total_flops_so_far": 641604114579456.0,
      "budget_used_percent": 0.641604114579456
    },
    {
      "type": "training",
      "description": "Training step 448",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:22",
      "total_flops_so_far": 643036266620928.0,
      "budget_used_percent": 0.6430362666209279
    },
    {
      "type": "training",
      "description": "Training step 449",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:22",
      "total_flops_so_far": 644468418662400.0,
      "budget_used_percent": 0.6444684186624
    },
    {
      "type": "training",
      "description": "Training step 450",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:22",
      "total_flops_so_far": 645900570703872.0,
      "budget_used_percent": 0.6459005707038721
    },
    {
      "type": "training",
      "description": "Training step 451",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:22",
      "total_flops_so_far": 647332722745344.0,
      "budget_used_percent": 0.647332722745344
    },
    {
      "type": "training",
      "description": "Training step 452",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:22",
      "total_flops_so_far": 648764874786816.0,
      "budget_used_percent": 0.648764874786816
    },
    {
      "type": "training",
      "description": "Training step 453",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:23",
      "total_flops_so_far": 650197026828288.0,
      "budget_used_percent": 0.6501970268282881
    },
    {
      "type": "training",
      "description": "Training step 454",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:23",
      "total_flops_so_far": 651629178869760.0,
      "budget_used_percent": 0.65162917886976
    },
    {
      "type": "training",
      "description": "Training step 455",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:23",
      "total_flops_so_far": 653061330911232.0,
      "budget_used_percent": 0.653061330911232
    },
    {
      "type": "training",
      "description": "Training step 456",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:23",
      "total_flops_so_far": 654493482952704.0,
      "budget_used_percent": 0.6544934829527039
    },
    {
      "type": "training",
      "description": "Training step 457",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:23",
      "total_flops_so_far": 655925634994176.0,
      "budget_used_percent": 0.655925634994176
    },
    {
      "type": "training",
      "description": "Training step 458",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:23",
      "total_flops_so_far": 657357787035648.0,
      "budget_used_percent": 0.6573577870356481
    },
    {
      "type": "training",
      "description": "Training step 459",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:23",
      "total_flops_so_far": 658789939077120.0,
      "budget_used_percent": 0.6587899390771199
    },
    {
      "type": "training",
      "description": "Training step 460",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:23",
      "total_flops_so_far": 660222091118592.0,
      "budget_used_percent": 0.660222091118592
    },
    {
      "type": "training",
      "description": "Training step 461",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:24",
      "total_flops_so_far": 661654243160064.0,
      "budget_used_percent": 0.661654243160064
    },
    {
      "type": "training",
      "description": "Training step 462",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:24",
      "total_flops_so_far": 663086395201536.0,
      "budget_used_percent": 0.663086395201536
    },
    {
      "type": "training",
      "description": "Training step 463",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:24",
      "total_flops_so_far": 664518547243008.0,
      "budget_used_percent": 0.664518547243008
    },
    {
      "type": "training",
      "description": "Training step 464",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:24",
      "total_flops_so_far": 665950699284480.0,
      "budget_used_percent": 0.66595069928448
    },
    {
      "type": "training",
      "description": "Training step 465",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:24",
      "total_flops_so_far": 667382851325952.0,
      "budget_used_percent": 0.667382851325952
    },
    {
      "type": "training",
      "description": "Training step 466",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:24",
      "total_flops_so_far": 668815003367424.0,
      "budget_used_percent": 0.6688150033674239
    },
    {
      "type": "training",
      "description": "Training step 467",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:24",
      "total_flops_so_far": 670247155408896.0,
      "budget_used_percent": 0.670247155408896
    },
    {
      "type": "training",
      "description": "Training step 468",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:24",
      "total_flops_so_far": 671679307450368.0,
      "budget_used_percent": 0.671679307450368
    },
    {
      "type": "training",
      "description": "Training step 469",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:25",
      "total_flops_so_far": 673111459491840.0,
      "budget_used_percent": 0.67311145949184
    },
    {
      "type": "training",
      "description": "Training step 470",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:25",
      "total_flops_so_far": 674543611533312.0,
      "budget_used_percent": 0.674543611533312
    },
    {
      "type": "training",
      "description": "Training step 471",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:25",
      "total_flops_so_far": 675975763574784.0,
      "budget_used_percent": 0.675975763574784
    },
    {
      "type": "training",
      "description": "Training step 472",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:25",
      "total_flops_so_far": 677407915616256.0,
      "budget_used_percent": 0.677407915616256
    },
    {
      "type": "training",
      "description": "Training step 473",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:25",
      "total_flops_so_far": 678840067657728.0,
      "budget_used_percent": 0.678840067657728
    },
    {
      "type": "training",
      "description": "Training step 474",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:25",
      "total_flops_so_far": 680272219699200.0,
      "budget_used_percent": 0.6802722196991999
    },
    {
      "type": "training",
      "description": "Training step 475",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:25",
      "total_flops_so_far": 681704371740672.0,
      "budget_used_percent": 0.681704371740672
    },
    {
      "type": "training",
      "description": "Training step 476",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:25",
      "total_flops_so_far": 683136523782144.0,
      "budget_used_percent": 0.6831365237821441
    },
    {
      "type": "training",
      "description": "Training step 477",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:26",
      "total_flops_so_far": 684568675823616.0,
      "budget_used_percent": 0.684568675823616
    },
    {
      "type": "training",
      "description": "Training step 478",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:26",
      "total_flops_so_far": 686000827865088.0,
      "budget_used_percent": 0.686000827865088
    },
    {
      "type": "training",
      "description": "Training step 479",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:26",
      "total_flops_so_far": 687432979906560.0,
      "budget_used_percent": 0.68743297990656
    },
    {
      "type": "training",
      "description": "Training step 480",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:26",
      "total_flops_so_far": 688865131948032.0,
      "budget_used_percent": 0.688865131948032
    },
    {
      "type": "training",
      "description": "Training step 481",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:26",
      "total_flops_so_far": 690297283989504.0,
      "budget_used_percent": 0.690297283989504
    },
    {
      "type": "training",
      "description": "Training step 482",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:26",
      "total_flops_so_far": 691729436030976.0,
      "budget_used_percent": 0.691729436030976
    },
    {
      "type": "training",
      "description": "Training step 483",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:26",
      "total_flops_so_far": 693161588072448.0,
      "budget_used_percent": 0.693161588072448
    },
    {
      "type": "training",
      "description": "Training step 484",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:27",
      "total_flops_so_far": 694593740113920.0,
      "budget_used_percent": 0.69459374011392
    },
    {
      "type": "training",
      "description": "Training step 485",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:27",
      "total_flops_so_far": 696025892155392.0,
      "budget_used_percent": 0.696025892155392
    },
    {
      "type": "training",
      "description": "Training step 486",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:27",
      "total_flops_so_far": 697458044196864.0,
      "budget_used_percent": 0.697458044196864
    },
    {
      "type": "training",
      "description": "Training step 487",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:27",
      "total_flops_so_far": 698890196238336.0,
      "budget_used_percent": 0.698890196238336
    },
    {
      "type": "training",
      "description": "Training step 488",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:27",
      "total_flops_so_far": 700322348279808.0,
      "budget_used_percent": 0.700322348279808
    },
    {
      "type": "training",
      "description": "Training step 489",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:27",
      "total_flops_so_far": 701754500321280.0,
      "budget_used_percent": 0.70175450032128
    },
    {
      "type": "training",
      "description": "Training step 490",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:27",
      "total_flops_so_far": 703186652362752.0,
      "budget_used_percent": 0.703186652362752
    },
    {
      "type": "training",
      "description": "Training step 491",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:27",
      "total_flops_so_far": 704618804404224.0,
      "budget_used_percent": 0.704618804404224
    },
    {
      "type": "training",
      "description": "Training step 492",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:28",
      "total_flops_so_far": 706050956445696.0,
      "budget_used_percent": 0.706050956445696
    },
    {
      "type": "training",
      "description": "Training step 493",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:28",
      "total_flops_so_far": 707483108487168.0,
      "budget_used_percent": 0.707483108487168
    },
    {
      "type": "training",
      "description": "Training step 494",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:28",
      "total_flops_so_far": 708915260528640.0,
      "budget_used_percent": 0.70891526052864
    },
    {
      "type": "training",
      "description": "Training step 495",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:28",
      "total_flops_so_far": 710347412570112.0,
      "budget_used_percent": 0.710347412570112
    },
    {
      "type": "training",
      "description": "Training step 496",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:28",
      "total_flops_so_far": 711779564611584.0,
      "budget_used_percent": 0.711779564611584
    },
    {
      "type": "training",
      "description": "Training step 497",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:28",
      "total_flops_so_far": 713211716653056.0,
      "budget_used_percent": 0.7132117166530559
    },
    {
      "type": "training",
      "description": "Training step 498",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:28",
      "total_flops_so_far": 714643868694528.0,
      "budget_used_percent": 0.714643868694528
    },
    {
      "type": "training",
      "description": "Training step 499",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:28",
      "total_flops_so_far": 716076020736000.0,
      "budget_used_percent": 0.7160760207360001
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 0",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552526568288.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:30",
      "total_flops_so_far": 716628547304288.0,
      "budget_used_percent": 0.7166285473042879
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 1",
      "context_len": 604,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 556130834256.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:31",
      "total_flops_so_far": 717184678138544.0,
      "budget_used_percent": 0.717184678138544
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 2",
      "context_len": 602,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 554328341080.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:32",
      "total_flops_so_far": 717739006479624.0,
      "budget_used_percent": 0.717739006479624
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 3",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552526568288.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:34",
      "total_flops_so_far": 718291533047912.0,
      "budget_used_percent": 0.718291533047912
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 4",
      "context_len": 603,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 555229497620.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:35",
      "total_flops_so_far": 718846762545532.0,
      "budget_used_percent": 0.718846762545532
    },
    {
      "type": "training",
      "description": "Training step 500",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:35",
      "total_flops_so_far": 720278914587004.0,
      "budget_used_percent": 0.720278914587004
    },
    {
      "type": "training",
      "description": "Training step 501",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:35",
      "total_flops_so_far": 721711066628476.0,
      "budget_used_percent": 0.721711066628476
    },
    {
      "type": "training",
      "description": "Training step 502",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:36",
      "total_flops_so_far": 723143218669948.0,
      "budget_used_percent": 0.723143218669948
    },
    {
      "type": "training",
      "description": "Training step 503",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:36",
      "total_flops_so_far": 724575370711420.0,
      "budget_used_percent": 0.72457537071142
    },
    {
      "type": "training",
      "description": "Training step 504",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:36",
      "total_flops_so_far": 726007522752892.0,
      "budget_used_percent": 0.7260075227528919
    },
    {
      "type": "training",
      "description": "Training step 505",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:36",
      "total_flops_so_far": 727439674794364.0,
      "budget_used_percent": 0.727439674794364
    },
    {
      "type": "training",
      "description": "Training step 506",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:36",
      "total_flops_so_far": 728871826835836.0,
      "budget_used_percent": 0.7288718268358361
    },
    {
      "type": "training",
      "description": "Training step 507",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:36",
      "total_flops_so_far": 730303978877308.0,
      "budget_used_percent": 0.730303978877308
    },
    {
      "type": "training",
      "description": "Training step 508",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:36",
      "total_flops_so_far": 731736130918780.0,
      "budget_used_percent": 0.73173613091878
    },
    {
      "type": "training",
      "description": "Training step 509",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:36",
      "total_flops_so_far": 733168282960252.0,
      "budget_used_percent": 0.733168282960252
    },
    {
      "type": "training",
      "description": "Training step 510",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:37",
      "total_flops_so_far": 734600435001724.0,
      "budget_used_percent": 0.734600435001724
    },
    {
      "type": "training",
      "description": "Training step 511",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:37",
      "total_flops_so_far": 736032587043196.0,
      "budget_used_percent": 0.736032587043196
    },
    {
      "type": "training",
      "description": "Training step 512",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:37",
      "total_flops_so_far": 737464739084668.0,
      "budget_used_percent": 0.737464739084668
    },
    {
      "type": "training",
      "description": "Training step 513",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:37",
      "total_flops_so_far": 738896891126140.0,
      "budget_used_percent": 0.73889689112614
    },
    {
      "type": "training",
      "description": "Training step 514",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:37",
      "total_flops_so_far": 740329043167612.0,
      "budget_used_percent": 0.740329043167612
    },
    {
      "type": "training",
      "description": "Training step 515",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:37",
      "total_flops_so_far": 741761195209084.0,
      "budget_used_percent": 0.741761195209084
    },
    {
      "type": "training",
      "description": "Training step 516",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:37",
      "total_flops_so_far": 743193347250556.0,
      "budget_used_percent": 0.743193347250556
    },
    {
      "type": "training",
      "description": "Training step 517",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:37",
      "total_flops_so_far": 744625499292028.0,
      "budget_used_percent": 0.744625499292028
    },
    {
      "type": "training",
      "description": "Training step 518",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:38",
      "total_flops_so_far": 746057651333500.0,
      "budget_used_percent": 0.7460576513335
    },
    {
      "type": "training",
      "description": "Training step 519",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:38",
      "total_flops_so_far": 747489803374972.0,
      "budget_used_percent": 0.747489803374972
    },
    {
      "type": "training",
      "description": "Training step 520",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:38",
      "total_flops_so_far": 748921955416444.0,
      "budget_used_percent": 0.748921955416444
    },
    {
      "type": "training",
      "description": "Training step 521",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:38",
      "total_flops_so_far": 750354107457916.0,
      "budget_used_percent": 0.7503541074579161
    },
    {
      "type": "training",
      "description": "Training step 522",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:38",
      "total_flops_so_far": 751786259499388.0,
      "budget_used_percent": 0.7517862594993879
    },
    {
      "type": "training",
      "description": "Training step 523",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:38",
      "total_flops_so_far": 753218411540860.0,
      "budget_used_percent": 0.75321841154086
    },
    {
      "type": "training",
      "description": "Training step 524",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:38",
      "total_flops_so_far": 754650563582332.0,
      "budget_used_percent": 0.754650563582332
    },
    {
      "type": "training",
      "description": "Training step 525",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:38",
      "total_flops_so_far": 756082715623804.0,
      "budget_used_percent": 0.756082715623804
    },
    {
      "type": "training",
      "description": "Training step 526",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:39",
      "total_flops_so_far": 757514867665276.0,
      "budget_used_percent": 0.757514867665276
    },
    {
      "type": "training",
      "description": "Training step 527",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:39",
      "total_flops_so_far": 758947019706748.0,
      "budget_used_percent": 0.7589470197067479
    },
    {
      "type": "training",
      "description": "Training step 528",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:39",
      "total_flops_so_far": 760379171748220.0,
      "budget_used_percent": 0.76037917174822
    },
    {
      "type": "training",
      "description": "Training step 529",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:39",
      "total_flops_so_far": 761811323789692.0,
      "budget_used_percent": 0.761811323789692
    },
    {
      "type": "training",
      "description": "Training step 530",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:39",
      "total_flops_so_far": 763243475831164.0,
      "budget_used_percent": 0.7632434758311639
    },
    {
      "type": "training",
      "description": "Training step 531",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:39",
      "total_flops_so_far": 764675627872636.0,
      "budget_used_percent": 0.764675627872636
    },
    {
      "type": "training",
      "description": "Training step 532",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:39",
      "total_flops_so_far": 766107779914108.0,
      "budget_used_percent": 0.7661077799141081
    },
    {
      "type": "training",
      "description": "Training step 533",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:40",
      "total_flops_so_far": 767539931955580.0,
      "budget_used_percent": 0.76753993195558
    },
    {
      "type": "training",
      "description": "Training step 534",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:40",
      "total_flops_so_far": 768972083997052.0,
      "budget_used_percent": 0.768972083997052
    },
    {
      "type": "training",
      "description": "Training step 535",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:40",
      "total_flops_so_far": 770404236038524.0,
      "budget_used_percent": 0.770404236038524
    },
    {
      "type": "training",
      "description": "Training step 536",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:40",
      "total_flops_so_far": 771836388079996.0,
      "budget_used_percent": 0.771836388079996
    },
    {
      "type": "training",
      "description": "Training step 537",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:40",
      "total_flops_so_far": 773268540121468.0,
      "budget_used_percent": 0.773268540121468
    },
    {
      "type": "training",
      "description": "Training step 538",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:40",
      "total_flops_so_far": 774700692162940.0,
      "budget_used_percent": 0.77470069216294
    },
    {
      "type": "training",
      "description": "Training step 539",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:40",
      "total_flops_so_far": 776132844204412.0,
      "budget_used_percent": 0.776132844204412
    },
    {
      "type": "training",
      "description": "Training step 540",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:40",
      "total_flops_so_far": 777564996245884.0,
      "budget_used_percent": 0.777564996245884
    },
    {
      "type": "training",
      "description": "Training step 541",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:41",
      "total_flops_so_far": 778997148287356.0,
      "budget_used_percent": 0.778997148287356
    },
    {
      "type": "training",
      "description": "Training step 542",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:41",
      "total_flops_so_far": 780429300328828.0,
      "budget_used_percent": 0.780429300328828
    },
    {
      "type": "training",
      "description": "Training step 543",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:41",
      "total_flops_so_far": 781861452370300.0,
      "budget_used_percent": 0.7818614523702999
    },
    {
      "type": "training",
      "description": "Training step 544",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:41",
      "total_flops_so_far": 783293604411772.0,
      "budget_used_percent": 0.783293604411772
    },
    {
      "type": "training",
      "description": "Training step 545",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:41",
      "total_flops_so_far": 784725756453244.0,
      "budget_used_percent": 0.7847257564532439
    },
    {
      "type": "training",
      "description": "Training step 546",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:41",
      "total_flops_so_far": 786157908494716.0,
      "budget_used_percent": 0.7861579084947159
    },
    {
      "type": "training",
      "description": "Training step 547",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:41",
      "total_flops_so_far": 787590060536188.0,
      "budget_used_percent": 0.7875900605361881
    },
    {
      "type": "training",
      "description": "Training step 548",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:41",
      "total_flops_so_far": 789022212577660.0,
      "budget_used_percent": 0.78902221257766
    },
    {
      "type": "training",
      "description": "Training step 549",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:42",
      "total_flops_so_far": 790454364619132.0,
      "budget_used_percent": 0.7904543646191319
    },
    {
      "type": "training",
      "description": "Training step 550",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:42",
      "total_flops_so_far": 791886516660604.0,
      "budget_used_percent": 0.7918865166606041
    },
    {
      "type": "training",
      "description": "Training step 551",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:42",
      "total_flops_so_far": 793318668702076.0,
      "budget_used_percent": 0.793318668702076
    },
    {
      "type": "training",
      "description": "Training step 552",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:42",
      "total_flops_so_far": 794750820743548.0,
      "budget_used_percent": 0.794750820743548
    },
    {
      "type": "training",
      "description": "Training step 553",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:42",
      "total_flops_so_far": 796182972785020.0,
      "budget_used_percent": 0.79618297278502
    },
    {
      "type": "training",
      "description": "Training step 554",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:42",
      "total_flops_so_far": 797615124826492.0,
      "budget_used_percent": 0.797615124826492
    },
    {
      "type": "training",
      "description": "Training step 555",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:42",
      "total_flops_so_far": 799047276867964.0,
      "budget_used_percent": 0.799047276867964
    },
    {
      "type": "training",
      "description": "Training step 556",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:42",
      "total_flops_so_far": 800479428909436.0,
      "budget_used_percent": 0.800479428909436
    },
    {
      "type": "training",
      "description": "Training step 557",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:43",
      "total_flops_so_far": 801911580950908.0,
      "budget_used_percent": 0.801911580950908
    },
    {
      "type": "training",
      "description": "Training step 558",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:43",
      "total_flops_so_far": 803343732992380.0,
      "budget_used_percent": 0.8033437329923799
    },
    {
      "type": "training",
      "description": "Training step 559",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:43",
      "total_flops_so_far": 804775885033852.0,
      "budget_used_percent": 0.804775885033852
    },
    {
      "type": "training",
      "description": "Training step 560",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:43",
      "total_flops_so_far": 806208037075324.0,
      "budget_used_percent": 0.806208037075324
    },
    {
      "type": "training",
      "description": "Training step 561",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:43",
      "total_flops_so_far": 807640189116796.0,
      "budget_used_percent": 0.8076401891167959
    },
    {
      "type": "training",
      "description": "Training step 562",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:43",
      "total_flops_so_far": 809072341158268.0,
      "budget_used_percent": 0.8090723411582681
    },
    {
      "type": "training",
      "description": "Training step 563",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:43",
      "total_flops_so_far": 810504493199740.0,
      "budget_used_percent": 0.8105044931997399
    },
    {
      "type": "training",
      "description": "Training step 564",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:44",
      "total_flops_so_far": 811936645241212.0,
      "budget_used_percent": 0.8119366452412119
    },
    {
      "type": "training",
      "description": "Training step 565",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:44",
      "total_flops_so_far": 813368797282684.0,
      "budget_used_percent": 0.8133687972826841
    },
    {
      "type": "training",
      "description": "Training step 566",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:44",
      "total_flops_so_far": 814800949324156.0,
      "budget_used_percent": 0.814800949324156
    },
    {
      "type": "training",
      "description": "Training step 567",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:44",
      "total_flops_so_far": 816233101365628.0,
      "budget_used_percent": 0.8162331013656279
    },
    {
      "type": "training",
      "description": "Training step 568",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:44",
      "total_flops_so_far": 817665253407100.0,
      "budget_used_percent": 0.8176652534071001
    },
    {
      "type": "training",
      "description": "Training step 569",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:44",
      "total_flops_so_far": 819097405448572.0,
      "budget_used_percent": 0.819097405448572
    },
    {
      "type": "training",
      "description": "Training step 570",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:44",
      "total_flops_so_far": 820529557490044.0,
      "budget_used_percent": 0.820529557490044
    },
    {
      "type": "training",
      "description": "Training step 571",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:44",
      "total_flops_so_far": 821961709531516.0,
      "budget_used_percent": 0.821961709531516
    },
    {
      "type": "training",
      "description": "Training step 572",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:45",
      "total_flops_so_far": 823393861572988.0,
      "budget_used_percent": 0.823393861572988
    },
    {
      "type": "training",
      "description": "Training step 573",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:45",
      "total_flops_so_far": 824826013614460.0,
      "budget_used_percent": 0.82482601361446
    },
    {
      "type": "training",
      "description": "Training step 574",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:45",
      "total_flops_so_far": 826258165655932.0,
      "budget_used_percent": 0.826258165655932
    },
    {
      "type": "training",
      "description": "Training step 575",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:45",
      "total_flops_so_far": 827690317697404.0,
      "budget_used_percent": 0.827690317697404
    },
    {
      "type": "training",
      "description": "Training step 576",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:45",
      "total_flops_so_far": 829122469738876.0,
      "budget_used_percent": 0.8291224697388759
    },
    {
      "type": "training",
      "description": "Training step 577",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:45",
      "total_flops_so_far": 830554621780348.0,
      "budget_used_percent": 0.8305546217803481
    },
    {
      "type": "training",
      "description": "Training step 578",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:45",
      "total_flops_so_far": 831986773821820.0,
      "budget_used_percent": 0.83198677382182
    },
    {
      "type": "training",
      "description": "Training step 579",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:45",
      "total_flops_so_far": 833418925863292.0,
      "budget_used_percent": 0.8334189258632919
    },
    {
      "type": "training",
      "description": "Training step 580",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:46",
      "total_flops_so_far": 834851077904764.0,
      "budget_used_percent": 0.8348510779047641
    },
    {
      "type": "training",
      "description": "Training step 581",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:46",
      "total_flops_so_far": 836283229946236.0,
      "budget_used_percent": 0.836283229946236
    },
    {
      "type": "training",
      "description": "Training step 582",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:46",
      "total_flops_so_far": 837715381987708.0,
      "budget_used_percent": 0.8377153819877079
    },
    {
      "type": "training",
      "description": "Training step 583",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:46",
      "total_flops_so_far": 839147534029180.0,
      "budget_used_percent": 0.8391475340291801
    },
    {
      "type": "training",
      "description": "Training step 584",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:46",
      "total_flops_so_far": 840579686070652.0,
      "budget_used_percent": 0.840579686070652
    },
    {
      "type": "training",
      "description": "Training step 585",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:46",
      "total_flops_so_far": 842011838112124.0,
      "budget_used_percent": 0.842011838112124
    },
    {
      "type": "training",
      "description": "Training step 586",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:46",
      "total_flops_so_far": 843443990153596.0,
      "budget_used_percent": 0.8434439901535961
    },
    {
      "type": "training",
      "description": "Training step 587",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:46",
      "total_flops_so_far": 844876142195068.0,
      "budget_used_percent": 0.844876142195068
    },
    {
      "type": "training",
      "description": "Training step 588",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:47",
      "total_flops_so_far": 846308294236540.0,
      "budget_used_percent": 0.84630829423654
    },
    {
      "type": "training",
      "description": "Training step 589",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:47",
      "total_flops_so_far": 847740446278012.0,
      "budget_used_percent": 0.847740446278012
    },
    {
      "type": "training",
      "description": "Training step 590",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:47",
      "total_flops_so_far": 849172598319484.0,
      "budget_used_percent": 0.849172598319484
    },
    {
      "type": "training",
      "description": "Training step 591",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:47",
      "total_flops_so_far": 850604750360956.0,
      "budget_used_percent": 0.850604750360956
    },
    {
      "type": "training",
      "description": "Training step 592",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:47",
      "total_flops_so_far": 852036902402428.0,
      "budget_used_percent": 0.852036902402428
    },
    {
      "type": "training",
      "description": "Training step 593",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:47",
      "total_flops_so_far": 853469054443900.0,
      "budget_used_percent": 0.8534690544439
    },
    {
      "type": "training",
      "description": "Training step 594",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:47",
      "total_flops_so_far": 854901206485372.0,
      "budget_used_percent": 0.8549012064853719
    },
    {
      "type": "training",
      "description": "Training step 595",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:48",
      "total_flops_so_far": 856333358526844.0,
      "budget_used_percent": 0.8563333585268441
    },
    {
      "type": "training",
      "description": "Training step 596",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:48",
      "total_flops_so_far": 857765510568316.0,
      "budget_used_percent": 0.857765510568316
    },
    {
      "type": "training",
      "description": "Training step 597",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:48",
      "total_flops_so_far": 859197662609788.0,
      "budget_used_percent": 0.8591976626097879
    },
    {
      "type": "training",
      "description": "Training step 598",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:48",
      "total_flops_so_far": 860629814651260.0,
      "budget_used_percent": 0.8606298146512601
    },
    {
      "type": "training",
      "description": "Training step 599",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:48",
      "total_flops_so_far": 862061966692732.0,
      "budget_used_percent": 0.862061966692732
    },
    {
      "type": "training",
      "description": "Training step 600",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:48",
      "total_flops_so_far": 863494118734204.0,
      "budget_used_percent": 0.863494118734204
    },
    {
      "type": "training",
      "description": "Training step 601",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:48",
      "total_flops_so_far": 864926270775676.0,
      "budget_used_percent": 0.8649262707756761
    },
    {
      "type": "training",
      "description": "Training step 602",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:48",
      "total_flops_so_far": 866358422817148.0,
      "budget_used_percent": 0.866358422817148
    },
    {
      "type": "training",
      "description": "Training step 603",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:49",
      "total_flops_so_far": 867790574858620.0,
      "budget_used_percent": 0.86779057485862
    },
    {
      "type": "training",
      "description": "Training step 604",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:49",
      "total_flops_so_far": 869222726900092.0,
      "budget_used_percent": 0.8692227269000921
    },
    {
      "type": "training",
      "description": "Training step 605",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:49",
      "total_flops_so_far": 870654878941564.0,
      "budget_used_percent": 0.870654878941564
    },
    {
      "type": "training",
      "description": "Training step 606",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:49",
      "total_flops_so_far": 872087030983036.0,
      "budget_used_percent": 0.872087030983036
    },
    {
      "type": "training",
      "description": "Training step 607",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:49",
      "total_flops_so_far": 873519183024508.0,
      "budget_used_percent": 0.873519183024508
    },
    {
      "type": "training",
      "description": "Training step 608",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:49",
      "total_flops_so_far": 874951335065980.0,
      "budget_used_percent": 0.87495133506598
    },
    {
      "type": "training",
      "description": "Training step 609",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:49",
      "total_flops_so_far": 876383487107452.0,
      "budget_used_percent": 0.876383487107452
    },
    {
      "type": "training",
      "description": "Training step 610",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:49",
      "total_flops_so_far": 877815639148924.0,
      "budget_used_percent": 0.8778156391489241
    },
    {
      "type": "training",
      "description": "Training step 611",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:50",
      "total_flops_so_far": 879247791190396.0,
      "budget_used_percent": 0.879247791190396
    },
    {
      "type": "training",
      "description": "Training step 612",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:50",
      "total_flops_so_far": 880679943231868.0,
      "budget_used_percent": 0.8806799432318679
    },
    {
      "type": "training",
      "description": "Training step 613",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:50",
      "total_flops_so_far": 882112095273340.0,
      "budget_used_percent": 0.8821120952733401
    },
    {
      "type": "training",
      "description": "Training step 614",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:50",
      "total_flops_so_far": 883544247314812.0,
      "budget_used_percent": 0.8835442473148121
    },
    {
      "type": "training",
      "description": "Training step 615",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:50",
      "total_flops_so_far": 884976399356284.0,
      "budget_used_percent": 0.884976399356284
    },
    {
      "type": "training",
      "description": "Training step 616",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:50",
      "total_flops_so_far": 886408551397756.0,
      "budget_used_percent": 0.8864085513977559
    },
    {
      "type": "training",
      "description": "Training step 617",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:50",
      "total_flops_so_far": 887840703439228.0,
      "budget_used_percent": 0.887840703439228
    },
    {
      "type": "training",
      "description": "Training step 618",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:51",
      "total_flops_so_far": 889272855480700.0,
      "budget_used_percent": 0.8892728554807
    },
    {
      "type": "training",
      "description": "Training step 619",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:51",
      "total_flops_so_far": 890705007522172.0,
      "budget_used_percent": 0.890705007522172
    },
    {
      "type": "training",
      "description": "Training step 620",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:51",
      "total_flops_so_far": 892137159563644.0,
      "budget_used_percent": 0.892137159563644
    },
    {
      "type": "training",
      "description": "Training step 621",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:51",
      "total_flops_so_far": 893569311605116.0,
      "budget_used_percent": 0.893569311605116
    },
    {
      "type": "training",
      "description": "Training step 622",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:51",
      "total_flops_so_far": 895001463646588.0,
      "budget_used_percent": 0.895001463646588
    },
    {
      "type": "training",
      "description": "Training step 623",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:51",
      "total_flops_so_far": 896433615688060.0,
      "budget_used_percent": 0.89643361568806
    },
    {
      "type": "training",
      "description": "Training step 624",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:51",
      "total_flops_so_far": 897865767729532.0,
      "budget_used_percent": 0.897865767729532
    },
    {
      "type": "training",
      "description": "Training step 625",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:51",
      "total_flops_so_far": 899297919771004.0,
      "budget_used_percent": 0.8992979197710039
    },
    {
      "type": "training",
      "description": "Training step 626",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:52",
      "total_flops_so_far": 900730071812476.0,
      "budget_used_percent": 0.900730071812476
    },
    {
      "type": "training",
      "description": "Training step 627",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:52",
      "total_flops_so_far": 902162223853948.0,
      "budget_used_percent": 0.902162223853948
    },
    {
      "type": "training",
      "description": "Training step 628",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:52",
      "total_flops_so_far": 903594375895420.0,
      "budget_used_percent": 0.9035943758954199
    },
    {
      "type": "training",
      "description": "Training step 629",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:52",
      "total_flops_so_far": 905026527936892.0,
      "budget_used_percent": 0.9050265279368921
    },
    {
      "type": "training",
      "description": "Training step 630",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:52",
      "total_flops_so_far": 906458679978364.0,
      "budget_used_percent": 0.9064586799783639
    },
    {
      "type": "training",
      "description": "Training step 631",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:52",
      "total_flops_so_far": 907890832019836.0,
      "budget_used_percent": 0.9078908320198359
    },
    {
      "type": "training",
      "description": "Training step 632",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:52",
      "total_flops_so_far": 909322984061308.0,
      "budget_used_percent": 0.9093229840613081
    },
    {
      "type": "training",
      "description": "Training step 633",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:52",
      "total_flops_so_far": 910755136102780.0,
      "budget_used_percent": 0.91075513610278
    },
    {
      "type": "training",
      "description": "Training step 634",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:53",
      "total_flops_so_far": 912187288144252.0,
      "budget_used_percent": 0.9121872881442519
    },
    {
      "type": "training",
      "description": "Training step 635",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:53",
      "total_flops_so_far": 913619440185724.0,
      "budget_used_percent": 0.913619440185724
    },
    {
      "type": "training",
      "description": "Training step 636",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:53",
      "total_flops_so_far": 915051592227196.0,
      "budget_used_percent": 0.915051592227196
    },
    {
      "type": "training",
      "description": "Training step 637",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:53",
      "total_flops_so_far": 916483744268668.0,
      "budget_used_percent": 0.916483744268668
    },
    {
      "type": "training",
      "description": "Training step 638",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:53",
      "total_flops_so_far": 917915896310140.0,
      "budget_used_percent": 0.91791589631014
    },
    {
      "type": "training",
      "description": "Training step 639",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:53",
      "total_flops_so_far": 919348048351612.0,
      "budget_used_percent": 0.919348048351612
    },
    {
      "type": "training",
      "description": "Training step 640",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:53",
      "total_flops_so_far": 920780200393084.0,
      "budget_used_percent": 0.920780200393084
    },
    {
      "type": "training",
      "description": "Training step 641",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:54",
      "total_flops_so_far": 922212352434556.0,
      "budget_used_percent": 0.922212352434556
    },
    {
      "type": "training",
      "description": "Training step 642",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:54",
      "total_flops_so_far": 923644504476028.0,
      "budget_used_percent": 0.923644504476028
    },
    {
      "type": "training",
      "description": "Training step 643",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:54",
      "total_flops_so_far": 925076656517500.0,
      "budget_used_percent": 0.9250766565174999
    },
    {
      "type": "training",
      "description": "Training step 644",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:54",
      "total_flops_so_far": 926508808558972.0,
      "budget_used_percent": 0.9265088085589721
    },
    {
      "type": "training",
      "description": "Training step 645",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:54",
      "total_flops_so_far": 927940960600444.0,
      "budget_used_percent": 0.927940960600444
    },
    {
      "type": "training",
      "description": "Training step 646",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:54",
      "total_flops_so_far": 929373112641916.0,
      "budget_used_percent": 0.9293731126419159
    },
    {
      "type": "training",
      "description": "Training step 647",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:54",
      "total_flops_so_far": 930805264683388.0,
      "budget_used_percent": 0.9308052646833881
    },
    {
      "type": "training",
      "description": "Training step 648",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:54",
      "total_flops_so_far": 932237416724860.0,
      "budget_used_percent": 0.93223741672486
    },
    {
      "type": "training",
      "description": "Training step 649",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:55",
      "total_flops_so_far": 933669568766332.0,
      "budget_used_percent": 0.9336695687663319
    },
    {
      "type": "training",
      "description": "Training step 650",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:55",
      "total_flops_so_far": 935101720807804.0,
      "budget_used_percent": 0.9351017208078041
    },
    {
      "type": "training",
      "description": "Training step 651",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:55",
      "total_flops_so_far": 936533872849276.0,
      "budget_used_percent": 0.936533872849276
    },
    {
      "type": "training",
      "description": "Training step 652",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:55",
      "total_flops_so_far": 937966024890748.0,
      "budget_used_percent": 0.937966024890748
    },
    {
      "type": "training",
      "description": "Training step 653",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:55",
      "total_flops_so_far": 939398176932220.0,
      "budget_used_percent": 0.93939817693222
    },
    {
      "type": "training",
      "description": "Training step 654",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:55",
      "total_flops_so_far": 940830328973692.0,
      "budget_used_percent": 0.940830328973692
    },
    {
      "type": "training",
      "description": "Training step 655",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:55",
      "total_flops_so_far": 942262481015164.0,
      "budget_used_percent": 0.942262481015164
    },
    {
      "type": "training",
      "description": "Training step 656",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:56",
      "total_flops_so_far": 943694633056636.0,
      "budget_used_percent": 0.943694633056636
    },
    {
      "type": "training",
      "description": "Training step 657",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:56",
      "total_flops_so_far": 945126785098108.0,
      "budget_used_percent": 0.945126785098108
    },
    {
      "type": "training",
      "description": "Training step 658",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:56",
      "total_flops_so_far": 946558937139580.0,
      "budget_used_percent": 0.94655893713958
    },
    {
      "type": "training",
      "description": "Training step 659",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:56",
      "total_flops_so_far": 947991089181052.0,
      "budget_used_percent": 0.947991089181052
    },
    {
      "type": "training",
      "description": "Training step 660",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:56",
      "total_flops_so_far": 949423241222524.0,
      "budget_used_percent": 0.949423241222524
    },
    {
      "type": "training",
      "description": "Training step 661",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:56",
      "total_flops_so_far": 950855393263996.0,
      "budget_used_percent": 0.9508553932639959
    },
    {
      "type": "training",
      "description": "Training step 662",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:56",
      "total_flops_so_far": 952287545305468.0,
      "budget_used_percent": 0.9522875453054681
    },
    {
      "type": "training",
      "description": "Training step 663",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:56",
      "total_flops_so_far": 953719697346940.0,
      "budget_used_percent": 0.95371969734694
    },
    {
      "type": "training",
      "description": "Training step 664",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:57",
      "total_flops_so_far": 955151849388412.0,
      "budget_used_percent": 0.9551518493884119
    },
    {
      "type": "training",
      "description": "Training step 665",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:57",
      "total_flops_so_far": 956584001429884.0,
      "budget_used_percent": 0.9565840014298841
    },
    {
      "type": "training",
      "description": "Training step 666",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:57",
      "total_flops_so_far": 958016153471356.0,
      "budget_used_percent": 0.958016153471356
    },
    {
      "type": "training",
      "description": "Training step 667",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:57",
      "total_flops_so_far": 959448305512828.0,
      "budget_used_percent": 0.959448305512828
    },
    {
      "type": "training",
      "description": "Training step 668",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:57",
      "total_flops_so_far": 960880457554300.0,
      "budget_used_percent": 0.9608804575543001
    },
    {
      "type": "training",
      "description": "Training step 669",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:57",
      "total_flops_so_far": 962312609595772.0,
      "budget_used_percent": 0.962312609595772
    },
    {
      "type": "training",
      "description": "Training step 670",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:57",
      "total_flops_so_far": 963744761637244.0,
      "budget_used_percent": 0.963744761637244
    },
    {
      "type": "training",
      "description": "Training step 671",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:57",
      "total_flops_so_far": 965176913678716.0,
      "budget_used_percent": 0.965176913678716
    },
    {
      "type": "training",
      "description": "Training step 672",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:58",
      "total_flops_so_far": 966609065720188.0,
      "budget_used_percent": 0.966609065720188
    },
    {
      "type": "training",
      "description": "Training step 673",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:58",
      "total_flops_so_far": 968041217761660.0,
      "budget_used_percent": 0.96804121776166
    },
    {
      "type": "training",
      "description": "Training step 674",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:58",
      "total_flops_so_far": 969473369803132.0,
      "budget_used_percent": 0.969473369803132
    },
    {
      "type": "training",
      "description": "Training step 675",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:58",
      "total_flops_so_far": 970905521844604.0,
      "budget_used_percent": 0.970905521844604
    },
    {
      "type": "training",
      "description": "Training step 676",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:58",
      "total_flops_so_far": 972337673886076.0,
      "budget_used_percent": 0.972337673886076
    },
    {
      "type": "training",
      "description": "Training step 677",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:58",
      "total_flops_so_far": 973769825927548.0,
      "budget_used_percent": 0.9737698259275481
    },
    {
      "type": "training",
      "description": "Training step 678",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:58",
      "total_flops_so_far": 975201977969020.0,
      "budget_used_percent": 0.97520197796902
    },
    {
      "type": "training",
      "description": "Training step 679",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:59",
      "total_flops_so_far": 976634130010492.0,
      "budget_used_percent": 0.9766341300104919
    },
    {
      "type": "training",
      "description": "Training step 680",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:59",
      "total_flops_so_far": 978066282051964.0,
      "budget_used_percent": 0.9780662820519641
    },
    {
      "type": "training",
      "description": "Training step 681",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:59",
      "total_flops_so_far": 979498434093436.0,
      "budget_used_percent": 0.9794984340934361
    },
    {
      "type": "training",
      "description": "Training step 682",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:59",
      "total_flops_so_far": 980930586134908.0,
      "budget_used_percent": 0.980930586134908
    },
    {
      "type": "training",
      "description": "Training step 683",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:59",
      "total_flops_so_far": 982362738176380.0,
      "budget_used_percent": 0.9823627381763801
    },
    {
      "type": "training",
      "description": "Training step 684",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:59",
      "total_flops_so_far": 983794890217852.0,
      "budget_used_percent": 0.983794890217852
    },
    {
      "type": "training",
      "description": "Training step 685",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:59",
      "total_flops_so_far": 985227042259324.0,
      "budget_used_percent": 0.985227042259324
    },
    {
      "type": "training",
      "description": "Training step 686",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:44:59",
      "total_flops_so_far": 986659194300796.0,
      "budget_used_percent": 0.9866591943007961
    },
    {
      "type": "training",
      "description": "Training step 687",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:00",
      "total_flops_so_far": 988091346342268.0,
      "budget_used_percent": 0.988091346342268
    },
    {
      "type": "training",
      "description": "Training step 688",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:00",
      "total_flops_so_far": 989523498383740.0,
      "budget_used_percent": 0.98952349838374
    },
    {
      "type": "training",
      "description": "Training step 689",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:00",
      "total_flops_so_far": 990955650425212.0,
      "budget_used_percent": 0.9909556504252119
    },
    {
      "type": "training",
      "description": "Training step 690",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:00",
      "total_flops_so_far": 992387802466684.0,
      "budget_used_percent": 0.992387802466684
    },
    {
      "type": "training",
      "description": "Training step 691",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:00",
      "total_flops_so_far": 993819954508156.0,
      "budget_used_percent": 0.993819954508156
    },
    {
      "type": "training",
      "description": "Training step 692",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:00",
      "total_flops_so_far": 995252106549628.0,
      "budget_used_percent": 0.9952521065496279
    },
    {
      "type": "training",
      "description": "Training step 693",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:00",
      "total_flops_so_far": 996684258591100.0,
      "budget_used_percent": 0.9966842585911
    },
    {
      "type": "training",
      "description": "Training step 694",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:01",
      "total_flops_so_far": 998116410632572.0,
      "budget_used_percent": 0.998116410632572
    },
    {
      "type": "training",
      "description": "Training step 695",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:01",
      "total_flops_so_far": 999548562674044.0,
      "budget_used_percent": 0.9995485626740439
    },
    {
      "type": "training",
      "description": "Training step 696",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:01",
      "total_flops_so_far": 1000980714715516.0,
      "budget_used_percent": 1.000980714715516
    },
    {
      "type": "training",
      "description": "Training step 697",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:01",
      "total_flops_so_far": 1002412866756988.0,
      "budget_used_percent": 1.002412866756988
    },
    {
      "type": "training",
      "description": "Training step 698",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:01",
      "total_flops_so_far": 1003845018798460.0,
      "budget_used_percent": 1.00384501879846
    },
    {
      "type": "training",
      "description": "Training step 699",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:01",
      "total_flops_so_far": 1005277170839932.0,
      "budget_used_percent": 1.005277170839932
    },
    {
      "type": "training",
      "description": "Training step 700",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:01",
      "total_flops_so_far": 1006709322881404.0,
      "budget_used_percent": 1.006709322881404
    },
    {
      "type": "training",
      "description": "Training step 701",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:01",
      "total_flops_so_far": 1008141474922876.0,
      "budget_used_percent": 1.0081414749228759
    },
    {
      "type": "training",
      "description": "Training step 702",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:02",
      "total_flops_so_far": 1009573626964348.0,
      "budget_used_percent": 1.009573626964348
    },
    {
      "type": "training",
      "description": "Training step 703",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:02",
      "total_flops_so_far": 1011005779005820.0,
      "budget_used_percent": 1.01100577900582
    },
    {
      "type": "training",
      "description": "Training step 704",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:02",
      "total_flops_so_far": 1012437931047292.0,
      "budget_used_percent": 1.012437931047292
    },
    {
      "type": "training",
      "description": "Training step 705",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:02",
      "total_flops_so_far": 1013870083088764.0,
      "budget_used_percent": 1.0138700830887641
    },
    {
      "type": "training",
      "description": "Training step 706",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:02",
      "total_flops_so_far": 1015302235130236.0,
      "budget_used_percent": 1.0153022351302359
    },
    {
      "type": "training",
      "description": "Training step 707",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:02",
      "total_flops_so_far": 1016734387171708.0,
      "budget_used_percent": 1.0167343871717078
    },
    {
      "type": "training",
      "description": "Training step 708",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:02",
      "total_flops_so_far": 1018166539213180.0,
      "budget_used_percent": 1.01816653921318
    },
    {
      "type": "training",
      "description": "Training step 709",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:03",
      "total_flops_so_far": 1019598691254652.0,
      "budget_used_percent": 1.019598691254652
    },
    {
      "type": "training",
      "description": "Training step 710",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:03",
      "total_flops_so_far": 1021030843296124.0,
      "budget_used_percent": 1.021030843296124
    },
    {
      "type": "training",
      "description": "Training step 711",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:03",
      "total_flops_so_far": 1022462995337596.0,
      "budget_used_percent": 1.022462995337596
    },
    {
      "type": "training",
      "description": "Training step 712",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:03",
      "total_flops_so_far": 1023895147379068.0,
      "budget_used_percent": 1.023895147379068
    },
    {
      "type": "training",
      "description": "Training step 713",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:03",
      "total_flops_so_far": 1025327299420540.0,
      "budget_used_percent": 1.02532729942054
    },
    {
      "type": "training",
      "description": "Training step 714",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:03",
      "total_flops_so_far": 1026759451462012.0,
      "budget_used_percent": 1.026759451462012
    },
    {
      "type": "training",
      "description": "Training step 715",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:03",
      "total_flops_so_far": 1028191603503484.0,
      "budget_used_percent": 1.028191603503484
    },
    {
      "type": "training",
      "description": "Training step 716",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:03",
      "total_flops_so_far": 1029623755544956.0,
      "budget_used_percent": 1.0296237555449559
    },
    {
      "type": "training",
      "description": "Training step 717",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:04",
      "total_flops_so_far": 1031055907586428.0,
      "budget_used_percent": 1.031055907586428
    },
    {
      "type": "training",
      "description": "Training step 718",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:04",
      "total_flops_so_far": 1032488059627900.0,
      "budget_used_percent": 1.0324880596279
    },
    {
      "type": "training",
      "description": "Training step 719",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:04",
      "total_flops_so_far": 1033920211669372.0,
      "budget_used_percent": 1.033920211669372
    },
    {
      "type": "training",
      "description": "Training step 720",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:04",
      "total_flops_so_far": 1035352363710844.0,
      "budget_used_percent": 1.0353523637108442
    },
    {
      "type": "training",
      "description": "Training step 721",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:04",
      "total_flops_so_far": 1036784515752316.0,
      "budget_used_percent": 1.036784515752316
    },
    {
      "type": "training",
      "description": "Training step 722",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:04",
      "total_flops_so_far": 1038216667793788.0,
      "budget_used_percent": 1.0382166677937879
    },
    {
      "type": "training",
      "description": "Training step 723",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:04",
      "total_flops_so_far": 1039648819835260.0,
      "budget_used_percent": 1.03964881983526
    },
    {
      "type": "training",
      "description": "Training step 724",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:04",
      "total_flops_so_far": 1041080971876732.0,
      "budget_used_percent": 1.041080971876732
    },
    {
      "type": "training",
      "description": "Training step 725",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:05",
      "total_flops_so_far": 1042513123918204.0,
      "budget_used_percent": 1.042513123918204
    },
    {
      "type": "training",
      "description": "Training step 726",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:05",
      "total_flops_so_far": 1043945275959676.0,
      "budget_used_percent": 1.0439452759596761
    },
    {
      "type": "training",
      "description": "Training step 727",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:05",
      "total_flops_so_far": 1045377428001148.0,
      "budget_used_percent": 1.045377428001148
    },
    {
      "type": "training",
      "description": "Training step 728",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:05",
      "total_flops_so_far": 1046809580042620.0,
      "budget_used_percent": 1.04680958004262
    },
    {
      "type": "training",
      "description": "Training step 729",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:05",
      "total_flops_so_far": 1048241732084092.0,
      "budget_used_percent": 1.048241732084092
    },
    {
      "type": "training",
      "description": "Training step 730",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:05",
      "total_flops_so_far": 1049673884125564.0,
      "budget_used_percent": 1.049673884125564
    },
    {
      "type": "training",
      "description": "Training step 731",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:05",
      "total_flops_so_far": 1051106036167036.0,
      "budget_used_percent": 1.051106036167036
    },
    {
      "type": "training",
      "description": "Training step 732",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:06",
      "total_flops_so_far": 1052538188208508.0,
      "budget_used_percent": 1.052538188208508
    },
    {
      "type": "training",
      "description": "Training step 733",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:06",
      "total_flops_so_far": 1053970340249980.0,
      "budget_used_percent": 1.05397034024998
    },
    {
      "type": "training",
      "description": "Training step 734",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:06",
      "total_flops_so_far": 1055402492291452.0,
      "budget_used_percent": 1.055402492291452
    },
    {
      "type": "training",
      "description": "Training step 735",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:06",
      "total_flops_so_far": 1056834644332924.0,
      "budget_used_percent": 1.0568346443329242
    },
    {
      "type": "training",
      "description": "Training step 736",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:06",
      "total_flops_so_far": 1058266796374396.0,
      "budget_used_percent": 1.058266796374396
    },
    {
      "type": "training",
      "description": "Training step 737",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:06",
      "total_flops_so_far": 1059698948415868.0,
      "budget_used_percent": 1.0596989484158679
    },
    {
      "type": "training",
      "description": "Training step 738",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:06",
      "total_flops_so_far": 1061131100457340.0,
      "budget_used_percent": 1.06113110045734
    },
    {
      "type": "training",
      "description": "Training step 739",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:06",
      "total_flops_so_far": 1062563252498812.0,
      "budget_used_percent": 1.062563252498812
    },
    {
      "type": "training",
      "description": "Training step 740",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:07",
      "total_flops_so_far": 1063995404540284.0,
      "budget_used_percent": 1.063995404540284
    },
    {
      "type": "training",
      "description": "Training step 741",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:07",
      "total_flops_so_far": 1065427556581756.0,
      "budget_used_percent": 1.0654275565817561
    },
    {
      "type": "training",
      "description": "Training step 742",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:07",
      "total_flops_so_far": 1066859708623228.0,
      "budget_used_percent": 1.066859708623228
    },
    {
      "type": "training",
      "description": "Training step 743",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:07",
      "total_flops_so_far": 1068291860664700.0,
      "budget_used_percent": 1.0682918606647
    },
    {
      "type": "training",
      "description": "Training step 744",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:07",
      "total_flops_so_far": 1069724012706172.0,
      "budget_used_percent": 1.069724012706172
    },
    {
      "type": "training",
      "description": "Training step 745",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:07",
      "total_flops_so_far": 1071156164747644.0,
      "budget_used_percent": 1.071156164747644
    },
    {
      "type": "training",
      "description": "Training step 746",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:07",
      "total_flops_so_far": 1072588316789116.0,
      "budget_used_percent": 1.072588316789116
    },
    {
      "type": "training",
      "description": "Training step 747",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:08",
      "total_flops_so_far": 1074020468830588.0,
      "budget_used_percent": 1.074020468830588
    },
    {
      "type": "training",
      "description": "Training step 748",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:08",
      "total_flops_so_far": 1075452620872060.0,
      "budget_used_percent": 1.07545262087206
    },
    {
      "type": "training",
      "description": "Training step 749",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:08",
      "total_flops_so_far": 1076884772913532.0,
      "budget_used_percent": 1.076884772913532
    },
    {
      "type": "training",
      "description": "Training step 750",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:08",
      "total_flops_so_far": 1078316924955004.0,
      "budget_used_percent": 1.078316924955004
    },
    {
      "type": "training",
      "description": "Training step 751",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:08",
      "total_flops_so_far": 1079749076996476.0,
      "budget_used_percent": 1.079749076996476
    },
    {
      "type": "training",
      "description": "Training step 752",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:08",
      "total_flops_so_far": 1081181229037948.0,
      "budget_used_percent": 1.0811812290379479
    },
    {
      "type": "training",
      "description": "Training step 753",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:08",
      "total_flops_so_far": 1082613381079420.0,
      "budget_used_percent": 1.08261338107942
    },
    {
      "type": "training",
      "description": "Training step 754",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:08",
      "total_flops_so_far": 1084045533120892.0,
      "budget_used_percent": 1.084045533120892
    },
    {
      "type": "training",
      "description": "Training step 755",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:09",
      "total_flops_so_far": 1085477685162364.0,
      "budget_used_percent": 1.085477685162364
    },
    {
      "type": "training",
      "description": "Training step 756",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:09",
      "total_flops_so_far": 1086909837203836.0,
      "budget_used_percent": 1.0869098372038362
    },
    {
      "type": "training",
      "description": "Training step 757",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:09",
      "total_flops_so_far": 1088341989245308.0,
      "budget_used_percent": 1.0883419892453081
    },
    {
      "type": "training",
      "description": "Training step 758",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:09",
      "total_flops_so_far": 1089774141286780.0,
      "budget_used_percent": 1.08977414128678
    },
    {
      "type": "training",
      "description": "Training step 759",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:09",
      "total_flops_so_far": 1091206293328252.0,
      "budget_used_percent": 1.091206293328252
    },
    {
      "type": "training",
      "description": "Training step 760",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:09",
      "total_flops_so_far": 1092638445369724.0,
      "budget_used_percent": 1.092638445369724
    },
    {
      "type": "training",
      "description": "Training step 761",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:09",
      "total_flops_so_far": 1094070597411196.0,
      "budget_used_percent": 1.094070597411196
    },
    {
      "type": "training",
      "description": "Training step 762",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:10",
      "total_flops_so_far": 1095502749452668.0,
      "budget_used_percent": 1.095502749452668
    },
    {
      "type": "training",
      "description": "Training step 763",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:10",
      "total_flops_so_far": 1096934901494140.0,
      "budget_used_percent": 1.09693490149414
    },
    {
      "type": "training",
      "description": "Training step 764",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:10",
      "total_flops_so_far": 1098367053535612.0,
      "budget_used_percent": 1.098367053535612
    },
    {
      "type": "training",
      "description": "Training step 765",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:10",
      "total_flops_so_far": 1099799205577084.0,
      "budget_used_percent": 1.099799205577084
    },
    {
      "type": "training",
      "description": "Training step 766",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:10",
      "total_flops_so_far": 1101231357618556.0,
      "budget_used_percent": 1.101231357618556
    },
    {
      "type": "training",
      "description": "Training step 767",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:10",
      "total_flops_so_far": 1102663509660028.0,
      "budget_used_percent": 1.102663509660028
    },
    {
      "type": "training",
      "description": "Training step 768",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:10",
      "total_flops_so_far": 1104095661701500.0,
      "budget_used_percent": 1.1040956617014999
    },
    {
      "type": "training",
      "description": "Training step 769",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:11",
      "total_flops_so_far": 1105527813742972.0,
      "budget_used_percent": 1.105527813742972
    },
    {
      "type": "training",
      "description": "Training step 770",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:11",
      "total_flops_so_far": 1106959965784444.0,
      "budget_used_percent": 1.106959965784444
    },
    {
      "type": "training",
      "description": "Training step 771",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:11",
      "total_flops_so_far": 1108392117825916.0,
      "budget_used_percent": 1.108392117825916
    },
    {
      "type": "training",
      "description": "Training step 772",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:11",
      "total_flops_so_far": 1109824269867388.0,
      "budget_used_percent": 1.1098242698673881
    },
    {
      "type": "training",
      "description": "Training step 773",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:11",
      "total_flops_so_far": 1111256421908860.0,
      "budget_used_percent": 1.1112564219088599
    },
    {
      "type": "training",
      "description": "Training step 774",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:11",
      "total_flops_so_far": 1112688573950332.0,
      "budget_used_percent": 1.1126885739503318
    },
    {
      "type": "training",
      "description": "Training step 775",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:11",
      "total_flops_so_far": 1114120725991804.0,
      "budget_used_percent": 1.114120725991804
    },
    {
      "type": "training",
      "description": "Training step 776",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:11",
      "total_flops_so_far": 1115552878033276.0,
      "budget_used_percent": 1.115552878033276
    },
    {
      "type": "training",
      "description": "Training step 777",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:12",
      "total_flops_so_far": 1116985030074748.0,
      "budget_used_percent": 1.116985030074748
    },
    {
      "type": "training",
      "description": "Training step 778",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:12",
      "total_flops_so_far": 1118417182116220.0,
      "budget_used_percent": 1.11841718211622
    },
    {
      "type": "training",
      "description": "Training step 779",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:12",
      "total_flops_so_far": 1119849334157692.0,
      "budget_used_percent": 1.119849334157692
    },
    {
      "type": "training",
      "description": "Training step 780",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:12",
      "total_flops_so_far": 1121281486199164.0,
      "budget_used_percent": 1.121281486199164
    },
    {
      "type": "training",
      "description": "Training step 781",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:12",
      "total_flops_so_far": 1122713638240636.0,
      "budget_used_percent": 1.122713638240636
    },
    {
      "type": "training",
      "description": "Training step 782",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:12",
      "total_flops_so_far": 1124145790282108.0,
      "budget_used_percent": 1.124145790282108
    },
    {
      "type": "training",
      "description": "Training step 783",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:12",
      "total_flops_so_far": 1125577942323580.0,
      "budget_used_percent": 1.1255779423235799
    },
    {
      "type": "training",
      "description": "Training step 784",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:13",
      "total_flops_so_far": 1127010094365052.0,
      "budget_used_percent": 1.127010094365052
    },
    {
      "type": "training",
      "description": "Training step 785",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:13",
      "total_flops_so_far": 1128442246406524.0,
      "budget_used_percent": 1.128442246406524
    },
    {
      "type": "training",
      "description": "Training step 786",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:13",
      "total_flops_so_far": 1129874398447996.0,
      "budget_used_percent": 1.129874398447996
    },
    {
      "type": "training",
      "description": "Training step 787",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:13",
      "total_flops_so_far": 1131306550489468.0,
      "budget_used_percent": 1.1313065504894682
    },
    {
      "type": "training",
      "description": "Training step 788",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:13",
      "total_flops_so_far": 1132738702530940.0,
      "budget_used_percent": 1.13273870253094
    },
    {
      "type": "training",
      "description": "Training step 789",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:13",
      "total_flops_so_far": 1134170854572412.0,
      "budget_used_percent": 1.1341708545724118
    },
    {
      "type": "training",
      "description": "Training step 790",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:13",
      "total_flops_so_far": 1135603006613884.0,
      "budget_used_percent": 1.135603006613884
    },
    {
      "type": "training",
      "description": "Training step 791",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:13",
      "total_flops_so_far": 1137035158655356.0,
      "budget_used_percent": 1.137035158655356
    },
    {
      "type": "training",
      "description": "Training step 792",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:14",
      "total_flops_so_far": 1138467310696828.0,
      "budget_used_percent": 1.138467310696828
    },
    {
      "type": "training",
      "description": "Training step 793",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:14",
      "total_flops_so_far": 1139899462738300.0,
      "budget_used_percent": 1.1398994627383001
    },
    {
      "type": "training",
      "description": "Training step 794",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:14",
      "total_flops_so_far": 1141331614779772.0,
      "budget_used_percent": 1.141331614779772
    },
    {
      "type": "training",
      "description": "Training step 795",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:14",
      "total_flops_so_far": 1142763766821244.0,
      "budget_used_percent": 1.142763766821244
    },
    {
      "type": "training",
      "description": "Training step 796",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:14",
      "total_flops_so_far": 1144195918862716.0,
      "budget_used_percent": 1.144195918862716
    },
    {
      "type": "training",
      "description": "Training step 797",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:14",
      "total_flops_so_far": 1145628070904188.0,
      "budget_used_percent": 1.145628070904188
    },
    {
      "type": "training",
      "description": "Training step 798",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:14",
      "total_flops_so_far": 1147060222945660.0,
      "budget_used_percent": 1.14706022294566
    },
    {
      "type": "training",
      "description": "Training step 799",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:15",
      "total_flops_so_far": 1148492374987132.0,
      "budget_used_percent": 1.148492374987132
    },
    {
      "type": "training",
      "description": "Training step 800",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:15",
      "total_flops_so_far": 1149924527028604.0,
      "budget_used_percent": 1.149924527028604
    },
    {
      "type": "training",
      "description": "Training step 801",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:15",
      "total_flops_so_far": 1151356679070076.0,
      "budget_used_percent": 1.151356679070076
    },
    {
      "type": "training",
      "description": "Training step 802",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:15",
      "total_flops_so_far": 1152788831111548.0,
      "budget_used_percent": 1.1527888311115482
    },
    {
      "type": "training",
      "description": "Training step 803",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:15",
      "total_flops_so_far": 1154220983153020.0,
      "budget_used_percent": 1.15422098315302
    },
    {
      "type": "training",
      "description": "Training step 804",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:15",
      "total_flops_so_far": 1155653135194492.0,
      "budget_used_percent": 1.1556531351944919
    },
    {
      "type": "training",
      "description": "Training step 805",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:15",
      "total_flops_so_far": 1157085287235964.0,
      "budget_used_percent": 1.157085287235964
    },
    {
      "type": "training",
      "description": "Training step 806",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:16",
      "total_flops_so_far": 1158517439277436.0,
      "budget_used_percent": 1.158517439277436
    },
    {
      "type": "training",
      "description": "Training step 807",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:16",
      "total_flops_so_far": 1159949591318908.0,
      "budget_used_percent": 1.159949591318908
    },
    {
      "type": "training",
      "description": "Training step 808",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:16",
      "total_flops_so_far": 1161381743360380.0,
      "budget_used_percent": 1.1613817433603801
    },
    {
      "type": "training",
      "description": "Training step 809",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:16",
      "total_flops_so_far": 1162813895401852.0,
      "budget_used_percent": 1.162813895401852
    },
    {
      "type": "training",
      "description": "Training step 810",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:16",
      "total_flops_so_far": 1164246047443324.0,
      "budget_used_percent": 1.164246047443324
    },
    {
      "type": "training",
      "description": "Training step 811",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:16",
      "total_flops_so_far": 1165678199484796.0,
      "budget_used_percent": 1.165678199484796
    },
    {
      "type": "training",
      "description": "Training step 812",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:16",
      "total_flops_so_far": 1167110351526268.0,
      "budget_used_percent": 1.167110351526268
    },
    {
      "type": "training",
      "description": "Training step 813",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:16",
      "total_flops_so_far": 1168542503567740.0,
      "budget_used_percent": 1.16854250356774
    },
    {
      "type": "training",
      "description": "Training step 814",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:17",
      "total_flops_so_far": 1169974655609212.0,
      "budget_used_percent": 1.169974655609212
    },
    {
      "type": "training",
      "description": "Training step 815",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:17",
      "total_flops_so_far": 1171406807650684.0,
      "budget_used_percent": 1.171406807650684
    },
    {
      "type": "training",
      "description": "Training step 816",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:17",
      "total_flops_so_far": 1172838959692156.0,
      "budget_used_percent": 1.172838959692156
    },
    {
      "type": "training",
      "description": "Training step 817",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:17",
      "total_flops_so_far": 1174271111733628.0,
      "budget_used_percent": 1.174271111733628
    },
    {
      "type": "training",
      "description": "Training step 818",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:17",
      "total_flops_so_far": 1175703263775100.0,
      "budget_used_percent": 1.1757032637751
    },
    {
      "type": "training",
      "description": "Training step 819",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:17",
      "total_flops_so_far": 1177135415816572.0,
      "budget_used_percent": 1.1771354158165719
    },
    {
      "type": "training",
      "description": "Training step 820",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:17",
      "total_flops_so_far": 1178567567858044.0,
      "budget_used_percent": 1.178567567858044
    },
    {
      "type": "training",
      "description": "Training step 821",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:18",
      "total_flops_so_far": 1179999719899516.0,
      "budget_used_percent": 1.179999719899516
    },
    {
      "type": "training",
      "description": "Training step 822",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:18",
      "total_flops_so_far": 1181431871940988.0,
      "budget_used_percent": 1.181431871940988
    },
    {
      "type": "training",
      "description": "Training step 823",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:18",
      "total_flops_so_far": 1182864023982460.0,
      "budget_used_percent": 1.1828640239824602
    },
    {
      "type": "training",
      "description": "Training step 824",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:18",
      "total_flops_so_far": 1184296176023932.0,
      "budget_used_percent": 1.1842961760239321
    },
    {
      "type": "training",
      "description": "Training step 825",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:18",
      "total_flops_so_far": 1185728328065404.0,
      "budget_used_percent": 1.185728328065404
    },
    {
      "type": "training",
      "description": "Training step 826",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:18",
      "total_flops_so_far": 1187160480106876.0,
      "budget_used_percent": 1.187160480106876
    },
    {
      "type": "training",
      "description": "Training step 827",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:18",
      "total_flops_so_far": 1188592632148348.0,
      "budget_used_percent": 1.188592632148348
    },
    {
      "type": "training",
      "description": "Training step 828",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:18",
      "total_flops_so_far": 1190024784189820.0,
      "budget_used_percent": 1.19002478418982
    },
    {
      "type": "training",
      "description": "Training step 829",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:19",
      "total_flops_so_far": 1191456936231292.0,
      "budget_used_percent": 1.1914569362312921
    },
    {
      "type": "training",
      "description": "Training step 830",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:19",
      "total_flops_so_far": 1192889088272764.0,
      "budget_used_percent": 1.192889088272764
    },
    {
      "type": "training",
      "description": "Training step 831",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:19",
      "total_flops_so_far": 1194321240314236.0,
      "budget_used_percent": 1.194321240314236
    },
    {
      "type": "training",
      "description": "Training step 832",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:19",
      "total_flops_so_far": 1195753392355708.0,
      "budget_used_percent": 1.195753392355708
    },
    {
      "type": "training",
      "description": "Training step 833",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:19",
      "total_flops_so_far": 1197185544397180.0,
      "budget_used_percent": 1.19718554439718
    },
    {
      "type": "training",
      "description": "Training step 834",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:19",
      "total_flops_so_far": 1198617696438652.0,
      "budget_used_percent": 1.198617696438652
    },
    {
      "type": "training",
      "description": "Training step 835",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:19",
      "total_flops_so_far": 1200049848480124.0,
      "budget_used_percent": 1.2000498484801239
    },
    {
      "type": "training",
      "description": "Training step 836",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:20",
      "total_flops_so_far": 1201482000521596.0,
      "budget_used_percent": 1.201482000521596
    },
    {
      "type": "training",
      "description": "Training step 837",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:20",
      "total_flops_so_far": 1202914152563068.0,
      "budget_used_percent": 1.202914152563068
    },
    {
      "type": "training",
      "description": "Training step 838",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:20",
      "total_flops_so_far": 1204346304604540.0,
      "budget_used_percent": 1.20434630460454
    },
    {
      "type": "training",
      "description": "Training step 839",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:20",
      "total_flops_so_far": 1205778456646012.0,
      "budget_used_percent": 1.2057784566460121
    },
    {
      "type": "training",
      "description": "Training step 840",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:20",
      "total_flops_so_far": 1207210608687484.0,
      "budget_used_percent": 1.2072106086874839
    },
    {
      "type": "training",
      "description": "Training step 841",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:20",
      "total_flops_so_far": 1208642760728956.0,
      "budget_used_percent": 1.2086427607289558
    },
    {
      "type": "training",
      "description": "Training step 842",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:20",
      "total_flops_so_far": 1210074912770428.0,
      "budget_used_percent": 1.210074912770428
    },
    {
      "type": "training",
      "description": "Training step 843",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:21",
      "total_flops_so_far": 1211507064811900.0,
      "budget_used_percent": 1.2115070648119
    },
    {
      "type": "training",
      "description": "Training step 844",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:21",
      "total_flops_so_far": 1212939216853372.0,
      "budget_used_percent": 1.212939216853372
    },
    {
      "type": "training",
      "description": "Training step 845",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:21",
      "total_flops_so_far": 1214371368894844.0,
      "budget_used_percent": 1.214371368894844
    },
    {
      "type": "training",
      "description": "Training step 846",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:21",
      "total_flops_so_far": 1215803520936316.0,
      "budget_used_percent": 1.215803520936316
    },
    {
      "type": "training",
      "description": "Training step 847",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:21",
      "total_flops_so_far": 1217235672977788.0,
      "budget_used_percent": 1.217235672977788
    },
    {
      "type": "training",
      "description": "Training step 848",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:21",
      "total_flops_so_far": 1218667825019260.0,
      "budget_used_percent": 1.21866782501926
    },
    {
      "type": "training",
      "description": "Training step 849",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:21",
      "total_flops_so_far": 1220099977060732.0,
      "budget_used_percent": 1.220099977060732
    },
    {
      "type": "training",
      "description": "Training step 850",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:21",
      "total_flops_so_far": 1221532129102204.0,
      "budget_used_percent": 1.2215321291022039
    },
    {
      "type": "training",
      "description": "Training step 851",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:22",
      "total_flops_so_far": 1222964281143676.0,
      "budget_used_percent": 1.222964281143676
    },
    {
      "type": "training",
      "description": "Training step 852",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:22",
      "total_flops_so_far": 1224396433185148.0,
      "budget_used_percent": 1.224396433185148
    },
    {
      "type": "training",
      "description": "Training step 853",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:22",
      "total_flops_so_far": 1225828585226620.0,
      "budget_used_percent": 1.22582858522662
    },
    {
      "type": "training",
      "description": "Training step 854",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:22",
      "total_flops_so_far": 1227260737268092.0,
      "budget_used_percent": 1.2272607372680922
    },
    {
      "type": "training",
      "description": "Training step 855",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:22",
      "total_flops_so_far": 1228692889309564.0,
      "budget_used_percent": 1.2286928893095639
    },
    {
      "type": "training",
      "description": "Training step 856",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:22",
      "total_flops_so_far": 1230125041351036.0,
      "budget_used_percent": 1.2301250413510358
    },
    {
      "type": "training",
      "description": "Training step 857",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:22",
      "total_flops_so_far": 1231557193392508.0,
      "budget_used_percent": 1.231557193392508
    },
    {
      "type": "training",
      "description": "Training step 858",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:23",
      "total_flops_so_far": 1232989345433980.0,
      "budget_used_percent": 1.23298934543398
    },
    {
      "type": "training",
      "description": "Training step 859",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:23",
      "total_flops_so_far": 1234421497475452.0,
      "budget_used_percent": 1.234421497475452
    },
    {
      "type": "training",
      "description": "Training step 860",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:23",
      "total_flops_so_far": 1235853649516924.0,
      "budget_used_percent": 1.2358536495169241
    },
    {
      "type": "training",
      "description": "Training step 861",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:23",
      "total_flops_so_far": 1237285801558396.0,
      "budget_used_percent": 1.237285801558396
    },
    {
      "type": "training",
      "description": "Training step 862",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:23",
      "total_flops_so_far": 1238717953599868.0,
      "budget_used_percent": 1.238717953599868
    },
    {
      "type": "training",
      "description": "Training step 863",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:23",
      "total_flops_so_far": 1240150105641340.0,
      "budget_used_percent": 1.24015010564134
    },
    {
      "type": "training",
      "description": "Training step 864",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:23",
      "total_flops_so_far": 1241582257682812.0,
      "budget_used_percent": 1.241582257682812
    },
    {
      "type": "training",
      "description": "Training step 865",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:23",
      "total_flops_so_far": 1243014409724284.0,
      "budget_used_percent": 1.243014409724284
    },
    {
      "type": "training",
      "description": "Training step 866",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:24",
      "total_flops_so_far": 1244446561765756.0,
      "budget_used_percent": 1.244446561765756
    },
    {
      "type": "training",
      "description": "Training step 867",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:24",
      "total_flops_so_far": 1245878713807228.0,
      "budget_used_percent": 1.245878713807228
    },
    {
      "type": "training",
      "description": "Training step 868",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:24",
      "total_flops_so_far": 1247310865848700.0,
      "budget_used_percent": 1.2473108658487
    },
    {
      "type": "training",
      "description": "Training step 869",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:24",
      "total_flops_so_far": 1248743017890172.0,
      "budget_used_percent": 1.2487430178901722
    },
    {
      "type": "training",
      "description": "Training step 870",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:24",
      "total_flops_so_far": 1250175169931644.0,
      "budget_used_percent": 1.250175169931644
    },
    {
      "type": "training",
      "description": "Training step 871",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:24",
      "total_flops_so_far": 1251607321973116.0,
      "budget_used_percent": 1.2516073219731159
    },
    {
      "type": "training",
      "description": "Training step 872",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:24",
      "total_flops_so_far": 1253039474014588.0,
      "budget_used_percent": 1.253039474014588
    },
    {
      "type": "training",
      "description": "Training step 873",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:25",
      "total_flops_so_far": 1254471626056060.0,
      "budget_used_percent": 1.25447162605606
    },
    {
      "type": "training",
      "description": "Training step 874",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:25",
      "total_flops_so_far": 1255903778097532.0,
      "budget_used_percent": 1.255903778097532
    },
    {
      "type": "training",
      "description": "Training step 875",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:25",
      "total_flops_so_far": 1257335930139004.0,
      "budget_used_percent": 1.2573359301390041
    },
    {
      "type": "training",
      "description": "Training step 876",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:25",
      "total_flops_so_far": 1258768082180476.0,
      "budget_used_percent": 1.258768082180476
    },
    {
      "type": "training",
      "description": "Training step 877",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:25",
      "total_flops_so_far": 1260200234221948.0,
      "budget_used_percent": 1.260200234221948
    },
    {
      "type": "training",
      "description": "Training step 878",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:25",
      "total_flops_so_far": 1261632386263420.0,
      "budget_used_percent": 1.26163238626342
    },
    {
      "type": "training",
      "description": "Training step 879",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:25",
      "total_flops_so_far": 1263064538304892.0,
      "budget_used_percent": 1.263064538304892
    },
    {
      "type": "training",
      "description": "Training step 880",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:26",
      "total_flops_so_far": 1264496690346364.0,
      "budget_used_percent": 1.264496690346364
    },
    {
      "type": "training",
      "description": "Training step 881",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:26",
      "total_flops_so_far": 1265928842387836.0,
      "budget_used_percent": 1.265928842387836
    },
    {
      "type": "training",
      "description": "Training step 882",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:26",
      "total_flops_so_far": 1267360994429308.0,
      "budget_used_percent": 1.267360994429308
    },
    {
      "type": "training",
      "description": "Training step 883",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:26",
      "total_flops_so_far": 1268793146470780.0,
      "budget_used_percent": 1.26879314647078
    },
    {
      "type": "training",
      "description": "Training step 884",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:26",
      "total_flops_so_far": 1270225298512252.0,
      "budget_used_percent": 1.270225298512252
    },
    {
      "type": "training",
      "description": "Training step 885",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:26",
      "total_flops_so_far": 1271657450553724.0,
      "budget_used_percent": 1.271657450553724
    },
    {
      "type": "training",
      "description": "Training step 886",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:26",
      "total_flops_so_far": 1273089602595196.0,
      "budget_used_percent": 1.2730896025951959
    },
    {
      "type": "training",
      "description": "Training step 887",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:26",
      "total_flops_so_far": 1274521754636668.0,
      "budget_used_percent": 1.274521754636668
    },
    {
      "type": "training",
      "description": "Training step 888",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:27",
      "total_flops_so_far": 1275953906678140.0,
      "budget_used_percent": 1.27595390667814
    },
    {
      "type": "training",
      "description": "Training step 889",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:27",
      "total_flops_so_far": 1277386058719612.0,
      "budget_used_percent": 1.277386058719612
    },
    {
      "type": "training",
      "description": "Training step 890",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:27",
      "total_flops_so_far": 1278818210761084.0,
      "budget_used_percent": 1.2788182107610842
    },
    {
      "type": "training",
      "description": "Training step 891",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:27",
      "total_flops_so_far": 1280250362802556.0,
      "budget_used_percent": 1.280250362802556
    },
    {
      "type": "training",
      "description": "Training step 892",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:27",
      "total_flops_so_far": 1281682514844028.0,
      "budget_used_percent": 1.281682514844028
    },
    {
      "type": "training",
      "description": "Training step 893",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:27",
      "total_flops_so_far": 1283114666885500.0,
      "budget_used_percent": 1.2831146668855
    },
    {
      "type": "training",
      "description": "Training step 894",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:27",
      "total_flops_so_far": 1284546818926972.0,
      "budget_used_percent": 1.284546818926972
    },
    {
      "type": "training",
      "description": "Training step 895",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:28",
      "total_flops_so_far": 1285978970968444.0,
      "budget_used_percent": 1.285978970968444
    },
    {
      "type": "training",
      "description": "Training step 896",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:28",
      "total_flops_so_far": 1287411123009916.0,
      "budget_used_percent": 1.2874111230099161
    },
    {
      "type": "training",
      "description": "Training step 897",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:28",
      "total_flops_so_far": 1288843275051388.0,
      "budget_used_percent": 1.288843275051388
    },
    {
      "type": "training",
      "description": "Training step 898",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:28",
      "total_flops_so_far": 1290275427092860.0,
      "budget_used_percent": 1.29027542709286
    },
    {
      "type": "training",
      "description": "Training step 899",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:28",
      "total_flops_so_far": 1291707579134332.0,
      "budget_used_percent": 1.291707579134332
    },
    {
      "type": "training",
      "description": "Training step 900",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:28",
      "total_flops_so_far": 1293139731175804.0,
      "budget_used_percent": 1.293139731175804
    },
    {
      "type": "training",
      "description": "Training step 901",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:28",
      "total_flops_so_far": 1294571883217276.0,
      "budget_used_percent": 1.294571883217276
    },
    {
      "type": "training",
      "description": "Training step 902",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:29",
      "total_flops_so_far": 1296004035258748.0,
      "budget_used_percent": 1.296004035258748
    },
    {
      "type": "training",
      "description": "Training step 903",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:29",
      "total_flops_so_far": 1297436187300220.0,
      "budget_used_percent": 1.29743618730022
    },
    {
      "type": "training",
      "description": "Training step 904",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:29",
      "total_flops_so_far": 1298868339341692.0,
      "budget_used_percent": 1.298868339341692
    },
    {
      "type": "training",
      "description": "Training step 905",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:29",
      "total_flops_so_far": 1300300491383164.0,
      "budget_used_percent": 1.3003004913831642
    },
    {
      "type": "training",
      "description": "Training step 906",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:29",
      "total_flops_so_far": 1301732643424636.0,
      "budget_used_percent": 1.3017326434246361
    },
    {
      "type": "training",
      "description": "Training step 907",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:29",
      "total_flops_so_far": 1303164795466108.0,
      "budget_used_percent": 1.3031647954661079
    },
    {
      "type": "training",
      "description": "Training step 908",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:29",
      "total_flops_so_far": 1304596947507580.0,
      "budget_used_percent": 1.3045969475075798
    },
    {
      "type": "training",
      "description": "Training step 909",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:30",
      "total_flops_so_far": 1306029099549052.0,
      "budget_used_percent": 1.306029099549052
    },
    {
      "type": "training",
      "description": "Training step 910",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:30",
      "total_flops_so_far": 1307461251590524.0,
      "budget_used_percent": 1.307461251590524
    },
    {
      "type": "training",
      "description": "Training step 911",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:30",
      "total_flops_so_far": 1308893403631996.0,
      "budget_used_percent": 1.308893403631996
    },
    {
      "type": "training",
      "description": "Training step 912",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:30",
      "total_flops_so_far": 1310325555673468.0,
      "budget_used_percent": 1.310325555673468
    },
    {
      "type": "training",
      "description": "Training step 913",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:30",
      "total_flops_so_far": 1311757707714940.0,
      "budget_used_percent": 1.31175770771494
    },
    {
      "type": "training",
      "description": "Training step 914",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:30",
      "total_flops_so_far": 1313189859756412.0,
      "budget_used_percent": 1.313189859756412
    },
    {
      "type": "training",
      "description": "Training step 915",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:30",
      "total_flops_so_far": 1314622011797884.0,
      "budget_used_percent": 1.314622011797884
    },
    {
      "type": "training",
      "description": "Training step 916",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:30",
      "total_flops_so_far": 1316054163839356.0,
      "budget_used_percent": 1.316054163839356
    },
    {
      "type": "training",
      "description": "Training step 917",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:31",
      "total_flops_so_far": 1317486315880828.0,
      "budget_used_percent": 1.3174863158808279
    },
    {
      "type": "training",
      "description": "Training step 918",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:31",
      "total_flops_so_far": 1318918467922300.0,
      "budget_used_percent": 1.3189184679223
    },
    {
      "type": "training",
      "description": "Training step 919",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:31",
      "total_flops_so_far": 1320350619963772.0,
      "budget_used_percent": 1.320350619963772
    },
    {
      "type": "training",
      "description": "Training step 920",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:31",
      "total_flops_so_far": 1321782772005244.0,
      "budget_used_percent": 1.321782772005244
    },
    {
      "type": "training",
      "description": "Training step 921",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:31",
      "total_flops_so_far": 1323214924046716.0,
      "budget_used_percent": 1.3232149240467161
    },
    {
      "type": "training",
      "description": "Training step 922",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:31",
      "total_flops_so_far": 1324647076088188.0,
      "budget_used_percent": 1.3246470760881879
    },
    {
      "type": "training",
      "description": "Training step 923",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:31",
      "total_flops_so_far": 1326079228129660.0,
      "budget_used_percent": 1.3260792281296598
    },
    {
      "type": "training",
      "description": "Training step 924",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:32",
      "total_flops_so_far": 1327511380171132.0,
      "budget_used_percent": 1.327511380171132
    },
    {
      "type": "training",
      "description": "Training step 925",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:32",
      "total_flops_so_far": 1328943532212604.0,
      "budget_used_percent": 1.328943532212604
    },
    {
      "type": "training",
      "description": "Training step 926",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:32",
      "total_flops_so_far": 1330375684254076.0,
      "budget_used_percent": 1.330375684254076
    },
    {
      "type": "training",
      "description": "Training step 927",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:32",
      "total_flops_so_far": 1331807836295548.0,
      "budget_used_percent": 1.331807836295548
    },
    {
      "type": "training",
      "description": "Training step 928",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:32",
      "total_flops_so_far": 1333239988337020.0,
      "budget_used_percent": 1.33323998833702
    },
    {
      "type": "training",
      "description": "Training step 929",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:32",
      "total_flops_so_far": 1334672140378492.0,
      "budget_used_percent": 1.334672140378492
    },
    {
      "type": "training",
      "description": "Training step 930",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:32",
      "total_flops_so_far": 1336104292419964.0,
      "budget_used_percent": 1.336104292419964
    },
    {
      "type": "training",
      "description": "Training step 931",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:33",
      "total_flops_so_far": 1337536444461436.0,
      "budget_used_percent": 1.337536444461436
    },
    {
      "type": "training",
      "description": "Training step 932",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:33",
      "total_flops_so_far": 1338968596502908.0,
      "budget_used_percent": 1.338968596502908
    },
    {
      "type": "training",
      "description": "Training step 933",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:33",
      "total_flops_so_far": 1340400748544380.0,
      "budget_used_percent": 1.34040074854438
    },
    {
      "type": "training",
      "description": "Training step 934",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:33",
      "total_flops_so_far": 1341832900585852.0,
      "budget_used_percent": 1.341832900585852
    },
    {
      "type": "training",
      "description": "Training step 935",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:33",
      "total_flops_so_far": 1343265052627324.0,
      "budget_used_percent": 1.343265052627324
    },
    {
      "type": "training",
      "description": "Training step 936",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:33",
      "total_flops_so_far": 1344697204668796.0,
      "budget_used_percent": 1.3446972046687962
    },
    {
      "type": "training",
      "description": "Training step 937",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:33",
      "total_flops_so_far": 1346129356710268.0,
      "budget_used_percent": 1.346129356710268
    },
    {
      "type": "training",
      "description": "Training step 938",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:33",
      "total_flops_so_far": 1347561508751740.0,
      "budget_used_percent": 1.3475615087517399
    },
    {
      "type": "training",
      "description": "Training step 939",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:34",
      "total_flops_so_far": 1348993660793212.0,
      "budget_used_percent": 1.348993660793212
    },
    {
      "type": "training",
      "description": "Training step 940",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:34",
      "total_flops_so_far": 1350425812834684.0,
      "budget_used_percent": 1.350425812834684
    },
    {
      "type": "training",
      "description": "Training step 941",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:34",
      "total_flops_so_far": 1351857964876156.0,
      "budget_used_percent": 1.351857964876156
    },
    {
      "type": "training",
      "description": "Training step 942",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:34",
      "total_flops_so_far": 1353290116917628.0,
      "budget_used_percent": 1.3532901169176281
    },
    {
      "type": "training",
      "description": "Training step 943",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:34",
      "total_flops_so_far": 1354722268959100.0,
      "budget_used_percent": 1.3547222689591
    },
    {
      "type": "training",
      "description": "Training step 944",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:34",
      "total_flops_so_far": 1356154421000572.0,
      "budget_used_percent": 1.356154421000572
    },
    {
      "type": "training",
      "description": "Training step 945",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:34",
      "total_flops_so_far": 1357586573042044.0,
      "budget_used_percent": 1.357586573042044
    },
    {
      "type": "training",
      "description": "Training step 946",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:35",
      "total_flops_so_far": 1359018725083516.0,
      "budget_used_percent": 1.359018725083516
    },
    {
      "type": "training",
      "description": "Training step 947",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:35",
      "total_flops_so_far": 1360450877124988.0,
      "budget_used_percent": 1.360450877124988
    },
    {
      "type": "training",
      "description": "Training step 948",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:35",
      "total_flops_so_far": 1361883029166460.0,
      "budget_used_percent": 1.36188302916646
    },
    {
      "type": "training",
      "description": "Training step 949",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:35",
      "total_flops_so_far": 1363315181207932.0,
      "budget_used_percent": 1.363315181207932
    },
    {
      "type": "training",
      "description": "Training step 950",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:35",
      "total_flops_so_far": 1364747333249404.0,
      "budget_used_percent": 1.364747333249404
    },
    {
      "type": "training",
      "description": "Training step 951",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:35",
      "total_flops_so_far": 1366179485290876.0,
      "budget_used_percent": 1.366179485290876
    },
    {
      "type": "training",
      "description": "Training step 952",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:35",
      "total_flops_so_far": 1367611637332348.0,
      "budget_used_percent": 1.367611637332348
    },
    {
      "type": "training",
      "description": "Training step 953",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:36",
      "total_flops_so_far": 1369043789373820.0,
      "budget_used_percent": 1.3690437893738199
    },
    {
      "type": "training",
      "description": "Training step 954",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:36",
      "total_flops_so_far": 1370475941415292.0,
      "budget_used_percent": 1.370475941415292
    },
    {
      "type": "training",
      "description": "Training step 955",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:36",
      "total_flops_so_far": 1371908093456764.0,
      "budget_used_percent": 1.371908093456764
    },
    {
      "type": "training",
      "description": "Training step 956",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:36",
      "total_flops_so_far": 1373340245498236.0,
      "budget_used_percent": 1.373340245498236
    },
    {
      "type": "training",
      "description": "Training step 957",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:36",
      "total_flops_so_far": 1374772397539708.0,
      "budget_used_percent": 1.3747723975397081
    },
    {
      "type": "training",
      "description": "Training step 958",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:36",
      "total_flops_so_far": 1376204549581180.0,
      "budget_used_percent": 1.37620454958118
    },
    {
      "type": "training",
      "description": "Training step 959",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:36",
      "total_flops_so_far": 1377636701622652.0,
      "budget_used_percent": 1.377636701622652
    },
    {
      "type": "training",
      "description": "Training step 960",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:37",
      "total_flops_so_far": 1379068853664124.0,
      "budget_used_percent": 1.379068853664124
    },
    {
      "type": "training",
      "description": "Training step 961",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:37",
      "total_flops_so_far": 1380501005705596.0,
      "budget_used_percent": 1.380501005705596
    },
    {
      "type": "training",
      "description": "Training step 962",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:37",
      "total_flops_so_far": 1381933157747068.0,
      "budget_used_percent": 1.381933157747068
    },
    {
      "type": "training",
      "description": "Training step 963",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:37",
      "total_flops_so_far": 1383365309788540.0,
      "budget_used_percent": 1.38336530978854
    },
    {
      "type": "training",
      "description": "Training step 964",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:37",
      "total_flops_so_far": 1384797461830012.0,
      "budget_used_percent": 1.384797461830012
    },
    {
      "type": "training",
      "description": "Training step 965",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:37",
      "total_flops_so_far": 1386229613871484.0,
      "budget_used_percent": 1.386229613871484
    },
    {
      "type": "training",
      "description": "Training step 966",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:37",
      "total_flops_so_far": 1387661765912956.0,
      "budget_used_percent": 1.387661765912956
    },
    {
      "type": "training",
      "description": "Training step 967",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:37",
      "total_flops_so_far": 1389093917954428.0,
      "budget_used_percent": 1.389093917954428
    },
    {
      "type": "training",
      "description": "Training step 968",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:38",
      "total_flops_so_far": 1390526069995900.0,
      "budget_used_percent": 1.3905260699959
    },
    {
      "type": "training",
      "description": "Training step 969",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:38",
      "total_flops_so_far": 1391958222037372.0,
      "budget_used_percent": 1.391958222037372
    },
    {
      "type": "training",
      "description": "Training step 970",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:38",
      "total_flops_so_far": 1393390374078844.0,
      "budget_used_percent": 1.393390374078844
    },
    {
      "type": "training",
      "description": "Training step 971",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:38",
      "total_flops_so_far": 1394822526120316.0,
      "budget_used_percent": 1.394822526120316
    },
    {
      "type": "training",
      "description": "Training step 972",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:38",
      "total_flops_so_far": 1396254678161788.0,
      "budget_used_percent": 1.3962546781617882
    },
    {
      "type": "training",
      "description": "Training step 973",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:38",
      "total_flops_so_far": 1397686830203260.0,
      "budget_used_percent": 1.3976868302032601
    },
    {
      "type": "training",
      "description": "Training step 974",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:38",
      "total_flops_so_far": 1399118982244732.0,
      "budget_used_percent": 1.3991189822447319
    },
    {
      "type": "training",
      "description": "Training step 975",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:39",
      "total_flops_so_far": 1400551134286204.0,
      "budget_used_percent": 1.400551134286204
    },
    {
      "type": "training",
      "description": "Training step 976",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:39",
      "total_flops_so_far": 1401983286327676.0,
      "budget_used_percent": 1.401983286327676
    },
    {
      "type": "training",
      "description": "Training step 977",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:39",
      "total_flops_so_far": 1403415438369148.0,
      "budget_used_percent": 1.403415438369148
    },
    {
      "type": "training",
      "description": "Training step 978",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:39",
      "total_flops_so_far": 1404847590410620.0,
      "budget_used_percent": 1.40484759041062
    },
    {
      "type": "training",
      "description": "Training step 979",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:39",
      "total_flops_so_far": 1406279742452092.0,
      "budget_used_percent": 1.406279742452092
    },
    {
      "type": "training",
      "description": "Training step 980",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:39",
      "total_flops_so_far": 1407711894493564.0,
      "budget_used_percent": 1.407711894493564
    },
    {
      "type": "training",
      "description": "Training step 981",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:39",
      "total_flops_so_far": 1409144046535036.0,
      "budget_used_percent": 1.409144046535036
    },
    {
      "type": "training",
      "description": "Training step 982",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:40",
      "total_flops_so_far": 1410576198576508.0,
      "budget_used_percent": 1.410576198576508
    },
    {
      "type": "training",
      "description": "Training step 983",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:40",
      "total_flops_so_far": 1412008350617980.0,
      "budget_used_percent": 1.41200835061798
    },
    {
      "type": "training",
      "description": "Training step 984",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:40",
      "total_flops_so_far": 1413440502659452.0,
      "budget_used_percent": 1.4134405026594519
    },
    {
      "type": "training",
      "description": "Training step 985",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:40",
      "total_flops_so_far": 1414872654700924.0,
      "budget_used_percent": 1.414872654700924
    },
    {
      "type": "training",
      "description": "Training step 986",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:40",
      "total_flops_so_far": 1416304806742396.0,
      "budget_used_percent": 1.416304806742396
    },
    {
      "type": "training",
      "description": "Training step 987",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:40",
      "total_flops_so_far": 1417736958783868.0,
      "budget_used_percent": 1.417736958783868
    },
    {
      "type": "training",
      "description": "Training step 988",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:40",
      "total_flops_so_far": 1419169110825340.0,
      "budget_used_percent": 1.4191691108253401
    },
    {
      "type": "training",
      "description": "Training step 989",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:41",
      "total_flops_so_far": 1420601262866812.0,
      "budget_used_percent": 1.4206012628668119
    },
    {
      "type": "training",
      "description": "Training step 990",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:41",
      "total_flops_so_far": 1422033414908284.0,
      "budget_used_percent": 1.4220334149082838
    },
    {
      "type": "training",
      "description": "Training step 991",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:41",
      "total_flops_so_far": 1423465566949756.0,
      "budget_used_percent": 1.423465566949756
    },
    {
      "type": "training",
      "description": "Training step 992",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:41",
      "total_flops_so_far": 1424897718991228.0,
      "budget_used_percent": 1.424897718991228
    },
    {
      "type": "training",
      "description": "Training step 993",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:41",
      "total_flops_so_far": 1426329871032700.0,
      "budget_used_percent": 1.4263298710327
    },
    {
      "type": "training",
      "description": "Training step 994",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:41",
      "total_flops_so_far": 1427762023074172.0,
      "budget_used_percent": 1.427762023074172
    },
    {
      "type": "training",
      "description": "Training step 995",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:41",
      "total_flops_so_far": 1429194175115644.0,
      "budget_used_percent": 1.429194175115644
    },
    {
      "type": "training",
      "description": "Training step 996",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:42",
      "total_flops_so_far": 1430626327157116.0,
      "budget_used_percent": 1.430626327157116
    },
    {
      "type": "training",
      "description": "Training step 997",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:42",
      "total_flops_so_far": 1432058479198588.0,
      "budget_used_percent": 1.432058479198588
    },
    {
      "type": "training",
      "description": "Training step 998",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:42",
      "total_flops_so_far": 1433490631240060.0,
      "budget_used_percent": 1.43349063124006
    },
    {
      "type": "training",
      "description": "Training step 999",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:42",
      "total_flops_so_far": 1434922783281532.0,
      "budget_used_percent": 1.4349227832815319
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 0",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552526568288.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:43",
      "total_flops_so_far": 1435475309849820.0,
      "budget_used_percent": 1.43547530984982
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 1",
      "context_len": 604,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 556130834256.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:45",
      "total_flops_so_far": 1436031440684076.0,
      "budget_used_percent": 1.436031440684076
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 2",
      "context_len": 602,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 554328341080.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:46",
      "total_flops_so_far": 1436585769025156.0,
      "budget_used_percent": 1.436585769025156
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 3",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552526568288.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:47",
      "total_flops_so_far": 1437138295593444.0,
      "budget_used_percent": 1.437138295593444
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 4",
      "context_len": 603,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 555229497620.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:48",
      "total_flops_so_far": 1437693525091064.0,
      "budget_used_percent": 1.437693525091064
    },
    {
      "type": "training",
      "description": "Training step 1000",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:49",
      "total_flops_so_far": 1439125677132536.0,
      "budget_used_percent": 1.439125677132536
    },
    {
      "type": "training",
      "description": "Training step 1001",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:49",
      "total_flops_so_far": 1440557829174008.0,
      "budget_used_percent": 1.440557829174008
    },
    {
      "type": "training",
      "description": "Training step 1002",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:49",
      "total_flops_so_far": 1441989981215480.0,
      "budget_used_percent": 1.44198998121548
    },
    {
      "type": "training",
      "description": "Training step 1003",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:49",
      "total_flops_so_far": 1443422133256952.0,
      "budget_used_percent": 1.443422133256952
    },
    {
      "type": "training",
      "description": "Training step 1004",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:49",
      "total_flops_so_far": 1444854285298424.0,
      "budget_used_percent": 1.444854285298424
    },
    {
      "type": "training",
      "description": "Training step 1005",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:50",
      "total_flops_so_far": 1446286437339896.0,
      "budget_used_percent": 1.446286437339896
    },
    {
      "type": "training",
      "description": "Training step 1006",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:50",
      "total_flops_so_far": 1447718589381368.0,
      "budget_used_percent": 1.447718589381368
    },
    {
      "type": "training",
      "description": "Training step 1007",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:50",
      "total_flops_so_far": 1449150741422840.0,
      "budget_used_percent": 1.44915074142284
    },
    {
      "type": "training",
      "description": "Training step 1008",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:50",
      "total_flops_so_far": 1450582893464312.0,
      "budget_used_percent": 1.450582893464312
    },
    {
      "type": "training",
      "description": "Training step 1009",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:50",
      "total_flops_so_far": 1452015045505784.0,
      "budget_used_percent": 1.4520150455057839
    },
    {
      "type": "training",
      "description": "Training step 1010",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:50",
      "total_flops_so_far": 1453447197547256.0,
      "budget_used_percent": 1.453447197547256
    },
    {
      "type": "training",
      "description": "Training step 1011",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:51",
      "total_flops_so_far": 1454879349588728.0,
      "budget_used_percent": 1.454879349588728
    },
    {
      "type": "training",
      "description": "Training step 1012",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:51",
      "total_flops_so_far": 1456311501630200.0,
      "budget_used_percent": 1.4563115016302
    },
    {
      "type": "training",
      "description": "Training step 1013",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:51",
      "total_flops_so_far": 1457743653671672.0,
      "budget_used_percent": 1.4577436536716721
    },
    {
      "type": "training",
      "description": "Training step 1014",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:51",
      "total_flops_so_far": 1459175805713144.0,
      "budget_used_percent": 1.459175805713144
    },
    {
      "type": "training",
      "description": "Training step 1015",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:51",
      "total_flops_so_far": 1460607957754616.0,
      "budget_used_percent": 1.460607957754616
    },
    {
      "type": "training",
      "description": "Training step 1016",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:51",
      "total_flops_so_far": 1462040109796088.0,
      "budget_used_percent": 1.462040109796088
    },
    {
      "type": "training",
      "description": "Training step 1017",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:51",
      "total_flops_so_far": 1463472261837560.0,
      "budget_used_percent": 1.46347226183756
    },
    {
      "type": "training",
      "description": "Training step 1018",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:51",
      "total_flops_so_far": 1464904413879032.0,
      "budget_used_percent": 1.464904413879032
    },
    {
      "type": "training",
      "description": "Training step 1019",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:52",
      "total_flops_so_far": 1466336565920504.0,
      "budget_used_percent": 1.466336565920504
    },
    {
      "type": "training",
      "description": "Training step 1020",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:52",
      "total_flops_so_far": 1467768717961976.0,
      "budget_used_percent": 1.467768717961976
    },
    {
      "type": "training",
      "description": "Training step 1021",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:52",
      "total_flops_so_far": 1469200870003448.0,
      "budget_used_percent": 1.469200870003448
    },
    {
      "type": "training",
      "description": "Training step 1022",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:52",
      "total_flops_so_far": 1470633022044920.0,
      "budget_used_percent": 1.47063302204492
    },
    {
      "type": "training",
      "description": "Training step 1023",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:52",
      "total_flops_so_far": 1472065174086392.0,
      "budget_used_percent": 1.472065174086392
    },
    {
      "type": "training",
      "description": "Training step 1024",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:52",
      "total_flops_so_far": 1473497326127864.0,
      "budget_used_percent": 1.4734973261278639
    },
    {
      "type": "training",
      "description": "Training step 1025",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:52",
      "total_flops_so_far": 1474929478169336.0,
      "budget_used_percent": 1.474929478169336
    },
    {
      "type": "training",
      "description": "Training step 1026",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:53",
      "total_flops_so_far": 1476361630210808.0,
      "budget_used_percent": 1.476361630210808
    },
    {
      "type": "training",
      "description": "Training step 1027",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:53",
      "total_flops_so_far": 1477793782252280.0,
      "budget_used_percent": 1.47779378225228
    },
    {
      "type": "training",
      "description": "Training step 1028",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:53",
      "total_flops_so_far": 1479225934293752.0,
      "budget_used_percent": 1.4792259342937522
    },
    {
      "type": "training",
      "description": "Training step 1029",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:53",
      "total_flops_so_far": 1480658086335224.0,
      "budget_used_percent": 1.480658086335224
    },
    {
      "type": "training",
      "description": "Training step 1030",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:53",
      "total_flops_so_far": 1482090238376696.0,
      "budget_used_percent": 1.482090238376696
    },
    {
      "type": "training",
      "description": "Training step 1031",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:53",
      "total_flops_so_far": 1483522390418168.0,
      "budget_used_percent": 1.483522390418168
    },
    {
      "type": "training",
      "description": "Training step 1032",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:53",
      "total_flops_so_far": 1484954542459640.0,
      "budget_used_percent": 1.48495454245964
    },
    {
      "type": "training",
      "description": "Training step 1033",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:54",
      "total_flops_so_far": 1486386694501112.0,
      "budget_used_percent": 1.486386694501112
    },
    {
      "type": "training",
      "description": "Training step 1034",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:54",
      "total_flops_so_far": 1487818846542584.0,
      "budget_used_percent": 1.4878188465425841
    },
    {
      "type": "training",
      "description": "Training step 1035",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:54",
      "total_flops_so_far": 1489250998584056.0,
      "budget_used_percent": 1.489250998584056
    },
    {
      "type": "training",
      "description": "Training step 1036",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:54",
      "total_flops_so_far": 1490683150625528.0,
      "budget_used_percent": 1.490683150625528
    },
    {
      "type": "training",
      "description": "Training step 1037",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:54",
      "total_flops_so_far": 1492115302667000.0,
      "budget_used_percent": 1.492115302667
    },
    {
      "type": "training",
      "description": "Training step 1038",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:54",
      "total_flops_so_far": 1493547454708472.0,
      "budget_used_percent": 1.493547454708472
    },
    {
      "type": "training",
      "description": "Training step 1039",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:54",
      "total_flops_so_far": 1494979606749944.0,
      "budget_used_percent": 1.494979606749944
    },
    {
      "type": "training",
      "description": "Training step 1040",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:55",
      "total_flops_so_far": 1496411758791416.0,
      "budget_used_percent": 1.496411758791416
    },
    {
      "type": "training",
      "description": "Training step 1041",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:55",
      "total_flops_so_far": 1497843910832888.0,
      "budget_used_percent": 1.497843910832888
    },
    {
      "type": "training",
      "description": "Training step 1042",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:55",
      "total_flops_so_far": 1499276062874360.0,
      "budget_used_percent": 1.49927606287436
    },
    {
      "type": "training",
      "description": "Training step 1043",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:55",
      "total_flops_so_far": 1500708214915832.0,
      "budget_used_percent": 1.5007082149158322
    },
    {
      "type": "training",
      "description": "Training step 1044",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:55",
      "total_flops_so_far": 1502140366957304.0,
      "budget_used_percent": 1.5021403669573041
    },
    {
      "type": "training",
      "description": "Training step 1045",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:55",
      "total_flops_so_far": 1503572518998776.0,
      "budget_used_percent": 1.5035725189987759
    },
    {
      "type": "training",
      "description": "Training step 1046",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:55",
      "total_flops_so_far": 1505004671040248.0,
      "budget_used_percent": 1.505004671040248
    },
    {
      "type": "training",
      "description": "Training step 1047",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:56",
      "total_flops_so_far": 1506436823081720.0,
      "budget_used_percent": 1.50643682308172
    },
    {
      "type": "training",
      "description": "Training step 1048",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:56",
      "total_flops_so_far": 1507868975123192.0,
      "budget_used_percent": 1.507868975123192
    },
    {
      "type": "training",
      "description": "Training step 1049",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:56",
      "total_flops_so_far": 1509301127164664.0,
      "budget_used_percent": 1.509301127164664
    },
    {
      "type": "training",
      "description": "Training step 1050",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:56",
      "total_flops_so_far": 1510733279206136.0,
      "budget_used_percent": 1.510733279206136
    },
    {
      "type": "training",
      "description": "Training step 1051",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:56",
      "total_flops_so_far": 1512165431247608.0,
      "budget_used_percent": 1.512165431247608
    },
    {
      "type": "training",
      "description": "Training step 1052",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:56",
      "total_flops_so_far": 1513597583289080.0,
      "budget_used_percent": 1.51359758328908
    },
    {
      "type": "training",
      "description": "Training step 1053",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:56",
      "total_flops_so_far": 1515029735330552.0,
      "budget_used_percent": 1.515029735330552
    },
    {
      "type": "training",
      "description": "Training step 1054",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:57",
      "total_flops_so_far": 1516461887372024.0,
      "budget_used_percent": 1.516461887372024
    },
    {
      "type": "training",
      "description": "Training step 1055",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:57",
      "total_flops_so_far": 1517894039413496.0,
      "budget_used_percent": 1.5178940394134959
    },
    {
      "type": "training",
      "description": "Training step 1056",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:57",
      "total_flops_so_far": 1519326191454968.0,
      "budget_used_percent": 1.519326191454968
    },
    {
      "type": "training",
      "description": "Training step 1057",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:57",
      "total_flops_so_far": 1520758343496440.0,
      "budget_used_percent": 1.52075834349644
    },
    {
      "type": "training",
      "description": "Training step 1058",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:57",
      "total_flops_so_far": 1522190495537912.0,
      "budget_used_percent": 1.522190495537912
    },
    {
      "type": "training",
      "description": "Training step 1059",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:57",
      "total_flops_so_far": 1523622647579384.0,
      "budget_used_percent": 1.523622647579384
    },
    {
      "type": "training",
      "description": "Training step 1060",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:57",
      "total_flops_so_far": 1525054799620856.0,
      "budget_used_percent": 1.5250547996208559
    },
    {
      "type": "training",
      "description": "Training step 1061",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:58",
      "total_flops_so_far": 1526486951662328.0,
      "budget_used_percent": 1.5264869516623278
    },
    {
      "type": "training",
      "description": "Training step 1062",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:58",
      "total_flops_so_far": 1527919103703800.0,
      "budget_used_percent": 1.5279191037038
    },
    {
      "type": "training",
      "description": "Training step 1063",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:58",
      "total_flops_so_far": 1529351255745272.0,
      "budget_used_percent": 1.529351255745272
    },
    {
      "type": "training",
      "description": "Training step 1064",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:58",
      "total_flops_so_far": 1530783407786744.0,
      "budget_used_percent": 1.530783407786744
    },
    {
      "type": "training",
      "description": "Training step 1065",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:58",
      "total_flops_so_far": 1532215559828216.0,
      "budget_used_percent": 1.5322155598282161
    },
    {
      "type": "training",
      "description": "Training step 1066",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:58",
      "total_flops_so_far": 1533647711869688.0,
      "budget_used_percent": 1.533647711869688
    },
    {
      "type": "training",
      "description": "Training step 1067",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:58",
      "total_flops_so_far": 1535079863911160.0,
      "budget_used_percent": 1.53507986391116
    },
    {
      "type": "training",
      "description": "Training step 1068",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:58",
      "total_flops_so_far": 1536512015952632.0,
      "budget_used_percent": 1.536512015952632
    },
    {
      "type": "training",
      "description": "Training step 1069",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:59",
      "total_flops_so_far": 1537944167994104.0,
      "budget_used_percent": 1.537944167994104
    },
    {
      "type": "training",
      "description": "Training step 1070",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:59",
      "total_flops_so_far": 1539376320035576.0,
      "budget_used_percent": 1.539376320035576
    },
    {
      "type": "training",
      "description": "Training step 1071",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:59",
      "total_flops_so_far": 1540808472077048.0,
      "budget_used_percent": 1.540808472077048
    },
    {
      "type": "training",
      "description": "Training step 1072",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:59",
      "total_flops_so_far": 1542240624118520.0,
      "budget_used_percent": 1.54224062411852
    },
    {
      "type": "training",
      "description": "Training step 1073",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:59",
      "total_flops_so_far": 1543672776159992.0,
      "budget_used_percent": 1.543672776159992
    },
    {
      "type": "training",
      "description": "Training step 1074",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:59",
      "total_flops_so_far": 1545104928201464.0,
      "budget_used_percent": 1.545104928201464
    },
    {
      "type": "training",
      "description": "Training step 1075",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:45:59",
      "total_flops_so_far": 1546537080242936.0,
      "budget_used_percent": 1.546537080242936
    },
    {
      "type": "training",
      "description": "Training step 1076",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:00",
      "total_flops_so_far": 1547969232284408.0,
      "budget_used_percent": 1.5479692322844079
    },
    {
      "type": "training",
      "description": "Training step 1077",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:00",
      "total_flops_so_far": 1549401384325880.0,
      "budget_used_percent": 1.54940138432588
    },
    {
      "type": "training",
      "description": "Training step 1078",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:00",
      "total_flops_so_far": 1550833536367352.0,
      "budget_used_percent": 1.550833536367352
    },
    {
      "type": "training",
      "description": "Training step 1079",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:00",
      "total_flops_so_far": 1552265688408824.0,
      "budget_used_percent": 1.552265688408824
    },
    {
      "type": "training",
      "description": "Training step 1080",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:00",
      "total_flops_so_far": 1553697840450296.0,
      "budget_used_percent": 1.5536978404502961
    },
    {
      "type": "training",
      "description": "Training step 1081",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:00",
      "total_flops_so_far": 1555129992491768.0,
      "budget_used_percent": 1.555129992491768
    },
    {
      "type": "training",
      "description": "Training step 1082",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:00",
      "total_flops_so_far": 1556562144533240.0,
      "budget_used_percent": 1.55656214453324
    },
    {
      "type": "training",
      "description": "Training step 1083",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:01",
      "total_flops_so_far": 1557994296574712.0,
      "budget_used_percent": 1.557994296574712
    },
    {
      "type": "training",
      "description": "Training step 1084",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:01",
      "total_flops_so_far": 1559426448616184.0,
      "budget_used_percent": 1.559426448616184
    },
    {
      "type": "training",
      "description": "Training step 1085",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:01",
      "total_flops_so_far": 1560858600657656.0,
      "budget_used_percent": 1.560858600657656
    },
    {
      "type": "training",
      "description": "Training step 1086",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:01",
      "total_flops_so_far": 1562290752699128.0,
      "budget_used_percent": 1.562290752699128
    },
    {
      "type": "training",
      "description": "Training step 1087",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:01",
      "total_flops_so_far": 1563722904740600.0,
      "budget_used_percent": 1.5637229047405998
    },
    {
      "type": "training",
      "description": "Training step 1088",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:01",
      "total_flops_so_far": 1565155056782072.0,
      "budget_used_percent": 1.5651550567820722
    },
    {
      "type": "training",
      "description": "Training step 1089",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:01",
      "total_flops_so_far": 1566587208823544.0,
      "budget_used_percent": 1.566587208823544
    },
    {
      "type": "training",
      "description": "Training step 1090",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:02",
      "total_flops_so_far": 1568019360865016.0,
      "budget_used_percent": 1.568019360865016
    },
    {
      "type": "training",
      "description": "Training step 1091",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:02",
      "total_flops_so_far": 1569451512906488.0,
      "budget_used_percent": 1.5694515129064879
    },
    {
      "type": "training",
      "description": "Training step 1092",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:02",
      "total_flops_so_far": 1570883664947960.0,
      "budget_used_percent": 1.5708836649479598
    },
    {
      "type": "training",
      "description": "Training step 1093",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:02",
      "total_flops_so_far": 1572315816989432.0,
      "budget_used_percent": 1.5723158169894318
    },
    {
      "type": "training",
      "description": "Training step 1094",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:02",
      "total_flops_so_far": 1573747969030904.0,
      "budget_used_percent": 1.5737479690309042
    },
    {
      "type": "training",
      "description": "Training step 1095",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:02",
      "total_flops_so_far": 1575180121072376.0,
      "budget_used_percent": 1.5751801210723761
    },
    {
      "type": "training",
      "description": "Training step 1096",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:02",
      "total_flops_so_far": 1576612273113848.0,
      "budget_used_percent": 1.576612273113848
    },
    {
      "type": "training",
      "description": "Training step 1097",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:03",
      "total_flops_so_far": 1578044425155320.0,
      "budget_used_percent": 1.57804442515532
    },
    {
      "type": "training",
      "description": "Training step 1098",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:03",
      "total_flops_so_far": 1579476577196792.0,
      "budget_used_percent": 1.5794765771967918
    },
    {
      "type": "training",
      "description": "Training step 1099",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:03",
      "total_flops_so_far": 1580908729238264.0,
      "budget_used_percent": 1.5809087292382638
    },
    {
      "type": "training",
      "description": "Training step 1100",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:03",
      "total_flops_so_far": 1582340881279736.0,
      "budget_used_percent": 1.5823408812797362
    },
    {
      "type": "training",
      "description": "Training step 1101",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:03",
      "total_flops_so_far": 1583773033321208.0,
      "budget_used_percent": 1.5837730333212081
    },
    {
      "type": "training",
      "description": "Training step 1102",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:03",
      "total_flops_so_far": 1585205185362680.0,
      "budget_used_percent": 1.58520518536268
    },
    {
      "type": "training",
      "description": "Training step 1103",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:03",
      "total_flops_so_far": 1586637337404152.0,
      "budget_used_percent": 1.586637337404152
    },
    {
      "type": "training",
      "description": "Training step 1104",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:04",
      "total_flops_so_far": 1588069489445624.0,
      "budget_used_percent": 1.588069489445624
    },
    {
      "type": "training",
      "description": "Training step 1105",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:04",
      "total_flops_so_far": 1589501641487096.0,
      "budget_used_percent": 1.589501641487096
    },
    {
      "type": "training",
      "description": "Training step 1106",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:04",
      "total_flops_so_far": 1590933793528568.0,
      "budget_used_percent": 1.5909337935285681
    },
    {
      "type": "training",
      "description": "Training step 1107",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:04",
      "total_flops_so_far": 1592365945570040.0,
      "budget_used_percent": 1.59236594557004
    },
    {
      "type": "training",
      "description": "Training step 1108",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:04",
      "total_flops_so_far": 1593798097611512.0,
      "budget_used_percent": 1.593798097611512
    },
    {
      "type": "training",
      "description": "Training step 1109",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:04",
      "total_flops_so_far": 1595230249652984.0,
      "budget_used_percent": 1.595230249652984
    },
    {
      "type": "training",
      "description": "Training step 1110",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:04",
      "total_flops_so_far": 1596662401694456.0,
      "budget_used_percent": 1.596662401694456
    },
    {
      "type": "training",
      "description": "Training step 1111",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:05",
      "total_flops_so_far": 1598094553735928.0,
      "budget_used_percent": 1.598094553735928
    },
    {
      "type": "training",
      "description": "Training step 1112",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:05",
      "total_flops_so_far": 1599526705777400.0,
      "budget_used_percent": 1.5995267057774
    },
    {
      "type": "training",
      "description": "Training step 1113",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:05",
      "total_flops_so_far": 1600958857818872.0,
      "budget_used_percent": 1.600958857818872
    },
    {
      "type": "training",
      "description": "Training step 1114",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:05",
      "total_flops_so_far": 1602391009860344.0,
      "budget_used_percent": 1.602391009860344
    },
    {
      "type": "training",
      "description": "Training step 1115",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:05",
      "total_flops_so_far": 1603823161901816.0,
      "budget_used_percent": 1.603823161901816
    },
    {
      "type": "training",
      "description": "Training step 1116",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:05",
      "total_flops_so_far": 1605255313943288.0,
      "budget_used_percent": 1.605255313943288
    },
    {
      "type": "training",
      "description": "Training step 1117",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:05",
      "total_flops_so_far": 1606687465984760.0,
      "budget_used_percent": 1.6066874659847599
    },
    {
      "type": "training",
      "description": "Training step 1118",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:06",
      "total_flops_so_far": 1608119618026232.0,
      "budget_used_percent": 1.608119618026232
    },
    {
      "type": "training",
      "description": "Training step 1119",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:06",
      "total_flops_so_far": 1609551770067704.0,
      "budget_used_percent": 1.609551770067704
    },
    {
      "type": "training",
      "description": "Training step 1120",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:06",
      "total_flops_so_far": 1610983922109176.0,
      "budget_used_percent": 1.610983922109176
    },
    {
      "type": "training",
      "description": "Training step 1121",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:06",
      "total_flops_so_far": 1612416074150648.0,
      "budget_used_percent": 1.612416074150648
    },
    {
      "type": "training",
      "description": "Training step 1122",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:06",
      "total_flops_so_far": 1613848226192120.0,
      "budget_used_percent": 1.6138482261921199
    },
    {
      "type": "training",
      "description": "Training step 1123",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:06",
      "total_flops_so_far": 1615280378233592.0,
      "budget_used_percent": 1.6152803782335918
    },
    {
      "type": "training",
      "description": "Training step 1124",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:06",
      "total_flops_so_far": 1616712530275064.0,
      "budget_used_percent": 1.6167125302750642
    },
    {
      "type": "training",
      "description": "Training step 1125",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:07",
      "total_flops_so_far": 1618144682316536.0,
      "budget_used_percent": 1.6181446823165362
    },
    {
      "type": "training",
      "description": "Training step 1126",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:07",
      "total_flops_so_far": 1619576834358008.0,
      "budget_used_percent": 1.619576834358008
    },
    {
      "type": "training",
      "description": "Training step 1127",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:07",
      "total_flops_so_far": 1621008986399480.0,
      "budget_used_percent": 1.6210089863994799
    },
    {
      "type": "training",
      "description": "Training step 1128",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:07",
      "total_flops_so_far": 1622441138440952.0,
      "budget_used_percent": 1.6224411384409518
    },
    {
      "type": "training",
      "description": "Training step 1129",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:07",
      "total_flops_so_far": 1623873290482424.0,
      "budget_used_percent": 1.6238732904824238
    },
    {
      "type": "training",
      "description": "Training step 1130",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:07",
      "total_flops_so_far": 1625305442523896.0,
      "budget_used_percent": 1.6253054425238962
    },
    {
      "type": "training",
      "description": "Training step 1131",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:07",
      "total_flops_so_far": 1626737594565368.0,
      "budget_used_percent": 1.6267375945653682
    },
    {
      "type": "training",
      "description": "Training step 1132",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:08",
      "total_flops_so_far": 1628169746606840.0,
      "budget_used_percent": 1.62816974660684
    },
    {
      "type": "training",
      "description": "Training step 1133",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:08",
      "total_flops_so_far": 1629601898648312.0,
      "budget_used_percent": 1.629601898648312
    },
    {
      "type": "training",
      "description": "Training step 1134",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:08",
      "total_flops_so_far": 1631034050689784.0,
      "budget_used_percent": 1.631034050689784
    },
    {
      "type": "training",
      "description": "Training step 1135",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:08",
      "total_flops_so_far": 1632466202731256.0,
      "budget_used_percent": 1.6324662027312558
    },
    {
      "type": "training",
      "description": "Training step 1136",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:08",
      "total_flops_so_far": 1633898354772728.0,
      "budget_used_percent": 1.6338983547727282
    },
    {
      "type": "training",
      "description": "Training step 1137",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:08",
      "total_flops_so_far": 1635330506814200.0,
      "budget_used_percent": 1.6353305068142001
    },
    {
      "type": "training",
      "description": "Training step 1138",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:08",
      "total_flops_so_far": 1636762658855672.0,
      "budget_used_percent": 1.636762658855672
    },
    {
      "type": "training",
      "description": "Training step 1139",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:08",
      "total_flops_so_far": 1638194810897144.0,
      "budget_used_percent": 1.638194810897144
    },
    {
      "type": "training",
      "description": "Training step 1140",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:09",
      "total_flops_so_far": 1639626962938616.0,
      "budget_used_percent": 1.639626962938616
    },
    {
      "type": "training",
      "description": "Training step 1141",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:09",
      "total_flops_so_far": 1641059114980088.0,
      "budget_used_percent": 1.641059114980088
    },
    {
      "type": "training",
      "description": "Training step 1142",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:09",
      "total_flops_so_far": 1642491267021560.0,
      "budget_used_percent": 1.6424912670215601
    },
    {
      "type": "training",
      "description": "Training step 1143",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:09",
      "total_flops_so_far": 1643923419063032.0,
      "budget_used_percent": 1.643923419063032
    },
    {
      "type": "training",
      "description": "Training step 1144",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:09",
      "total_flops_so_far": 1645355571104504.0,
      "budget_used_percent": 1.645355571104504
    },
    {
      "type": "training",
      "description": "Training step 1145",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:09",
      "total_flops_so_far": 1646787723145976.0,
      "budget_used_percent": 1.646787723145976
    },
    {
      "type": "training",
      "description": "Training step 1146",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:09",
      "total_flops_so_far": 1648219875187448.0,
      "budget_used_percent": 1.648219875187448
    },
    {
      "type": "training",
      "description": "Training step 1147",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:10",
      "total_flops_so_far": 1649652027228920.0,
      "budget_used_percent": 1.64965202722892
    },
    {
      "type": "training",
      "description": "Training step 1148",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:10",
      "total_flops_so_far": 1651084179270392.0,
      "budget_used_percent": 1.651084179270392
    },
    {
      "type": "training",
      "description": "Training step 1149",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:10",
      "total_flops_so_far": 1652516331311864.0,
      "budget_used_percent": 1.652516331311864
    },
    {
      "type": "training",
      "description": "Training step 1150",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:10",
      "total_flops_so_far": 1653948483353336.0,
      "budget_used_percent": 1.653948483353336
    },
    {
      "type": "training",
      "description": "Training step 1151",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:10",
      "total_flops_so_far": 1655380635394808.0,
      "budget_used_percent": 1.655380635394808
    },
    {
      "type": "training",
      "description": "Training step 1152",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:10",
      "total_flops_so_far": 1656812787436280.0,
      "budget_used_percent": 1.65681278743628
    },
    {
      "type": "training",
      "description": "Training step 1153",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:10",
      "total_flops_so_far": 1658244939477752.0,
      "budget_used_percent": 1.6582449394777519
    },
    {
      "type": "training",
      "description": "Training step 1154",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:11",
      "total_flops_so_far": 1659677091519224.0,
      "budget_used_percent": 1.6596770915192243
    },
    {
      "type": "training",
      "description": "Training step 1155",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:11",
      "total_flops_so_far": 1661109243560696.0,
      "budget_used_percent": 1.6611092435606962
    },
    {
      "type": "training",
      "description": "Training step 1156",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:11",
      "total_flops_so_far": 1662541395602168.0,
      "budget_used_percent": 1.662541395602168
    },
    {
      "type": "training",
      "description": "Training step 1157",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:11",
      "total_flops_so_far": 1663973547643640.0,
      "budget_used_percent": 1.66397354764364
    },
    {
      "type": "training",
      "description": "Training step 1158",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:11",
      "total_flops_so_far": 1665405699685112.0,
      "budget_used_percent": 1.6654056996851119
    },
    {
      "type": "training",
      "description": "Training step 1159",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:11",
      "total_flops_so_far": 1666837851726584.0,
      "budget_used_percent": 1.6668378517265838
    },
    {
      "type": "training",
      "description": "Training step 1160",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:11",
      "total_flops_so_far": 1668270003768056.0,
      "budget_used_percent": 1.6682700037680558
    },
    {
      "type": "training",
      "description": "Training step 1161",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:12",
      "total_flops_so_far": 1669702155809528.0,
      "budget_used_percent": 1.6697021558095282
    },
    {
      "type": "training",
      "description": "Training step 1162",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:12",
      "total_flops_so_far": 1671134307851000.0,
      "budget_used_percent": 1.6711343078510001
    },
    {
      "type": "training",
      "description": "Training step 1163",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:12",
      "total_flops_so_far": 1672566459892472.0,
      "budget_used_percent": 1.672566459892472
    },
    {
      "type": "training",
      "description": "Training step 1164",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:12",
      "total_flops_so_far": 1673998611933944.0,
      "budget_used_percent": 1.673998611933944
    },
    {
      "type": "training",
      "description": "Training step 1165",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:12",
      "total_flops_so_far": 1675430763975416.0,
      "budget_used_percent": 1.6754307639754158
    },
    {
      "type": "training",
      "description": "Training step 1166",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:12",
      "total_flops_so_far": 1676862916016888.0,
      "budget_used_percent": 1.6768629160168878
    },
    {
      "type": "training",
      "description": "Training step 1167",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:12",
      "total_flops_so_far": 1678295068058360.0,
      "budget_used_percent": 1.6782950680583602
    },
    {
      "type": "training",
      "description": "Training step 1168",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:13",
      "total_flops_so_far": 1679727220099832.0,
      "budget_used_percent": 1.679727220099832
    },
    {
      "type": "training",
      "description": "Training step 1169",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:13",
      "total_flops_so_far": 1681159372141304.0,
      "budget_used_percent": 1.681159372141304
    },
    {
      "type": "training",
      "description": "Training step 1170",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:13",
      "total_flops_so_far": 1682591524182776.0,
      "budget_used_percent": 1.682591524182776
    },
    {
      "type": "training",
      "description": "Training step 1171",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:13",
      "total_flops_so_far": 1684023676224248.0,
      "budget_used_percent": 1.684023676224248
    },
    {
      "type": "training",
      "description": "Training step 1172",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:13",
      "total_flops_so_far": 1685455828265720.0,
      "budget_used_percent": 1.68545582826572
    },
    {
      "type": "training",
      "description": "Training step 1173",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:13",
      "total_flops_so_far": 1686887980307192.0,
      "budget_used_percent": 1.6868879803071921
    },
    {
      "type": "training",
      "description": "Training step 1174",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:13",
      "total_flops_so_far": 1688320132348664.0,
      "budget_used_percent": 1.688320132348664
    },
    {
      "type": "training",
      "description": "Training step 1175",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:14",
      "total_flops_so_far": 1689752284390136.0,
      "budget_used_percent": 1.689752284390136
    },
    {
      "type": "training",
      "description": "Training step 1176",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:14",
      "total_flops_so_far": 1691184436431608.0,
      "budget_used_percent": 1.691184436431608
    },
    {
      "type": "training",
      "description": "Training step 1177",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:14",
      "total_flops_so_far": 1692616588473080.0,
      "budget_used_percent": 1.69261658847308
    },
    {
      "type": "training",
      "description": "Training step 1178",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:14",
      "total_flops_so_far": 1694048740514552.0,
      "budget_used_percent": 1.694048740514552
    },
    {
      "type": "training",
      "description": "Training step 1179",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:14",
      "total_flops_so_far": 1695480892556024.0,
      "budget_used_percent": 1.695480892556024
    },
    {
      "type": "training",
      "description": "Training step 1180",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:14",
      "total_flops_so_far": 1696913044597496.0,
      "budget_used_percent": 1.696913044597496
    },
    {
      "type": "training",
      "description": "Training step 1181",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:14",
      "total_flops_so_far": 1698345196638968.0,
      "budget_used_percent": 1.698345196638968
    },
    {
      "type": "training",
      "description": "Training step 1182",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:15",
      "total_flops_so_far": 1699777348680440.0,
      "budget_used_percent": 1.69977734868044
    },
    {
      "type": "training",
      "description": "Training step 1183",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:15",
      "total_flops_so_far": 1701209500721912.0,
      "budget_used_percent": 1.701209500721912
    },
    {
      "type": "training",
      "description": "Training step 1184",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:15",
      "total_flops_so_far": 1702641652763384.0,
      "budget_used_percent": 1.7026416527633839
    },
    {
      "type": "training",
      "description": "Training step 1185",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:15",
      "total_flops_so_far": 1704073804804856.0,
      "budget_used_percent": 1.704073804804856
    },
    {
      "type": "training",
      "description": "Training step 1186",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:15",
      "total_flops_so_far": 1705505956846328.0,
      "budget_used_percent": 1.705505956846328
    },
    {
      "type": "training",
      "description": "Training step 1187",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:15",
      "total_flops_so_far": 1706938108887800.0,
      "budget_used_percent": 1.7069381088878
    },
    {
      "type": "training",
      "description": "Training step 1188",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:15",
      "total_flops_so_far": 1708370260929272.0,
      "budget_used_percent": 1.708370260929272
    },
    {
      "type": "training",
      "description": "Training step 1189",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:16",
      "total_flops_so_far": 1709802412970744.0,
      "budget_used_percent": 1.7098024129707439
    },
    {
      "type": "training",
      "description": "Training step 1190",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:16",
      "total_flops_so_far": 1711234565012216.0,
      "budget_used_percent": 1.7112345650122158
    },
    {
      "type": "training",
      "description": "Training step 1191",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:16",
      "total_flops_so_far": 1712666717053688.0,
      "budget_used_percent": 1.7126667170536882
    },
    {
      "type": "training",
      "description": "Training step 1192",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:16",
      "total_flops_so_far": 1714098869095160.0,
      "budget_used_percent": 1.7140988690951602
    },
    {
      "type": "training",
      "description": "Training step 1193",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:16",
      "total_flops_so_far": 1715531021136632.0,
      "budget_used_percent": 1.715531021136632
    },
    {
      "type": "training",
      "description": "Training step 1194",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:16",
      "total_flops_so_far": 1716963173178104.0,
      "budget_used_percent": 1.7169631731781039
    },
    {
      "type": "training",
      "description": "Training step 1195",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:16",
      "total_flops_so_far": 1718395325219576.0,
      "budget_used_percent": 1.7183953252195758
    },
    {
      "type": "training",
      "description": "Training step 1196",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:17",
      "total_flops_so_far": 1719827477261048.0,
      "budget_used_percent": 1.7198274772610478
    },
    {
      "type": "training",
      "description": "Training step 1197",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:17",
      "total_flops_so_far": 1721259629302520.0,
      "budget_used_percent": 1.7212596293025202
    },
    {
      "type": "training",
      "description": "Training step 1198",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:17",
      "total_flops_so_far": 1722691781343992.0,
      "budget_used_percent": 1.7226917813439921
    },
    {
      "type": "training",
      "description": "Training step 1199",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:17",
      "total_flops_so_far": 1724123933385464.0,
      "budget_used_percent": 1.724123933385464
    },
    {
      "type": "training",
      "description": "Training step 1200",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:17",
      "total_flops_so_far": 1725556085426936.0,
      "budget_used_percent": 1.725556085426936
    },
    {
      "type": "training",
      "description": "Training step 1201",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:17",
      "total_flops_so_far": 1726988237468408.0,
      "budget_used_percent": 1.726988237468408
    },
    {
      "type": "training",
      "description": "Training step 1202",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:17",
      "total_flops_so_far": 1728420389509880.0,
      "budget_used_percent": 1.7284203895098798
    },
    {
      "type": "training",
      "description": "Training step 1203",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:18",
      "total_flops_so_far": 1729852541551352.0,
      "budget_used_percent": 1.7298525415513522
    },
    {
      "type": "training",
      "description": "Training step 1204",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:18",
      "total_flops_so_far": 1731284693592824.0,
      "budget_used_percent": 1.731284693592824
    },
    {
      "type": "training",
      "description": "Training step 1205",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:18",
      "total_flops_so_far": 1732716845634296.0,
      "budget_used_percent": 1.732716845634296
    },
    {
      "type": "training",
      "description": "Training step 1206",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:18",
      "total_flops_so_far": 1734148997675768.0,
      "budget_used_percent": 1.734148997675768
    },
    {
      "type": "training",
      "description": "Training step 1207",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:18",
      "total_flops_so_far": 1735581149717240.0,
      "budget_used_percent": 1.73558114971724
    },
    {
      "type": "training",
      "description": "Training step 1208",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:18",
      "total_flops_so_far": 1737013301758712.0,
      "budget_used_percent": 1.737013301758712
    },
    {
      "type": "training",
      "description": "Training step 1209",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:18",
      "total_flops_so_far": 1738445453800184.0,
      "budget_used_percent": 1.7384454538001841
    },
    {
      "type": "training",
      "description": "Training step 1210",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:19",
      "total_flops_so_far": 1739877605841656.0,
      "budget_used_percent": 1.739877605841656
    },
    {
      "type": "training",
      "description": "Training step 1211",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:19",
      "total_flops_so_far": 1741309757883128.0,
      "budget_used_percent": 1.741309757883128
    },
    {
      "type": "training",
      "description": "Training step 1212",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:19",
      "total_flops_so_far": 1742741909924600.0,
      "budget_used_percent": 1.7427419099246
    },
    {
      "type": "training",
      "description": "Training step 1213",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:19",
      "total_flops_so_far": 1744174061966072.0,
      "budget_used_percent": 1.744174061966072
    },
    {
      "type": "training",
      "description": "Training step 1214",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:19",
      "total_flops_so_far": 1745606214007544.0,
      "budget_used_percent": 1.745606214007544
    },
    {
      "type": "training",
      "description": "Training step 1215",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:19",
      "total_flops_so_far": 1747038366049016.0,
      "budget_used_percent": 1.747038366049016
    },
    {
      "type": "training",
      "description": "Training step 1216",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:19",
      "total_flops_so_far": 1748470518090488.0,
      "budget_used_percent": 1.748470518090488
    },
    {
      "type": "training",
      "description": "Training step 1217",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:20",
      "total_flops_so_far": 1749902670131960.0,
      "budget_used_percent": 1.74990267013196
    },
    {
      "type": "training",
      "description": "Training step 1218",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:20",
      "total_flops_so_far": 1751334822173432.0,
      "budget_used_percent": 1.751334822173432
    },
    {
      "type": "training",
      "description": "Training step 1219",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:20",
      "total_flops_so_far": 1752766974214904.0,
      "budget_used_percent": 1.752766974214904
    },
    {
      "type": "training",
      "description": "Training step 1220",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:20",
      "total_flops_so_far": 1754199126256376.0,
      "budget_used_percent": 1.7541991262563759
    },
    {
      "type": "training",
      "description": "Training step 1221",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:20",
      "total_flops_so_far": 1755631278297848.0,
      "budget_used_percent": 1.7556312782978483
    },
    {
      "type": "training",
      "description": "Training step 1222",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:20",
      "total_flops_so_far": 1757063430339320.0,
      "budget_used_percent": 1.7570634303393202
    },
    {
      "type": "training",
      "description": "Training step 1223",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:20",
      "total_flops_so_far": 1758495582380792.0,
      "budget_used_percent": 1.758495582380792
    },
    {
      "type": "training",
      "description": "Training step 1224",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:21",
      "total_flops_so_far": 1759927734422264.0,
      "budget_used_percent": 1.759927734422264
    },
    {
      "type": "training",
      "description": "Training step 1225",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:21",
      "total_flops_so_far": 1761359886463736.0,
      "budget_used_percent": 1.7613598864637359
    },
    {
      "type": "training",
      "description": "Training step 1226",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:21",
      "total_flops_so_far": 1762792038505208.0,
      "budget_used_percent": 1.7627920385052078
    },
    {
      "type": "training",
      "description": "Training step 1227",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:21",
      "total_flops_so_far": 1764224190546680.0,
      "budget_used_percent": 1.7642241905466802
    },
    {
      "type": "training",
      "description": "Training step 1228",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:21",
      "total_flops_so_far": 1765656342588152.0,
      "budget_used_percent": 1.7656563425881522
    },
    {
      "type": "training",
      "description": "Training step 1229",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:21",
      "total_flops_so_far": 1767088494629624.0,
      "budget_used_percent": 1.7670884946296241
    },
    {
      "type": "training",
      "description": "Training step 1230",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:21",
      "total_flops_so_far": 1768520646671096.0,
      "budget_used_percent": 1.768520646671096
    },
    {
      "type": "training",
      "description": "Training step 1231",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:22",
      "total_flops_so_far": 1769952798712568.0,
      "budget_used_percent": 1.769952798712568
    },
    {
      "type": "training",
      "description": "Training step 1232",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:22",
      "total_flops_so_far": 1771384950754040.0,
      "budget_used_percent": 1.7713849507540398
    },
    {
      "type": "training",
      "description": "Training step 1233",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:22",
      "total_flops_so_far": 1772817102795512.0,
      "budget_used_percent": 1.7728171027955117
    },
    {
      "type": "training",
      "description": "Training step 1234",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:22",
      "total_flops_so_far": 1774249254836984.0,
      "budget_used_percent": 1.7742492548369841
    },
    {
      "type": "training",
      "description": "Training step 1235",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:22",
      "total_flops_so_far": 1775681406878456.0,
      "budget_used_percent": 1.775681406878456
    },
    {
      "type": "training",
      "description": "Training step 1236",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:22",
      "total_flops_so_far": 1777113558919928.0,
      "budget_used_percent": 1.777113558919928
    },
    {
      "type": "training",
      "description": "Training step 1237",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:22",
      "total_flops_so_far": 1778545710961400.0,
      "budget_used_percent": 1.7785457109614
    },
    {
      "type": "training",
      "description": "Training step 1238",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:22",
      "total_flops_so_far": 1779977863002872.0,
      "budget_used_percent": 1.779977863002872
    },
    {
      "type": "training",
      "description": "Training step 1239",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:23",
      "total_flops_so_far": 1781410015044344.0,
      "budget_used_percent": 1.781410015044344
    },
    {
      "type": "training",
      "description": "Training step 1240",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:23",
      "total_flops_so_far": 1782842167085816.0,
      "budget_used_percent": 1.782842167085816
    },
    {
      "type": "training",
      "description": "Training step 1241",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:23",
      "total_flops_so_far": 1784274319127288.0,
      "budget_used_percent": 1.784274319127288
    },
    {
      "type": "training",
      "description": "Training step 1242",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:23",
      "total_flops_so_far": 1785706471168760.0,
      "budget_used_percent": 1.78570647116876
    },
    {
      "type": "training",
      "description": "Training step 1243",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:23",
      "total_flops_so_far": 1787138623210232.0,
      "budget_used_percent": 1.787138623210232
    },
    {
      "type": "training",
      "description": "Training step 1244",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:23",
      "total_flops_so_far": 1788570775251704.0,
      "budget_used_percent": 1.788570775251704
    },
    {
      "type": "training",
      "description": "Training step 1245",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:24",
      "total_flops_so_far": 1790002927293176.0,
      "budget_used_percent": 1.790002927293176
    },
    {
      "type": "training",
      "description": "Training step 1246",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:24",
      "total_flops_so_far": 1791435079334648.0,
      "budget_used_percent": 1.791435079334648
    },
    {
      "type": "training",
      "description": "Training step 1247",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:24",
      "total_flops_so_far": 1792867231376120.0,
      "budget_used_percent": 1.79286723137612
    },
    {
      "type": "training",
      "description": "Training step 1248",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:24",
      "total_flops_so_far": 1794299383417592.0,
      "budget_used_percent": 1.794299383417592
    },
    {
      "type": "training",
      "description": "Training step 1249",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:24",
      "total_flops_so_far": 1795731535459064.0,
      "budget_used_percent": 1.795731535459064
    },
    {
      "type": "training",
      "description": "Training step 1250",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:24",
      "total_flops_so_far": 1797163687500536.0,
      "budget_used_percent": 1.797163687500536
    },
    {
      "type": "training",
      "description": "Training step 1251",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:24",
      "total_flops_so_far": 1798595839542008.0,
      "budget_used_percent": 1.7985958395420079
    },
    {
      "type": "training",
      "description": "Training step 1252",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:25",
      "total_flops_so_far": 1800027991583480.0,
      "budget_used_percent": 1.80002799158348
    },
    {
      "type": "training",
      "description": "Training step 1253",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:25",
      "total_flops_so_far": 1801460143624952.0,
      "budget_used_percent": 1.801460143624952
    },
    {
      "type": "training",
      "description": "Training step 1254",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:25",
      "total_flops_so_far": 1802892295666424.0,
      "budget_used_percent": 1.802892295666424
    },
    {
      "type": "training",
      "description": "Training step 1255",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:25",
      "total_flops_so_far": 1804324447707896.0,
      "budget_used_percent": 1.804324447707896
    },
    {
      "type": "training",
      "description": "Training step 1256",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:25",
      "total_flops_so_far": 1805756599749368.0,
      "budget_used_percent": 1.8057565997493679
    },
    {
      "type": "training",
      "description": "Training step 1257",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:25",
      "total_flops_so_far": 1807188751790840.0,
      "budget_used_percent": 1.8071887517908398
    },
    {
      "type": "training",
      "description": "Training step 1258",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:25",
      "total_flops_so_far": 1808620903832312.0,
      "budget_used_percent": 1.8086209038323122
    },
    {
      "type": "training",
      "description": "Training step 1259",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:26",
      "total_flops_so_far": 1810053055873784.0,
      "budget_used_percent": 1.8100530558737842
    },
    {
      "type": "training",
      "description": "Training step 1260",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:26",
      "total_flops_so_far": 1811485207915256.0,
      "budget_used_percent": 1.811485207915256
    },
    {
      "type": "training",
      "description": "Training step 1261",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:26",
      "total_flops_so_far": 1812917359956728.0,
      "budget_used_percent": 1.8129173599567279
    },
    {
      "type": "training",
      "description": "Training step 1262",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:26",
      "total_flops_so_far": 1814349511998200.0,
      "budget_used_percent": 1.8143495119981998
    },
    {
      "type": "training",
      "description": "Training step 1263",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:26",
      "total_flops_so_far": 1815781664039672.0,
      "budget_used_percent": 1.8157816640396718
    },
    {
      "type": "training",
      "description": "Training step 1264",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:26",
      "total_flops_so_far": 1817213816081144.0,
      "budget_used_percent": 1.8172138160811442
    },
    {
      "type": "training",
      "description": "Training step 1265",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:26",
      "total_flops_so_far": 1818645968122616.0,
      "budget_used_percent": 1.8186459681226161
    },
    {
      "type": "training",
      "description": "Training step 1266",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:27",
      "total_flops_so_far": 1820078120164088.0,
      "budget_used_percent": 1.820078120164088
    },
    {
      "type": "training",
      "description": "Training step 1267",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:27",
      "total_flops_so_far": 1821510272205560.0,
      "budget_used_percent": 1.82151027220556
    },
    {
      "type": "training",
      "description": "Training step 1268",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:27",
      "total_flops_so_far": 1822942424247032.0,
      "budget_used_percent": 1.822942424247032
    },
    {
      "type": "training",
      "description": "Training step 1269",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:27",
      "total_flops_so_far": 1824374576288504.0,
      "budget_used_percent": 1.8243745762885037
    },
    {
      "type": "training",
      "description": "Training step 1270",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:27",
      "total_flops_so_far": 1825806728329976.0,
      "budget_used_percent": 1.8258067283299761
    },
    {
      "type": "training",
      "description": "Training step 1271",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:27",
      "total_flops_so_far": 1827238880371448.0,
      "budget_used_percent": 1.827238880371448
    },
    {
      "type": "training",
      "description": "Training step 1272",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:27",
      "total_flops_so_far": 1828671032412920.0,
      "budget_used_percent": 1.82867103241292
    },
    {
      "type": "training",
      "description": "Training step 1273",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:28",
      "total_flops_so_far": 1830103184454392.0,
      "budget_used_percent": 1.830103184454392
    },
    {
      "type": "training",
      "description": "Training step 1274",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:28",
      "total_flops_so_far": 1831535336495864.0,
      "budget_used_percent": 1.831535336495864
    },
    {
      "type": "training",
      "description": "Training step 1275",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:28",
      "total_flops_so_far": 1832967488537336.0,
      "budget_used_percent": 1.832967488537336
    },
    {
      "type": "training",
      "description": "Training step 1276",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:28",
      "total_flops_so_far": 1834399640578808.0,
      "budget_used_percent": 1.834399640578808
    },
    {
      "type": "training",
      "description": "Training step 1277",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:28",
      "total_flops_so_far": 1835831792620280.0,
      "budget_used_percent": 1.83583179262028
    },
    {
      "type": "training",
      "description": "Training step 1278",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:28",
      "total_flops_so_far": 1837263944661752.0,
      "budget_used_percent": 1.837263944661752
    },
    {
      "type": "training",
      "description": "Training step 1279",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:28",
      "total_flops_so_far": 1838696096703224.0,
      "budget_used_percent": 1.838696096703224
    },
    {
      "type": "training",
      "description": "Training step 1280",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:29",
      "total_flops_so_far": 1840128248744696.0,
      "budget_used_percent": 1.840128248744696
    },
    {
      "type": "training",
      "description": "Training step 1281",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:29",
      "total_flops_so_far": 1841560400786168.0,
      "budget_used_percent": 1.841560400786168
    },
    {
      "type": "training",
      "description": "Training step 1282",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:29",
      "total_flops_so_far": 1842992552827640.0,
      "budget_used_percent": 1.84299255282764
    },
    {
      "type": "training",
      "description": "Training step 1283",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:29",
      "total_flops_so_far": 1844424704869112.0,
      "budget_used_percent": 1.844424704869112
    },
    {
      "type": "training",
      "description": "Training step 1284",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:29",
      "total_flops_so_far": 1845856856910584.0,
      "budget_used_percent": 1.845856856910584
    },
    {
      "type": "training",
      "description": "Training step 1285",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:29",
      "total_flops_so_far": 1847289008952056.0,
      "budget_used_percent": 1.847289008952056
    },
    {
      "type": "training",
      "description": "Training step 1286",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:29",
      "total_flops_so_far": 1848721160993528.0,
      "budget_used_percent": 1.848721160993528
    },
    {
      "type": "training",
      "description": "Training step 1287",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:30",
      "total_flops_so_far": 1850153313035000.0,
      "budget_used_percent": 1.8501533130349999
    },
    {
      "type": "training",
      "description": "Training step 1288",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:30",
      "total_flops_so_far": 1851585465076472.0,
      "budget_used_percent": 1.8515854650764723
    },
    {
      "type": "training",
      "description": "Training step 1289",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:30",
      "total_flops_so_far": 1853017617117944.0,
      "budget_used_percent": 1.8530176171179442
    },
    {
      "type": "training",
      "description": "Training step 1290",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:30",
      "total_flops_so_far": 1854449769159416.0,
      "budget_used_percent": 1.854449769159416
    },
    {
      "type": "training",
      "description": "Training step 1291",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:30",
      "total_flops_so_far": 1855881921200888.0,
      "budget_used_percent": 1.855881921200888
    },
    {
      "type": "training",
      "description": "Training step 1292",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:30",
      "total_flops_so_far": 1857314073242360.0,
      "budget_used_percent": 1.8573140732423599
    },
    {
      "type": "training",
      "description": "Training step 1293",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:30",
      "total_flops_so_far": 1858746225283832.0,
      "budget_used_percent": 1.8587462252838318
    },
    {
      "type": "training",
      "description": "Training step 1294",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:31",
      "total_flops_so_far": 1860178377325304.0,
      "budget_used_percent": 1.8601783773253042
    },
    {
      "type": "training",
      "description": "Training step 1295",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:31",
      "total_flops_so_far": 1861610529366776.0,
      "budget_used_percent": 1.8616105293667762
    },
    {
      "type": "training",
      "description": "Training step 1296",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:31",
      "total_flops_so_far": 1863042681408248.0,
      "budget_used_percent": 1.8630426814082481
    },
    {
      "type": "training",
      "description": "Training step 1297",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:31",
      "total_flops_so_far": 1864474833449720.0,
      "budget_used_percent": 1.86447483344972
    },
    {
      "type": "training",
      "description": "Training step 1298",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:31",
      "total_flops_so_far": 1865906985491192.0,
      "budget_used_percent": 1.865906985491192
    },
    {
      "type": "training",
      "description": "Training step 1299",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:31",
      "total_flops_so_far": 1867339137532664.0,
      "budget_used_percent": 1.8673391375326638
    },
    {
      "type": "training",
      "description": "Training step 1300",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:31",
      "total_flops_so_far": 1868771289574136.0,
      "budget_used_percent": 1.8687712895741362
    },
    {
      "type": "training",
      "description": "Training step 1301",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:32",
      "total_flops_so_far": 1870203441615608.0,
      "budget_used_percent": 1.8702034416156081
    },
    {
      "type": "training",
      "description": "Training step 1302",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:32",
      "total_flops_so_far": 1871635593657080.0,
      "budget_used_percent": 1.87163559365708
    },
    {
      "type": "training",
      "description": "Training step 1303",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:32",
      "total_flops_so_far": 1873067745698552.0,
      "budget_used_percent": 1.873067745698552
    },
    {
      "type": "training",
      "description": "Training step 1304",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:32",
      "total_flops_so_far": 1874499897740024.0,
      "budget_used_percent": 1.874499897740024
    },
    {
      "type": "training",
      "description": "Training step 1305",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:32",
      "total_flops_so_far": 1875932049781496.0,
      "budget_used_percent": 1.875932049781496
    },
    {
      "type": "training",
      "description": "Training step 1306",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:32",
      "total_flops_so_far": 1877364201822968.0,
      "budget_used_percent": 1.877364201822968
    },
    {
      "type": "training",
      "description": "Training step 1307",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:32",
      "total_flops_so_far": 1878796353864440.0,
      "budget_used_percent": 1.87879635386444
    },
    {
      "type": "training",
      "description": "Training step 1308",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:33",
      "total_flops_so_far": 1880228505905912.0,
      "budget_used_percent": 1.880228505905912
    },
    {
      "type": "training",
      "description": "Training step 1309",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:33",
      "total_flops_so_far": 1881660657947384.0,
      "budget_used_percent": 1.881660657947384
    },
    {
      "type": "training",
      "description": "Training step 1310",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:33",
      "total_flops_so_far": 1883092809988856.0,
      "budget_used_percent": 1.883092809988856
    },
    {
      "type": "training",
      "description": "Training step 1311",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:33",
      "total_flops_so_far": 1884524962030328.0,
      "budget_used_percent": 1.884524962030328
    },
    {
      "type": "training",
      "description": "Training step 1312",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:33",
      "total_flops_so_far": 1885957114071800.0,
      "budget_used_percent": 1.8859571140718
    },
    {
      "type": "training",
      "description": "Training step 1313",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:33",
      "total_flops_so_far": 1887389266113272.0,
      "budget_used_percent": 1.887389266113272
    },
    {
      "type": "training",
      "description": "Training step 1314",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:33",
      "total_flops_so_far": 1888821418154744.0,
      "budget_used_percent": 1.888821418154744
    },
    {
      "type": "training",
      "description": "Training step 1315",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:34",
      "total_flops_so_far": 1890253570196216.0,
      "budget_used_percent": 1.890253570196216
    },
    {
      "type": "training",
      "description": "Training step 1316",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:34",
      "total_flops_so_far": 1891685722237688.0,
      "budget_used_percent": 1.891685722237688
    },
    {
      "type": "training",
      "description": "Training step 1317",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:34",
      "total_flops_so_far": 1893117874279160.0,
      "budget_used_percent": 1.89311787427916
    },
    {
      "type": "training",
      "description": "Training step 1318",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:34",
      "total_flops_so_far": 1894550026320632.0,
      "budget_used_percent": 1.8945500263206319
    },
    {
      "type": "training",
      "description": "Training step 1319",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:34",
      "total_flops_so_far": 1895982178362104.0,
      "budget_used_percent": 1.895982178362104
    },
    {
      "type": "training",
      "description": "Training step 1320",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:34",
      "total_flops_so_far": 1897414330403576.0,
      "budget_used_percent": 1.897414330403576
    },
    {
      "type": "training",
      "description": "Training step 1321",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:34",
      "total_flops_so_far": 1898846482445048.0,
      "budget_used_percent": 1.898846482445048
    },
    {
      "type": "training",
      "description": "Training step 1322",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:35",
      "total_flops_so_far": 1900278634486520.0,
      "budget_used_percent": 1.90027863448652
    },
    {
      "type": "training",
      "description": "Training step 1323",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:35",
      "total_flops_so_far": 1901710786527992.0,
      "budget_used_percent": 1.9017107865279919
    },
    {
      "type": "training",
      "description": "Training step 1324",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:35",
      "total_flops_so_far": 1903142938569464.0,
      "budget_used_percent": 1.9031429385694638
    },
    {
      "type": "training",
      "description": "Training step 1325",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:35",
      "total_flops_so_far": 1904575090610936.0,
      "budget_used_percent": 1.9045750906109362
    },
    {
      "type": "training",
      "description": "Training step 1326",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:35",
      "total_flops_so_far": 1906007242652408.0,
      "budget_used_percent": 1.9060072426524082
    },
    {
      "type": "training",
      "description": "Training step 1327",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:35",
      "total_flops_so_far": 1907439394693880.0,
      "budget_used_percent": 1.90743939469388
    },
    {
      "type": "training",
      "description": "Training step 1328",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:35",
      "total_flops_so_far": 1908871546735352.0,
      "budget_used_percent": 1.9088715467353519
    },
    {
      "type": "training",
      "description": "Training step 1329",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:36",
      "total_flops_so_far": 1910303698776824.0,
      "budget_used_percent": 1.9103036987768238
    },
    {
      "type": "training",
      "description": "Training step 1330",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:36",
      "total_flops_so_far": 1911735850818296.0,
      "budget_used_percent": 1.9117358508182958
    },
    {
      "type": "training",
      "description": "Training step 1331",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:36",
      "total_flops_so_far": 1913168002859768.0,
      "budget_used_percent": 1.9131680028597682
    },
    {
      "type": "training",
      "description": "Training step 1332",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:36",
      "total_flops_so_far": 1914600154901240.0,
      "budget_used_percent": 1.9146001549012401
    },
    {
      "type": "training",
      "description": "Training step 1333",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:36",
      "total_flops_so_far": 1916032306942712.0,
      "budget_used_percent": 1.916032306942712
    },
    {
      "type": "training",
      "description": "Training step 1334",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:36",
      "total_flops_so_far": 1917464458984184.0,
      "budget_used_percent": 1.917464458984184
    },
    {
      "type": "training",
      "description": "Training step 1335",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:37",
      "total_flops_so_far": 1918896611025656.0,
      "budget_used_percent": 1.918896611025656
    },
    {
      "type": "training",
      "description": "Training step 1336",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:37",
      "total_flops_so_far": 1920328763067128.0,
      "budget_used_percent": 1.9203287630671277
    },
    {
      "type": "training",
      "description": "Training step 1337",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:37",
      "total_flops_so_far": 1921760915108600.0,
      "budget_used_percent": 1.9217609151086001
    },
    {
      "type": "training",
      "description": "Training step 1338",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:37",
      "total_flops_so_far": 1923193067150072.0,
      "budget_used_percent": 1.923193067150072
    },
    {
      "type": "training",
      "description": "Training step 1339",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:37",
      "total_flops_so_far": 1924625219191544.0,
      "budget_used_percent": 1.924625219191544
    },
    {
      "type": "training",
      "description": "Training step 1340",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:37",
      "total_flops_so_far": 1926057371233016.0,
      "budget_used_percent": 1.926057371233016
    },
    {
      "type": "training",
      "description": "Training step 1341",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:37",
      "total_flops_so_far": 1927489523274488.0,
      "budget_used_percent": 1.927489523274488
    },
    {
      "type": "training",
      "description": "Training step 1342",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:38",
      "total_flops_so_far": 1928921675315960.0,
      "budget_used_percent": 1.92892167531596
    },
    {
      "type": "training",
      "description": "Training step 1343",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:38",
      "total_flops_so_far": 1930353827357432.0,
      "budget_used_percent": 1.930353827357432
    },
    {
      "type": "training",
      "description": "Training step 1344",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:38",
      "total_flops_so_far": 1931785979398904.0,
      "budget_used_percent": 1.931785979398904
    },
    {
      "type": "training",
      "description": "Training step 1345",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:38",
      "total_flops_so_far": 1933218131440376.0,
      "budget_used_percent": 1.933218131440376
    },
    {
      "type": "training",
      "description": "Training step 1346",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:38",
      "total_flops_so_far": 1934650283481848.0,
      "budget_used_percent": 1.934650283481848
    },
    {
      "type": "training",
      "description": "Training step 1347",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:38",
      "total_flops_so_far": 1936082435523320.0,
      "budget_used_percent": 1.93608243552332
    },
    {
      "type": "training",
      "description": "Training step 1348",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:38",
      "total_flops_so_far": 1937514587564792.0,
      "budget_used_percent": 1.937514587564792
    },
    {
      "type": "training",
      "description": "Training step 1349",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:39",
      "total_flops_so_far": 1938946739606264.0,
      "budget_used_percent": 1.938946739606264
    },
    {
      "type": "training",
      "description": "Training step 1350",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:39",
      "total_flops_so_far": 1940378891647736.0,
      "budget_used_percent": 1.940378891647736
    },
    {
      "type": "training",
      "description": "Training step 1351",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:39",
      "total_flops_so_far": 1941811043689208.0,
      "budget_used_percent": 1.941811043689208
    },
    {
      "type": "training",
      "description": "Training step 1352",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:39",
      "total_flops_so_far": 1943243195730680.0,
      "budget_used_percent": 1.94324319573068
    },
    {
      "type": "training",
      "description": "Training step 1353",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:39",
      "total_flops_so_far": 1944675347772152.0,
      "budget_used_percent": 1.944675347772152
    },
    {
      "type": "training",
      "description": "Training step 1354",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:39",
      "total_flops_so_far": 1946107499813624.0,
      "budget_used_percent": 1.9461074998136239
    },
    {
      "type": "training",
      "description": "Training step 1355",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:39",
      "total_flops_so_far": 1947539651855096.0,
      "budget_used_percent": 1.9475396518550963
    },
    {
      "type": "training",
      "description": "Training step 1356",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:40",
      "total_flops_so_far": 1948971803896568.0,
      "budget_used_percent": 1.9489718038965682
    },
    {
      "type": "training",
      "description": "Training step 1357",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:40",
      "total_flops_so_far": 1950403955938040.0,
      "budget_used_percent": 1.95040395593804
    },
    {
      "type": "training",
      "description": "Training step 1358",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:40",
      "total_flops_so_far": 1951836107979512.0,
      "budget_used_percent": 1.951836107979512
    },
    {
      "type": "training",
      "description": "Training step 1359",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:40",
      "total_flops_so_far": 1953268260020984.0,
      "budget_used_percent": 1.9532682600209839
    },
    {
      "type": "training",
      "description": "Training step 1360",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:40",
      "total_flops_so_far": 1954700412062456.0,
      "budget_used_percent": 1.9547004120624558
    },
    {
      "type": "training",
      "description": "Training step 1361",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:40",
      "total_flops_so_far": 1956132564103928.0,
      "budget_used_percent": 1.9561325641039282
    },
    {
      "type": "training",
      "description": "Training step 1362",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:40",
      "total_flops_so_far": 1957564716145400.0,
      "budget_used_percent": 1.9575647161454002
    },
    {
      "type": "training",
      "description": "Training step 1363",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:41",
      "total_flops_so_far": 1958996868186872.0,
      "budget_used_percent": 1.9589968681868721
    },
    {
      "type": "training",
      "description": "Training step 1364",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:41",
      "total_flops_so_far": 1960429020228344.0,
      "budget_used_percent": 1.960429020228344
    },
    {
      "type": "training",
      "description": "Training step 1365",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:41",
      "total_flops_so_far": 1961861172269816.0,
      "budget_used_percent": 1.961861172269816
    },
    {
      "type": "training",
      "description": "Training step 1366",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:41",
      "total_flops_so_far": 1963293324311288.0,
      "budget_used_percent": 1.9632933243112878
    },
    {
      "type": "training",
      "description": "Training step 1367",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:41",
      "total_flops_so_far": 1964725476352760.0,
      "budget_used_percent": 1.9647254763527602
    },
    {
      "type": "training",
      "description": "Training step 1368",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:41",
      "total_flops_so_far": 1966157628394232.0,
      "budget_used_percent": 1.9661576283942321
    },
    {
      "type": "training",
      "description": "Training step 1369",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:41",
      "total_flops_so_far": 1967589780435704.0,
      "budget_used_percent": 1.967589780435704
    },
    {
      "type": "training",
      "description": "Training step 1370",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:42",
      "total_flops_so_far": 1969021932477176.0,
      "budget_used_percent": 1.969021932477176
    },
    {
      "type": "training",
      "description": "Training step 1371",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:42",
      "total_flops_so_far": 1970454084518648.0,
      "budget_used_percent": 1.970454084518648
    },
    {
      "type": "training",
      "description": "Training step 1372",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:42",
      "total_flops_so_far": 1971886236560120.0,
      "budget_used_percent": 1.97188623656012
    },
    {
      "type": "training",
      "description": "Training step 1373",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:42",
      "total_flops_so_far": 1973318388601592.0,
      "budget_used_percent": 1.9733183886015921
    },
    {
      "type": "training",
      "description": "Training step 1374",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:42",
      "total_flops_so_far": 1974750540643064.0,
      "budget_used_percent": 1.974750540643064
    },
    {
      "type": "training",
      "description": "Training step 1375",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:42",
      "total_flops_so_far": 1976182692684536.0,
      "budget_used_percent": 1.976182692684536
    },
    {
      "type": "training",
      "description": "Training step 1376",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:42",
      "total_flops_so_far": 1977614844726008.0,
      "budget_used_percent": 1.977614844726008
    },
    {
      "type": "training",
      "description": "Training step 1377",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:43",
      "total_flops_so_far": 1979046996767480.0,
      "budget_used_percent": 1.97904699676748
    },
    {
      "type": "training",
      "description": "Training step 1378",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:43",
      "total_flops_so_far": 1980479148808952.0,
      "budget_used_percent": 1.980479148808952
    },
    {
      "type": "training",
      "description": "Training step 1379",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:43",
      "total_flops_so_far": 1981911300850424.0,
      "budget_used_percent": 1.9819113008504239
    },
    {
      "type": "training",
      "description": "Training step 1380",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:43",
      "total_flops_so_far": 1983343452891896.0,
      "budget_used_percent": 1.983343452891896
    },
    {
      "type": "training",
      "description": "Training step 1381",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:43",
      "total_flops_so_far": 1984775604933368.0,
      "budget_used_percent": 1.984775604933368
    },
    {
      "type": "training",
      "description": "Training step 1382",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:43",
      "total_flops_so_far": 1986207756974840.0,
      "budget_used_percent": 1.98620775697484
    },
    {
      "type": "training",
      "description": "Training step 1383",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:43",
      "total_flops_so_far": 1987639909016312.0,
      "budget_used_percent": 1.987639909016312
    },
    {
      "type": "training",
      "description": "Training step 1384",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:44",
      "total_flops_so_far": 1989072061057784.0,
      "budget_used_percent": 1.989072061057784
    },
    {
      "type": "training",
      "description": "Training step 1385",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:44",
      "total_flops_so_far": 1990504213099256.0,
      "budget_used_percent": 1.9905042130992558
    },
    {
      "type": "training",
      "description": "Training step 1386",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:44",
      "total_flops_so_far": 1991936365140728.0,
      "budget_used_percent": 1.991936365140728
    },
    {
      "type": "training",
      "description": "Training step 1387",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:44",
      "total_flops_so_far": 1993368517182200.0,
      "budget_used_percent": 1.9933685171822
    },
    {
      "type": "training",
      "description": "Training step 1388",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:44",
      "total_flops_so_far": 1994800669223672.0,
      "budget_used_percent": 1.994800669223672
    },
    {
      "type": "training",
      "description": "Training step 1389",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:44",
      "total_flops_so_far": 1996232821265144.0,
      "budget_used_percent": 1.996232821265144
    },
    {
      "type": "training",
      "description": "Training step 1390",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:44",
      "total_flops_so_far": 1997664973306616.0,
      "budget_used_percent": 1.9976649733066159
    },
    {
      "type": "training",
      "description": "Training step 1391",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:45",
      "total_flops_so_far": 1999097125348088.0,
      "budget_used_percent": 1.9990971253480878
    },
    {
      "type": "training",
      "description": "Training step 1392",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:45",
      "total_flops_so_far": 2000529277389560.0,
      "budget_used_percent": 2.00052927738956
    },
    {
      "type": "training",
      "description": "Training step 1393",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:45",
      "total_flops_so_far": 2001961429431032.0,
      "budget_used_percent": 2.001961429431032
    },
    {
      "type": "training",
      "description": "Training step 1394",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:45",
      "total_flops_so_far": 2003393581472504.0,
      "budget_used_percent": 2.003393581472504
    },
    {
      "type": "training",
      "description": "Training step 1395",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:45",
      "total_flops_so_far": 2004825733513976.0,
      "budget_used_percent": 2.004825733513976
    },
    {
      "type": "training",
      "description": "Training step 1396",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:45",
      "total_flops_so_far": 2006257885555448.0,
      "budget_used_percent": 2.006257885555448
    },
    {
      "type": "training",
      "description": "Training step 1397",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:45",
      "total_flops_so_far": 2007690037596920.0,
      "budget_used_percent": 2.00769003759692
    },
    {
      "type": "training",
      "description": "Training step 1398",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:46",
      "total_flops_so_far": 2009122189638392.0,
      "budget_used_percent": 2.009122189638392
    },
    {
      "type": "training",
      "description": "Training step 1399",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:46",
      "total_flops_so_far": 2010554341679864.0,
      "budget_used_percent": 2.010554341679864
    },
    {
      "type": "training",
      "description": "Training step 1400",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:46",
      "total_flops_so_far": 2011986493721336.0,
      "budget_used_percent": 2.011986493721336
    },
    {
      "type": "training",
      "description": "Training step 1401",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:46",
      "total_flops_so_far": 2013418645762808.0,
      "budget_used_percent": 2.013418645762808
    },
    {
      "type": "training",
      "description": "Training step 1402",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:46",
      "total_flops_so_far": 2014850797804280.0,
      "budget_used_percent": 2.01485079780428
    },
    {
      "type": "training",
      "description": "Training step 1403",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:46",
      "total_flops_so_far": 2016282949845752.0,
      "budget_used_percent": 2.0162829498457517
    },
    {
      "type": "training",
      "description": "Training step 1404",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:47",
      "total_flops_so_far": 2017715101887224.0,
      "budget_used_percent": 2.017715101887224
    },
    {
      "type": "training",
      "description": "Training step 1405",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:47",
      "total_flops_so_far": 2019147253928696.0,
      "budget_used_percent": 2.019147253928696
    },
    {
      "type": "training",
      "description": "Training step 1406",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:47",
      "total_flops_so_far": 2020579405970168.0,
      "budget_used_percent": 2.020579405970168
    },
    {
      "type": "training",
      "description": "Training step 1407",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:47",
      "total_flops_so_far": 2022011558011640.0,
      "budget_used_percent": 2.02201155801164
    },
    {
      "type": "training",
      "description": "Training step 1408",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:47",
      "total_flops_so_far": 2023443710053112.0,
      "budget_used_percent": 2.0234437100531117
    },
    {
      "type": "training",
      "description": "Training step 1409",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:47",
      "total_flops_so_far": 2024875862094584.0,
      "budget_used_percent": 2.024875862094584
    },
    {
      "type": "training",
      "description": "Training step 1410",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:47",
      "total_flops_so_far": 2026308014136056.0,
      "budget_used_percent": 2.026308014136056
    },
    {
      "type": "training",
      "description": "Training step 1411",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:48",
      "total_flops_so_far": 2027740166177528.0,
      "budget_used_percent": 2.0277401661775283
    },
    {
      "type": "training",
      "description": "Training step 1412",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:48",
      "total_flops_so_far": 2029172318219000.0,
      "budget_used_percent": 2.029172318219
    },
    {
      "type": "training",
      "description": "Training step 1413",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:48",
      "total_flops_so_far": 2030604470260472.0,
      "budget_used_percent": 2.0306044702604718
    },
    {
      "type": "training",
      "description": "Training step 1414",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:48",
      "total_flops_so_far": 2032036622301944.0,
      "budget_used_percent": 2.032036622301944
    },
    {
      "type": "training",
      "description": "Training step 1415",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:48",
      "total_flops_so_far": 2033468774343416.0,
      "budget_used_percent": 2.0334687743434157
    },
    {
      "type": "training",
      "description": "Training step 1416",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:48",
      "total_flops_so_far": 2034900926384888.0,
      "budget_used_percent": 2.0349009263848883
    },
    {
      "type": "training",
      "description": "Training step 1417",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:48",
      "total_flops_so_far": 2036333078426360.0,
      "budget_used_percent": 2.03633307842636
    },
    {
      "type": "training",
      "description": "Training step 1418",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:49",
      "total_flops_so_far": 2037765230467832.0,
      "budget_used_percent": 2.037765230467832
    },
    {
      "type": "training",
      "description": "Training step 1419",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:49",
      "total_flops_so_far": 2039197382509304.0,
      "budget_used_percent": 2.039197382509304
    },
    {
      "type": "training",
      "description": "Training step 1420",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:49",
      "total_flops_so_far": 2040629534550776.0,
      "budget_used_percent": 2.040629534550776
    },
    {
      "type": "training",
      "description": "Training step 1421",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:49",
      "total_flops_so_far": 2042061686592248.0,
      "budget_used_percent": 2.042061686592248
    },
    {
      "type": "training",
      "description": "Training step 1422",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:49",
      "total_flops_so_far": 2043493838633720.0,
      "budget_used_percent": 2.04349383863372
    },
    {
      "type": "training",
      "description": "Training step 1423",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:49",
      "total_flops_so_far": 2044925990675192.0,
      "budget_used_percent": 2.044925990675192
    },
    {
      "type": "training",
      "description": "Training step 1424",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:49",
      "total_flops_so_far": 2046358142716664.0,
      "budget_used_percent": 2.046358142716664
    },
    {
      "type": "training",
      "description": "Training step 1425",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:50",
      "total_flops_so_far": 2047790294758136.0,
      "budget_used_percent": 2.047790294758136
    },
    {
      "type": "training",
      "description": "Training step 1426",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:50",
      "total_flops_so_far": 2049222446799608.0,
      "budget_used_percent": 2.049222446799608
    },
    {
      "type": "training",
      "description": "Training step 1427",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:50",
      "total_flops_so_far": 2050654598841080.0,
      "budget_used_percent": 2.05065459884108
    },
    {
      "type": "training",
      "description": "Training step 1428",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:50",
      "total_flops_so_far": 2052086750882552.0,
      "budget_used_percent": 2.052086750882552
    },
    {
      "type": "training",
      "description": "Training step 1429",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:50",
      "total_flops_so_far": 2053518902924024.0,
      "budget_used_percent": 2.053518902924024
    },
    {
      "type": "training",
      "description": "Training step 1430",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:50",
      "total_flops_so_far": 2054951054965496.0,
      "budget_used_percent": 2.054951054965496
    },
    {
      "type": "training",
      "description": "Training step 1431",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:50",
      "total_flops_so_far": 2056383207006968.0,
      "budget_used_percent": 2.056383207006968
    },
    {
      "type": "training",
      "description": "Training step 1432",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:51",
      "total_flops_so_far": 2057815359048440.0,
      "budget_used_percent": 2.05781535904844
    },
    {
      "type": "training",
      "description": "Training step 1433",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:51",
      "total_flops_so_far": 2059247511089912.0,
      "budget_used_percent": 2.0592475110899118
    },
    {
      "type": "training",
      "description": "Training step 1434",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:51",
      "total_flops_so_far": 2060679663131384.0,
      "budget_used_percent": 2.060679663131384
    },
    {
      "type": "training",
      "description": "Training step 1435",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:51",
      "total_flops_so_far": 2062111815172856.0,
      "budget_used_percent": 2.062111815172856
    },
    {
      "type": "training",
      "description": "Training step 1436",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:51",
      "total_flops_so_far": 2063543967214328.0,
      "budget_used_percent": 2.063543967214328
    },
    {
      "type": "training",
      "description": "Training step 1437",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:51",
      "total_flops_so_far": 2064976119255800.0,
      "budget_used_percent": 2.0649761192558
    },
    {
      "type": "training",
      "description": "Training step 1438",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:51",
      "total_flops_so_far": 2066408271297272.0,
      "budget_used_percent": 2.066408271297272
    },
    {
      "type": "training",
      "description": "Training step 1439",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:52",
      "total_flops_so_far": 2067840423338744.0,
      "budget_used_percent": 2.067840423338744
    },
    {
      "type": "training",
      "description": "Training step 1440",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:52",
      "total_flops_so_far": 2069272575380216.0,
      "budget_used_percent": 2.069272575380216
    },
    {
      "type": "training",
      "description": "Training step 1441",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:52",
      "total_flops_so_far": 2070704727421688.0,
      "budget_used_percent": 2.0707047274216883
    },
    {
      "type": "training",
      "description": "Training step 1442",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:52",
      "total_flops_so_far": 2072136879463160.0,
      "budget_used_percent": 2.07213687946316
    },
    {
      "type": "training",
      "description": "Training step 1443",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:52",
      "total_flops_so_far": 2073569031504632.0,
      "budget_used_percent": 2.073569031504632
    },
    {
      "type": "training",
      "description": "Training step 1444",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:52",
      "total_flops_so_far": 2075001183546104.0,
      "budget_used_percent": 2.075001183546104
    },
    {
      "type": "training",
      "description": "Training step 1445",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:53",
      "total_flops_so_far": 2076433335587576.0,
      "budget_used_percent": 2.0764333355875757
    },
    {
      "type": "training",
      "description": "Training step 1446",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:53",
      "total_flops_so_far": 2077865487629048.0,
      "budget_used_percent": 2.0778654876290483
    },
    {
      "type": "training",
      "description": "Training step 1447",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:53",
      "total_flops_so_far": 2079297639670520.0,
      "budget_used_percent": 2.07929763967052
    },
    {
      "type": "training",
      "description": "Training step 1448",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:53",
      "total_flops_so_far": 2080729791711992.0,
      "budget_used_percent": 2.0807297917119922
    },
    {
      "type": "training",
      "description": "Training step 1449",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:53",
      "total_flops_so_far": 2082161943753464.0,
      "budget_used_percent": 2.082161943753464
    },
    {
      "type": "training",
      "description": "Training step 1450",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:53",
      "total_flops_so_far": 2083594095794936.0,
      "budget_used_percent": 2.083594095794936
    },
    {
      "type": "training",
      "description": "Training step 1451",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:53",
      "total_flops_so_far": 2085026247836408.0,
      "budget_used_percent": 2.085026247836408
    },
    {
      "type": "training",
      "description": "Training step 1452",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:54",
      "total_flops_so_far": 2086458399877880.0,
      "budget_used_percent": 2.0864583998778796
    },
    {
      "type": "training",
      "description": "Training step 1453",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:54",
      "total_flops_so_far": 2087890551919352.0,
      "budget_used_percent": 2.0878905519193522
    },
    {
      "type": "training",
      "description": "Training step 1454",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:54",
      "total_flops_so_far": 2089322703960824.0,
      "budget_used_percent": 2.089322703960824
    },
    {
      "type": "training",
      "description": "Training step 1455",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:54",
      "total_flops_so_far": 2090754856002296.0,
      "budget_used_percent": 2.090754856002296
    },
    {
      "type": "training",
      "description": "Training step 1456",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:54",
      "total_flops_so_far": 2092187008043768.0,
      "budget_used_percent": 2.092187008043768
    },
    {
      "type": "training",
      "description": "Training step 1457",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:54",
      "total_flops_so_far": 2093619160085240.0,
      "budget_used_percent": 2.09361916008524
    },
    {
      "type": "training",
      "description": "Training step 1458",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:54",
      "total_flops_so_far": 2095051312126712.0,
      "budget_used_percent": 2.095051312126712
    },
    {
      "type": "training",
      "description": "Training step 1459",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:55",
      "total_flops_so_far": 2096483464168184.0,
      "budget_used_percent": 2.096483464168184
    },
    {
      "type": "training",
      "description": "Training step 1460",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:55",
      "total_flops_so_far": 2097915616209656.0,
      "budget_used_percent": 2.097915616209656
    },
    {
      "type": "training",
      "description": "Training step 1461",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:55",
      "total_flops_so_far": 2099347768251128.0,
      "budget_used_percent": 2.099347768251128
    },
    {
      "type": "training",
      "description": "Training step 1462",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:55",
      "total_flops_so_far": 2100779920292600.0,
      "budget_used_percent": 2.1007799202926
    },
    {
      "type": "training",
      "description": "Training step 1463",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:55",
      "total_flops_so_far": 2102212072334072.0,
      "budget_used_percent": 2.102212072334072
    },
    {
      "type": "training",
      "description": "Training step 1464",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:55",
      "total_flops_so_far": 2103644224375544.0,
      "budget_used_percent": 2.103644224375544
    },
    {
      "type": "training",
      "description": "Training step 1465",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:55",
      "total_flops_so_far": 2105076376417016.0,
      "budget_used_percent": 2.105076376417016
    },
    {
      "type": "training",
      "description": "Training step 1466",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:56",
      "total_flops_so_far": 2106508528458488.0,
      "budget_used_percent": 2.106508528458488
    },
    {
      "type": "training",
      "description": "Training step 1467",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:56",
      "total_flops_so_far": 2107940680499960.0,
      "budget_used_percent": 2.10794068049996
    },
    {
      "type": "training",
      "description": "Training step 1468",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:56",
      "total_flops_so_far": 2109372832541432.0,
      "budget_used_percent": 2.109372832541432
    },
    {
      "type": "training",
      "description": "Training step 1469",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:56",
      "total_flops_so_far": 2110804984582904.0,
      "budget_used_percent": 2.110804984582904
    },
    {
      "type": "training",
      "description": "Training step 1470",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:56",
      "total_flops_so_far": 2112237136624376.0,
      "budget_used_percent": 2.1122371366243757
    },
    {
      "type": "training",
      "description": "Training step 1471",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:56",
      "total_flops_so_far": 2113669288665848.0,
      "budget_used_percent": 2.1136692886658484
    },
    {
      "type": "training",
      "description": "Training step 1472",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:56",
      "total_flops_so_far": 2115101440707320.0,
      "budget_used_percent": 2.11510144070732
    },
    {
      "type": "training",
      "description": "Training step 1473",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:57",
      "total_flops_so_far": 2116533592748792.0,
      "budget_used_percent": 2.116533592748792
    },
    {
      "type": "training",
      "description": "Training step 1474",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:57",
      "total_flops_so_far": 2117965744790264.0,
      "budget_used_percent": 2.117965744790264
    },
    {
      "type": "training",
      "description": "Training step 1475",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:57",
      "total_flops_so_far": 2119397896831736.0,
      "budget_used_percent": 2.1193978968317357
    },
    {
      "type": "training",
      "description": "Training step 1476",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:57",
      "total_flops_so_far": 2120830048873208.0,
      "budget_used_percent": 2.120830048873208
    },
    {
      "type": "training",
      "description": "Training step 1477",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:57",
      "total_flops_so_far": 2122262200914680.0,
      "budget_used_percent": 2.12226220091468
    },
    {
      "type": "training",
      "description": "Training step 1478",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:57",
      "total_flops_so_far": 2123694352956152.0,
      "budget_used_percent": 2.1236943529561523
    },
    {
      "type": "training",
      "description": "Training step 1479",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:58",
      "total_flops_so_far": 2125126504997624.0,
      "budget_used_percent": 2.125126504997624
    },
    {
      "type": "training",
      "description": "Training step 1480",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:58",
      "total_flops_so_far": 2126558657039096.0,
      "budget_used_percent": 2.126558657039096
    },
    {
      "type": "training",
      "description": "Training step 1481",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:58",
      "total_flops_so_far": 2127990809080568.0,
      "budget_used_percent": 2.127990809080568
    },
    {
      "type": "training",
      "description": "Training step 1482",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:58",
      "total_flops_so_far": 2129422961122040.0,
      "budget_used_percent": 2.1294229611220397
    },
    {
      "type": "training",
      "description": "Training step 1483",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:58",
      "total_flops_so_far": 2130855113163512.0,
      "budget_used_percent": 2.1308551131635123
    },
    {
      "type": "training",
      "description": "Training step 1484",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:58",
      "total_flops_so_far": 2132287265204984.0,
      "budget_used_percent": 2.132287265204984
    },
    {
      "type": "training",
      "description": "Training step 1485",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:58",
      "total_flops_so_far": 2133719417246456.0,
      "budget_used_percent": 2.133719417246456
    },
    {
      "type": "training",
      "description": "Training step 1486",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:59",
      "total_flops_so_far": 2135151569287928.0,
      "budget_used_percent": 2.135151569287928
    },
    {
      "type": "training",
      "description": "Training step 1487",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:59",
      "total_flops_so_far": 2136583721329400.0,
      "budget_used_percent": 2.1365837213294
    },
    {
      "type": "training",
      "description": "Training step 1488",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:59",
      "total_flops_so_far": 2138015873370872.0,
      "budget_used_percent": 2.138015873370872
    },
    {
      "type": "training",
      "description": "Training step 1489",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:59",
      "total_flops_so_far": 2139448025412344.0,
      "budget_used_percent": 2.139448025412344
    },
    {
      "type": "training",
      "description": "Training step 1490",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:59",
      "total_flops_so_far": 2140880177453816.0,
      "budget_used_percent": 2.140880177453816
    },
    {
      "type": "training",
      "description": "Training step 1491",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:59",
      "total_flops_so_far": 2142312329495288.0,
      "budget_used_percent": 2.142312329495288
    },
    {
      "type": "training",
      "description": "Training step 1492",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:46:59",
      "total_flops_so_far": 2143744481536760.0,
      "budget_used_percent": 2.14374448153676
    },
    {
      "type": "training",
      "description": "Training step 1493",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:00",
      "total_flops_so_far": 2145176633578232.0,
      "budget_used_percent": 2.145176633578232
    },
    {
      "type": "training",
      "description": "Training step 1494",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:00",
      "total_flops_so_far": 2146608785619704.0,
      "budget_used_percent": 2.146608785619704
    },
    {
      "type": "training",
      "description": "Training step 1495",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:00",
      "total_flops_so_far": 2148040937661176.0,
      "budget_used_percent": 2.148040937661176
    },
    {
      "type": "training",
      "description": "Training step 1496",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:00",
      "total_flops_so_far": 2149473089702648.0,
      "budget_used_percent": 2.149473089702648
    },
    {
      "type": "training",
      "description": "Training step 1497",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:00",
      "total_flops_so_far": 2150905241744120.0,
      "budget_used_percent": 2.15090524174412
    },
    {
      "type": "training",
      "description": "Training step 1498",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:00",
      "total_flops_so_far": 2152337393785592.0,
      "budget_used_percent": 2.152337393785592
    },
    {
      "type": "training",
      "description": "Training step 1499",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:00",
      "total_flops_so_far": 2153769545827064.0,
      "budget_used_percent": 2.153769545827064
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 0",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552526568288.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:02",
      "total_flops_so_far": 2154322072395352.0,
      "budget_used_percent": 2.154322072395352
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 1",
      "context_len": 604,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 556130834256.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:03",
      "total_flops_so_far": 2154878203229608.0,
      "budget_used_percent": 2.1548782032296083
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 2",
      "context_len": 602,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 554328341080.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:04",
      "total_flops_so_far": 2155432531570688.0,
      "budget_used_percent": 2.155432531570688
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 3",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552526568288.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:06",
      "total_flops_so_far": 2155985058138976.0,
      "budget_used_percent": 2.155985058138976
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 4",
      "context_len": 603,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 555229497620.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:07",
      "total_flops_so_far": 2156540287636596.0,
      "budget_used_percent": 2.156540287636596
    },
    {
      "type": "training",
      "description": "Training step 1500",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:07",
      "total_flops_so_far": 2157972439678068.0,
      "budget_used_percent": 2.1579724396780677
    },
    {
      "type": "training",
      "description": "Training step 1501",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:07",
      "total_flops_so_far": 2159404591719540.0,
      "budget_used_percent": 2.15940459171954
    },
    {
      "type": "training",
      "description": "Training step 1502",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:08",
      "total_flops_so_far": 2160836743761012.0,
      "budget_used_percent": 2.160836743761012
    },
    {
      "type": "training",
      "description": "Training step 1503",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:08",
      "total_flops_so_far": 2162268895802484.0,
      "budget_used_percent": 2.1622688958024843
    },
    {
      "type": "training",
      "description": "Training step 1504",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:08",
      "total_flops_so_far": 2163701047843956.0,
      "budget_used_percent": 2.163701047843956
    },
    {
      "type": "training",
      "description": "Training step 1505",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:08",
      "total_flops_so_far": 2165133199885428.0,
      "budget_used_percent": 2.165133199885428
    },
    {
      "type": "training",
      "description": "Training step 1506",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:08",
      "total_flops_so_far": 2166565351926900.0,
      "budget_used_percent": 2.1665653519269
    },
    {
      "type": "training",
      "description": "Training step 1507",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:08",
      "total_flops_so_far": 2167997503968372.0,
      "budget_used_percent": 2.1679975039683717
    },
    {
      "type": "training",
      "description": "Training step 1508",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:08",
      "total_flops_so_far": 2169429656009844.0,
      "budget_used_percent": 2.1694296560098443
    },
    {
      "type": "training",
      "description": "Training step 1509",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:09",
      "total_flops_so_far": 2170861808051316.0,
      "budget_used_percent": 2.170861808051316
    },
    {
      "type": "training",
      "description": "Training step 1510",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:09",
      "total_flops_so_far": 2172293960092788.0,
      "budget_used_percent": 2.172293960092788
    },
    {
      "type": "training",
      "description": "Training step 1511",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:09",
      "total_flops_so_far": 2173726112134260.0,
      "budget_used_percent": 2.17372611213426
    },
    {
      "type": "training",
      "description": "Training step 1512",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:09",
      "total_flops_so_far": 2175158264175732.0,
      "budget_used_percent": 2.175158264175732
    },
    {
      "type": "training",
      "description": "Training step 1513",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:09",
      "total_flops_so_far": 2176590416217204.0,
      "budget_used_percent": 2.176590416217204
    },
    {
      "type": "training",
      "description": "Training step 1514",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:10",
      "total_flops_so_far": 2178022568258676.0,
      "budget_used_percent": 2.178022568258676
    },
    {
      "type": "training",
      "description": "Training step 1515",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:10",
      "total_flops_so_far": 2179454720300148.0,
      "budget_used_percent": 2.179454720300148
    },
    {
      "type": "training",
      "description": "Training step 1516",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:10",
      "total_flops_so_far": 2180886872341620.0,
      "budget_used_percent": 2.18088687234162
    },
    {
      "type": "training",
      "description": "Training step 1517",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:10",
      "total_flops_so_far": 2182319024383092.0,
      "budget_used_percent": 2.182319024383092
    },
    {
      "type": "training",
      "description": "Training step 1518",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:10",
      "total_flops_so_far": 2183751176424564.0,
      "budget_used_percent": 2.183751176424564
    },
    {
      "type": "training",
      "description": "Training step 1519",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:10",
      "total_flops_so_far": 2185183328466036.0,
      "budget_used_percent": 2.185183328466036
    },
    {
      "type": "training",
      "description": "Training step 1520",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:10",
      "total_flops_so_far": 2186615480507508.0,
      "budget_used_percent": 2.1866154805075078
    },
    {
      "type": "training",
      "description": "Training step 1521",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:11",
      "total_flops_so_far": 2188047632548980.0,
      "budget_used_percent": 2.18804763254898
    },
    {
      "type": "training",
      "description": "Training step 1522",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:11",
      "total_flops_so_far": 2189479784590452.0,
      "budget_used_percent": 2.189479784590452
    },
    {
      "type": "training",
      "description": "Training step 1523",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:11",
      "total_flops_so_far": 2190911936631924.0,
      "budget_used_percent": 2.190911936631924
    },
    {
      "type": "training",
      "description": "Training step 1524",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:11",
      "total_flops_so_far": 2192344088673396.0,
      "budget_used_percent": 2.192344088673396
    },
    {
      "type": "training",
      "description": "Training step 1525",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:11",
      "total_flops_so_far": 2193776240714868.0,
      "budget_used_percent": 2.1937762407148678
    },
    {
      "type": "training",
      "description": "Training step 1526",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:11",
      "total_flops_so_far": 2195208392756340.0,
      "budget_used_percent": 2.19520839275634
    },
    {
      "type": "training",
      "description": "Training step 1527",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:11",
      "total_flops_so_far": 2196640544797812.0,
      "budget_used_percent": 2.196640544797812
    },
    {
      "type": "training",
      "description": "Training step 1528",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:12",
      "total_flops_so_far": 2198072696839284.0,
      "budget_used_percent": 2.198072696839284
    },
    {
      "type": "training",
      "description": "Training step 1529",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:12",
      "total_flops_so_far": 2199504848880756.0,
      "budget_used_percent": 2.199504848880756
    },
    {
      "type": "training",
      "description": "Training step 1530",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:12",
      "total_flops_so_far": 2200937000922228.0,
      "budget_used_percent": 2.2009370009222278
    },
    {
      "type": "training",
      "description": "Training step 1531",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:12",
      "total_flops_so_far": 2202369152963700.0,
      "budget_used_percent": 2.2023691529637
    },
    {
      "type": "training",
      "description": "Training step 1532",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:12",
      "total_flops_so_far": 2203801305005172.0,
      "budget_used_percent": 2.2038013050051717
    },
    {
      "type": "training",
      "description": "Training step 1533",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:12",
      "total_flops_so_far": 2205233457046644.0,
      "budget_used_percent": 2.2052334570466443
    },
    {
      "type": "training",
      "description": "Training step 1534",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:12",
      "total_flops_so_far": 2206665609088116.0,
      "budget_used_percent": 2.206665609088116
    },
    {
      "type": "training",
      "description": "Training step 1535",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:13",
      "total_flops_so_far": 2208097761129588.0,
      "budget_used_percent": 2.208097761129588
    },
    {
      "type": "training",
      "description": "Training step 1536",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:13",
      "total_flops_so_far": 2209529913171060.0,
      "budget_used_percent": 2.20952991317106
    },
    {
      "type": "training",
      "description": "Training step 1537",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:13",
      "total_flops_so_far": 2210962065212532.0,
      "budget_used_percent": 2.2109620652125317
    },
    {
      "type": "training",
      "description": "Training step 1538",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:13",
      "total_flops_so_far": 2212394217254004.0,
      "budget_used_percent": 2.212394217254004
    },
    {
      "type": "training",
      "description": "Training step 1539",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:13",
      "total_flops_so_far": 2213826369295476.0,
      "budget_used_percent": 2.213826369295476
    },
    {
      "type": "training",
      "description": "Training step 1540",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:13",
      "total_flops_so_far": 2215258521336948.0,
      "budget_used_percent": 2.2152585213369482
    },
    {
      "type": "training",
      "description": "Training step 1541",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:14",
      "total_flops_so_far": 2216690673378420.0,
      "budget_used_percent": 2.21669067337842
    },
    {
      "type": "training",
      "description": "Training step 1542",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:14",
      "total_flops_so_far": 2218122825419892.0,
      "budget_used_percent": 2.218122825419892
    },
    {
      "type": "training",
      "description": "Training step 1543",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:14",
      "total_flops_so_far": 2219554977461364.0,
      "budget_used_percent": 2.219554977461364
    },
    {
      "type": "training",
      "description": "Training step 1544",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:14",
      "total_flops_so_far": 2220987129502836.0,
      "budget_used_percent": 2.220987129502836
    },
    {
      "type": "training",
      "description": "Training step 1545",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:14",
      "total_flops_so_far": 2222419281544308.0,
      "budget_used_percent": 2.2224192815443082
    },
    {
      "type": "training",
      "description": "Training step 1546",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:14",
      "total_flops_so_far": 2223851433585780.0,
      "budget_used_percent": 2.22385143358578
    },
    {
      "type": "training",
      "description": "Training step 1547",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:14",
      "total_flops_so_far": 2225283585627252.0,
      "budget_used_percent": 2.225283585627252
    },
    {
      "type": "training",
      "description": "Training step 1548",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:15",
      "total_flops_so_far": 2226715737668724.0,
      "budget_used_percent": 2.226715737668724
    },
    {
      "type": "training",
      "description": "Training step 1549",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:15",
      "total_flops_so_far": 2228147889710196.0,
      "budget_used_percent": 2.228147889710196
    },
    {
      "type": "training",
      "description": "Training step 1550",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:15",
      "total_flops_so_far": 2229580041751668.0,
      "budget_used_percent": 2.229580041751668
    },
    {
      "type": "training",
      "description": "Training step 1551",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:15",
      "total_flops_so_far": 2231012193793140.0,
      "budget_used_percent": 2.23101219379314
    },
    {
      "type": "training",
      "description": "Training step 1552",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:15",
      "total_flops_so_far": 2232444345834612.0,
      "budget_used_percent": 2.232444345834612
    },
    {
      "type": "training",
      "description": "Training step 1553",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:15",
      "total_flops_so_far": 2233876497876084.0,
      "budget_used_percent": 2.233876497876084
    },
    {
      "type": "training",
      "description": "Training step 1554",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:15",
      "total_flops_so_far": 2235308649917556.0,
      "budget_used_percent": 2.235308649917556
    },
    {
      "type": "training",
      "description": "Training step 1555",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:16",
      "total_flops_so_far": 2236740801959028.0,
      "budget_used_percent": 2.236740801959028
    },
    {
      "type": "training",
      "description": "Training step 1556",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:16",
      "total_flops_so_far": 2238172954000500.0,
      "budget_used_percent": 2.2381729540005
    },
    {
      "type": "training",
      "description": "Training step 1557",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:16",
      "total_flops_so_far": 2239605106041972.0,
      "budget_used_percent": 2.239605106041972
    },
    {
      "type": "training",
      "description": "Training step 1558",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:16",
      "total_flops_so_far": 2241037258083444.0,
      "budget_used_percent": 2.241037258083444
    },
    {
      "type": "training",
      "description": "Training step 1559",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:16",
      "total_flops_so_far": 2242469410124916.0,
      "budget_used_percent": 2.242469410124916
    },
    {
      "type": "training",
      "description": "Training step 1560",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:16",
      "total_flops_so_far": 2243901562166388.0,
      "budget_used_percent": 2.243901562166388
    },
    {
      "type": "training",
      "description": "Training step 1561",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:17",
      "total_flops_so_far": 2245333714207860.0,
      "budget_used_percent": 2.24533371420786
    },
    {
      "type": "training",
      "description": "Training step 1562",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:17",
      "total_flops_so_far": 2246765866249332.0,
      "budget_used_percent": 2.2467658662493317
    },
    {
      "type": "training",
      "description": "Training step 1563",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:17",
      "total_flops_so_far": 2248198018290804.0,
      "budget_used_percent": 2.2481980182908043
    },
    {
      "type": "training",
      "description": "Training step 1564",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:17",
      "total_flops_so_far": 2249630170332276.0,
      "budget_used_percent": 2.249630170332276
    },
    {
      "type": "training",
      "description": "Training step 1565",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:17",
      "total_flops_so_far": 2251062322373748.0,
      "budget_used_percent": 2.2510623223737483
    },
    {
      "type": "training",
      "description": "Training step 1566",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:17",
      "total_flops_so_far": 2252494474415220.0,
      "budget_used_percent": 2.25249447441522
    },
    {
      "type": "training",
      "description": "Training step 1567",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:17",
      "total_flops_so_far": 2253926626456692.0,
      "budget_used_percent": 2.2539266264566917
    },
    {
      "type": "training",
      "description": "Training step 1568",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:18",
      "total_flops_so_far": 2255358778498164.0,
      "budget_used_percent": 2.255358778498164
    },
    {
      "type": "training",
      "description": "Training step 1569",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:18",
      "total_flops_so_far": 2256790930539636.0,
      "budget_used_percent": 2.256790930539636
    },
    {
      "type": "training",
      "description": "Training step 1570",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:18",
      "total_flops_so_far": 2258223082581108.0,
      "budget_used_percent": 2.2582230825811083
    },
    {
      "type": "training",
      "description": "Training step 1571",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:18",
      "total_flops_so_far": 2259655234622580.0,
      "budget_used_percent": 2.25965523462258
    },
    {
      "type": "training",
      "description": "Training step 1572",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:18",
      "total_flops_so_far": 2261087386664052.0,
      "budget_used_percent": 2.261087386664052
    },
    {
      "type": "training",
      "description": "Training step 1573",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:18",
      "total_flops_so_far": 2262519538705524.0,
      "budget_used_percent": 2.262519538705524
    },
    {
      "type": "training",
      "description": "Training step 1574",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:18",
      "total_flops_so_far": 2263951690746996.0,
      "budget_used_percent": 2.263951690746996
    },
    {
      "type": "training",
      "description": "Training step 1575",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:19",
      "total_flops_so_far": 2265383842788468.0,
      "budget_used_percent": 2.2653838427884683
    },
    {
      "type": "training",
      "description": "Training step 1576",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:19",
      "total_flops_so_far": 2266815994829940.0,
      "budget_used_percent": 2.26681599482994
    },
    {
      "type": "training",
      "description": "Training step 1577",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:19",
      "total_flops_so_far": 2268248146871412.0,
      "budget_used_percent": 2.268248146871412
    },
    {
      "type": "training",
      "description": "Training step 1578",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:19",
      "total_flops_so_far": 2269680298912884.0,
      "budget_used_percent": 2.269680298912884
    },
    {
      "type": "training",
      "description": "Training step 1579",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:19",
      "total_flops_so_far": 2271112450954356.0,
      "budget_used_percent": 2.271112450954356
    },
    {
      "type": "training",
      "description": "Training step 1580",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:19",
      "total_flops_so_far": 2272544602995828.0,
      "budget_used_percent": 2.272544602995828
    },
    {
      "type": "training",
      "description": "Training step 1581",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:20",
      "total_flops_so_far": 2273976755037300.0,
      "budget_used_percent": 2.2739767550373
    },
    {
      "type": "training",
      "description": "Training step 1582",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:20",
      "total_flops_so_far": 2275408907078772.0,
      "budget_used_percent": 2.275408907078772
    },
    {
      "type": "training",
      "description": "Training step 1583",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:20",
      "total_flops_so_far": 2276841059120244.0,
      "budget_used_percent": 2.276841059120244
    },
    {
      "type": "training",
      "description": "Training step 1584",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:20",
      "total_flops_so_far": 2278273211161716.0,
      "budget_used_percent": 2.278273211161716
    },
    {
      "type": "training",
      "description": "Training step 1585",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:20",
      "total_flops_so_far": 2279705363203188.0,
      "budget_used_percent": 2.279705363203188
    },
    {
      "type": "training",
      "description": "Training step 1586",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:20",
      "total_flops_so_far": 2281137515244660.0,
      "budget_used_percent": 2.28113751524466
    },
    {
      "type": "training",
      "description": "Training step 1587",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:20",
      "total_flops_so_far": 2282569667286132.0,
      "budget_used_percent": 2.282569667286132
    },
    {
      "type": "training",
      "description": "Training step 1588",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:21",
      "total_flops_so_far": 2284001819327604.0,
      "budget_used_percent": 2.284001819327604
    },
    {
      "type": "training",
      "description": "Training step 1589",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:21",
      "total_flops_so_far": 2285433971369076.0,
      "budget_used_percent": 2.285433971369076
    },
    {
      "type": "training",
      "description": "Training step 1590",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:21",
      "total_flops_so_far": 2286866123410548.0,
      "budget_used_percent": 2.286866123410548
    },
    {
      "type": "training",
      "description": "Training step 1591",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:21",
      "total_flops_so_far": 2288298275452020.0,
      "budget_used_percent": 2.28829827545202
    },
    {
      "type": "training",
      "description": "Training step 1592",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:21",
      "total_flops_so_far": 2289730427493492.0,
      "budget_used_percent": 2.2897304274934918
    },
    {
      "type": "training",
      "description": "Training step 1593",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:21",
      "total_flops_so_far": 2291162579534964.0,
      "budget_used_percent": 2.291162579534964
    },
    {
      "type": "training",
      "description": "Training step 1594",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:21",
      "total_flops_so_far": 2292594731576436.0,
      "budget_used_percent": 2.292594731576436
    },
    {
      "type": "training",
      "description": "Training step 1595",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:22",
      "total_flops_so_far": 2294026883617908.0,
      "budget_used_percent": 2.294026883617908
    },
    {
      "type": "training",
      "description": "Training step 1596",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:22",
      "total_flops_so_far": 2295459035659380.0,
      "budget_used_percent": 2.29545903565938
    },
    {
      "type": "training",
      "description": "Training step 1597",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:22",
      "total_flops_so_far": 2296891187700852.0,
      "budget_used_percent": 2.2968911877008518
    },
    {
      "type": "training",
      "description": "Training step 1598",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:22",
      "total_flops_so_far": 2298323339742324.0,
      "budget_used_percent": 2.298323339742324
    },
    {
      "type": "training",
      "description": "Training step 1599",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:22",
      "total_flops_so_far": 2299755491783796.0,
      "budget_used_percent": 2.2997554917837957
    },
    {
      "type": "training",
      "description": "Training step 1600",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:22",
      "total_flops_so_far": 2301187643825268.0,
      "budget_used_percent": 2.3011876438252683
    },
    {
      "type": "training",
      "description": "Training step 1601",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:23",
      "total_flops_so_far": 2302619795866740.0,
      "budget_used_percent": 2.30261979586674
    },
    {
      "type": "training",
      "description": "Training step 1602",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:23",
      "total_flops_so_far": 2304051947908212.0,
      "budget_used_percent": 2.304051947908212
    },
    {
      "type": "training",
      "description": "Training step 1603",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:23",
      "total_flops_so_far": 2305484099949684.0,
      "budget_used_percent": 2.305484099949684
    },
    {
      "type": "training",
      "description": "Training step 1604",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:23",
      "total_flops_so_far": 2306916251991156.0,
      "budget_used_percent": 2.3069162519911557
    },
    {
      "type": "training",
      "description": "Training step 1605",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:23",
      "total_flops_so_far": 2308348404032628.0,
      "budget_used_percent": 2.308348404032628
    },
    {
      "type": "training",
      "description": "Training step 1606",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:23",
      "total_flops_so_far": 2309780556074100.0,
      "budget_used_percent": 2.3097805560741
    },
    {
      "type": "training",
      "description": "Training step 1607",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:23",
      "total_flops_so_far": 2311212708115572.0,
      "budget_used_percent": 2.3112127081155722
    },
    {
      "type": "training",
      "description": "Training step 1608",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:24",
      "total_flops_so_far": 2312644860157044.0,
      "budget_used_percent": 2.312644860157044
    },
    {
      "type": "training",
      "description": "Training step 1609",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:24",
      "total_flops_so_far": 2314077012198516.0,
      "budget_used_percent": 2.314077012198516
    },
    {
      "type": "training",
      "description": "Training step 1610",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:24",
      "total_flops_so_far": 2315509164239988.0,
      "budget_used_percent": 2.315509164239988
    },
    {
      "type": "training",
      "description": "Training step 1611",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:24",
      "total_flops_so_far": 2316941316281460.0,
      "budget_used_percent": 2.31694131628146
    },
    {
      "type": "training",
      "description": "Training step 1612",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:24",
      "total_flops_so_far": 2318373468322932.0,
      "budget_used_percent": 2.3183734683229322
    },
    {
      "type": "training",
      "description": "Training step 1613",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:24",
      "total_flops_so_far": 2319805620364404.0,
      "budget_used_percent": 2.319805620364404
    },
    {
      "type": "training",
      "description": "Training step 1614",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:24",
      "total_flops_so_far": 2321237772405876.0,
      "budget_used_percent": 2.321237772405876
    },
    {
      "type": "training",
      "description": "Training step 1615",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:25",
      "total_flops_so_far": 2322669924447348.0,
      "budget_used_percent": 2.322669924447348
    },
    {
      "type": "training",
      "description": "Training step 1616",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:25",
      "total_flops_so_far": 2324102076488820.0,
      "budget_used_percent": 2.32410207648882
    },
    {
      "type": "training",
      "description": "Training step 1617",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:25",
      "total_flops_so_far": 2325534228530292.0,
      "budget_used_percent": 2.325534228530292
    },
    {
      "type": "training",
      "description": "Training step 1618",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:25",
      "total_flops_so_far": 2326966380571764.0,
      "budget_used_percent": 2.326966380571764
    },
    {
      "type": "training",
      "description": "Training step 1619",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:25",
      "total_flops_so_far": 2328398532613236.0,
      "budget_used_percent": 2.328398532613236
    },
    {
      "type": "training",
      "description": "Training step 1620",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:25",
      "total_flops_so_far": 2329830684654708.0,
      "budget_used_percent": 2.329830684654708
    },
    {
      "type": "training",
      "description": "Training step 1621",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:26",
      "total_flops_so_far": 2331262836696180.0,
      "budget_used_percent": 2.33126283669618
    },
    {
      "type": "training",
      "description": "Training step 1622",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:26",
      "total_flops_so_far": 2332694988737652.0,
      "budget_used_percent": 2.332694988737652
    },
    {
      "type": "training",
      "description": "Training step 1623",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:26",
      "total_flops_so_far": 2334127140779124.0,
      "budget_used_percent": 2.334127140779124
    },
    {
      "type": "training",
      "description": "Training step 1624",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:26",
      "total_flops_so_far": 2335559292820596.0,
      "budget_used_percent": 2.335559292820596
    },
    {
      "type": "training",
      "description": "Training step 1625",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:26",
      "total_flops_so_far": 2336991444862068.0,
      "budget_used_percent": 2.336991444862068
    },
    {
      "type": "training",
      "description": "Training step 1626",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:26",
      "total_flops_so_far": 2338423596903540.0,
      "budget_used_percent": 2.33842359690354
    },
    {
      "type": "training",
      "description": "Training step 1627",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:26",
      "total_flops_so_far": 2339855748945012.0,
      "budget_used_percent": 2.339855748945012
    },
    {
      "type": "training",
      "description": "Training step 1628",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:27",
      "total_flops_so_far": 2341287900986484.0,
      "budget_used_percent": 2.341287900986484
    },
    {
      "type": "training",
      "description": "Training step 1629",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:27",
      "total_flops_so_far": 2342720053027956.0,
      "budget_used_percent": 2.3427200530279557
    },
    {
      "type": "training",
      "description": "Training step 1630",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:27",
      "total_flops_so_far": 2344152205069428.0,
      "budget_used_percent": 2.3441522050694283
    },
    {
      "type": "training",
      "description": "Training step 1631",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:27",
      "total_flops_so_far": 2345584357110900.0,
      "budget_used_percent": 2.3455843571109
    },
    {
      "type": "training",
      "description": "Training step 1632",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:27",
      "total_flops_so_far": 2347016509152372.0,
      "budget_used_percent": 2.347016509152372
    },
    {
      "type": "training",
      "description": "Training step 1633",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:27",
      "total_flops_so_far": 2348448661193844.0,
      "budget_used_percent": 2.348448661193844
    },
    {
      "type": "training",
      "description": "Training step 1634",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:27",
      "total_flops_so_far": 2349880813235316.0,
      "budget_used_percent": 2.3498808132353157
    },
    {
      "type": "training",
      "description": "Training step 1635",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:28",
      "total_flops_so_far": 2351312965276788.0,
      "budget_used_percent": 2.351312965276788
    },
    {
      "type": "training",
      "description": "Training step 1636",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:28",
      "total_flops_so_far": 2352745117318260.0,
      "budget_used_percent": 2.35274511731826
    },
    {
      "type": "training",
      "description": "Training step 1637",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:28",
      "total_flops_so_far": 2354177269359732.0,
      "budget_used_percent": 2.3541772693597323
    },
    {
      "type": "training",
      "description": "Training step 1638",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:28",
      "total_flops_so_far": 2355609421401204.0,
      "budget_used_percent": 2.355609421401204
    },
    {
      "type": "training",
      "description": "Training step 1639",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:28",
      "total_flops_so_far": 2357041573442676.0,
      "budget_used_percent": 2.357041573442676
    },
    {
      "type": "training",
      "description": "Training step 1640",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:28",
      "total_flops_so_far": 2358473725484148.0,
      "budget_used_percent": 2.358473725484148
    },
    {
      "type": "training",
      "description": "Training step 1641",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:29",
      "total_flops_so_far": 2359905877525620.0,
      "budget_used_percent": 2.3599058775256196
    },
    {
      "type": "training",
      "description": "Training step 1642",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:29",
      "total_flops_so_far": 2361338029567092.0,
      "budget_used_percent": 2.3613380295670923
    },
    {
      "type": "training",
      "description": "Training step 1643",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:29",
      "total_flops_so_far": 2362770181608564.0,
      "budget_used_percent": 2.362770181608564
    },
    {
      "type": "training",
      "description": "Training step 1644",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:29",
      "total_flops_so_far": 2364202333650036.0,
      "budget_used_percent": 2.364202333650036
    },
    {
      "type": "training",
      "description": "Training step 1645",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:29",
      "total_flops_so_far": 2365634485691508.0,
      "budget_used_percent": 2.365634485691508
    },
    {
      "type": "training",
      "description": "Training step 1646",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:29",
      "total_flops_so_far": 2367066637732980.0,
      "budget_used_percent": 2.36706663773298
    },
    {
      "type": "training",
      "description": "Training step 1647",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:29",
      "total_flops_so_far": 2368498789774452.0,
      "budget_used_percent": 2.368498789774452
    },
    {
      "type": "training",
      "description": "Training step 1648",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:30",
      "total_flops_so_far": 2369930941815924.0,
      "budget_used_percent": 2.369930941815924
    },
    {
      "type": "training",
      "description": "Training step 1649",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:30",
      "total_flops_so_far": 2371363093857396.0,
      "budget_used_percent": 2.371363093857396
    },
    {
      "type": "training",
      "description": "Training step 1650",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:30",
      "total_flops_so_far": 2372795245898868.0,
      "budget_used_percent": 2.372795245898868
    },
    {
      "type": "training",
      "description": "Training step 1651",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:30",
      "total_flops_so_far": 2374227397940340.0,
      "budget_used_percent": 2.37422739794034
    },
    {
      "type": "training",
      "description": "Training step 1652",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:30",
      "total_flops_so_far": 2375659549981812.0,
      "budget_used_percent": 2.375659549981812
    },
    {
      "type": "training",
      "description": "Training step 1653",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:31",
      "total_flops_so_far": 2377091702023284.0,
      "budget_used_percent": 2.377091702023284
    },
    {
      "type": "training",
      "description": "Training step 1654",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:31",
      "total_flops_so_far": 2378523854064756.0,
      "budget_used_percent": 2.378523854064756
    },
    {
      "type": "training",
      "description": "Training step 1655",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:31",
      "total_flops_so_far": 2379956006106228.0,
      "budget_used_percent": 2.379956006106228
    },
    {
      "type": "training",
      "description": "Training step 1656",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:31",
      "total_flops_so_far": 2381388158147700.0,
      "budget_used_percent": 2.3813881581477
    },
    {
      "type": "training",
      "description": "Training step 1657",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:31",
      "total_flops_so_far": 2382820310189172.0,
      "budget_used_percent": 2.382820310189172
    },
    {
      "type": "training",
      "description": "Training step 1658",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:31",
      "total_flops_so_far": 2384252462230644.0,
      "budget_used_percent": 2.384252462230644
    },
    {
      "type": "training",
      "description": "Training step 1659",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:31",
      "total_flops_so_far": 2385684614272116.0,
      "budget_used_percent": 2.3856846142721158
    },
    {
      "type": "training",
      "description": "Training step 1660",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:32",
      "total_flops_so_far": 2387116766313588.0,
      "budget_used_percent": 2.3871167663135884
    },
    {
      "type": "training",
      "description": "Training step 1661",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:32",
      "total_flops_so_far": 2388548918355060.0,
      "budget_used_percent": 2.38854891835506
    },
    {
      "type": "training",
      "description": "Training step 1662",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:32",
      "total_flops_so_far": 2389981070396532.0,
      "budget_used_percent": 2.389981070396532
    },
    {
      "type": "training",
      "description": "Training step 1663",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:32",
      "total_flops_so_far": 2391413222438004.0,
      "budget_used_percent": 2.391413222438004
    },
    {
      "type": "training",
      "description": "Training step 1664",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:32",
      "total_flops_so_far": 2392845374479476.0,
      "budget_used_percent": 2.3928453744794758
    },
    {
      "type": "training",
      "description": "Training step 1665",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:32",
      "total_flops_so_far": 2394277526520948.0,
      "budget_used_percent": 2.394277526520948
    },
    {
      "type": "training",
      "description": "Training step 1666",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:33",
      "total_flops_so_far": 2395709678562420.0,
      "budget_used_percent": 2.3957096785624197
    },
    {
      "type": "training",
      "description": "Training step 1667",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:33",
      "total_flops_so_far": 2397141830603892.0,
      "budget_used_percent": 2.3971418306038923
    },
    {
      "type": "training",
      "description": "Training step 1668",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:33",
      "total_flops_so_far": 2398573982645364.0,
      "budget_used_percent": 2.398573982645364
    },
    {
      "type": "training",
      "description": "Training step 1669",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:33",
      "total_flops_so_far": 2400006134686836.0,
      "budget_used_percent": 2.400006134686836
    },
    {
      "type": "training",
      "description": "Training step 1670",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:33",
      "total_flops_so_far": 2401438286728308.0,
      "budget_used_percent": 2.401438286728308
    },
    {
      "type": "training",
      "description": "Training step 1671",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:33",
      "total_flops_so_far": 2402870438769780.0,
      "budget_used_percent": 2.4028704387697797
    },
    {
      "type": "training",
      "description": "Training step 1672",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:33",
      "total_flops_so_far": 2404302590811252.0,
      "budget_used_percent": 2.404302590811252
    },
    {
      "type": "training",
      "description": "Training step 1673",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:34",
      "total_flops_so_far": 2405734742852724.0,
      "budget_used_percent": 2.405734742852724
    },
    {
      "type": "training",
      "description": "Training step 1674",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:34",
      "total_flops_so_far": 2407166894894196.0,
      "budget_used_percent": 2.407166894894196
    },
    {
      "type": "training",
      "description": "Training step 1675",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:34",
      "total_flops_so_far": 2408599046935668.0,
      "budget_used_percent": 2.408599046935668
    },
    {
      "type": "training",
      "description": "Training step 1676",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:34",
      "total_flops_so_far": 2410031198977140.0,
      "budget_used_percent": 2.41003119897714
    },
    {
      "type": "training",
      "description": "Training step 1677",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:34",
      "total_flops_so_far": 2411463351018612.0,
      "budget_used_percent": 2.411463351018612
    },
    {
      "type": "training",
      "description": "Training step 1678",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:34",
      "total_flops_so_far": 2412895503060084.0,
      "budget_used_percent": 2.412895503060084
    },
    {
      "type": "training",
      "description": "Training step 1679",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:34",
      "total_flops_so_far": 2414327655101556.0,
      "budget_used_percent": 2.4143276551015562
    },
    {
      "type": "training",
      "description": "Training step 1680",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:35",
      "total_flops_so_far": 2415759807143028.0,
      "budget_used_percent": 2.415759807143028
    },
    {
      "type": "training",
      "description": "Training step 1681",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:35",
      "total_flops_so_far": 2417191959184500.0,
      "budget_used_percent": 2.4171919591845
    },
    {
      "type": "training",
      "description": "Training step 1682",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:35",
      "total_flops_so_far": 2418624111225972.0,
      "budget_used_percent": 2.418624111225972
    },
    {
      "type": "training",
      "description": "Training step 1683",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:35",
      "total_flops_so_far": 2420056263267444.0,
      "budget_used_percent": 2.420056263267444
    },
    {
      "type": "training",
      "description": "Training step 1684",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:35",
      "total_flops_so_far": 2421488415308916.0,
      "budget_used_percent": 2.421488415308916
    },
    {
      "type": "training",
      "description": "Training step 1685",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:35",
      "total_flops_so_far": 2422920567350388.0,
      "budget_used_percent": 2.422920567350388
    },
    {
      "type": "training",
      "description": "Training step 1686",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:36",
      "total_flops_so_far": 2424352719391860.0,
      "budget_used_percent": 2.42435271939186
    },
    {
      "type": "training",
      "description": "Training step 1687",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:36",
      "total_flops_so_far": 2425784871433332.0,
      "budget_used_percent": 2.425784871433332
    },
    {
      "type": "training",
      "description": "Training step 1688",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:36",
      "total_flops_so_far": 2427217023474804.0,
      "budget_used_percent": 2.427217023474804
    },
    {
      "type": "training",
      "description": "Training step 1689",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:36",
      "total_flops_so_far": 2428649175516276.0,
      "budget_used_percent": 2.428649175516276
    },
    {
      "type": "training",
      "description": "Training step 1690",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:36",
      "total_flops_so_far": 2430081327557748.0,
      "budget_used_percent": 2.430081327557748
    },
    {
      "type": "training",
      "description": "Training step 1691",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:36",
      "total_flops_so_far": 2431513479599220.0,
      "budget_used_percent": 2.43151347959922
    },
    {
      "type": "training",
      "description": "Training step 1692",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:36",
      "total_flops_so_far": 2432945631640692.0,
      "budget_used_percent": 2.432945631640692
    },
    {
      "type": "training",
      "description": "Training step 1693",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:37",
      "total_flops_so_far": 2434377783682164.0,
      "budget_used_percent": 2.434377783682164
    },
    {
      "type": "training",
      "description": "Training step 1694",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:37",
      "total_flops_so_far": 2435809935723636.0,
      "budget_used_percent": 2.435809935723636
    },
    {
      "type": "training",
      "description": "Training step 1695",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:37",
      "total_flops_so_far": 2437242087765108.0,
      "budget_used_percent": 2.437242087765108
    },
    {
      "type": "training",
      "description": "Training step 1696",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:37",
      "total_flops_so_far": 2438674239806580.0,
      "budget_used_percent": 2.4386742398065797
    },
    {
      "type": "training",
      "description": "Training step 1697",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:37",
      "total_flops_so_far": 2440106391848052.0,
      "budget_used_percent": 2.4401063918480523
    },
    {
      "type": "training",
      "description": "Training step 1698",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:37",
      "total_flops_so_far": 2441538543889524.0,
      "budget_used_percent": 2.441538543889524
    },
    {
      "type": "training",
      "description": "Training step 1699",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:38",
      "total_flops_so_far": 2442970695930996.0,
      "budget_used_percent": 2.4429706959309962
    },
    {
      "type": "training",
      "description": "Training step 1700",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:38",
      "total_flops_so_far": 2444402847972468.0,
      "budget_used_percent": 2.444402847972468
    },
    {
      "type": "training",
      "description": "Training step 1701",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:38",
      "total_flops_so_far": 2445835000013940.0,
      "budget_used_percent": 2.4458350000139397
    },
    {
      "type": "training",
      "description": "Training step 1702",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:38",
      "total_flops_so_far": 2447267152055412.0,
      "budget_used_percent": 2.447267152055412
    },
    {
      "type": "training",
      "description": "Training step 1703",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:38",
      "total_flops_so_far": 2448699304096884.0,
      "budget_used_percent": 2.448699304096884
    },
    {
      "type": "training",
      "description": "Training step 1704",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:38",
      "total_flops_so_far": 2450131456138356.0,
      "budget_used_percent": 2.4501314561383563
    },
    {
      "type": "training",
      "description": "Training step 1705",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:38",
      "total_flops_so_far": 2451563608179828.0,
      "budget_used_percent": 2.451563608179828
    },
    {
      "type": "training",
      "description": "Training step 1706",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:39",
      "total_flops_so_far": 2452995760221300.0,
      "budget_used_percent": 2.4529957602213
    },
    {
      "type": "training",
      "description": "Training step 1707",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:39",
      "total_flops_so_far": 2454427912262772.0,
      "budget_used_percent": 2.454427912262772
    },
    {
      "type": "training",
      "description": "Training step 1708",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:39",
      "total_flops_so_far": 2455860064304244.0,
      "budget_used_percent": 2.455860064304244
    },
    {
      "type": "training",
      "description": "Training step 1709",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:39",
      "total_flops_so_far": 2457292216345716.0,
      "budget_used_percent": 2.4572922163457163
    },
    {
      "type": "training",
      "description": "Training step 1710",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:39",
      "total_flops_so_far": 2458724368387188.0,
      "budget_used_percent": 2.458724368387188
    },
    {
      "type": "training",
      "description": "Training step 1711",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:39",
      "total_flops_so_far": 2460156520428660.0,
      "budget_used_percent": 2.46015652042866
    },
    {
      "type": "training",
      "description": "Training step 1712",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:40",
      "total_flops_so_far": 2461588672470132.0,
      "budget_used_percent": 2.461588672470132
    },
    {
      "type": "training",
      "description": "Training step 1713",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:40",
      "total_flops_so_far": 2463020824511604.0,
      "budget_used_percent": 2.463020824511604
    },
    {
      "type": "training",
      "description": "Training step 1714",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:40",
      "total_flops_so_far": 2464452976553076.0,
      "budget_used_percent": 2.464452976553076
    },
    {
      "type": "training",
      "description": "Training step 1715",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:40",
      "total_flops_so_far": 2465885128594548.0,
      "budget_used_percent": 2.465885128594548
    },
    {
      "type": "training",
      "description": "Training step 1716",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:40",
      "total_flops_so_far": 2467317280636020.0,
      "budget_used_percent": 2.46731728063602
    },
    {
      "type": "training",
      "description": "Training step 1717",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:40",
      "total_flops_so_far": 2468749432677492.0,
      "budget_used_percent": 2.468749432677492
    },
    {
      "type": "training",
      "description": "Training step 1718",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:40",
      "total_flops_so_far": 2470181584718964.0,
      "budget_used_percent": 2.470181584718964
    },
    {
      "type": "training",
      "description": "Training step 1719",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:41",
      "total_flops_so_far": 2471613736760436.0,
      "budget_used_percent": 2.471613736760436
    },
    {
      "type": "training",
      "description": "Training step 1720",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:41",
      "total_flops_so_far": 2473045888801908.0,
      "budget_used_percent": 2.473045888801908
    },
    {
      "type": "training",
      "description": "Training step 1721",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:41",
      "total_flops_so_far": 2474478040843380.0,
      "budget_used_percent": 2.47447804084338
    },
    {
      "type": "training",
      "description": "Training step 1722",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:41",
      "total_flops_so_far": 2475910192884852.0,
      "budget_used_percent": 2.475910192884852
    },
    {
      "type": "training",
      "description": "Training step 1723",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:41",
      "total_flops_so_far": 2477342344926324.0,
      "budget_used_percent": 2.477342344926324
    },
    {
      "type": "training",
      "description": "Training step 1724",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:41",
      "total_flops_so_far": 2478774496967796.0,
      "budget_used_percent": 2.478774496967796
    },
    {
      "type": "training",
      "description": "Training step 1725",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:41",
      "total_flops_so_far": 2480206649009268.0,
      "budget_used_percent": 2.480206649009268
    },
    {
      "type": "training",
      "description": "Training step 1726",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:42",
      "total_flops_so_far": 2481638801050740.0,
      "budget_used_percent": 2.4816388010507398
    },
    {
      "type": "training",
      "description": "Training step 1727",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:42",
      "total_flops_so_far": 2483070953092212.0,
      "budget_used_percent": 2.4830709530922124
    },
    {
      "type": "training",
      "description": "Training step 1728",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:42",
      "total_flops_so_far": 2484503105133684.0,
      "budget_used_percent": 2.484503105133684
    },
    {
      "type": "training",
      "description": "Training step 1729",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:42",
      "total_flops_so_far": 2485935257175156.0,
      "budget_used_percent": 2.485935257175156
    },
    {
      "type": "training",
      "description": "Training step 1730",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:42",
      "total_flops_so_far": 2487367409216628.0,
      "budget_used_percent": 2.487367409216628
    },
    {
      "type": "training",
      "description": "Training step 1731",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:42",
      "total_flops_so_far": 2488799561258100.0,
      "budget_used_percent": 2.4887995612580998
    },
    {
      "type": "training",
      "description": "Training step 1732",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:43",
      "total_flops_so_far": 2490231713299572.0,
      "budget_used_percent": 2.490231713299572
    },
    {
      "type": "training",
      "description": "Training step 1733",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:43",
      "total_flops_so_far": 2491663865341044.0,
      "budget_used_percent": 2.491663865341044
    },
    {
      "type": "training",
      "description": "Training step 1734",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:43",
      "total_flops_so_far": 2493096017382516.0,
      "budget_used_percent": 2.4930960173825163
    },
    {
      "type": "training",
      "description": "Training step 1735",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:43",
      "total_flops_so_far": 2494528169423988.0,
      "budget_used_percent": 2.494528169423988
    },
    {
      "type": "training",
      "description": "Training step 1736",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:43",
      "total_flops_so_far": 2495960321465460.0,
      "budget_used_percent": 2.49596032146546
    },
    {
      "type": "training",
      "description": "Training step 1737",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:43",
      "total_flops_so_far": 2497392473506932.0,
      "budget_used_percent": 2.497392473506932
    },
    {
      "type": "training",
      "description": "Training step 1738",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:43",
      "total_flops_so_far": 2498824625548404.0,
      "budget_used_percent": 2.4988246255484037
    },
    {
      "type": "training",
      "description": "Training step 1739",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:44",
      "total_flops_so_far": 2500256777589876.0,
      "budget_used_percent": 2.500256777589876
    },
    {
      "type": "training",
      "description": "Training step 1740",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:44",
      "total_flops_so_far": 2501688929631348.0,
      "budget_used_percent": 2.501688929631348
    },
    {
      "type": "training",
      "description": "Training step 1741",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:44",
      "total_flops_so_far": 2503121081672820.0,
      "budget_used_percent": 2.50312108167282
    },
    {
      "type": "training",
      "description": "Training step 1742",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:44",
      "total_flops_so_far": 2504553233714292.0,
      "budget_used_percent": 2.504553233714292
    },
    {
      "type": "training",
      "description": "Training step 1743",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:44",
      "total_flops_so_far": 2505985385755764.0,
      "budget_used_percent": 2.505985385755764
    },
    {
      "type": "training",
      "description": "Training step 1744",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:44",
      "total_flops_so_far": 2507417537797236.0,
      "budget_used_percent": 2.507417537797236
    },
    {
      "type": "training",
      "description": "Training step 1745",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:45",
      "total_flops_so_far": 2508849689838708.0,
      "budget_used_percent": 2.508849689838708
    },
    {
      "type": "training",
      "description": "Training step 1746",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:45",
      "total_flops_so_far": 2510281841880180.0,
      "budget_used_percent": 2.51028184188018
    },
    {
      "type": "training",
      "description": "Training step 1747",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:45",
      "total_flops_so_far": 2511713993921652.0,
      "budget_used_percent": 2.511713993921652
    },
    {
      "type": "training",
      "description": "Training step 1748",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:45",
      "total_flops_so_far": 2513146145963124.0,
      "budget_used_percent": 2.513146145963124
    },
    {
      "type": "training",
      "description": "Training step 1749",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:45",
      "total_flops_so_far": 2514578298004596.0,
      "budget_used_percent": 2.514578298004596
    },
    {
      "type": "training",
      "description": "Training step 1750",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:45",
      "total_flops_so_far": 2516010450046068.0,
      "budget_used_percent": 2.516010450046068
    },
    {
      "type": "training",
      "description": "Training step 1751",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:45",
      "total_flops_so_far": 2517442602087540.0,
      "budget_used_percent": 2.51744260208754
    },
    {
      "type": "training",
      "description": "Training step 1752",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:46",
      "total_flops_so_far": 2518874754129012.0,
      "budget_used_percent": 2.518874754129012
    },
    {
      "type": "training",
      "description": "Training step 1753",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:46",
      "total_flops_so_far": 2520306906170484.0,
      "budget_used_percent": 2.520306906170484
    },
    {
      "type": "training",
      "description": "Training step 1754",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:46",
      "total_flops_so_far": 2521739058211956.0,
      "budget_used_percent": 2.521739058211956
    },
    {
      "type": "training",
      "description": "Training step 1755",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:46",
      "total_flops_so_far": 2523171210253428.0,
      "budget_used_percent": 2.523171210253428
    },
    {
      "type": "training",
      "description": "Training step 1756",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:46",
      "total_flops_so_far": 2524603362294900.0,
      "budget_used_percent": 2.5246033622949
    },
    {
      "type": "training",
      "description": "Training step 1757",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:46",
      "total_flops_so_far": 2526035514336372.0,
      "budget_used_percent": 2.526035514336372
    },
    {
      "type": "training",
      "description": "Training step 1758",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:47",
      "total_flops_so_far": 2527467666377844.0,
      "budget_used_percent": 2.527467666377844
    },
    {
      "type": "training",
      "description": "Training step 1759",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:47",
      "total_flops_so_far": 2528899818419316.0,
      "budget_used_percent": 2.528899818419316
    },
    {
      "type": "training",
      "description": "Training step 1760",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:47",
      "total_flops_so_far": 2530331970460788.0,
      "budget_used_percent": 2.530331970460788
    },
    {
      "type": "training",
      "description": "Training step 1761",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:47",
      "total_flops_so_far": 2531764122502260.0,
      "budget_used_percent": 2.53176412250226
    },
    {
      "type": "training",
      "description": "Training step 1762",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:47",
      "total_flops_so_far": 2533196274543732.0,
      "budget_used_percent": 2.533196274543732
    },
    {
      "type": "training",
      "description": "Training step 1763",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:47",
      "total_flops_so_far": 2534628426585204.0,
      "budget_used_percent": 2.5346284265852037
    },
    {
      "type": "training",
      "description": "Training step 1764",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:47",
      "total_flops_so_far": 2536060578626676.0,
      "budget_used_percent": 2.5360605786266763
    },
    {
      "type": "training",
      "description": "Training step 1765",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:48",
      "total_flops_so_far": 2537492730668148.0,
      "budget_used_percent": 2.537492730668148
    },
    {
      "type": "training",
      "description": "Training step 1766",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:48",
      "total_flops_so_far": 2538924882709620.0,
      "budget_used_percent": 2.53892488270962
    },
    {
      "type": "training",
      "description": "Training step 1767",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:48",
      "total_flops_so_far": 2540357034751092.0,
      "budget_used_percent": 2.540357034751092
    },
    {
      "type": "training",
      "description": "Training step 1768",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:48",
      "total_flops_so_far": 2541789186792564.0,
      "budget_used_percent": 2.5417891867925637
    },
    {
      "type": "training",
      "description": "Training step 1769",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:48",
      "total_flops_so_far": 2543221338834036.0,
      "budget_used_percent": 2.543221338834036
    },
    {
      "type": "training",
      "description": "Training step 1770",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:48",
      "total_flops_so_far": 2544653490875508.0,
      "budget_used_percent": 2.544653490875508
    },
    {
      "type": "training",
      "description": "Training step 1771",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:49",
      "total_flops_so_far": 2546085642916980.0,
      "budget_used_percent": 2.5460856429169803
    },
    {
      "type": "training",
      "description": "Training step 1772",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:49",
      "total_flops_so_far": 2547517794958452.0,
      "budget_used_percent": 2.547517794958452
    },
    {
      "type": "training",
      "description": "Training step 1773",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:49",
      "total_flops_so_far": 2548949946999924.0,
      "budget_used_percent": 2.548949946999924
    },
    {
      "type": "training",
      "description": "Training step 1774",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:49",
      "total_flops_so_far": 2550382099041396.0,
      "budget_used_percent": 2.550382099041396
    },
    {
      "type": "training",
      "description": "Training step 1775",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:49",
      "total_flops_so_far": 2551814251082868.0,
      "budget_used_percent": 2.5518142510828676
    },
    {
      "type": "training",
      "description": "Training step 1776",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:49",
      "total_flops_so_far": 2553246403124340.0,
      "budget_used_percent": 2.5532464031243403
    },
    {
      "type": "training",
      "description": "Training step 1777",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:49",
      "total_flops_so_far": 2554678555165812.0,
      "budget_used_percent": 2.554678555165812
    },
    {
      "type": "training",
      "description": "Training step 1778",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:50",
      "total_flops_so_far": 2556110707207284.0,
      "budget_used_percent": 2.556110707207284
    },
    {
      "type": "training",
      "description": "Training step 1779",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:50",
      "total_flops_so_far": 2557542859248756.0,
      "budget_used_percent": 2.557542859248756
    },
    {
      "type": "training",
      "description": "Training step 1780",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:50",
      "total_flops_so_far": 2558975011290228.0,
      "budget_used_percent": 2.558975011290228
    },
    {
      "type": "training",
      "description": "Training step 1781",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:50",
      "total_flops_so_far": 2560407163331700.0,
      "budget_used_percent": 2.5604071633317
    },
    {
      "type": "training",
      "description": "Training step 1782",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:50",
      "total_flops_so_far": 2561839315373172.0,
      "budget_used_percent": 2.561839315373172
    },
    {
      "type": "training",
      "description": "Training step 1783",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:50",
      "total_flops_so_far": 2563271467414644.0,
      "budget_used_percent": 2.563271467414644
    },
    {
      "type": "training",
      "description": "Training step 1784",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:51",
      "total_flops_so_far": 2564703619456116.0,
      "budget_used_percent": 2.564703619456116
    },
    {
      "type": "training",
      "description": "Training step 1785",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:51",
      "total_flops_so_far": 2566135771497588.0,
      "budget_used_percent": 2.566135771497588
    },
    {
      "type": "training",
      "description": "Training step 1786",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:51",
      "total_flops_so_far": 2567567923539060.0,
      "budget_used_percent": 2.56756792353906
    },
    {
      "type": "training",
      "description": "Training step 1787",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:51",
      "total_flops_so_far": 2569000075580532.0,
      "budget_used_percent": 2.569000075580532
    },
    {
      "type": "training",
      "description": "Training step 1788",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:51",
      "total_flops_so_far": 2570432227622004.0,
      "budget_used_percent": 2.570432227622004
    },
    {
      "type": "training",
      "description": "Training step 1789",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:51",
      "total_flops_so_far": 2571864379663476.0,
      "budget_used_percent": 2.571864379663476
    },
    {
      "type": "training",
      "description": "Training step 1790",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:51",
      "total_flops_so_far": 2573296531704948.0,
      "budget_used_percent": 2.573296531704948
    },
    {
      "type": "training",
      "description": "Training step 1791",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:52",
      "total_flops_so_far": 2574728683746420.0,
      "budget_used_percent": 2.57472868374642
    },
    {
      "type": "training",
      "description": "Training step 1792",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:52",
      "total_flops_so_far": 2576160835787892.0,
      "budget_used_percent": 2.576160835787892
    },
    {
      "type": "training",
      "description": "Training step 1793",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:52",
      "total_flops_so_far": 2577592987829364.0,
      "budget_used_percent": 2.5775929878293637
    },
    {
      "type": "training",
      "description": "Training step 1794",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:52",
      "total_flops_so_far": 2579025139870836.0,
      "budget_used_percent": 2.5790251398708364
    },
    {
      "type": "training",
      "description": "Training step 1795",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:52",
      "total_flops_so_far": 2580457291912308.0,
      "budget_used_percent": 2.580457291912308
    },
    {
      "type": "training",
      "description": "Training step 1796",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:52",
      "total_flops_so_far": 2581889443953780.0,
      "budget_used_percent": 2.58188944395378
    },
    {
      "type": "training",
      "description": "Training step 1797",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:53",
      "total_flops_so_far": 2583321595995252.0,
      "budget_used_percent": 2.583321595995252
    },
    {
      "type": "training",
      "description": "Training step 1798",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:53",
      "total_flops_so_far": 2584753748036724.0,
      "budget_used_percent": 2.5847537480367238
    },
    {
      "type": "training",
      "description": "Training step 1799",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:53",
      "total_flops_so_far": 2586185900078196.0,
      "budget_used_percent": 2.586185900078196
    },
    {
      "type": "training",
      "description": "Training step 1800",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:53",
      "total_flops_so_far": 2587618052119668.0,
      "budget_used_percent": 2.587618052119668
    },
    {
      "type": "training",
      "description": "Training step 1801",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:53",
      "total_flops_so_far": 2589050204161140.0,
      "budget_used_percent": 2.5890502041611403
    },
    {
      "type": "training",
      "description": "Training step 1802",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:53",
      "total_flops_so_far": 2590482356202612.0,
      "budget_used_percent": 2.590482356202612
    },
    {
      "type": "training",
      "description": "Training step 1803",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:54",
      "total_flops_so_far": 2591914508244084.0,
      "budget_used_percent": 2.591914508244084
    },
    {
      "type": "training",
      "description": "Training step 1804",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:54",
      "total_flops_so_far": 2593346660285556.0,
      "budget_used_percent": 2.593346660285556
    },
    {
      "type": "training",
      "description": "Training step 1805",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:54",
      "total_flops_so_far": 2594778812327028.0,
      "budget_used_percent": 2.5947788123270277
    },
    {
      "type": "training",
      "description": "Training step 1806",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:54",
      "total_flops_so_far": 2596210964368500.0,
      "budget_used_percent": 2.5962109643685003
    },
    {
      "type": "training",
      "description": "Training step 1807",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:54",
      "total_flops_so_far": 2597643116409972.0,
      "budget_used_percent": 2.597643116409972
    },
    {
      "type": "training",
      "description": "Training step 1808",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:54",
      "total_flops_so_far": 2599075268451444.0,
      "budget_used_percent": 2.599075268451444
    },
    {
      "type": "training",
      "description": "Training step 1809",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:54",
      "total_flops_so_far": 2600507420492916.0,
      "budget_used_percent": 2.600507420492916
    },
    {
      "type": "training",
      "description": "Training step 1810",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:55",
      "total_flops_so_far": 2601939572534388.0,
      "budget_used_percent": 2.601939572534388
    },
    {
      "type": "training",
      "description": "Training step 1811",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:55",
      "total_flops_so_far": 2603371724575860.0,
      "budget_used_percent": 2.60337172457586
    },
    {
      "type": "training",
      "description": "Training step 1812",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:55",
      "total_flops_so_far": 2604803876617332.0,
      "budget_used_percent": 2.604803876617332
    },
    {
      "type": "training",
      "description": "Training step 1813",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:55",
      "total_flops_so_far": 2606236028658804.0,
      "budget_used_percent": 2.606236028658804
    },
    {
      "type": "training",
      "description": "Training step 1814",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:55",
      "total_flops_so_far": 2607668180700276.0,
      "budget_used_percent": 2.607668180700276
    },
    {
      "type": "training",
      "description": "Training step 1815",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:55",
      "total_flops_so_far": 2609100332741748.0,
      "budget_used_percent": 2.609100332741748
    },
    {
      "type": "training",
      "description": "Training step 1816",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:56",
      "total_flops_so_far": 2610532484783220.0,
      "budget_used_percent": 2.61053248478322
    },
    {
      "type": "training",
      "description": "Training step 1817",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:56",
      "total_flops_so_far": 2611964636824692.0,
      "budget_used_percent": 2.611964636824692
    },
    {
      "type": "training",
      "description": "Training step 1818",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:56",
      "total_flops_so_far": 2613396788866164.0,
      "budget_used_percent": 2.6133967888661638
    },
    {
      "type": "training",
      "description": "Training step 1819",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:56",
      "total_flops_so_far": 2614828940907636.0,
      "budget_used_percent": 2.614828940907636
    },
    {
      "type": "training",
      "description": "Training step 1820",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:56",
      "total_flops_so_far": 2616261092949108.0,
      "budget_used_percent": 2.616261092949108
    },
    {
      "type": "training",
      "description": "Training step 1821",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:56",
      "total_flops_so_far": 2617693244990580.0,
      "budget_used_percent": 2.61769324499058
    },
    {
      "type": "training",
      "description": "Training step 1822",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:56",
      "total_flops_so_far": 2619125397032052.0,
      "budget_used_percent": 2.619125397032052
    },
    {
      "type": "training",
      "description": "Training step 1823",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:57",
      "total_flops_so_far": 2620557549073524.0,
      "budget_used_percent": 2.620557549073524
    },
    {
      "type": "training",
      "description": "Training step 1824",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:57",
      "total_flops_so_far": 2621989701114996.0,
      "budget_used_percent": 2.621989701114996
    },
    {
      "type": "training",
      "description": "Training step 1825",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:57",
      "total_flops_so_far": 2623421853156468.0,
      "budget_used_percent": 2.623421853156468
    },
    {
      "type": "training",
      "description": "Training step 1826",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:57",
      "total_flops_so_far": 2624854005197940.0,
      "budget_used_percent": 2.62485400519794
    },
    {
      "type": "training",
      "description": "Training step 1827",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:57",
      "total_flops_so_far": 2626286157239412.0,
      "budget_used_percent": 2.626286157239412
    },
    {
      "type": "training",
      "description": "Training step 1828",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:57",
      "total_flops_so_far": 2627718309280884.0,
      "budget_used_percent": 2.627718309280884
    },
    {
      "type": "training",
      "description": "Training step 1829",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:58",
      "total_flops_so_far": 2629150461322356.0,
      "budget_used_percent": 2.629150461322356
    },
    {
      "type": "training",
      "description": "Training step 1830",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:58",
      "total_flops_so_far": 2630582613363828.0,
      "budget_used_percent": 2.6305826133638277
    },
    {
      "type": "training",
      "description": "Training step 1831",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:58",
      "total_flops_so_far": 2632014765405300.0,
      "budget_used_percent": 2.6320147654053003
    },
    {
      "type": "training",
      "description": "Training step 1832",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:58",
      "total_flops_so_far": 2633446917446772.0,
      "budget_used_percent": 2.633446917446772
    },
    {
      "type": "training",
      "description": "Training step 1833",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:58",
      "total_flops_so_far": 2634879069488244.0,
      "budget_used_percent": 2.6348790694882442
    },
    {
      "type": "training",
      "description": "Training step 1834",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:58",
      "total_flops_so_far": 2636311221529716.0,
      "budget_used_percent": 2.636311221529716
    },
    {
      "type": "training",
      "description": "Training step 1835",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:58",
      "total_flops_so_far": 2637743373571188.0,
      "budget_used_percent": 2.6377433735711877
    },
    {
      "type": "training",
      "description": "Training step 1836",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:59",
      "total_flops_so_far": 2639175525612660.0,
      "budget_used_percent": 2.63917552561266
    },
    {
      "type": "training",
      "description": "Training step 1837",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:59",
      "total_flops_so_far": 2640607677654132.0,
      "budget_used_percent": 2.640607677654132
    },
    {
      "type": "training",
      "description": "Training step 1838",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:59",
      "total_flops_so_far": 2642039829695604.0,
      "budget_used_percent": 2.6420398296956042
    },
    {
      "type": "training",
      "description": "Training step 1839",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:59",
      "total_flops_so_far": 2643471981737076.0,
      "budget_used_percent": 2.643471981737076
    },
    {
      "type": "training",
      "description": "Training step 1840",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:59",
      "total_flops_so_far": 2644904133778548.0,
      "budget_used_percent": 2.644904133778548
    },
    {
      "type": "training",
      "description": "Training step 1841",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:47:59",
      "total_flops_so_far": 2646336285820020.0,
      "budget_used_percent": 2.64633628582002
    },
    {
      "type": "training",
      "description": "Training step 1842",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:00",
      "total_flops_so_far": 2647768437861492.0,
      "budget_used_percent": 2.647768437861492
    },
    {
      "type": "training",
      "description": "Training step 1843",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:00",
      "total_flops_so_far": 2649200589902964.0,
      "budget_used_percent": 2.6492005899029643
    },
    {
      "type": "training",
      "description": "Training step 1844",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:00",
      "total_flops_so_far": 2650632741944436.0,
      "budget_used_percent": 2.650632741944436
    },
    {
      "type": "training",
      "description": "Training step 1845",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:00",
      "total_flops_so_far": 2652064893985908.0,
      "budget_used_percent": 2.652064893985908
    },
    {
      "type": "training",
      "description": "Training step 1846",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:00",
      "total_flops_so_far": 2653497046027380.0,
      "budget_used_percent": 2.65349704602738
    },
    {
      "type": "training",
      "description": "Training step 1847",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:00",
      "total_flops_so_far": 2654929198068852.0,
      "budget_used_percent": 2.654929198068852
    },
    {
      "type": "training",
      "description": "Training step 1848",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:00",
      "total_flops_so_far": 2656361350110324.0,
      "budget_used_percent": 2.656361350110324
    },
    {
      "type": "training",
      "description": "Training step 1849",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:01",
      "total_flops_so_far": 2657793502151796.0,
      "budget_used_percent": 2.657793502151796
    },
    {
      "type": "training",
      "description": "Training step 1850",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:01",
      "total_flops_so_far": 2659225654193268.0,
      "budget_used_percent": 2.659225654193268
    },
    {
      "type": "training",
      "description": "Training step 1851",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:01",
      "total_flops_so_far": 2660657806234740.0,
      "budget_used_percent": 2.66065780623474
    },
    {
      "type": "training",
      "description": "Training step 1852",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:01",
      "total_flops_so_far": 2662089958276212.0,
      "budget_used_percent": 2.662089958276212
    },
    {
      "type": "training",
      "description": "Training step 1853",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:01",
      "total_flops_so_far": 2663522110317684.0,
      "budget_used_percent": 2.663522110317684
    },
    {
      "type": "training",
      "description": "Training step 1854",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:02",
      "total_flops_so_far": 2664954262359156.0,
      "budget_used_percent": 2.664954262359156
    },
    {
      "type": "training",
      "description": "Training step 1855",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:02",
      "total_flops_so_far": 2666386414400628.0,
      "budget_used_percent": 2.666386414400628
    },
    {
      "type": "training",
      "description": "Training step 1856",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:02",
      "total_flops_so_far": 2667818566442100.0,
      "budget_used_percent": 2.6678185664421
    },
    {
      "type": "training",
      "description": "Training step 1857",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:02",
      "total_flops_so_far": 2669250718483572.0,
      "budget_used_percent": 2.669250718483572
    },
    {
      "type": "training",
      "description": "Training step 1858",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:02",
      "total_flops_so_far": 2670682870525044.0,
      "budget_used_percent": 2.670682870525044
    },
    {
      "type": "training",
      "description": "Training step 1859",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:02",
      "total_flops_so_far": 2672115022566516.0,
      "budget_used_percent": 2.672115022566516
    },
    {
      "type": "training",
      "description": "Training step 1860",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:03",
      "total_flops_so_far": 2673547174607988.0,
      "budget_used_percent": 2.6735471746079877
    },
    {
      "type": "training",
      "description": "Training step 1861",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:03",
      "total_flops_so_far": 2674979326649460.0,
      "budget_used_percent": 2.6749793266494604
    },
    {
      "type": "training",
      "description": "Training step 1862",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:03",
      "total_flops_so_far": 2676411478690932.0,
      "budget_used_percent": 2.676411478690932
    },
    {
      "type": "training",
      "description": "Training step 1863",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:03",
      "total_flops_so_far": 2677843630732404.0,
      "budget_used_percent": 2.677843630732404
    },
    {
      "type": "training",
      "description": "Training step 1864",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:03",
      "total_flops_so_far": 2679275782773876.0,
      "budget_used_percent": 2.679275782773876
    },
    {
      "type": "training",
      "description": "Training step 1865",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:03",
      "total_flops_so_far": 2680707934815348.0,
      "budget_used_percent": 2.6807079348153477
    },
    {
      "type": "training",
      "description": "Training step 1866",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:03",
      "total_flops_so_far": 2682140086856820.0,
      "budget_used_percent": 2.68214008685682
    },
    {
      "type": "training",
      "description": "Training step 1867",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:04",
      "total_flops_so_far": 2683572238898292.0,
      "budget_used_percent": 2.683572238898292
    },
    {
      "type": "training",
      "description": "Training step 1868",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:04",
      "total_flops_so_far": 2685004390939764.0,
      "budget_used_percent": 2.6850043909397643
    },
    {
      "type": "training",
      "description": "Training step 1869",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:04",
      "total_flops_so_far": 2686436542981236.0,
      "budget_used_percent": 2.686436542981236
    },
    {
      "type": "training",
      "description": "Training step 1870",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:04",
      "total_flops_so_far": 2687868695022708.0,
      "budget_used_percent": 2.687868695022708
    },
    {
      "type": "training",
      "description": "Training step 1871",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:04",
      "total_flops_so_far": 2689300847064180.0,
      "budget_used_percent": 2.68930084706418
    },
    {
      "type": "training",
      "description": "Training step 1872",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:04",
      "total_flops_so_far": 2690732999105652.0,
      "budget_used_percent": 2.6907329991056517
    },
    {
      "type": "training",
      "description": "Training step 1873",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:05",
      "total_flops_so_far": 2692165151147124.0,
      "budget_used_percent": 2.6921651511471243
    },
    {
      "type": "training",
      "description": "Training step 1874",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:05",
      "total_flops_so_far": 2693597303188596.0,
      "budget_used_percent": 2.693597303188596
    },
    {
      "type": "training",
      "description": "Training step 1875",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:05",
      "total_flops_so_far": 2695029455230068.0,
      "budget_used_percent": 2.695029455230068
    },
    {
      "type": "training",
      "description": "Training step 1876",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:05",
      "total_flops_so_far": 2696461607271540.0,
      "budget_used_percent": 2.69646160727154
    },
    {
      "type": "training",
      "description": "Training step 1877",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:05",
      "total_flops_so_far": 2697893759313012.0,
      "budget_used_percent": 2.697893759313012
    },
    {
      "type": "training",
      "description": "Training step 1878",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:05",
      "total_flops_so_far": 2699325911354484.0,
      "budget_used_percent": 2.699325911354484
    },
    {
      "type": "training",
      "description": "Training step 1879",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:06",
      "total_flops_so_far": 2700758063395956.0,
      "budget_used_percent": 2.700758063395956
    },
    {
      "type": "training",
      "description": "Training step 1880",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:06",
      "total_flops_so_far": 2702190215437428.0,
      "budget_used_percent": 2.702190215437428
    },
    {
      "type": "training",
      "description": "Training step 1881",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:06",
      "total_flops_so_far": 2703622367478900.0,
      "budget_used_percent": 2.7036223674789
    },
    {
      "type": "training",
      "description": "Training step 1882",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:06",
      "total_flops_so_far": 2705054519520372.0,
      "budget_used_percent": 2.705054519520372
    },
    {
      "type": "training",
      "description": "Training step 1883",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:06",
      "total_flops_so_far": 2706486671561844.0,
      "budget_used_percent": 2.706486671561844
    },
    {
      "type": "training",
      "description": "Training step 1884",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:06",
      "total_flops_so_far": 2707918823603316.0,
      "budget_used_percent": 2.707918823603316
    },
    {
      "type": "training",
      "description": "Training step 1885",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:06",
      "total_flops_so_far": 2709350975644788.0,
      "budget_used_percent": 2.7093509756447878
    },
    {
      "type": "training",
      "description": "Training step 1886",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:07",
      "total_flops_so_far": 2710783127686260.0,
      "budget_used_percent": 2.71078312768626
    },
    {
      "type": "training",
      "description": "Training step 1887",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:07",
      "total_flops_so_far": 2712215279727732.0,
      "budget_used_percent": 2.712215279727732
    },
    {
      "type": "training",
      "description": "Training step 1888",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:07",
      "total_flops_so_far": 2713647431769204.0,
      "budget_used_percent": 2.713647431769204
    },
    {
      "type": "training",
      "description": "Training step 1889",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:07",
      "total_flops_so_far": 2715079583810676.0,
      "budget_used_percent": 2.715079583810676
    },
    {
      "type": "training",
      "description": "Training step 1890",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:07",
      "total_flops_so_far": 2716511735852148.0,
      "budget_used_percent": 2.716511735852148
    },
    {
      "type": "training",
      "description": "Training step 1891",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:07",
      "total_flops_so_far": 2717943887893620.0,
      "budget_used_percent": 2.71794388789362
    },
    {
      "type": "training",
      "description": "Training step 1892",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:08",
      "total_flops_so_far": 2719376039935092.0,
      "budget_used_percent": 2.719376039935092
    },
    {
      "type": "training",
      "description": "Training step 1893",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:08",
      "total_flops_so_far": 2720808191976564.0,
      "budget_used_percent": 2.720808191976564
    },
    {
      "type": "training",
      "description": "Training step 1894",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:08",
      "total_flops_so_far": 2722240344018036.0,
      "budget_used_percent": 2.722240344018036
    },
    {
      "type": "training",
      "description": "Training step 1895",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:08",
      "total_flops_so_far": 2723672496059508.0,
      "budget_used_percent": 2.723672496059508
    },
    {
      "type": "training",
      "description": "Training step 1896",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:08",
      "total_flops_so_far": 2725104648100980.0,
      "budget_used_percent": 2.72510464810098
    },
    {
      "type": "training",
      "description": "Training step 1897",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:08",
      "total_flops_so_far": 2726536800142452.0,
      "budget_used_percent": 2.7265368001424517
    },
    {
      "type": "training",
      "description": "Training step 1898",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:08",
      "total_flops_so_far": 2727968952183924.0,
      "budget_used_percent": 2.7279689521839243
    },
    {
      "type": "training",
      "description": "Training step 1899",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:09",
      "total_flops_so_far": 2729401104225396.0,
      "budget_used_percent": 2.729401104225396
    },
    {
      "type": "training",
      "description": "Training step 1900",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:09",
      "total_flops_so_far": 2730833256266868.0,
      "budget_used_percent": 2.730833256266868
    },
    {
      "type": "training",
      "description": "Training step 1901",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:09",
      "total_flops_so_far": 2732265408308340.0,
      "budget_used_percent": 2.73226540830834
    },
    {
      "type": "training",
      "description": "Training step 1902",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:09",
      "total_flops_so_far": 2733697560349812.0,
      "budget_used_percent": 2.7336975603498117
    },
    {
      "type": "training",
      "description": "Training step 1903",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:09",
      "total_flops_so_far": 2735129712391284.0,
      "budget_used_percent": 2.735129712391284
    },
    {
      "type": "training",
      "description": "Training step 1904",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:09",
      "total_flops_so_far": 2736561864432756.0,
      "budget_used_percent": 2.736561864432756
    },
    {
      "type": "training",
      "description": "Training step 1905",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:10",
      "total_flops_so_far": 2737994016474228.0,
      "budget_used_percent": 2.7379940164742282
    },
    {
      "type": "training",
      "description": "Training step 1906",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:10",
      "total_flops_so_far": 2739426168515700.0,
      "budget_used_percent": 2.7394261685157
    },
    {
      "type": "training",
      "description": "Training step 1907",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:10",
      "total_flops_so_far": 2740858320557172.0,
      "budget_used_percent": 2.740858320557172
    },
    {
      "type": "training",
      "description": "Training step 1908",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:10",
      "total_flops_so_far": 2742290472598644.0,
      "budget_used_percent": 2.742290472598644
    },
    {
      "type": "training",
      "description": "Training step 1909",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:10",
      "total_flops_so_far": 2743722624640116.0,
      "budget_used_percent": 2.7437226246401156
    },
    {
      "type": "training",
      "description": "Training step 1910",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:10",
      "total_flops_so_far": 2745154776681588.0,
      "budget_used_percent": 2.7451547766815882
    },
    {
      "type": "training",
      "description": "Training step 1911",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:11",
      "total_flops_so_far": 2746586928723060.0,
      "budget_used_percent": 2.74658692872306
    },
    {
      "type": "training",
      "description": "Training step 1912",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:11",
      "total_flops_so_far": 2748019080764532.0,
      "budget_used_percent": 2.748019080764532
    },
    {
      "type": "training",
      "description": "Training step 1913",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:11",
      "total_flops_so_far": 2749451232806004.0,
      "budget_used_percent": 2.749451232806004
    },
    {
      "type": "training",
      "description": "Training step 1914",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:11",
      "total_flops_so_far": 2750883384847476.0,
      "budget_used_percent": 2.750883384847476
    },
    {
      "type": "training",
      "description": "Training step 1915",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:11",
      "total_flops_so_far": 2752315536888948.0,
      "budget_used_percent": 2.752315536888948
    },
    {
      "type": "training",
      "description": "Training step 1916",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:11",
      "total_flops_so_far": 2753747688930420.0,
      "budget_used_percent": 2.75374768893042
    },
    {
      "type": "training",
      "description": "Training step 1917",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:12",
      "total_flops_so_far": 2755179840971892.0,
      "budget_used_percent": 2.755179840971892
    },
    {
      "type": "training",
      "description": "Training step 1918",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:12",
      "total_flops_so_far": 2756611993013364.0,
      "budget_used_percent": 2.756611993013364
    },
    {
      "type": "training",
      "description": "Training step 1919",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:12",
      "total_flops_so_far": 2758044145054836.0,
      "budget_used_percent": 2.758044145054836
    },
    {
      "type": "training",
      "description": "Training step 1920",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:12",
      "total_flops_so_far": 2759476297096308.0,
      "budget_used_percent": 2.759476297096308
    },
    {
      "type": "training",
      "description": "Training step 1921",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:12",
      "total_flops_so_far": 2760908449137780.0,
      "budget_used_percent": 2.76090844913778
    },
    {
      "type": "training",
      "description": "Training step 1922",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:12",
      "total_flops_so_far": 2762340601179252.0,
      "budget_used_percent": 2.762340601179252
    },
    {
      "type": "training",
      "description": "Training step 1923",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:12",
      "total_flops_so_far": 2763772753220724.0,
      "budget_used_percent": 2.763772753220724
    },
    {
      "type": "training",
      "description": "Training step 1924",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:13",
      "total_flops_so_far": 2765204905262196.0,
      "budget_used_percent": 2.765204905262196
    },
    {
      "type": "training",
      "description": "Training step 1925",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:13",
      "total_flops_so_far": 2766637057303668.0,
      "budget_used_percent": 2.766637057303668
    },
    {
      "type": "training",
      "description": "Training step 1926",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:13",
      "total_flops_so_far": 2768069209345140.0,
      "budget_used_percent": 2.76806920934514
    },
    {
      "type": "training",
      "description": "Training step 1927",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:13",
      "total_flops_so_far": 2769501361386612.0,
      "budget_used_percent": 2.7695013613866117
    },
    {
      "type": "training",
      "description": "Training step 1928",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:13",
      "total_flops_so_far": 2770933513428084.0,
      "budget_used_percent": 2.7709335134280844
    },
    {
      "type": "training",
      "description": "Training step 1929",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:13",
      "total_flops_so_far": 2772365665469556.0,
      "budget_used_percent": 2.772365665469556
    },
    {
      "type": "training",
      "description": "Training step 1930",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:14",
      "total_flops_so_far": 2773797817511028.0,
      "budget_used_percent": 2.773797817511028
    },
    {
      "type": "training",
      "description": "Training step 1931",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:14",
      "total_flops_so_far": 2775229969552500.0,
      "budget_used_percent": 2.7752299695525
    },
    {
      "type": "training",
      "description": "Training step 1932",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:14",
      "total_flops_so_far": 2776662121593972.0,
      "budget_used_percent": 2.7766621215939717
    },
    {
      "type": "training",
      "description": "Training step 1933",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:14",
      "total_flops_so_far": 2778094273635444.0,
      "budget_used_percent": 2.778094273635444
    },
    {
      "type": "training",
      "description": "Training step 1934",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:14",
      "total_flops_so_far": 2779526425676916.0,
      "budget_used_percent": 2.779526425676916
    },
    {
      "type": "training",
      "description": "Training step 1935",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:14",
      "total_flops_so_far": 2780958577718388.0,
      "budget_used_percent": 2.7809585777183883
    },
    {
      "type": "training",
      "description": "Training step 1936",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:15",
      "total_flops_so_far": 2782390729759860.0,
      "budget_used_percent": 2.78239072975986
    },
    {
      "type": "training",
      "description": "Training step 1937",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:15",
      "total_flops_so_far": 2783822881801332.0,
      "budget_used_percent": 2.783822881801332
    },
    {
      "type": "training",
      "description": "Training step 1938",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:15",
      "total_flops_so_far": 2785255033842804.0,
      "budget_used_percent": 2.785255033842804
    },
    {
      "type": "training",
      "description": "Training step 1939",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:15",
      "total_flops_so_far": 2786687185884276.0,
      "budget_used_percent": 2.7866871858842757
    },
    {
      "type": "training",
      "description": "Training step 1940",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:15",
      "total_flops_so_far": 2788119337925748.0,
      "budget_used_percent": 2.7881193379257483
    },
    {
      "type": "training",
      "description": "Training step 1941",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:15",
      "total_flops_so_far": 2789551489967220.0,
      "budget_used_percent": 2.78955148996722
    },
    {
      "type": "training",
      "description": "Training step 1942",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:15",
      "total_flops_so_far": 2790983642008692.0,
      "budget_used_percent": 2.790983642008692
    },
    {
      "type": "training",
      "description": "Training step 1943",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:16",
      "total_flops_so_far": 2792415794050164.0,
      "budget_used_percent": 2.792415794050164
    },
    {
      "type": "training",
      "description": "Training step 1944",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:16",
      "total_flops_so_far": 2793847946091636.0,
      "budget_used_percent": 2.793847946091636
    },
    {
      "type": "training",
      "description": "Training step 1945",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:16",
      "total_flops_so_far": 2795280098133108.0,
      "budget_used_percent": 2.795280098133108
    },
    {
      "type": "training",
      "description": "Training step 1946",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:16",
      "total_flops_so_far": 2796712250174580.0,
      "budget_used_percent": 2.79671225017458
    },
    {
      "type": "training",
      "description": "Training step 1947",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:16",
      "total_flops_so_far": 2798144402216052.0,
      "budget_used_percent": 2.798144402216052
    },
    {
      "type": "training",
      "description": "Training step 1948",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:16",
      "total_flops_so_far": 2799576554257524.0,
      "budget_used_percent": 2.799576554257524
    },
    {
      "type": "training",
      "description": "Training step 1949",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:17",
      "total_flops_so_far": 2801008706298996.0,
      "budget_used_percent": 2.801008706298996
    },
    {
      "type": "training",
      "description": "Training step 1950",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:17",
      "total_flops_so_far": 2802440858340468.0,
      "budget_used_percent": 2.802440858340468
    },
    {
      "type": "training",
      "description": "Training step 1951",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:17",
      "total_flops_so_far": 2803873010381940.0,
      "budget_used_percent": 2.80387301038194
    },
    {
      "type": "training",
      "description": "Training step 1952",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:17",
      "total_flops_so_far": 2805305162423412.0,
      "budget_used_percent": 2.805305162423412
    },
    {
      "type": "training",
      "description": "Training step 1953",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:17",
      "total_flops_so_far": 2806737314464884.0,
      "budget_used_percent": 2.806737314464884
    },
    {
      "type": "training",
      "description": "Training step 1954",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:17",
      "total_flops_so_far": 2808169466506356.0,
      "budget_used_percent": 2.808169466506356
    },
    {
      "type": "training",
      "description": "Training step 1955",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:18",
      "total_flops_so_far": 2809601618547828.0,
      "budget_used_percent": 2.809601618547828
    },
    {
      "type": "training",
      "description": "Training step 1956",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:18",
      "total_flops_so_far": 2811033770589300.0,
      "budget_used_percent": 2.8110337705893
    },
    {
      "type": "training",
      "description": "Training step 1957",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:18",
      "total_flops_so_far": 2812465922630772.0,
      "budget_used_percent": 2.8124659226307718
    },
    {
      "type": "training",
      "description": "Training step 1958",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:18",
      "total_flops_so_far": 2813898074672244.0,
      "budget_used_percent": 2.813898074672244
    },
    {
      "type": "training",
      "description": "Training step 1959",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:18",
      "total_flops_so_far": 2815330226713716.0,
      "budget_used_percent": 2.815330226713716
    },
    {
      "type": "training",
      "description": "Training step 1960",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:18",
      "total_flops_so_far": 2816762378755188.0,
      "budget_used_percent": 2.816762378755188
    },
    {
      "type": "training",
      "description": "Training step 1961",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:18",
      "total_flops_so_far": 2818194530796660.0,
      "budget_used_percent": 2.81819453079666
    },
    {
      "type": "training",
      "description": "Training step 1962",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:19",
      "total_flops_so_far": 2819626682838132.0,
      "budget_used_percent": 2.819626682838132
    },
    {
      "type": "training",
      "description": "Training step 1963",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:19",
      "total_flops_so_far": 2821058834879604.0,
      "budget_used_percent": 2.821058834879604
    },
    {
      "type": "training",
      "description": "Training step 1964",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:19",
      "total_flops_so_far": 2822490986921076.0,
      "budget_used_percent": 2.8224909869210757
    },
    {
      "type": "training",
      "description": "Training step 1965",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:19",
      "total_flops_so_far": 2823923138962548.0,
      "budget_used_percent": 2.8239231389625483
    },
    {
      "type": "training",
      "description": "Training step 1966",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:19",
      "total_flops_so_far": 2825355291004020.0,
      "budget_used_percent": 2.82535529100402
    },
    {
      "type": "training",
      "description": "Training step 1967",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:19",
      "total_flops_so_far": 2826787443045492.0,
      "budget_used_percent": 2.8267874430454922
    },
    {
      "type": "training",
      "description": "Training step 1968",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:20",
      "total_flops_so_far": 2828219595086964.0,
      "budget_used_percent": 2.828219595086964
    },
    {
      "type": "training",
      "description": "Training step 1969",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:20",
      "total_flops_so_far": 2829651747128436.0,
      "budget_used_percent": 2.8296517471284357
    },
    {
      "type": "training",
      "description": "Training step 1970",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:20",
      "total_flops_so_far": 2831083899169908.0,
      "budget_used_percent": 2.831083899169908
    },
    {
      "type": "training",
      "description": "Training step 1971",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:20",
      "total_flops_so_far": 2832516051211380.0,
      "budget_used_percent": 2.83251605121138
    },
    {
      "type": "training",
      "description": "Training step 1972",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:20",
      "total_flops_so_far": 2833948203252852.0,
      "budget_used_percent": 2.8339482032528522
    },
    {
      "type": "training",
      "description": "Training step 1973",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:20",
      "total_flops_so_far": 2835380355294324.0,
      "budget_used_percent": 2.835380355294324
    },
    {
      "type": "training",
      "description": "Training step 1974",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:21",
      "total_flops_so_far": 2836812507335796.0,
      "budget_used_percent": 2.836812507335796
    },
    {
      "type": "training",
      "description": "Training step 1975",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:21",
      "total_flops_so_far": 2838244659377268.0,
      "budget_used_percent": 2.838244659377268
    },
    {
      "type": "training",
      "description": "Training step 1976",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:21",
      "total_flops_so_far": 2839676811418740.0,
      "budget_used_percent": 2.83967681141874
    },
    {
      "type": "training",
      "description": "Training step 1977",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:21",
      "total_flops_so_far": 2841108963460212.0,
      "budget_used_percent": 2.8411089634602122
    },
    {
      "type": "training",
      "description": "Training step 1978",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:21",
      "total_flops_so_far": 2842541115501684.0,
      "budget_used_percent": 2.842541115501684
    },
    {
      "type": "training",
      "description": "Training step 1979",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:21",
      "total_flops_so_far": 2843973267543156.0,
      "budget_used_percent": 2.843973267543156
    },
    {
      "type": "training",
      "description": "Training step 1980",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:22",
      "total_flops_so_far": 2845405419584628.0,
      "budget_used_percent": 2.845405419584628
    },
    {
      "type": "training",
      "description": "Training step 1981",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:22",
      "total_flops_so_far": 2846837571626100.0,
      "budget_used_percent": 2.8468375716261
    },
    {
      "type": "training",
      "description": "Training step 1982",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:22",
      "total_flops_so_far": 2848269723667572.0,
      "budget_used_percent": 2.848269723667572
    },
    {
      "type": "training",
      "description": "Training step 1983",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:22",
      "total_flops_so_far": 2849701875709044.0,
      "budget_used_percent": 2.849701875709044
    },
    {
      "type": "training",
      "description": "Training step 1984",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:22",
      "total_flops_so_far": 2851134027750516.0,
      "budget_used_percent": 2.851134027750516
    },
    {
      "type": "training",
      "description": "Training step 1985",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:22",
      "total_flops_so_far": 2852566179791988.0,
      "budget_used_percent": 2.852566179791988
    },
    {
      "type": "training",
      "description": "Training step 1986",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:22",
      "total_flops_so_far": 2853998331833460.0,
      "budget_used_percent": 2.85399833183346
    },
    {
      "type": "training",
      "description": "Training step 1987",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:23",
      "total_flops_so_far": 2855430483874932.0,
      "budget_used_percent": 2.855430483874932
    },
    {
      "type": "training",
      "description": "Training step 1988",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:23",
      "total_flops_so_far": 2856862635916404.0,
      "budget_used_percent": 2.856862635916404
    },
    {
      "type": "training",
      "description": "Training step 1989",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:23",
      "total_flops_so_far": 2858294787957876.0,
      "budget_used_percent": 2.858294787957876
    },
    {
      "type": "training",
      "description": "Training step 1990",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:23",
      "total_flops_so_far": 2859726939999348.0,
      "budget_used_percent": 2.859726939999348
    },
    {
      "type": "training",
      "description": "Training step 1991",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:23",
      "total_flops_so_far": 2861159092040820.0,
      "budget_used_percent": 2.86115909204082
    },
    {
      "type": "training",
      "description": "Training step 1992",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:23",
      "total_flops_so_far": 2862591244082292.0,
      "budget_used_percent": 2.862591244082292
    },
    {
      "type": "training",
      "description": "Training step 1993",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:24",
      "total_flops_so_far": 2864023396123764.0,
      "budget_used_percent": 2.864023396123764
    },
    {
      "type": "training",
      "description": "Training step 1994",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:24",
      "total_flops_so_far": 2865455548165236.0,
      "budget_used_percent": 2.8654555481652357
    },
    {
      "type": "training",
      "description": "Training step 1995",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:24",
      "total_flops_so_far": 2866887700206708.0,
      "budget_used_percent": 2.8668877002067084
    },
    {
      "type": "training",
      "description": "Training step 1996",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:24",
      "total_flops_so_far": 2868319852248180.0,
      "budget_used_percent": 2.86831985224818
    },
    {
      "type": "training",
      "description": "Training step 1997",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:24",
      "total_flops_so_far": 2869752004289652.0,
      "budget_used_percent": 2.869752004289652
    },
    {
      "type": "training",
      "description": "Training step 1998",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:25",
      "total_flops_so_far": 2871184156331124.0,
      "budget_used_percent": 2.871184156331124
    },
    {
      "type": "training",
      "description": "Training step 1999",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477384013824.0,
      "backward_flops": 954768027648.0,
      "flops": 1432152041472.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:25",
      "total_flops_so_far": 2872616308372596.0,
      "budget_used_percent": 2.8726163083725957
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 0",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552526568288.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:26",
      "total_flops_so_far": 2873168834940884.0,
      "budget_used_percent": 2.873168834940884
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 1",
      "context_len": 604,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 556130834256.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:27",
      "total_flops_so_far": 2873724965775140.0,
      "budget_used_percent": 2.87372496577514
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 2",
      "context_len": 602,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 554328341080.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:29",
      "total_flops_so_far": 2874279294116220.0,
      "budget_used_percent": 2.87427929411622
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 3",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552526568288.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:30",
      "total_flops_so_far": 2874831820684508.0,
      "budget_used_percent": 2.8748318206845083
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 4",
      "context_len": 603,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 555229497620.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:31",
      "total_flops_so_far": 2875387050182128.0,
      "budget_used_percent": 2.875387050182128
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 0",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552526568288.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:33",
      "total_flops_so_far": 2875939576750416.0,
      "budget_used_percent": 2.875939576750416
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 1",
      "context_len": 604,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 556130834256.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:34",
      "total_flops_so_far": 2876495707584672.0,
      "budget_used_percent": 2.876495707584672
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 2",
      "context_len": 602,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 554328341080.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:36",
      "total_flops_so_far": 2877050035925752.0,
      "budget_used_percent": 2.8770500359257523
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 3",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552526568288.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:37",
      "total_flops_so_far": 2877602562494040.0,
      "budget_used_percent": 2.8776025624940402
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 4",
      "context_len": 603,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 555229497620.0,
      "lora_r": 8,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:48:38",
      "total_flops_so_far": 2878157791991660.0,
      "budget_used_percent": 2.87815779199166
    }
  ],
  "total_flops": 2878157791991660.0,
  "budget_used_percent": 2.87815779199166
}