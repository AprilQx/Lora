{
  "experiment_name": "lr1e-04_rank4",
  "model_config": {
    "hidden_size": 896,
    "num_attention_heads": 14,
    "num_hidden_layers": 24,
    "intermediate_size": 4864,
    "head_dim": 64,
    "vocab_size": 151936,
    "lora_r": 4,
    "lora_target_modules": [
      "q_proj",
      "v_proj"
    ]
  },
  "max_budget": 1e+17,
  "start_time": "2025-03-23 14:38:02",
  "operations": [
    {
      "type": "training",
      "description": "Training step 0",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:05",
      "total_flops_so_far": 1431095371776.0,
      "budget_used_percent": 0.001431095371776
    },
    {
      "type": "training",
      "description": "Training step 1",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:05",
      "total_flops_so_far": 2862190743552.0,
      "budget_used_percent": 0.002862190743552
    },
    {
      "type": "training",
      "description": "Training step 2",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:06",
      "total_flops_so_far": 4293286115328.0,
      "budget_used_percent": 0.004293286115328
    },
    {
      "type": "training",
      "description": "Training step 3",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:06",
      "total_flops_so_far": 5724381487104.0,
      "budget_used_percent": 0.005724381487104
    },
    {
      "type": "training",
      "description": "Training step 4",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:06",
      "total_flops_so_far": 7155476858880.0,
      "budget_used_percent": 0.00715547685888
    },
    {
      "type": "training",
      "description": "Training step 5",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:06",
      "total_flops_so_far": 8586572230656.0,
      "budget_used_percent": 0.008586572230656
    },
    {
      "type": "training",
      "description": "Training step 6",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:06",
      "total_flops_so_far": 10017667602432.0,
      "budget_used_percent": 0.010017667602432001
    },
    {
      "type": "training",
      "description": "Training step 7",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:06",
      "total_flops_so_far": 11448762974208.0,
      "budget_used_percent": 0.011448762974208
    },
    {
      "type": "training",
      "description": "Training step 8",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:06",
      "total_flops_so_far": 12879858345984.0,
      "budget_used_percent": 0.012879858345984
    },
    {
      "type": "training",
      "description": "Training step 9",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:06",
      "total_flops_so_far": 14310953717760.0,
      "budget_used_percent": 0.01431095371776
    },
    {
      "type": "training",
      "description": "Training step 10",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:06",
      "total_flops_so_far": 15742049089536.0,
      "budget_used_percent": 0.015742049089536
    },
    {
      "type": "training",
      "description": "Training step 11",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:07",
      "total_flops_so_far": 17173144461312.0,
      "budget_used_percent": 0.017173144461312
    },
    {
      "type": "training",
      "description": "Training step 12",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:07",
      "total_flops_so_far": 18604239833088.0,
      "budget_used_percent": 0.018604239833088
    },
    {
      "type": "training",
      "description": "Training step 13",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:07",
      "total_flops_so_far": 20035335204864.0,
      "budget_used_percent": 0.020035335204864002
    },
    {
      "type": "training",
      "description": "Training step 14",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:07",
      "total_flops_so_far": 21466430576640.0,
      "budget_used_percent": 0.02146643057664
    },
    {
      "type": "training",
      "description": "Training step 15",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:07",
      "total_flops_so_far": 22897525948416.0,
      "budget_used_percent": 0.022897525948416
    },
    {
      "type": "training",
      "description": "Training step 16",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:07",
      "total_flops_so_far": 24328621320192.0,
      "budget_used_percent": 0.024328621320192
    },
    {
      "type": "training",
      "description": "Training step 17",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:07",
      "total_flops_so_far": 25759716691968.0,
      "budget_used_percent": 0.025759716691968
    },
    {
      "type": "training",
      "description": "Training step 18",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:07",
      "total_flops_so_far": 27190812063744.0,
      "budget_used_percent": 0.027190812063743998
    },
    {
      "type": "training",
      "description": "Training step 19",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:08",
      "total_flops_so_far": 28621907435520.0,
      "budget_used_percent": 0.02862190743552
    },
    {
      "type": "training",
      "description": "Training step 20",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:08",
      "total_flops_so_far": 30053002807296.0,
      "budget_used_percent": 0.030053002807296
    },
    {
      "type": "training",
      "description": "Training step 21",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:08",
      "total_flops_so_far": 31484098179072.0,
      "budget_used_percent": 0.031484098179072
    },
    {
      "type": "training",
      "description": "Training step 22",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:08",
      "total_flops_so_far": 32915193550848.0,
      "budget_used_percent": 0.032915193550848
    },
    {
      "type": "training",
      "description": "Training step 23",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:08",
      "total_flops_so_far": 34346288922624.0,
      "budget_used_percent": 0.034346288922624
    },
    {
      "type": "training",
      "description": "Training step 24",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:08",
      "total_flops_so_far": 35777384294400.0,
      "budget_used_percent": 0.0357773842944
    },
    {
      "type": "training",
      "description": "Training step 25",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:08",
      "total_flops_so_far": 37208479666176.0,
      "budget_used_percent": 0.037208479666176
    },
    {
      "type": "training",
      "description": "Training step 26",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:08",
      "total_flops_so_far": 38639575037952.0,
      "budget_used_percent": 0.038639575037952
    },
    {
      "type": "training",
      "description": "Training step 27",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:08",
      "total_flops_so_far": 40070670409728.0,
      "budget_used_percent": 0.040070670409728004
    },
    {
      "type": "training",
      "description": "Training step 28",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:09",
      "total_flops_so_far": 41501765781504.0,
      "budget_used_percent": 0.041501765781504
    },
    {
      "type": "training",
      "description": "Training step 29",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:09",
      "total_flops_so_far": 42932861153280.0,
      "budget_used_percent": 0.04293286115328
    },
    {
      "type": "training",
      "description": "Training step 30",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:09",
      "total_flops_so_far": 44363956525056.0,
      "budget_used_percent": 0.044363956525056
    },
    {
      "type": "training",
      "description": "Training step 31",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:09",
      "total_flops_so_far": 45795051896832.0,
      "budget_used_percent": 0.045795051896832
    },
    {
      "type": "training",
      "description": "Training step 32",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:09",
      "total_flops_so_far": 47226147268608.0,
      "budget_used_percent": 0.047226147268608
    },
    {
      "type": "training",
      "description": "Training step 33",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:09",
      "total_flops_so_far": 48657242640384.0,
      "budget_used_percent": 0.048657242640384
    },
    {
      "type": "training",
      "description": "Training step 34",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:09",
      "total_flops_so_far": 50088338012160.0,
      "budget_used_percent": 0.050088338012160005
    },
    {
      "type": "training",
      "description": "Training step 35",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:09",
      "total_flops_so_far": 51519433383936.0,
      "budget_used_percent": 0.051519433383936
    },
    {
      "type": "training",
      "description": "Training step 36",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:10",
      "total_flops_so_far": 52950528755712.0,
      "budget_used_percent": 0.052950528755712004
    },
    {
      "type": "training",
      "description": "Training step 37",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:10",
      "total_flops_so_far": 54381624127488.0,
      "budget_used_percent": 0.054381624127487996
    },
    {
      "type": "training",
      "description": "Training step 38",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:10",
      "total_flops_so_far": 55812719499264.0,
      "budget_used_percent": 0.055812719499264
    },
    {
      "type": "training",
      "description": "Training step 39",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:10",
      "total_flops_so_far": 57243814871040.0,
      "budget_used_percent": 0.05724381487104
    },
    {
      "type": "training",
      "description": "Training step 40",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:10",
      "total_flops_so_far": 58674910242816.0,
      "budget_used_percent": 0.05867491024281601
    },
    {
      "type": "training",
      "description": "Training step 41",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:10",
      "total_flops_so_far": 60106005614592.0,
      "budget_used_percent": 0.060106005614592
    },
    {
      "type": "training",
      "description": "Training step 42",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:10",
      "total_flops_so_far": 61537100986368.0,
      "budget_used_percent": 0.061537100986368005
    },
    {
      "type": "training",
      "description": "Training step 43",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:10",
      "total_flops_so_far": 62968196358144.0,
      "budget_used_percent": 0.062968196358144
    },
    {
      "type": "training",
      "description": "Training step 44",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:10",
      "total_flops_so_far": 64399291729920.0,
      "budget_used_percent": 0.06439929172992
    },
    {
      "type": "training",
      "description": "Training step 45",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:11",
      "total_flops_so_far": 65830387101696.0,
      "budget_used_percent": 0.065830387101696
    },
    {
      "type": "training",
      "description": "Training step 46",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:11",
      "total_flops_so_far": 67261482473472.0,
      "budget_used_percent": 0.067261482473472
    },
    {
      "type": "training",
      "description": "Training step 47",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:11",
      "total_flops_so_far": 68692577845248.0,
      "budget_used_percent": 0.068692577845248
    },
    {
      "type": "training",
      "description": "Training step 48",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:11",
      "total_flops_so_far": 70123673217024.0,
      "budget_used_percent": 0.070123673217024
    },
    {
      "type": "training",
      "description": "Training step 49",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:11",
      "total_flops_so_far": 71554768588800.0,
      "budget_used_percent": 0.0715547685888
    },
    {
      "type": "training",
      "description": "Training step 50",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:11",
      "total_flops_so_far": 72985863960576.0,
      "budget_used_percent": 0.07298586396057599
    },
    {
      "type": "training",
      "description": "Training step 51",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:11",
      "total_flops_so_far": 74416959332352.0,
      "budget_used_percent": 0.074416959332352
    },
    {
      "type": "training",
      "description": "Training step 52",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:11",
      "total_flops_so_far": 75848054704128.0,
      "budget_used_percent": 0.07584805470412799
    },
    {
      "type": "training",
      "description": "Training step 53",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:12",
      "total_flops_so_far": 77279150075904.0,
      "budget_used_percent": 0.077279150075904
    },
    {
      "type": "training",
      "description": "Training step 54",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:12",
      "total_flops_so_far": 78710245447680.0,
      "budget_used_percent": 0.07871024544768
    },
    {
      "type": "training",
      "description": "Training step 55",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:12",
      "total_flops_so_far": 80141340819456.0,
      "budget_used_percent": 0.08014134081945601
    },
    {
      "type": "training",
      "description": "Training step 56",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:12",
      "total_flops_so_far": 81572436191232.0,
      "budget_used_percent": 0.081572436191232
    },
    {
      "type": "training",
      "description": "Training step 57",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:12",
      "total_flops_so_far": 83003531563008.0,
      "budget_used_percent": 0.083003531563008
    },
    {
      "type": "training",
      "description": "Training step 58",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:12",
      "total_flops_so_far": 84434626934784.0,
      "budget_used_percent": 0.084434626934784
    },
    {
      "type": "training",
      "description": "Training step 59",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:12",
      "total_flops_so_far": 85865722306560.0,
      "budget_used_percent": 0.08586572230656
    },
    {
      "type": "training",
      "description": "Training step 60",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:12",
      "total_flops_so_far": 87296817678336.0,
      "budget_used_percent": 0.087296817678336
    },
    {
      "type": "training",
      "description": "Training step 61",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:12",
      "total_flops_so_far": 88727913050112.0,
      "budget_used_percent": 0.088727913050112
    },
    {
      "type": "training",
      "description": "Training step 62",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:13",
      "total_flops_so_far": 90159008421888.0,
      "budget_used_percent": 0.090159008421888
    },
    {
      "type": "training",
      "description": "Training step 63",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:13",
      "total_flops_so_far": 91590103793664.0,
      "budget_used_percent": 0.091590103793664
    },
    {
      "type": "training",
      "description": "Training step 64",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:13",
      "total_flops_so_far": 93021199165440.0,
      "budget_used_percent": 0.09302119916544
    },
    {
      "type": "training",
      "description": "Training step 65",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:13",
      "total_flops_so_far": 94452294537216.0,
      "budget_used_percent": 0.094452294537216
    },
    {
      "type": "training",
      "description": "Training step 66",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:13",
      "total_flops_so_far": 95883389908992.0,
      "budget_used_percent": 0.095883389908992
    },
    {
      "type": "training",
      "description": "Training step 67",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:13",
      "total_flops_so_far": 97314485280768.0,
      "budget_used_percent": 0.097314485280768
    },
    {
      "type": "training",
      "description": "Training step 68",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:13",
      "total_flops_so_far": 98745580652544.0,
      "budget_used_percent": 0.09874558065254399
    },
    {
      "type": "training",
      "description": "Training step 69",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:13",
      "total_flops_so_far": 100176676024320.0,
      "budget_used_percent": 0.10017667602432001
    },
    {
      "type": "training",
      "description": "Training step 70",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:14",
      "total_flops_so_far": 101607771396096.0,
      "budget_used_percent": 0.101607771396096
    },
    {
      "type": "training",
      "description": "Training step 71",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:14",
      "total_flops_so_far": 103038866767872.0,
      "budget_used_percent": 0.103038866767872
    },
    {
      "type": "training",
      "description": "Training step 72",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:14",
      "total_flops_so_far": 104469962139648.0,
      "budget_used_percent": 0.10446996213964799
    },
    {
      "type": "training",
      "description": "Training step 73",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:14",
      "total_flops_so_far": 105901057511424.0,
      "budget_used_percent": 0.10590105751142401
    },
    {
      "type": "training",
      "description": "Training step 74",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:14",
      "total_flops_so_far": 107332152883200.0,
      "budget_used_percent": 0.1073321528832
    },
    {
      "type": "training",
      "description": "Training step 75",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:14",
      "total_flops_so_far": 108763248254976.0,
      "budget_used_percent": 0.10876324825497599
    },
    {
      "type": "training",
      "description": "Training step 76",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:14",
      "total_flops_so_far": 110194343626752.0,
      "budget_used_percent": 0.110194343626752
    },
    {
      "type": "training",
      "description": "Training step 77",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:14",
      "total_flops_so_far": 111625438998528.0,
      "budget_used_percent": 0.111625438998528
    },
    {
      "type": "training",
      "description": "Training step 78",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:15",
      "total_flops_so_far": 113056534370304.0,
      "budget_used_percent": 0.113056534370304
    },
    {
      "type": "training",
      "description": "Training step 79",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:15",
      "total_flops_so_far": 114487629742080.0,
      "budget_used_percent": 0.11448762974208
    },
    {
      "type": "training",
      "description": "Training step 80",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:15",
      "total_flops_so_far": 115918725113856.0,
      "budget_used_percent": 0.115918725113856
    },
    {
      "type": "training",
      "description": "Training step 81",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:15",
      "total_flops_so_far": 117349820485632.0,
      "budget_used_percent": 0.11734982048563201
    },
    {
      "type": "training",
      "description": "Training step 82",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:15",
      "total_flops_so_far": 118780915857408.0,
      "budget_used_percent": 0.118780915857408
    },
    {
      "type": "training",
      "description": "Training step 83",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:15",
      "total_flops_so_far": 120212011229184.0,
      "budget_used_percent": 0.120212011229184
    },
    {
      "type": "training",
      "description": "Training step 84",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:15",
      "total_flops_so_far": 121643106600960.0,
      "budget_used_percent": 0.12164310660095999
    },
    {
      "type": "training",
      "description": "Training step 85",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:15",
      "total_flops_so_far": 123074201972736.0,
      "budget_used_percent": 0.12307420197273601
    },
    {
      "type": "training",
      "description": "Training step 86",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:16",
      "total_flops_so_far": 124505297344512.0,
      "budget_used_percent": 0.124505297344512
    },
    {
      "type": "training",
      "description": "Training step 87",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:16",
      "total_flops_so_far": 125936392716288.0,
      "budget_used_percent": 0.125936392716288
    },
    {
      "type": "training",
      "description": "Training step 88",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:16",
      "total_flops_so_far": 127367488088064.0,
      "budget_used_percent": 0.127367488088064
    },
    {
      "type": "training",
      "description": "Training step 89",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:16",
      "total_flops_so_far": 128798583459840.0,
      "budget_used_percent": 0.12879858345984
    },
    {
      "type": "training",
      "description": "Training step 90",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:16",
      "total_flops_so_far": 130229678831616.0,
      "budget_used_percent": 0.130229678831616
    },
    {
      "type": "training",
      "description": "Training step 91",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:16",
      "total_flops_so_far": 131660774203392.0,
      "budget_used_percent": 0.131660774203392
    },
    {
      "type": "training",
      "description": "Training step 92",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:16",
      "total_flops_so_far": 133091869575168.0,
      "budget_used_percent": 0.133091869575168
    },
    {
      "type": "training",
      "description": "Training step 93",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:16",
      "total_flops_so_far": 134522964946944.0,
      "budget_used_percent": 0.134522964946944
    },
    {
      "type": "training",
      "description": "Training step 94",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:17",
      "total_flops_so_far": 135954060318720.0,
      "budget_used_percent": 0.13595406031872
    },
    {
      "type": "training",
      "description": "Training step 95",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:17",
      "total_flops_so_far": 137385155690496.0,
      "budget_used_percent": 0.137385155690496
    },
    {
      "type": "training",
      "description": "Training step 96",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:17",
      "total_flops_so_far": 138816251062272.0,
      "budget_used_percent": 0.138816251062272
    },
    {
      "type": "training",
      "description": "Training step 97",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:17",
      "total_flops_so_far": 140247346434048.0,
      "budget_used_percent": 0.140247346434048
    },
    {
      "type": "training",
      "description": "Training step 98",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:17",
      "total_flops_so_far": 141678441805824.0,
      "budget_used_percent": 0.141678441805824
    },
    {
      "type": "training",
      "description": "Training step 99",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:17",
      "total_flops_so_far": 143109537177600.0,
      "budget_used_percent": 0.1431095371776
    },
    {
      "type": "training",
      "description": "Training step 100",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:17",
      "total_flops_so_far": 144540632549376.0,
      "budget_used_percent": 0.144540632549376
    },
    {
      "type": "training",
      "description": "Training step 101",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:17",
      "total_flops_so_far": 145971727921152.0,
      "budget_used_percent": 0.14597172792115198
    },
    {
      "type": "training",
      "description": "Training step 102",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:18",
      "total_flops_so_far": 147402823292928.0,
      "budget_used_percent": 0.147402823292928
    },
    {
      "type": "training",
      "description": "Training step 103",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:18",
      "total_flops_so_far": 148833918664704.0,
      "budget_used_percent": 0.148833918664704
    },
    {
      "type": "training",
      "description": "Training step 104",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:18",
      "total_flops_so_far": 150265014036480.0,
      "budget_used_percent": 0.15026501403648
    },
    {
      "type": "training",
      "description": "Training step 105",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:18",
      "total_flops_so_far": 151696109408256.0,
      "budget_used_percent": 0.15169610940825598
    },
    {
      "type": "training",
      "description": "Training step 106",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:18",
      "total_flops_so_far": 153127204780032.0,
      "budget_used_percent": 0.153127204780032
    },
    {
      "type": "training",
      "description": "Training step 107",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:18",
      "total_flops_so_far": 154558300151808.0,
      "budget_used_percent": 0.154558300151808
    },
    {
      "type": "training",
      "description": "Training step 108",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:18",
      "total_flops_so_far": 155989395523584.0,
      "budget_used_percent": 0.155989395523584
    },
    {
      "type": "training",
      "description": "Training step 109",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:18",
      "total_flops_so_far": 157420490895360.0,
      "budget_used_percent": 0.15742049089536
    },
    {
      "type": "training",
      "description": "Training step 110",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:18",
      "total_flops_so_far": 158851586267136.0,
      "budget_used_percent": 0.15885158626713602
    },
    {
      "type": "training",
      "description": "Training step 111",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:19",
      "total_flops_so_far": 160282681638912.0,
      "budget_used_percent": 0.16028268163891202
    },
    {
      "type": "training",
      "description": "Training step 112",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:19",
      "total_flops_so_far": 161713777010688.0,
      "budget_used_percent": 0.161713777010688
    },
    {
      "type": "training",
      "description": "Training step 113",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:19",
      "total_flops_so_far": 163144872382464.0,
      "budget_used_percent": 0.163144872382464
    },
    {
      "type": "training",
      "description": "Training step 114",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:19",
      "total_flops_so_far": 164575967754240.0,
      "budget_used_percent": 0.16457596775424
    },
    {
      "type": "training",
      "description": "Training step 115",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:19",
      "total_flops_so_far": 166007063126016.0,
      "budget_used_percent": 0.166007063126016
    },
    {
      "type": "training",
      "description": "Training step 116",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:19",
      "total_flops_so_far": 167438158497792.0,
      "budget_used_percent": 0.167438158497792
    },
    {
      "type": "training",
      "description": "Training step 117",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:19",
      "total_flops_so_far": 168869253869568.0,
      "budget_used_percent": 0.168869253869568
    },
    {
      "type": "training",
      "description": "Training step 118",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:19",
      "total_flops_so_far": 170300349241344.0,
      "budget_used_percent": 0.170300349241344
    },
    {
      "type": "training",
      "description": "Training step 119",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:20",
      "total_flops_so_far": 171731444613120.0,
      "budget_used_percent": 0.17173144461312
    },
    {
      "type": "training",
      "description": "Training step 120",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:20",
      "total_flops_so_far": 173162539984896.0,
      "budget_used_percent": 0.173162539984896
    },
    {
      "type": "training",
      "description": "Training step 121",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:20",
      "total_flops_so_far": 174593635356672.0,
      "budget_used_percent": 0.174593635356672
    },
    {
      "type": "training",
      "description": "Training step 122",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:20",
      "total_flops_so_far": 176024730728448.0,
      "budget_used_percent": 0.176024730728448
    },
    {
      "type": "training",
      "description": "Training step 123",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:20",
      "total_flops_so_far": 177455826100224.0,
      "budget_used_percent": 0.177455826100224
    },
    {
      "type": "training",
      "description": "Training step 124",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:20",
      "total_flops_so_far": 178886921472000.0,
      "budget_used_percent": 0.178886921472
    },
    {
      "type": "training",
      "description": "Training step 125",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:20",
      "total_flops_so_far": 180318016843776.0,
      "budget_used_percent": 0.180318016843776
    },
    {
      "type": "training",
      "description": "Training step 126",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:20",
      "total_flops_so_far": 181749112215552.0,
      "budget_used_percent": 0.18174911221555198
    },
    {
      "type": "training",
      "description": "Training step 127",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:21",
      "total_flops_so_far": 183180207587328.0,
      "budget_used_percent": 0.183180207587328
    },
    {
      "type": "training",
      "description": "Training step 128",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:21",
      "total_flops_so_far": 184611302959104.0,
      "budget_used_percent": 0.184611302959104
    },
    {
      "type": "training",
      "description": "Training step 129",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:21",
      "total_flops_so_far": 186042398330880.0,
      "budget_used_percent": 0.18604239833088
    },
    {
      "type": "training",
      "description": "Training step 130",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:21",
      "total_flops_so_far": 187473493702656.0,
      "budget_used_percent": 0.18747349370265598
    },
    {
      "type": "training",
      "description": "Training step 131",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:21",
      "total_flops_so_far": 188904589074432.0,
      "budget_used_percent": 0.188904589074432
    },
    {
      "type": "training",
      "description": "Training step 132",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:21",
      "total_flops_so_far": 190335684446208.0,
      "budget_used_percent": 0.190335684446208
    },
    {
      "type": "training",
      "description": "Training step 133",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:21",
      "total_flops_so_far": 191766779817984.0,
      "budget_used_percent": 0.191766779817984
    },
    {
      "type": "training",
      "description": "Training step 134",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:21",
      "total_flops_so_far": 193197875189760.0,
      "budget_used_percent": 0.19319787518976
    },
    {
      "type": "training",
      "description": "Training step 135",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:22",
      "total_flops_so_far": 194628970561536.0,
      "budget_used_percent": 0.194628970561536
    },
    {
      "type": "training",
      "description": "Training step 136",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:22",
      "total_flops_so_far": 196060065933312.0,
      "budget_used_percent": 0.19606006593331202
    },
    {
      "type": "training",
      "description": "Training step 137",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:22",
      "total_flops_so_far": 197491161305088.0,
      "budget_used_percent": 0.19749116130508798
    },
    {
      "type": "training",
      "description": "Training step 138",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:22",
      "total_flops_so_far": 198922256676864.0,
      "budget_used_percent": 0.198922256676864
    },
    {
      "type": "training",
      "description": "Training step 139",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:22",
      "total_flops_so_far": 200353352048640.0,
      "budget_used_percent": 0.20035335204864002
    },
    {
      "type": "training",
      "description": "Training step 140",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:22",
      "total_flops_so_far": 201784447420416.0,
      "budget_used_percent": 0.20178444742041599
    },
    {
      "type": "training",
      "description": "Training step 141",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:22",
      "total_flops_so_far": 203215542792192.0,
      "budget_used_percent": 0.203215542792192
    },
    {
      "type": "training",
      "description": "Training step 142",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:22",
      "total_flops_so_far": 204646638163968.0,
      "budget_used_percent": 0.20464663816396803
    },
    {
      "type": "training",
      "description": "Training step 143",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:22",
      "total_flops_so_far": 206077733535744.0,
      "budget_used_percent": 0.206077733535744
    },
    {
      "type": "training",
      "description": "Training step 144",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:23",
      "total_flops_so_far": 207508828907520.0,
      "budget_used_percent": 0.20750882890752
    },
    {
      "type": "training",
      "description": "Training step 145",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:23",
      "total_flops_so_far": 208939924279296.0,
      "budget_used_percent": 0.20893992427929597
    },
    {
      "type": "training",
      "description": "Training step 146",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:23",
      "total_flops_so_far": 210371019651072.0,
      "budget_used_percent": 0.210371019651072
    },
    {
      "type": "training",
      "description": "Training step 147",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:23",
      "total_flops_so_far": 211802115022848.0,
      "budget_used_percent": 0.21180211502284801
    },
    {
      "type": "training",
      "description": "Training step 148",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:23",
      "total_flops_so_far": 213233210394624.0,
      "budget_used_percent": 0.21323321039462398
    },
    {
      "type": "training",
      "description": "Training step 149",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:23",
      "total_flops_so_far": 214664305766400.0,
      "budget_used_percent": 0.2146643057664
    },
    {
      "type": "training",
      "description": "Training step 150",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:23",
      "total_flops_so_far": 216095401138176.0,
      "budget_used_percent": 0.21609540113817602
    },
    {
      "type": "training",
      "description": "Training step 151",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:23",
      "total_flops_so_far": 217526496509952.0,
      "budget_used_percent": 0.21752649650995198
    },
    {
      "type": "training",
      "description": "Training step 152",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:24",
      "total_flops_so_far": 218957591881728.0,
      "budget_used_percent": 0.218957591881728
    },
    {
      "type": "training",
      "description": "Training step 153",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:24",
      "total_flops_so_far": 220388687253504.0,
      "budget_used_percent": 0.220388687253504
    },
    {
      "type": "training",
      "description": "Training step 154",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:24",
      "total_flops_so_far": 221819782625280.0,
      "budget_used_percent": 0.22181978262528
    },
    {
      "type": "training",
      "description": "Training step 155",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:24",
      "total_flops_so_far": 223250877997056.0,
      "budget_used_percent": 0.223250877997056
    },
    {
      "type": "training",
      "description": "Training step 156",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:24",
      "total_flops_so_far": 224681973368832.0,
      "budget_used_percent": 0.224681973368832
    },
    {
      "type": "training",
      "description": "Training step 157",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:24",
      "total_flops_so_far": 226113068740608.0,
      "budget_used_percent": 0.226113068740608
    },
    {
      "type": "training",
      "description": "Training step 158",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:24",
      "total_flops_so_far": 227544164112384.0,
      "budget_used_percent": 0.22754416411238398
    },
    {
      "type": "training",
      "description": "Training step 159",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:24",
      "total_flops_so_far": 228975259484160.0,
      "budget_used_percent": 0.22897525948416
    },
    {
      "type": "training",
      "description": "Training step 160",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:25",
      "total_flops_so_far": 230406354855936.0,
      "budget_used_percent": 0.23040635485593602
    },
    {
      "type": "training",
      "description": "Training step 161",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:25",
      "total_flops_so_far": 231837450227712.0,
      "budget_used_percent": 0.231837450227712
    },
    {
      "type": "training",
      "description": "Training step 162",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:25",
      "total_flops_so_far": 233268545599488.0,
      "budget_used_percent": 0.233268545599488
    },
    {
      "type": "training",
      "description": "Training step 163",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:25",
      "total_flops_so_far": 234699640971264.0,
      "budget_used_percent": 0.23469964097126403
    },
    {
      "type": "training",
      "description": "Training step 164",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:25",
      "total_flops_so_far": 236130736343040.0,
      "budget_used_percent": 0.23613073634304
    },
    {
      "type": "training",
      "description": "Training step 165",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:25",
      "total_flops_so_far": 237561831714816.0,
      "budget_used_percent": 0.237561831714816
    },
    {
      "type": "training",
      "description": "Training step 166",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:25",
      "total_flops_so_far": 238992927086592.0,
      "budget_used_percent": 0.23899292708659198
    },
    {
      "type": "training",
      "description": "Training step 167",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:25",
      "total_flops_so_far": 240424022458368.0,
      "budget_used_percent": 0.240424022458368
    },
    {
      "type": "training",
      "description": "Training step 168",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:26",
      "total_flops_so_far": 241855117830144.0,
      "budget_used_percent": 0.24185511783014402
    },
    {
      "type": "training",
      "description": "Training step 169",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:26",
      "total_flops_so_far": 243286213201920.0,
      "budget_used_percent": 0.24328621320191998
    },
    {
      "type": "training",
      "description": "Training step 170",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:26",
      "total_flops_so_far": 244717308573696.0,
      "budget_used_percent": 0.244717308573696
    },
    {
      "type": "training",
      "description": "Training step 171",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:26",
      "total_flops_so_far": 246148403945472.0,
      "budget_used_percent": 0.24614840394547202
    },
    {
      "type": "training",
      "description": "Training step 172",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:26",
      "total_flops_so_far": 247579499317248.0,
      "budget_used_percent": 0.247579499317248
    },
    {
      "type": "training",
      "description": "Training step 173",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:26",
      "total_flops_so_far": 249010594689024.0,
      "budget_used_percent": 0.249010594689024
    },
    {
      "type": "training",
      "description": "Training step 174",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:26",
      "total_flops_so_far": 250441690060800.0,
      "budget_used_percent": 0.25044169006079997
    },
    {
      "type": "training",
      "description": "Training step 175",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:26",
      "total_flops_so_far": 251872785432576.0,
      "budget_used_percent": 0.251872785432576
    },
    {
      "type": "training",
      "description": "Training step 176",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:26",
      "total_flops_so_far": 253303880804352.0,
      "budget_used_percent": 0.253303880804352
    },
    {
      "type": "training",
      "description": "Training step 177",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:27",
      "total_flops_so_far": 254734976176128.0,
      "budget_used_percent": 0.254734976176128
    },
    {
      "type": "training",
      "description": "Training step 178",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:27",
      "total_flops_so_far": 256166071547904.0,
      "budget_used_percent": 0.256166071547904
    },
    {
      "type": "training",
      "description": "Training step 179",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:27",
      "total_flops_so_far": 257597166919680.0,
      "budget_used_percent": 0.25759716691968
    },
    {
      "type": "training",
      "description": "Training step 180",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:27",
      "total_flops_so_far": 259028262291456.0,
      "budget_used_percent": 0.259028262291456
    },
    {
      "type": "training",
      "description": "Training step 181",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:27",
      "total_flops_so_far": 260459357663232.0,
      "budget_used_percent": 0.260459357663232
    },
    {
      "type": "training",
      "description": "Training step 182",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:27",
      "total_flops_so_far": 261890453035008.0,
      "budget_used_percent": 0.26189045303500796
    },
    {
      "type": "training",
      "description": "Training step 183",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:27",
      "total_flops_so_far": 263321548406784.0,
      "budget_used_percent": 0.263321548406784
    },
    {
      "type": "training",
      "description": "Training step 184",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:27",
      "total_flops_so_far": 264752643778560.0,
      "budget_used_percent": 0.26475264377856
    },
    {
      "type": "training",
      "description": "Training step 185",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:28",
      "total_flops_so_far": 266183739150336.0,
      "budget_used_percent": 0.266183739150336
    },
    {
      "type": "training",
      "description": "Training step 186",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:28",
      "total_flops_so_far": 267614834522112.0,
      "budget_used_percent": 0.267614834522112
    },
    {
      "type": "training",
      "description": "Training step 187",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:28",
      "total_flops_so_far": 269045929893888.0,
      "budget_used_percent": 0.269045929893888
    },
    {
      "type": "training",
      "description": "Training step 188",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:28",
      "total_flops_so_far": 270477025265664.0,
      "budget_used_percent": 0.270477025265664
    },
    {
      "type": "training",
      "description": "Training step 189",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:28",
      "total_flops_so_far": 271908120637440.0,
      "budget_used_percent": 0.27190812063744
    },
    {
      "type": "training",
      "description": "Training step 190",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:28",
      "total_flops_so_far": 273339216009216.0,
      "budget_used_percent": 0.273339216009216
    },
    {
      "type": "training",
      "description": "Training step 191",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:28",
      "total_flops_so_far": 274770311380992.0,
      "budget_used_percent": 0.274770311380992
    },
    {
      "type": "training",
      "description": "Training step 192",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:28",
      "total_flops_so_far": 276201406752768.0,
      "budget_used_percent": 0.276201406752768
    },
    {
      "type": "training",
      "description": "Training step 193",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:29",
      "total_flops_so_far": 277632502124544.0,
      "budget_used_percent": 0.277632502124544
    },
    {
      "type": "training",
      "description": "Training step 194",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:29",
      "total_flops_so_far": 279063597496320.0,
      "budget_used_percent": 0.27906359749632004
    },
    {
      "type": "training",
      "description": "Training step 195",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:29",
      "total_flops_so_far": 280494692868096.0,
      "budget_used_percent": 0.280494692868096
    },
    {
      "type": "training",
      "description": "Training step 196",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:29",
      "total_flops_so_far": 281925788239872.0,
      "budget_used_percent": 0.281925788239872
    },
    {
      "type": "training",
      "description": "Training step 197",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:29",
      "total_flops_so_far": 283356883611648.0,
      "budget_used_percent": 0.283356883611648
    },
    {
      "type": "training",
      "description": "Training step 198",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:29",
      "total_flops_so_far": 284787978983424.0,
      "budget_used_percent": 0.284787978983424
    },
    {
      "type": "training",
      "description": "Training step 199",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:29",
      "total_flops_so_far": 286219074355200.0,
      "budget_used_percent": 0.2862190743552
    },
    {
      "type": "training",
      "description": "Training step 200",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:29",
      "total_flops_so_far": 287650169726976.0,
      "budget_used_percent": 0.287650169726976
    },
    {
      "type": "training",
      "description": "Training step 201",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:30",
      "total_flops_so_far": 289081265098752.0,
      "budget_used_percent": 0.289081265098752
    },
    {
      "type": "training",
      "description": "Training step 202",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:30",
      "total_flops_so_far": 290512360470528.0,
      "budget_used_percent": 0.29051236047052803
    },
    {
      "type": "training",
      "description": "Training step 203",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:30",
      "total_flops_so_far": 291943455842304.0,
      "budget_used_percent": 0.29194345584230397
    },
    {
      "type": "training",
      "description": "Training step 204",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:30",
      "total_flops_so_far": 293374551214080.0,
      "budget_used_percent": 0.29337455121408
    },
    {
      "type": "training",
      "description": "Training step 205",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:30",
      "total_flops_so_far": 294805646585856.0,
      "budget_used_percent": 0.294805646585856
    },
    {
      "type": "training",
      "description": "Training step 206",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:30",
      "total_flops_so_far": 296236741957632.0,
      "budget_used_percent": 0.296236741957632
    },
    {
      "type": "training",
      "description": "Training step 207",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:30",
      "total_flops_so_far": 297667837329408.0,
      "budget_used_percent": 0.297667837329408
    },
    {
      "type": "training",
      "description": "Training step 208",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:30",
      "total_flops_so_far": 299098932701184.0,
      "budget_used_percent": 0.299098932701184
    },
    {
      "type": "training",
      "description": "Training step 209",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:31",
      "total_flops_so_far": 300530028072960.0,
      "budget_used_percent": 0.30053002807296
    },
    {
      "type": "training",
      "description": "Training step 210",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:31",
      "total_flops_so_far": 301961123444736.0,
      "budget_used_percent": 0.301961123444736
    },
    {
      "type": "training",
      "description": "Training step 211",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:31",
      "total_flops_so_far": 303392218816512.0,
      "budget_used_percent": 0.30339221881651196
    },
    {
      "type": "training",
      "description": "Training step 212",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:31",
      "total_flops_so_far": 304823314188288.0,
      "budget_used_percent": 0.304823314188288
    },
    {
      "type": "training",
      "description": "Training step 213",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:31",
      "total_flops_so_far": 306254409560064.0,
      "budget_used_percent": 0.306254409560064
    },
    {
      "type": "training",
      "description": "Training step 214",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:31",
      "total_flops_so_far": 307685504931840.0,
      "budget_used_percent": 0.30768550493184
    },
    {
      "type": "training",
      "description": "Training step 215",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:31",
      "total_flops_so_far": 309116600303616.0,
      "budget_used_percent": 0.309116600303616
    },
    {
      "type": "training",
      "description": "Training step 216",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:31",
      "total_flops_so_far": 310547695675392.0,
      "budget_used_percent": 0.310547695675392
    },
    {
      "type": "training",
      "description": "Training step 217",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:31",
      "total_flops_so_far": 311978791047168.0,
      "budget_used_percent": 0.311978791047168
    },
    {
      "type": "training",
      "description": "Training step 218",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:32",
      "total_flops_so_far": 313409886418944.0,
      "budget_used_percent": 0.313409886418944
    },
    {
      "type": "training",
      "description": "Training step 219",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:32",
      "total_flops_so_far": 314840981790720.0,
      "budget_used_percent": 0.31484098179072
    },
    {
      "type": "training",
      "description": "Training step 220",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:32",
      "total_flops_so_far": 316272077162496.0,
      "budget_used_percent": 0.316272077162496
    },
    {
      "type": "training",
      "description": "Training step 221",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:32",
      "total_flops_so_far": 317703172534272.0,
      "budget_used_percent": 0.31770317253427205
    },
    {
      "type": "training",
      "description": "Training step 222",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:32",
      "total_flops_so_far": 319134267906048.0,
      "budget_used_percent": 0.319134267906048
    },
    {
      "type": "training",
      "description": "Training step 223",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:32",
      "total_flops_so_far": 320565363277824.0,
      "budget_used_percent": 0.32056536327782403
    },
    {
      "type": "training",
      "description": "Training step 224",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:32",
      "total_flops_so_far": 321996458649600.0,
      "budget_used_percent": 0.32199645864959997
    },
    {
      "type": "training",
      "description": "Training step 225",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:32",
      "total_flops_so_far": 323427554021376.0,
      "budget_used_percent": 0.323427554021376
    },
    {
      "type": "training",
      "description": "Training step 226",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:33",
      "total_flops_so_far": 324858649393152.0,
      "budget_used_percent": 0.324858649393152
    },
    {
      "type": "training",
      "description": "Training step 227",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:33",
      "total_flops_so_far": 326289744764928.0,
      "budget_used_percent": 0.326289744764928
    },
    {
      "type": "training",
      "description": "Training step 228",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:33",
      "total_flops_so_far": 327720840136704.0,
      "budget_used_percent": 0.327720840136704
    },
    {
      "type": "training",
      "description": "Training step 229",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:33",
      "total_flops_so_far": 329151935508480.0,
      "budget_used_percent": 0.32915193550848
    },
    {
      "type": "training",
      "description": "Training step 230",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:33",
      "total_flops_so_far": 330583030880256.0,
      "budget_used_percent": 0.330583030880256
    },
    {
      "type": "training",
      "description": "Training step 231",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:33",
      "total_flops_so_far": 332014126252032.0,
      "budget_used_percent": 0.332014126252032
    },
    {
      "type": "training",
      "description": "Training step 232",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:33",
      "total_flops_so_far": 333445221623808.0,
      "budget_used_percent": 0.33344522162380796
    },
    {
      "type": "training",
      "description": "Training step 233",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:33",
      "total_flops_so_far": 334876316995584.0,
      "budget_used_percent": 0.334876316995584
    },
    {
      "type": "training",
      "description": "Training step 234",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:34",
      "total_flops_so_far": 336307412367360.0,
      "budget_used_percent": 0.33630741236736
    },
    {
      "type": "training",
      "description": "Training step 235",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:34",
      "total_flops_so_far": 337738507739136.0,
      "budget_used_percent": 0.337738507739136
    },
    {
      "type": "training",
      "description": "Training step 236",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:34",
      "total_flops_so_far": 339169603110912.0,
      "budget_used_percent": 0.339169603110912
    },
    {
      "type": "training",
      "description": "Training step 237",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:34",
      "total_flops_so_far": 340600698482688.0,
      "budget_used_percent": 0.340600698482688
    },
    {
      "type": "training",
      "description": "Training step 238",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:34",
      "total_flops_so_far": 342031793854464.0,
      "budget_used_percent": 0.342031793854464
    },
    {
      "type": "training",
      "description": "Training step 239",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:34",
      "total_flops_so_far": 343462889226240.0,
      "budget_used_percent": 0.34346288922624
    },
    {
      "type": "training",
      "description": "Training step 240",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:34",
      "total_flops_so_far": 344893984598016.0,
      "budget_used_percent": 0.344893984598016
    },
    {
      "type": "training",
      "description": "Training step 241",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:34",
      "total_flops_so_far": 346325079969792.0,
      "budget_used_percent": 0.346325079969792
    },
    {
      "type": "training",
      "description": "Training step 242",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:35",
      "total_flops_so_far": 347756175341568.0,
      "budget_used_percent": 0.347756175341568
    },
    {
      "type": "training",
      "description": "Training step 243",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:35",
      "total_flops_so_far": 349187270713344.0,
      "budget_used_percent": 0.349187270713344
    },
    {
      "type": "training",
      "description": "Training step 244",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:35",
      "total_flops_so_far": 350618366085120.0,
      "budget_used_percent": 0.35061836608512004
    },
    {
      "type": "training",
      "description": "Training step 245",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:35",
      "total_flops_so_far": 352049461456896.0,
      "budget_used_percent": 0.352049461456896
    },
    {
      "type": "training",
      "description": "Training step 246",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:35",
      "total_flops_so_far": 353480556828672.0,
      "budget_used_percent": 0.353480556828672
    },
    {
      "type": "training",
      "description": "Training step 247",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:35",
      "total_flops_so_far": 354911652200448.0,
      "budget_used_percent": 0.354911652200448
    },
    {
      "type": "training",
      "description": "Training step 248",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:35",
      "total_flops_so_far": 356342747572224.0,
      "budget_used_percent": 0.356342747572224
    },
    {
      "type": "training",
      "description": "Training step 249",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:35",
      "total_flops_so_far": 357773842944000.0,
      "budget_used_percent": 0.357773842944
    },
    {
      "type": "training",
      "description": "Training step 250",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:36",
      "total_flops_so_far": 359204938315776.0,
      "budget_used_percent": 0.359204938315776
    },
    {
      "type": "training",
      "description": "Training step 251",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:36",
      "total_flops_so_far": 360636033687552.0,
      "budget_used_percent": 0.360636033687552
    },
    {
      "type": "training",
      "description": "Training step 252",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:36",
      "total_flops_so_far": 362067129059328.0,
      "budget_used_percent": 0.36206712905932803
    },
    {
      "type": "training",
      "description": "Training step 253",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:36",
      "total_flops_so_far": 363498224431104.0,
      "budget_used_percent": 0.36349822443110397
    },
    {
      "type": "training",
      "description": "Training step 254",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:36",
      "total_flops_so_far": 364929319802880.0,
      "budget_used_percent": 0.36492931980288
    },
    {
      "type": "training",
      "description": "Training step 255",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:36",
      "total_flops_so_far": 366360415174656.0,
      "budget_used_percent": 0.366360415174656
    },
    {
      "type": "training",
      "description": "Training step 256",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:36",
      "total_flops_so_far": 367791510546432.0,
      "budget_used_percent": 0.367791510546432
    },
    {
      "type": "training",
      "description": "Training step 257",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:36",
      "total_flops_so_far": 369222605918208.0,
      "budget_used_percent": 0.369222605918208
    },
    {
      "type": "training",
      "description": "Training step 258",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:37",
      "total_flops_so_far": 370653701289984.0,
      "budget_used_percent": 0.370653701289984
    },
    {
      "type": "training",
      "description": "Training step 259",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:37",
      "total_flops_so_far": 372084796661760.0,
      "budget_used_percent": 0.37208479666176
    },
    {
      "type": "training",
      "description": "Training step 260",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:37",
      "total_flops_so_far": 373515892033536.0,
      "budget_used_percent": 0.373515892033536
    },
    {
      "type": "training",
      "description": "Training step 261",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:37",
      "total_flops_so_far": 374946987405312.0,
      "budget_used_percent": 0.37494698740531196
    },
    {
      "type": "training",
      "description": "Training step 262",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:37",
      "total_flops_so_far": 376378082777088.0,
      "budget_used_percent": 0.376378082777088
    },
    {
      "type": "training",
      "description": "Training step 263",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:37",
      "total_flops_so_far": 377809178148864.0,
      "budget_used_percent": 0.377809178148864
    },
    {
      "type": "training",
      "description": "Training step 264",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:37",
      "total_flops_so_far": 379240273520640.0,
      "budget_used_percent": 0.37924027352064
    },
    {
      "type": "training",
      "description": "Training step 265",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:37",
      "total_flops_so_far": 380671368892416.0,
      "budget_used_percent": 0.380671368892416
    },
    {
      "type": "training",
      "description": "Training step 266",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:38",
      "total_flops_so_far": 382102464264192.0,
      "budget_used_percent": 0.382102464264192
    },
    {
      "type": "training",
      "description": "Training step 267",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:38",
      "total_flops_so_far": 383533559635968.0,
      "budget_used_percent": 0.383533559635968
    },
    {
      "type": "training",
      "description": "Training step 268",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:38",
      "total_flops_so_far": 384964655007744.0,
      "budget_used_percent": 0.384964655007744
    },
    {
      "type": "training",
      "description": "Training step 269",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:38",
      "total_flops_so_far": 386395750379520.0,
      "budget_used_percent": 0.38639575037952
    },
    {
      "type": "training",
      "description": "Training step 270",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:38",
      "total_flops_so_far": 387826845751296.0,
      "budget_used_percent": 0.387826845751296
    },
    {
      "type": "training",
      "description": "Training step 271",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:38",
      "total_flops_so_far": 389257941123072.0,
      "budget_used_percent": 0.389257941123072
    },
    {
      "type": "training",
      "description": "Training step 272",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:38",
      "total_flops_so_far": 390689036494848.0,
      "budget_used_percent": 0.390689036494848
    },
    {
      "type": "training",
      "description": "Training step 273",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:38",
      "total_flops_so_far": 392120131866624.0,
      "budget_used_percent": 0.39212013186662403
    },
    {
      "type": "training",
      "description": "Training step 274",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:39",
      "total_flops_so_far": 393551227238400.0,
      "budget_used_percent": 0.3935512272384
    },
    {
      "type": "training",
      "description": "Training step 275",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:39",
      "total_flops_so_far": 394982322610176.0,
      "budget_used_percent": 0.39498232261017596
    },
    {
      "type": "training",
      "description": "Training step 276",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:39",
      "total_flops_so_far": 396413417981952.0,
      "budget_used_percent": 0.39641341798195195
    },
    {
      "type": "training",
      "description": "Training step 277",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:39",
      "total_flops_so_far": 397844513353728.0,
      "budget_used_percent": 0.397844513353728
    },
    {
      "type": "training",
      "description": "Training step 278",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:39",
      "total_flops_so_far": 399275608725504.0,
      "budget_used_percent": 0.399275608725504
    },
    {
      "type": "training",
      "description": "Training step 279",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:39",
      "total_flops_so_far": 400706704097280.0,
      "budget_used_percent": 0.40070670409728004
    },
    {
      "type": "training",
      "description": "Training step 280",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:39",
      "total_flops_so_far": 402137799469056.0,
      "budget_used_percent": 0.40213779946905603
    },
    {
      "type": "training",
      "description": "Training step 281",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:39",
      "total_flops_so_far": 403568894840832.0,
      "budget_used_percent": 0.40356889484083197
    },
    {
      "type": "training",
      "description": "Training step 282",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:40",
      "total_flops_so_far": 404999990212608.0,
      "budget_used_percent": 0.40499999021260796
    },
    {
      "type": "training",
      "description": "Training step 283",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:40",
      "total_flops_so_far": 406431085584384.0,
      "budget_used_percent": 0.406431085584384
    },
    {
      "type": "training",
      "description": "Training step 284",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:40",
      "total_flops_so_far": 407862180956160.0,
      "budget_used_percent": 0.40786218095616
    },
    {
      "type": "training",
      "description": "Training step 285",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:40",
      "total_flops_so_far": 409293276327936.0,
      "budget_used_percent": 0.40929327632793605
    },
    {
      "type": "training",
      "description": "Training step 286",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:40",
      "total_flops_so_far": 410724371699712.0,
      "budget_used_percent": 0.410724371699712
    },
    {
      "type": "training",
      "description": "Training step 287",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:40",
      "total_flops_so_far": 412155467071488.0,
      "budget_used_percent": 0.412155467071488
    },
    {
      "type": "training",
      "description": "Training step 288",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:40",
      "total_flops_so_far": 413586562443264.0,
      "budget_used_percent": 0.41358656244326397
    },
    {
      "type": "training",
      "description": "Training step 289",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:40",
      "total_flops_so_far": 415017657815040.0,
      "budget_used_percent": 0.41501765781504
    },
    {
      "type": "training",
      "description": "Training step 290",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:41",
      "total_flops_so_far": 416448753186816.0,
      "budget_used_percent": 0.416448753186816
    },
    {
      "type": "training",
      "description": "Training step 291",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:41",
      "total_flops_so_far": 417879848558592.0,
      "budget_used_percent": 0.41787984855859195
    },
    {
      "type": "training",
      "description": "Training step 292",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:41",
      "total_flops_so_far": 419310943930368.0,
      "budget_used_percent": 0.419310943930368
    },
    {
      "type": "training",
      "description": "Training step 293",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:41",
      "total_flops_so_far": 420742039302144.0,
      "budget_used_percent": 0.420742039302144
    },
    {
      "type": "training",
      "description": "Training step 294",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:41",
      "total_flops_so_far": 422173134673920.0,
      "budget_used_percent": 0.42217313467392004
    },
    {
      "type": "training",
      "description": "Training step 295",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:41",
      "total_flops_so_far": 423604230045696.0,
      "budget_used_percent": 0.42360423004569603
    },
    {
      "type": "training",
      "description": "Training step 296",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:41",
      "total_flops_so_far": 425035325417472.0,
      "budget_used_percent": 0.42503532541747197
    },
    {
      "type": "training",
      "description": "Training step 297",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:41",
      "total_flops_so_far": 426466420789248.0,
      "budget_used_percent": 0.42646642078924796
    },
    {
      "type": "training",
      "description": "Training step 298",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:42",
      "total_flops_so_far": 427897516161024.0,
      "budget_used_percent": 0.427897516161024
    },
    {
      "type": "training",
      "description": "Training step 299",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:42",
      "total_flops_so_far": 429328611532800.0,
      "budget_used_percent": 0.4293286115328
    },
    {
      "type": "training",
      "description": "Training step 300",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:42",
      "total_flops_so_far": 430759706904576.0,
      "budget_used_percent": 0.43075970690457605
    },
    {
      "type": "training",
      "description": "Training step 301",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:42",
      "total_flops_so_far": 432190802276352.0,
      "budget_used_percent": 0.43219080227635204
    },
    {
      "type": "training",
      "description": "Training step 302",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:42",
      "total_flops_so_far": 433621897648128.0,
      "budget_used_percent": 0.433621897648128
    },
    {
      "type": "training",
      "description": "Training step 303",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:42",
      "total_flops_so_far": 435052993019904.0,
      "budget_used_percent": 0.43505299301990397
    },
    {
      "type": "training",
      "description": "Training step 304",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:42",
      "total_flops_so_far": 436484088391680.0,
      "budget_used_percent": 0.43648408839168
    },
    {
      "type": "training",
      "description": "Training step 305",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:42",
      "total_flops_so_far": 437915183763456.0,
      "budget_used_percent": 0.437915183763456
    },
    {
      "type": "training",
      "description": "Training step 306",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:43",
      "total_flops_so_far": 439346279135232.0,
      "budget_used_percent": 0.43934627913523205
    },
    {
      "type": "training",
      "description": "Training step 307",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:43",
      "total_flops_so_far": 440777374507008.0,
      "budget_used_percent": 0.440777374507008
    },
    {
      "type": "training",
      "description": "Training step 308",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:43",
      "total_flops_so_far": 442208469878784.0,
      "budget_used_percent": 0.442208469878784
    },
    {
      "type": "training",
      "description": "Training step 309",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:43",
      "total_flops_so_far": 443639565250560.0,
      "budget_used_percent": 0.44363956525056
    },
    {
      "type": "training",
      "description": "Training step 310",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:43",
      "total_flops_so_far": 445070660622336.0,
      "budget_used_percent": 0.445070660622336
    },
    {
      "type": "training",
      "description": "Training step 311",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:43",
      "total_flops_so_far": 446501755994112.0,
      "budget_used_percent": 0.446501755994112
    },
    {
      "type": "training",
      "description": "Training step 312",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:43",
      "total_flops_so_far": 447932851365888.0,
      "budget_used_percent": 0.44793285136588795
    },
    {
      "type": "training",
      "description": "Training step 313",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:43",
      "total_flops_so_far": 449363946737664.0,
      "budget_used_percent": 0.449363946737664
    },
    {
      "type": "training",
      "description": "Training step 314",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:44",
      "total_flops_so_far": 450795042109440.0,
      "budget_used_percent": 0.45079504210944
    },
    {
      "type": "training",
      "description": "Training step 315",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:44",
      "total_flops_so_far": 452226137481216.0,
      "budget_used_percent": 0.452226137481216
    },
    {
      "type": "training",
      "description": "Training step 316",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:44",
      "total_flops_so_far": 453657232852992.0,
      "budget_used_percent": 0.45365723285299203
    },
    {
      "type": "training",
      "description": "Training step 317",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:44",
      "total_flops_so_far": 455088328224768.0,
      "budget_used_percent": 0.45508832822476797
    },
    {
      "type": "training",
      "description": "Training step 318",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:44",
      "total_flops_so_far": 456519423596544.0,
      "budget_used_percent": 0.45651942359654396
    },
    {
      "type": "training",
      "description": "Training step 319",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:44",
      "total_flops_so_far": 457950518968320.0,
      "budget_used_percent": 0.45795051896832
    },
    {
      "type": "training",
      "description": "Training step 320",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:44",
      "total_flops_so_far": 459381614340096.0,
      "budget_used_percent": 0.459381614340096
    },
    {
      "type": "training",
      "description": "Training step 321",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:44",
      "total_flops_so_far": 460812709711872.0,
      "budget_used_percent": 0.46081270971187205
    },
    {
      "type": "training",
      "description": "Training step 322",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:45",
      "total_flops_so_far": 462243805083648.0,
      "budget_used_percent": 0.46224380508364804
    },
    {
      "type": "training",
      "description": "Training step 323",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:45",
      "total_flops_so_far": 463674900455424.0,
      "budget_used_percent": 0.463674900455424
    },
    {
      "type": "training",
      "description": "Training step 324",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:45",
      "total_flops_so_far": 465105995827200.0,
      "budget_used_percent": 0.46510599582719997
    },
    {
      "type": "training",
      "description": "Training step 325",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:45",
      "total_flops_so_far": 466537091198976.0,
      "budget_used_percent": 0.466537091198976
    },
    {
      "type": "training",
      "description": "Training step 326",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:45",
      "total_flops_so_far": 467968186570752.0,
      "budget_used_percent": 0.467968186570752
    },
    {
      "type": "training",
      "description": "Training step 327",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:45",
      "total_flops_so_far": 469399281942528.0,
      "budget_used_percent": 0.46939928194252806
    },
    {
      "type": "training",
      "description": "Training step 328",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:45",
      "total_flops_so_far": 470830377314304.0,
      "budget_used_percent": 0.470830377314304
    },
    {
      "type": "training",
      "description": "Training step 329",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:45",
      "total_flops_so_far": 472261472686080.0,
      "budget_used_percent": 0.47226147268608
    },
    {
      "type": "training",
      "description": "Training step 330",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:46",
      "total_flops_so_far": 473692568057856.0,
      "budget_used_percent": 0.473692568057856
    },
    {
      "type": "training",
      "description": "Training step 331",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:46",
      "total_flops_so_far": 475123663429632.0,
      "budget_used_percent": 0.475123663429632
    },
    {
      "type": "training",
      "description": "Training step 332",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:46",
      "total_flops_so_far": 476554758801408.0,
      "budget_used_percent": 0.476554758801408
    },
    {
      "type": "training",
      "description": "Training step 333",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:46",
      "total_flops_so_far": 477985854173184.0,
      "budget_used_percent": 0.47798585417318395
    },
    {
      "type": "training",
      "description": "Training step 334",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:46",
      "total_flops_so_far": 479416949544960.0,
      "budget_used_percent": 0.47941694954496
    },
    {
      "type": "training",
      "description": "Training step 335",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:46",
      "total_flops_so_far": 480848044916736.0,
      "budget_used_percent": 0.480848044916736
    },
    {
      "type": "training",
      "description": "Training step 336",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:46",
      "total_flops_so_far": 482279140288512.0,
      "budget_used_percent": 0.482279140288512
    },
    {
      "type": "training",
      "description": "Training step 337",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:46",
      "total_flops_so_far": 483710235660288.0,
      "budget_used_percent": 0.48371023566028803
    },
    {
      "type": "training",
      "description": "Training step 338",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:47",
      "total_flops_so_far": 485141331032064.0,
      "budget_used_percent": 0.48514133103206397
    },
    {
      "type": "training",
      "description": "Training step 339",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:47",
      "total_flops_so_far": 486572426403840.0,
      "budget_used_percent": 0.48657242640383996
    },
    {
      "type": "training",
      "description": "Training step 340",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:47",
      "total_flops_so_far": 488003521775616.0,
      "budget_used_percent": 0.488003521775616
    },
    {
      "type": "training",
      "description": "Training step 341",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:47",
      "total_flops_so_far": 489434617147392.0,
      "budget_used_percent": 0.489434617147392
    },
    {
      "type": "training",
      "description": "Training step 342",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:47",
      "total_flops_so_far": 490865712519168.0,
      "budget_used_percent": 0.490865712519168
    },
    {
      "type": "training",
      "description": "Training step 343",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:47",
      "total_flops_so_far": 492296807890944.0,
      "budget_used_percent": 0.49229680789094404
    },
    {
      "type": "training",
      "description": "Training step 344",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:47",
      "total_flops_so_far": 493727903262720.0,
      "budget_used_percent": 0.49372790326272
    },
    {
      "type": "training",
      "description": "Training step 345",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:47",
      "total_flops_so_far": 495158998634496.0,
      "budget_used_percent": 0.495158998634496
    },
    {
      "type": "training",
      "description": "Training step 346",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:48",
      "total_flops_so_far": 496590094006272.0,
      "budget_used_percent": 0.496590094006272
    },
    {
      "type": "training",
      "description": "Training step 347",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:48",
      "total_flops_so_far": 498021189378048.0,
      "budget_used_percent": 0.498021189378048
    },
    {
      "type": "training",
      "description": "Training step 348",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:48",
      "total_flops_so_far": 499452284749824.0,
      "budget_used_percent": 0.49945228474982406
    },
    {
      "type": "training",
      "description": "Training step 349",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:48",
      "total_flops_so_far": 500883380121600.0,
      "budget_used_percent": 0.5008833801215999
    },
    {
      "type": "training",
      "description": "Training step 350",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:48",
      "total_flops_so_far": 502314475493376.0,
      "budget_used_percent": 0.5023144754933759
    },
    {
      "type": "training",
      "description": "Training step 351",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:48",
      "total_flops_so_far": 503745570865152.0,
      "budget_used_percent": 0.503745570865152
    },
    {
      "type": "training",
      "description": "Training step 352",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:48",
      "total_flops_so_far": 505176666236928.0,
      "budget_used_percent": 0.505176666236928
    },
    {
      "type": "training",
      "description": "Training step 353",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:48",
      "total_flops_so_far": 506607761608704.0,
      "budget_used_percent": 0.506607761608704
    },
    {
      "type": "training",
      "description": "Training step 354",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:49",
      "total_flops_so_far": 508038856980480.0,
      "budget_used_percent": 0.50803885698048
    },
    {
      "type": "training",
      "description": "Training step 355",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:49",
      "total_flops_so_far": 509469952352256.0,
      "budget_used_percent": 0.509469952352256
    },
    {
      "type": "training",
      "description": "Training step 356",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:49",
      "total_flops_so_far": 510901047724032.0,
      "budget_used_percent": 0.510901047724032
    },
    {
      "type": "training",
      "description": "Training step 357",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:49",
      "total_flops_so_far": 512332143095808.0,
      "budget_used_percent": 0.512332143095808
    },
    {
      "type": "training",
      "description": "Training step 358",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:49",
      "total_flops_so_far": 513763238467584.0,
      "budget_used_percent": 0.513763238467584
    },
    {
      "type": "training",
      "description": "Training step 359",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:49",
      "total_flops_so_far": 515194333839360.0,
      "budget_used_percent": 0.51519433383936
    },
    {
      "type": "training",
      "description": "Training step 360",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:49",
      "total_flops_so_far": 516625429211136.0,
      "budget_used_percent": 0.516625429211136
    },
    {
      "type": "training",
      "description": "Training step 361",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:49",
      "total_flops_so_far": 518056524582912.0,
      "budget_used_percent": 0.518056524582912
    },
    {
      "type": "training",
      "description": "Training step 362",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:50",
      "total_flops_so_far": 519487619954688.0,
      "budget_used_percent": 0.5194876199546881
    },
    {
      "type": "training",
      "description": "Training step 363",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:50",
      "total_flops_so_far": 520918715326464.0,
      "budget_used_percent": 0.520918715326464
    },
    {
      "type": "training",
      "description": "Training step 364",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:50",
      "total_flops_so_far": 522349810698240.0,
      "budget_used_percent": 0.52234981069824
    },
    {
      "type": "training",
      "description": "Training step 365",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:50",
      "total_flops_so_far": 523780906070016.0,
      "budget_used_percent": 0.5237809060700159
    },
    {
      "type": "training",
      "description": "Training step 366",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:50",
      "total_flops_so_far": 525212001441792.0,
      "budget_used_percent": 0.525212001441792
    },
    {
      "type": "training",
      "description": "Training step 367",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:50",
      "total_flops_so_far": 526643096813568.0,
      "budget_used_percent": 0.526643096813568
    },
    {
      "type": "training",
      "description": "Training step 368",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:50",
      "total_flops_so_far": 528074192185344.0,
      "budget_used_percent": 0.528074192185344
    },
    {
      "type": "training",
      "description": "Training step 369",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:51",
      "total_flops_so_far": 529505287557120.0,
      "budget_used_percent": 0.52950528755712
    },
    {
      "type": "training",
      "description": "Training step 370",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:51",
      "total_flops_so_far": 530936382928896.0,
      "budget_used_percent": 0.530936382928896
    },
    {
      "type": "training",
      "description": "Training step 371",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:51",
      "total_flops_so_far": 532367478300672.0,
      "budget_used_percent": 0.532367478300672
    },
    {
      "type": "training",
      "description": "Training step 372",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:51",
      "total_flops_so_far": 533798573672448.0,
      "budget_used_percent": 0.533798573672448
    },
    {
      "type": "training",
      "description": "Training step 373",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:51",
      "total_flops_so_far": 535229669044224.0,
      "budget_used_percent": 0.535229669044224
    },
    {
      "type": "training",
      "description": "Training step 374",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:51",
      "total_flops_so_far": 536660764416000.0,
      "budget_used_percent": 0.5366607644160001
    },
    {
      "type": "training",
      "description": "Training step 375",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:51",
      "total_flops_so_far": 538091859787776.0,
      "budget_used_percent": 0.538091859787776
    },
    {
      "type": "training",
      "description": "Training step 376",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:51",
      "total_flops_so_far": 539522955159552.0,
      "budget_used_percent": 0.539522955159552
    },
    {
      "type": "training",
      "description": "Training step 377",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:52",
      "total_flops_so_far": 540954050531328.0,
      "budget_used_percent": 0.540954050531328
    },
    {
      "type": "training",
      "description": "Training step 378",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:52",
      "total_flops_so_far": 542385145903104.0,
      "budget_used_percent": 0.542385145903104
    },
    {
      "type": "training",
      "description": "Training step 379",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:52",
      "total_flops_so_far": 543816241274880.0,
      "budget_used_percent": 0.54381624127488
    },
    {
      "type": "training",
      "description": "Training step 380",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:52",
      "total_flops_so_far": 545247336646656.0,
      "budget_used_percent": 0.5452473366466559
    },
    {
      "type": "training",
      "description": "Training step 381",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:52",
      "total_flops_so_far": 546678432018432.0,
      "budget_used_percent": 0.546678432018432
    },
    {
      "type": "training",
      "description": "Training step 382",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:52",
      "total_flops_so_far": 548109527390208.0,
      "budget_used_percent": 0.548109527390208
    },
    {
      "type": "training",
      "description": "Training step 383",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:52",
      "total_flops_so_far": 549540622761984.0,
      "budget_used_percent": 0.549540622761984
    },
    {
      "type": "training",
      "description": "Training step 384",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:52",
      "total_flops_so_far": 550971718133760.0,
      "budget_used_percent": 0.55097171813376
    },
    {
      "type": "training",
      "description": "Training step 385",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:53",
      "total_flops_so_far": 552402813505536.0,
      "budget_used_percent": 0.552402813505536
    },
    {
      "type": "training",
      "description": "Training step 386",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:53",
      "total_flops_so_far": 553833908877312.0,
      "budget_used_percent": 0.553833908877312
    },
    {
      "type": "training",
      "description": "Training step 387",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:53",
      "total_flops_so_far": 555265004249088.0,
      "budget_used_percent": 0.555265004249088
    },
    {
      "type": "training",
      "description": "Training step 388",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:53",
      "total_flops_so_far": 556696099620864.0,
      "budget_used_percent": 0.556696099620864
    },
    {
      "type": "training",
      "description": "Training step 389",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:53",
      "total_flops_so_far": 558127194992640.0,
      "budget_used_percent": 0.5581271949926401
    },
    {
      "type": "training",
      "description": "Training step 390",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:53",
      "total_flops_so_far": 559558290364416.0,
      "budget_used_percent": 0.5595582903644161
    },
    {
      "type": "training",
      "description": "Training step 391",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:53",
      "total_flops_so_far": 560989385736192.0,
      "budget_used_percent": 0.560989385736192
    },
    {
      "type": "training",
      "description": "Training step 392",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:53",
      "total_flops_so_far": 562420481107968.0,
      "budget_used_percent": 0.5624204811079679
    },
    {
      "type": "training",
      "description": "Training step 393",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:54",
      "total_flops_so_far": 563851576479744.0,
      "budget_used_percent": 0.563851576479744
    },
    {
      "type": "training",
      "description": "Training step 394",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:54",
      "total_flops_so_far": 565282671851520.0,
      "budget_used_percent": 0.56528267185152
    },
    {
      "type": "training",
      "description": "Training step 395",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:54",
      "total_flops_so_far": 566713767223296.0,
      "budget_used_percent": 0.566713767223296
    },
    {
      "type": "training",
      "description": "Training step 396",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:54",
      "total_flops_so_far": 568144862595072.0,
      "budget_used_percent": 0.5681448625950719
    },
    {
      "type": "training",
      "description": "Training step 397",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:54",
      "total_flops_so_far": 569575957966848.0,
      "budget_used_percent": 0.569575957966848
    },
    {
      "type": "training",
      "description": "Training step 398",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:54",
      "total_flops_so_far": 571007053338624.0,
      "budget_used_percent": 0.571007053338624
    },
    {
      "type": "training",
      "description": "Training step 399",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:55",
      "total_flops_so_far": 572438148710400.0,
      "budget_used_percent": 0.5724381487104
    },
    {
      "type": "training",
      "description": "Training step 400",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:55",
      "total_flops_so_far": 573869244082176.0,
      "budget_used_percent": 0.573869244082176
    },
    {
      "type": "training",
      "description": "Training step 401",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:55",
      "total_flops_so_far": 575300339453952.0,
      "budget_used_percent": 0.575300339453952
    },
    {
      "type": "training",
      "description": "Training step 402",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:55",
      "total_flops_so_far": 576731434825728.0,
      "budget_used_percent": 0.576731434825728
    },
    {
      "type": "training",
      "description": "Training step 403",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:55",
      "total_flops_so_far": 578162530197504.0,
      "budget_used_percent": 0.578162530197504
    },
    {
      "type": "training",
      "description": "Training step 404",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:55",
      "total_flops_so_far": 579593625569280.0,
      "budget_used_percent": 0.57959362556928
    },
    {
      "type": "training",
      "description": "Training step 405",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:55",
      "total_flops_so_far": 581024720941056.0,
      "budget_used_percent": 0.5810247209410561
    },
    {
      "type": "training",
      "description": "Training step 406",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:55",
      "total_flops_so_far": 582455816312832.0,
      "budget_used_percent": 0.582455816312832
    },
    {
      "type": "training",
      "description": "Training step 407",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:56",
      "total_flops_so_far": 583886911684608.0,
      "budget_used_percent": 0.5838869116846079
    },
    {
      "type": "training",
      "description": "Training step 408",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:56",
      "total_flops_so_far": 585318007056384.0,
      "budget_used_percent": 0.585318007056384
    },
    {
      "type": "training",
      "description": "Training step 409",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:56",
      "total_flops_so_far": 586749102428160.0,
      "budget_used_percent": 0.58674910242816
    },
    {
      "type": "training",
      "description": "Training step 410",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:56",
      "total_flops_so_far": 588180197799936.0,
      "budget_used_percent": 0.588180197799936
    },
    {
      "type": "training",
      "description": "Training step 411",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:56",
      "total_flops_so_far": 589611293171712.0,
      "budget_used_percent": 0.589611293171712
    },
    {
      "type": "training",
      "description": "Training step 412",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:56",
      "total_flops_so_far": 591042388543488.0,
      "budget_used_percent": 0.591042388543488
    },
    {
      "type": "training",
      "description": "Training step 413",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:56",
      "total_flops_so_far": 592473483915264.0,
      "budget_used_percent": 0.592473483915264
    },
    {
      "type": "training",
      "description": "Training step 414",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:56",
      "total_flops_so_far": 593904579287040.0,
      "budget_used_percent": 0.59390457928704
    },
    {
      "type": "training",
      "description": "Training step 415",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:57",
      "total_flops_so_far": 595335674658816.0,
      "budget_used_percent": 0.595335674658816
    },
    {
      "type": "training",
      "description": "Training step 416",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:57",
      "total_flops_so_far": 596766770030592.0,
      "budget_used_percent": 0.5967667700305921
    },
    {
      "type": "training",
      "description": "Training step 417",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:57",
      "total_flops_so_far": 598197865402368.0,
      "budget_used_percent": 0.598197865402368
    },
    {
      "type": "training",
      "description": "Training step 418",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:57",
      "total_flops_so_far": 599628960774144.0,
      "budget_used_percent": 0.599628960774144
    },
    {
      "type": "training",
      "description": "Training step 419",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:57",
      "total_flops_so_far": 601060056145920.0,
      "budget_used_percent": 0.60106005614592
    },
    {
      "type": "training",
      "description": "Training step 420",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:57",
      "total_flops_so_far": 602491151517696.0,
      "budget_used_percent": 0.602491151517696
    },
    {
      "type": "training",
      "description": "Training step 421",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:57",
      "total_flops_so_far": 603922246889472.0,
      "budget_used_percent": 0.603922246889472
    },
    {
      "type": "training",
      "description": "Training step 422",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:57",
      "total_flops_so_far": 605353342261248.0,
      "budget_used_percent": 0.605353342261248
    },
    {
      "type": "training",
      "description": "Training step 423",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:58",
      "total_flops_so_far": 606784437633024.0,
      "budget_used_percent": 0.6067844376330239
    },
    {
      "type": "training",
      "description": "Training step 424",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:58",
      "total_flops_so_far": 608215533004800.0,
      "budget_used_percent": 0.6082155330048
    },
    {
      "type": "training",
      "description": "Training step 425",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:58",
      "total_flops_so_far": 609646628376576.0,
      "budget_used_percent": 0.609646628376576
    },
    {
      "type": "training",
      "description": "Training step 426",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:58",
      "total_flops_so_far": 611077723748352.0,
      "budget_used_percent": 0.611077723748352
    },
    {
      "type": "training",
      "description": "Training step 427",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:58",
      "total_flops_so_far": 612508819120128.0,
      "budget_used_percent": 0.612508819120128
    },
    {
      "type": "training",
      "description": "Training step 428",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:58",
      "total_flops_so_far": 613939914491904.0,
      "budget_used_percent": 0.613939914491904
    },
    {
      "type": "training",
      "description": "Training step 429",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:58",
      "total_flops_so_far": 615371009863680.0,
      "budget_used_percent": 0.61537100986368
    },
    {
      "type": "training",
      "description": "Training step 430",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:58",
      "total_flops_so_far": 616802105235456.0,
      "budget_used_percent": 0.616802105235456
    },
    {
      "type": "training",
      "description": "Training step 431",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:59",
      "total_flops_so_far": 618233200607232.0,
      "budget_used_percent": 0.618233200607232
    },
    {
      "type": "training",
      "description": "Training step 432",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:59",
      "total_flops_so_far": 619664295979008.0,
      "budget_used_percent": 0.6196642959790081
    },
    {
      "type": "training",
      "description": "Training step 433",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:59",
      "total_flops_so_far": 621095391350784.0,
      "budget_used_percent": 0.621095391350784
    },
    {
      "type": "training",
      "description": "Training step 434",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:59",
      "total_flops_so_far": 622526486722560.0,
      "budget_used_percent": 0.62252648672256
    },
    {
      "type": "training",
      "description": "Training step 435",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:59",
      "total_flops_so_far": 623957582094336.0,
      "budget_used_percent": 0.623957582094336
    },
    {
      "type": "training",
      "description": "Training step 436",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:59",
      "total_flops_so_far": 625388677466112.0,
      "budget_used_percent": 0.625388677466112
    },
    {
      "type": "training",
      "description": "Training step 437",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:59",
      "total_flops_so_far": 626819772837888.0,
      "budget_used_percent": 0.626819772837888
    },
    {
      "type": "training",
      "description": "Training step 438",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:38:59",
      "total_flops_so_far": 628250868209664.0,
      "budget_used_percent": 0.6282508682096639
    },
    {
      "type": "training",
      "description": "Training step 439",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:00",
      "total_flops_so_far": 629681963581440.0,
      "budget_used_percent": 0.62968196358144
    },
    {
      "type": "training",
      "description": "Training step 440",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:00",
      "total_flops_so_far": 631113058953216.0,
      "budget_used_percent": 0.631113058953216
    },
    {
      "type": "training",
      "description": "Training step 441",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:00",
      "total_flops_so_far": 632544154324992.0,
      "budget_used_percent": 0.632544154324992
    },
    {
      "type": "training",
      "description": "Training step 442",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:00",
      "total_flops_so_far": 633975249696768.0,
      "budget_used_percent": 0.633975249696768
    },
    {
      "type": "training",
      "description": "Training step 443",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:00",
      "total_flops_so_far": 635406345068544.0,
      "budget_used_percent": 0.6354063450685441
    },
    {
      "type": "training",
      "description": "Training step 444",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:00",
      "total_flops_so_far": 636837440440320.0,
      "budget_used_percent": 0.63683744044032
    },
    {
      "type": "training",
      "description": "Training step 445",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:00",
      "total_flops_so_far": 638268535812096.0,
      "budget_used_percent": 0.638268535812096
    },
    {
      "type": "training",
      "description": "Training step 446",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:01",
      "total_flops_so_far": 639699631183872.0,
      "budget_used_percent": 0.639699631183872
    },
    {
      "type": "training",
      "description": "Training step 447",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:01",
      "total_flops_so_far": 641130726555648.0,
      "budget_used_percent": 0.6411307265556481
    },
    {
      "type": "training",
      "description": "Training step 448",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:01",
      "total_flops_so_far": 642561821927424.0,
      "budget_used_percent": 0.6425618219274241
    },
    {
      "type": "training",
      "description": "Training step 449",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:01",
      "total_flops_so_far": 643992917299200.0,
      "budget_used_percent": 0.6439929172991999
    },
    {
      "type": "training",
      "description": "Training step 450",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:01",
      "total_flops_so_far": 645424012670976.0,
      "budget_used_percent": 0.6454240126709759
    },
    {
      "type": "training",
      "description": "Training step 451",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:01",
      "total_flops_so_far": 646855108042752.0,
      "budget_used_percent": 0.646855108042752
    },
    {
      "type": "training",
      "description": "Training step 452",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:01",
      "total_flops_so_far": 648286203414528.0,
      "budget_used_percent": 0.648286203414528
    },
    {
      "type": "training",
      "description": "Training step 453",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:01",
      "total_flops_so_far": 649717298786304.0,
      "budget_used_percent": 0.649717298786304
    },
    {
      "type": "training",
      "description": "Training step 454",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:02",
      "total_flops_so_far": 651148394158080.0,
      "budget_used_percent": 0.65114839415808
    },
    {
      "type": "training",
      "description": "Training step 455",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:02",
      "total_flops_so_far": 652579489529856.0,
      "budget_used_percent": 0.652579489529856
    },
    {
      "type": "training",
      "description": "Training step 456",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:02",
      "total_flops_so_far": 654010584901632.0,
      "budget_used_percent": 0.654010584901632
    },
    {
      "type": "training",
      "description": "Training step 457",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:02",
      "total_flops_so_far": 655441680273408.0,
      "budget_used_percent": 0.655441680273408
    },
    {
      "type": "training",
      "description": "Training step 458",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:02",
      "total_flops_so_far": 656872775645184.0,
      "budget_used_percent": 0.656872775645184
    },
    {
      "type": "training",
      "description": "Training step 459",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:02",
      "total_flops_so_far": 658303871016960.0,
      "budget_used_percent": 0.65830387101696
    },
    {
      "type": "training",
      "description": "Training step 460",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:02",
      "total_flops_so_far": 659734966388736.0,
      "budget_used_percent": 0.659734966388736
    },
    {
      "type": "training",
      "description": "Training step 461",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:02",
      "total_flops_so_far": 661166061760512.0,
      "budget_used_percent": 0.661166061760512
    },
    {
      "type": "training",
      "description": "Training step 462",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:03",
      "total_flops_so_far": 662597157132288.0,
      "budget_used_percent": 0.6625971571322881
    },
    {
      "type": "training",
      "description": "Training step 463",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:03",
      "total_flops_so_far": 664028252504064.0,
      "budget_used_percent": 0.664028252504064
    },
    {
      "type": "training",
      "description": "Training step 464",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:03",
      "total_flops_so_far": 665459347875840.0,
      "budget_used_percent": 0.66545934787584
    },
    {
      "type": "training",
      "description": "Training step 465",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:03",
      "total_flops_so_far": 666890443247616.0,
      "budget_used_percent": 0.6668904432476159
    },
    {
      "type": "training",
      "description": "Training step 466",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:03",
      "total_flops_so_far": 668321538619392.0,
      "budget_used_percent": 0.668321538619392
    },
    {
      "type": "training",
      "description": "Training step 467",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:03",
      "total_flops_so_far": 669752633991168.0,
      "budget_used_percent": 0.669752633991168
    },
    {
      "type": "training",
      "description": "Training step 468",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:03",
      "total_flops_so_far": 671183729362944.0,
      "budget_used_percent": 0.671183729362944
    },
    {
      "type": "training",
      "description": "Training step 469",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:03",
      "total_flops_so_far": 672614824734720.0,
      "budget_used_percent": 0.67261482473472
    },
    {
      "type": "training",
      "description": "Training step 470",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:04",
      "total_flops_so_far": 674045920106496.0,
      "budget_used_percent": 0.674045920106496
    },
    {
      "type": "training",
      "description": "Training step 471",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:04",
      "total_flops_so_far": 675477015478272.0,
      "budget_used_percent": 0.675477015478272
    },
    {
      "type": "training",
      "description": "Training step 472",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:04",
      "total_flops_so_far": 676908110850048.0,
      "budget_used_percent": 0.676908110850048
    },
    {
      "type": "training",
      "description": "Training step 473",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:04",
      "total_flops_so_far": 678339206221824.0,
      "budget_used_percent": 0.678339206221824
    },
    {
      "type": "training",
      "description": "Training step 474",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:04",
      "total_flops_so_far": 679770301593600.0,
      "budget_used_percent": 0.6797703015936001
    },
    {
      "type": "training",
      "description": "Training step 475",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:04",
      "total_flops_so_far": 681201396965376.0,
      "budget_used_percent": 0.681201396965376
    },
    {
      "type": "training",
      "description": "Training step 476",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:04",
      "total_flops_so_far": 682632492337152.0,
      "budget_used_percent": 0.682632492337152
    },
    {
      "type": "training",
      "description": "Training step 477",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:04",
      "total_flops_so_far": 684063587708928.0,
      "budget_used_percent": 0.684063587708928
    },
    {
      "type": "training",
      "description": "Training step 478",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:05",
      "total_flops_so_far": 685494683080704.0,
      "budget_used_percent": 0.685494683080704
    },
    {
      "type": "training",
      "description": "Training step 479",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:05",
      "total_flops_so_far": 686925778452480.0,
      "budget_used_percent": 0.68692577845248
    },
    {
      "type": "training",
      "description": "Training step 480",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:05",
      "total_flops_so_far": 688356873824256.0,
      "budget_used_percent": 0.6883568738242559
    },
    {
      "type": "training",
      "description": "Training step 481",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:05",
      "total_flops_so_far": 689787969196032.0,
      "budget_used_percent": 0.689787969196032
    },
    {
      "type": "training",
      "description": "Training step 482",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:05",
      "total_flops_so_far": 691219064567808.0,
      "budget_used_percent": 0.691219064567808
    },
    {
      "type": "training",
      "description": "Training step 483",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:05",
      "total_flops_so_far": 692650159939584.0,
      "budget_used_percent": 0.692650159939584
    },
    {
      "type": "training",
      "description": "Training step 484",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:05",
      "total_flops_so_far": 694081255311360.0,
      "budget_used_percent": 0.69408125531136
    },
    {
      "type": "training",
      "description": "Training step 485",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:06",
      "total_flops_so_far": 695512350683136.0,
      "budget_used_percent": 0.695512350683136
    },
    {
      "type": "training",
      "description": "Training step 486",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:06",
      "total_flops_so_far": 696943446054912.0,
      "budget_used_percent": 0.696943446054912
    },
    {
      "type": "training",
      "description": "Training step 487",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:06",
      "total_flops_so_far": 698374541426688.0,
      "budget_used_percent": 0.698374541426688
    },
    {
      "type": "training",
      "description": "Training step 488",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:06",
      "total_flops_so_far": 699805636798464.0,
      "budget_used_percent": 0.699805636798464
    },
    {
      "type": "training",
      "description": "Training step 489",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:06",
      "total_flops_so_far": 701236732170240.0,
      "budget_used_percent": 0.7012367321702401
    },
    {
      "type": "training",
      "description": "Training step 490",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:06",
      "total_flops_so_far": 702667827542016.0,
      "budget_used_percent": 0.7026678275420161
    },
    {
      "type": "training",
      "description": "Training step 491",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:06",
      "total_flops_so_far": 704098922913792.0,
      "budget_used_percent": 0.704098922913792
    },
    {
      "type": "training",
      "description": "Training step 492",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:06",
      "total_flops_so_far": 705530018285568.0,
      "budget_used_percent": 0.7055300182855679
    },
    {
      "type": "training",
      "description": "Training step 493",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:07",
      "total_flops_so_far": 706961113657344.0,
      "budget_used_percent": 0.706961113657344
    },
    {
      "type": "training",
      "description": "Training step 494",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:07",
      "total_flops_so_far": 708392209029120.0,
      "budget_used_percent": 0.70839220902912
    },
    {
      "type": "training",
      "description": "Training step 495",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:07",
      "total_flops_so_far": 709823304400896.0,
      "budget_used_percent": 0.709823304400896
    },
    {
      "type": "training",
      "description": "Training step 496",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:07",
      "total_flops_so_far": 711254399772672.0,
      "budget_used_percent": 0.7112543997726719
    },
    {
      "type": "training",
      "description": "Training step 497",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:07",
      "total_flops_so_far": 712685495144448.0,
      "budget_used_percent": 0.712685495144448
    },
    {
      "type": "training",
      "description": "Training step 498",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:07",
      "total_flops_so_far": 714116590516224.0,
      "budget_used_percent": 0.714116590516224
    },
    {
      "type": "training",
      "description": "Training step 499",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:07",
      "total_flops_so_far": 715547685888000.0,
      "budget_used_percent": 0.715547685888
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 0",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552080785760.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:09",
      "total_flops_so_far": 716099766673760.0,
      "budget_used_percent": 0.71609976667376
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 1",
      "context_len": 604,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 555682299984.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:10",
      "total_flops_so_far": 716655448973744.0,
      "budget_used_percent": 0.716655448973744
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 2",
      "context_len": 602,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 553881182680.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:11",
      "total_flops_so_far": 717209330156424.0,
      "budget_used_percent": 0.717209330156424
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 3",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552080785760.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:12",
      "total_flops_so_far": 717761410942184.0,
      "budget_used_percent": 0.717761410942184
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 4",
      "context_len": 603,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 554781651284.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:14",
      "total_flops_so_far": 718316192593468.0,
      "budget_used_percent": 0.718316192593468
    },
    {
      "type": "training",
      "description": "Training step 500",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:14",
      "total_flops_so_far": 719747287965244.0,
      "budget_used_percent": 0.719747287965244
    },
    {
      "type": "training",
      "description": "Training step 501",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:14",
      "total_flops_so_far": 721178383337020.0,
      "budget_used_percent": 0.72117838333702
    },
    {
      "type": "training",
      "description": "Training step 502",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:14",
      "total_flops_so_far": 722609478708796.0,
      "budget_used_percent": 0.722609478708796
    },
    {
      "type": "training",
      "description": "Training step 503",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:14",
      "total_flops_so_far": 724040574080572.0,
      "budget_used_percent": 0.724040574080572
    },
    {
      "type": "training",
      "description": "Training step 504",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:15",
      "total_flops_so_far": 725471669452348.0,
      "budget_used_percent": 0.725471669452348
    },
    {
      "type": "training",
      "description": "Training step 505",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:15",
      "total_flops_so_far": 726902764824124.0,
      "budget_used_percent": 0.726902764824124
    },
    {
      "type": "training",
      "description": "Training step 506",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:15",
      "total_flops_so_far": 728333860195900.0,
      "budget_used_percent": 0.7283338601959001
    },
    {
      "type": "training",
      "description": "Training step 507",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:15",
      "total_flops_so_far": 729764955567676.0,
      "budget_used_percent": 0.729764955567676
    },
    {
      "type": "training",
      "description": "Training step 508",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:15",
      "total_flops_so_far": 731196050939452.0,
      "budget_used_percent": 0.731196050939452
    },
    {
      "type": "training",
      "description": "Training step 509",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:15",
      "total_flops_so_far": 732627146311228.0,
      "budget_used_percent": 0.7326271463112279
    },
    {
      "type": "training",
      "description": "Training step 510",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:15",
      "total_flops_so_far": 734058241683004.0,
      "budget_used_percent": 0.734058241683004
    },
    {
      "type": "training",
      "description": "Training step 511",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:16",
      "total_flops_so_far": 735489337054780.0,
      "budget_used_percent": 0.73548933705478
    },
    {
      "type": "training",
      "description": "Training step 512",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:16",
      "total_flops_so_far": 736920432426556.0,
      "budget_used_percent": 0.7369204324265559
    },
    {
      "type": "training",
      "description": "Training step 513",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:16",
      "total_flops_so_far": 738351527798332.0,
      "budget_used_percent": 0.738351527798332
    },
    {
      "type": "training",
      "description": "Training step 514",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:16",
      "total_flops_so_far": 739782623170108.0,
      "budget_used_percent": 0.739782623170108
    },
    {
      "type": "training",
      "description": "Training step 515",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:16",
      "total_flops_so_far": 741213718541884.0,
      "budget_used_percent": 0.741213718541884
    },
    {
      "type": "training",
      "description": "Training step 516",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:16",
      "total_flops_so_far": 742644813913660.0,
      "budget_used_percent": 0.74264481391366
    },
    {
      "type": "training",
      "description": "Training step 517",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:16",
      "total_flops_so_far": 744075909285436.0,
      "budget_used_percent": 0.744075909285436
    },
    {
      "type": "training",
      "description": "Training step 518",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:16",
      "total_flops_so_far": 745507004657212.0,
      "budget_used_percent": 0.745507004657212
    },
    {
      "type": "training",
      "description": "Training step 519",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:17",
      "total_flops_so_far": 746938100028988.0,
      "budget_used_percent": 0.746938100028988
    },
    {
      "type": "training",
      "description": "Training step 520",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:17",
      "total_flops_so_far": 748369195400764.0,
      "budget_used_percent": 0.748369195400764
    },
    {
      "type": "training",
      "description": "Training step 521",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:17",
      "total_flops_so_far": 749800290772540.0,
      "budget_used_percent": 0.7498002907725401
    },
    {
      "type": "training",
      "description": "Training step 522",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:17",
      "total_flops_so_far": 751231386144316.0,
      "budget_used_percent": 0.7512313861443161
    },
    {
      "type": "training",
      "description": "Training step 523",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:17",
      "total_flops_so_far": 752662481516092.0,
      "budget_used_percent": 0.7526624815160919
    },
    {
      "type": "training",
      "description": "Training step 524",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:17",
      "total_flops_so_far": 754093576887868.0,
      "budget_used_percent": 0.7540935768878679
    },
    {
      "type": "training",
      "description": "Training step 525",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:17",
      "total_flops_so_far": 755524672259644.0,
      "budget_used_percent": 0.755524672259644
    },
    {
      "type": "training",
      "description": "Training step 526",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:17",
      "total_flops_so_far": 756955767631420.0,
      "budget_used_percent": 0.75695576763142
    },
    {
      "type": "training",
      "description": "Training step 527",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:18",
      "total_flops_so_far": 758386863003196.0,
      "budget_used_percent": 0.758386863003196
    },
    {
      "type": "training",
      "description": "Training step 528",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:18",
      "total_flops_so_far": 759817958374972.0,
      "budget_used_percent": 0.759817958374972
    },
    {
      "type": "training",
      "description": "Training step 529",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:18",
      "total_flops_so_far": 761249053746748.0,
      "budget_used_percent": 0.761249053746748
    },
    {
      "type": "training",
      "description": "Training step 530",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:18",
      "total_flops_so_far": 762680149118524.0,
      "budget_used_percent": 0.762680149118524
    },
    {
      "type": "training",
      "description": "Training step 531",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:18",
      "total_flops_so_far": 764111244490300.0,
      "budget_used_percent": 0.7641112444903
    },
    {
      "type": "training",
      "description": "Training step 532",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:18",
      "total_flops_so_far": 765542339862076.0,
      "budget_used_percent": 0.765542339862076
    },
    {
      "type": "training",
      "description": "Training step 533",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:18",
      "total_flops_so_far": 766973435233852.0,
      "budget_used_percent": 0.766973435233852
    },
    {
      "type": "training",
      "description": "Training step 534",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:19",
      "total_flops_so_far": 768404530605628.0,
      "budget_used_percent": 0.768404530605628
    },
    {
      "type": "training",
      "description": "Training step 535",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:19",
      "total_flops_so_far": 769835625977404.0,
      "budget_used_percent": 0.769835625977404
    },
    {
      "type": "training",
      "description": "Training step 536",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:19",
      "total_flops_so_far": 771266721349180.0,
      "budget_used_percent": 0.77126672134918
    },
    {
      "type": "training",
      "description": "Training step 537",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:19",
      "total_flops_so_far": 772697816720956.0,
      "budget_used_percent": 0.772697816720956
    },
    {
      "type": "training",
      "description": "Training step 538",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:19",
      "total_flops_so_far": 774128912092732.0,
      "budget_used_percent": 0.774128912092732
    },
    {
      "type": "training",
      "description": "Training step 539",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:19",
      "total_flops_so_far": 775560007464508.0,
      "budget_used_percent": 0.7755600074645079
    },
    {
      "type": "training",
      "description": "Training step 540",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:19",
      "total_flops_so_far": 776991102836284.0,
      "budget_used_percent": 0.776991102836284
    },
    {
      "type": "training",
      "description": "Training step 541",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:19",
      "total_flops_so_far": 778422198208060.0,
      "budget_used_percent": 0.77842219820806
    },
    {
      "type": "training",
      "description": "Training step 542",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:20",
      "total_flops_so_far": 779853293579836.0,
      "budget_used_percent": 0.779853293579836
    },
    {
      "type": "training",
      "description": "Training step 543",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:20",
      "total_flops_so_far": 781284388951612.0,
      "budget_used_percent": 0.781284388951612
    },
    {
      "type": "training",
      "description": "Training step 544",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:20",
      "total_flops_so_far": 782715484323388.0,
      "budget_used_percent": 0.782715484323388
    },
    {
      "type": "training",
      "description": "Training step 545",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:20",
      "total_flops_so_far": 784146579695164.0,
      "budget_used_percent": 0.7841465796951641
    },
    {
      "type": "training",
      "description": "Training step 546",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:20",
      "total_flops_so_far": 785577675066940.0,
      "budget_used_percent": 0.78557767506694
    },
    {
      "type": "training",
      "description": "Training step 547",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:20",
      "total_flops_so_far": 787008770438716.0,
      "budget_used_percent": 0.787008770438716
    },
    {
      "type": "training",
      "description": "Training step 548",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:20",
      "total_flops_so_far": 788439865810492.0,
      "budget_used_percent": 0.7884398658104921
    },
    {
      "type": "training",
      "description": "Training step 549",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:20",
      "total_flops_so_far": 789870961182268.0,
      "budget_used_percent": 0.789870961182268
    },
    {
      "type": "training",
      "description": "Training step 550",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:21",
      "total_flops_so_far": 791302056554044.0,
      "budget_used_percent": 0.7913020565540441
    },
    {
      "type": "training",
      "description": "Training step 551",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:21",
      "total_flops_so_far": 792733151925820.0,
      "budget_used_percent": 0.79273315192582
    },
    {
      "type": "training",
      "description": "Training step 552",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:21",
      "total_flops_so_far": 794164247297596.0,
      "budget_used_percent": 0.7941642472975959
    },
    {
      "type": "training",
      "description": "Training step 553",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:21",
      "total_flops_so_far": 795595342669372.0,
      "budget_used_percent": 0.795595342669372
    },
    {
      "type": "training",
      "description": "Training step 554",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:21",
      "total_flops_so_far": 797026438041148.0,
      "budget_used_percent": 0.7970264380411479
    },
    {
      "type": "training",
      "description": "Training step 555",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:21",
      "total_flops_so_far": 798457533412924.0,
      "budget_used_percent": 0.798457533412924
    },
    {
      "type": "training",
      "description": "Training step 556",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:21",
      "total_flops_so_far": 799888628784700.0,
      "budget_used_percent": 0.7998886287847
    },
    {
      "type": "training",
      "description": "Training step 557",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:22",
      "total_flops_so_far": 801319724156476.0,
      "budget_used_percent": 0.8013197241564759
    },
    {
      "type": "training",
      "description": "Training step 558",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:22",
      "total_flops_so_far": 802750819528252.0,
      "budget_used_percent": 0.802750819528252
    },
    {
      "type": "training",
      "description": "Training step 559",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:22",
      "total_flops_so_far": 804181914900028.0,
      "budget_used_percent": 0.804181914900028
    },
    {
      "type": "training",
      "description": "Training step 560",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:22",
      "total_flops_so_far": 805613010271804.0,
      "budget_used_percent": 0.8056130102718041
    },
    {
      "type": "training",
      "description": "Training step 561",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:22",
      "total_flops_so_far": 807044105643580.0,
      "budget_used_percent": 0.80704410564358
    },
    {
      "type": "training",
      "description": "Training step 562",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:22",
      "total_flops_so_far": 808475201015356.0,
      "budget_used_percent": 0.808475201015356
    },
    {
      "type": "training",
      "description": "Training step 563",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:22",
      "total_flops_so_far": 809906296387132.0,
      "budget_used_percent": 0.809906296387132
    },
    {
      "type": "training",
      "description": "Training step 564",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:22",
      "total_flops_so_far": 811337391758908.0,
      "budget_used_percent": 0.811337391758908
    },
    {
      "type": "training",
      "description": "Training step 565",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:23",
      "total_flops_so_far": 812768487130684.0,
      "budget_used_percent": 0.8127684871306841
    },
    {
      "type": "training",
      "description": "Training step 566",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:23",
      "total_flops_so_far": 814199582502460.0,
      "budget_used_percent": 0.8141995825024599
    },
    {
      "type": "training",
      "description": "Training step 567",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:23",
      "total_flops_so_far": 815630677874236.0,
      "budget_used_percent": 0.815630677874236
    },
    {
      "type": "training",
      "description": "Training step 568",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:23",
      "total_flops_so_far": 817061773246012.0,
      "budget_used_percent": 0.817061773246012
    },
    {
      "type": "training",
      "description": "Training step 569",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:23",
      "total_flops_so_far": 818492868617788.0,
      "budget_used_percent": 0.8184928686177879
    },
    {
      "type": "training",
      "description": "Training step 570",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:23",
      "total_flops_so_far": 819923963989564.0,
      "budget_used_percent": 0.819923963989564
    },
    {
      "type": "training",
      "description": "Training step 571",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:23",
      "total_flops_so_far": 821355059361340.0,
      "budget_used_percent": 0.82135505936134
    },
    {
      "type": "training",
      "description": "Training step 572",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:23",
      "total_flops_so_far": 822786154733116.0,
      "budget_used_percent": 0.8227861547331161
    },
    {
      "type": "training",
      "description": "Training step 573",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:24",
      "total_flops_so_far": 824217250104892.0,
      "budget_used_percent": 0.824217250104892
    },
    {
      "type": "training",
      "description": "Training step 574",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:24",
      "total_flops_so_far": 825648345476668.0,
      "budget_used_percent": 0.825648345476668
    },
    {
      "type": "training",
      "description": "Training step 575",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:24",
      "total_flops_so_far": 827079440848444.0,
      "budget_used_percent": 0.8270794408484441
    },
    {
      "type": "training",
      "description": "Training step 576",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:24",
      "total_flops_so_far": 828510536220220.0,
      "budget_used_percent": 0.82851053622022
    },
    {
      "type": "training",
      "description": "Training step 577",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:24",
      "total_flops_so_far": 829941631591996.0,
      "budget_used_percent": 0.8299416315919961
    },
    {
      "type": "training",
      "description": "Training step 578",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:24",
      "total_flops_so_far": 831372726963772.0,
      "budget_used_percent": 0.831372726963772
    },
    {
      "type": "training",
      "description": "Training step 579",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:24",
      "total_flops_so_far": 832803822335548.0,
      "budget_used_percent": 0.832803822335548
    },
    {
      "type": "training",
      "description": "Training step 580",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:25",
      "total_flops_so_far": 834234917707324.0,
      "budget_used_percent": 0.834234917707324
    },
    {
      "type": "training",
      "description": "Training step 581",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:25",
      "total_flops_so_far": 835666013079100.0,
      "budget_used_percent": 0.8356660130790999
    },
    {
      "type": "training",
      "description": "Training step 582",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:25",
      "total_flops_so_far": 837097108450876.0,
      "budget_used_percent": 0.837097108450876
    },
    {
      "type": "training",
      "description": "Training step 583",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:25",
      "total_flops_so_far": 838528203822652.0,
      "budget_used_percent": 0.838528203822652
    },
    {
      "type": "training",
      "description": "Training step 584",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:25",
      "total_flops_so_far": 839959299194428.0,
      "budget_used_percent": 0.8399592991944279
    },
    {
      "type": "training",
      "description": "Training step 585",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:25",
      "total_flops_so_far": 841390394566204.0,
      "budget_used_percent": 0.841390394566204
    },
    {
      "type": "training",
      "description": "Training step 586",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:25",
      "total_flops_so_far": 842821489937980.0,
      "budget_used_percent": 0.84282148993798
    },
    {
      "type": "training",
      "description": "Training step 587",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:25",
      "total_flops_so_far": 844252585309756.0,
      "budget_used_percent": 0.8442525853097561
    },
    {
      "type": "training",
      "description": "Training step 588",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:26",
      "total_flops_so_far": 845683680681532.0,
      "budget_used_percent": 0.845683680681532
    },
    {
      "type": "training",
      "description": "Training step 589",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:26",
      "total_flops_so_far": 847114776053308.0,
      "budget_used_percent": 0.847114776053308
    },
    {
      "type": "training",
      "description": "Training step 590",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:26",
      "total_flops_so_far": 848545871425084.0,
      "budget_used_percent": 0.848545871425084
    },
    {
      "type": "training",
      "description": "Training step 591",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:26",
      "total_flops_so_far": 849976966796860.0,
      "budget_used_percent": 0.84997696679686
    },
    {
      "type": "training",
      "description": "Training step 592",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:26",
      "total_flops_so_far": 851408062168636.0,
      "budget_used_percent": 0.8514080621686361
    },
    {
      "type": "training",
      "description": "Training step 593",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:26",
      "total_flops_so_far": 852839157540412.0,
      "budget_used_percent": 0.852839157540412
    },
    {
      "type": "training",
      "description": "Training step 594",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:26",
      "total_flops_so_far": 854270252912188.0,
      "budget_used_percent": 0.8542702529121879
    },
    {
      "type": "training",
      "description": "Training step 595",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:26",
      "total_flops_so_far": 855701348283964.0,
      "budget_used_percent": 0.855701348283964
    },
    {
      "type": "training",
      "description": "Training step 596",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:27",
      "total_flops_so_far": 857132443655740.0,
      "budget_used_percent": 0.8571324436557399
    },
    {
      "type": "training",
      "description": "Training step 597",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:27",
      "total_flops_so_far": 858563539027516.0,
      "budget_used_percent": 0.858563539027516
    },
    {
      "type": "training",
      "description": "Training step 598",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:27",
      "total_flops_so_far": 859994634399292.0,
      "budget_used_percent": 0.859994634399292
    },
    {
      "type": "training",
      "description": "Training step 599",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:27",
      "total_flops_so_far": 861425729771068.0,
      "budget_used_percent": 0.8614257297710679
    },
    {
      "type": "training",
      "description": "Training step 600",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:27",
      "total_flops_so_far": 862856825142844.0,
      "budget_used_percent": 0.862856825142844
    },
    {
      "type": "training",
      "description": "Training step 601",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:27",
      "total_flops_so_far": 864287920514620.0,
      "budget_used_percent": 0.86428792051462
    },
    {
      "type": "training",
      "description": "Training step 602",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:27",
      "total_flops_so_far": 865719015886396.0,
      "budget_used_percent": 0.8657190158863961
    },
    {
      "type": "training",
      "description": "Training step 603",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:28",
      "total_flops_so_far": 867150111258172.0,
      "budget_used_percent": 0.867150111258172
    },
    {
      "type": "training",
      "description": "Training step 604",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:28",
      "total_flops_so_far": 868581206629948.0,
      "budget_used_percent": 0.8685812066299479
    },
    {
      "type": "training",
      "description": "Training step 605",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:28",
      "total_flops_so_far": 870012302001724.0,
      "budget_used_percent": 0.870012302001724
    },
    {
      "type": "training",
      "description": "Training step 606",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:28",
      "total_flops_so_far": 871443397373500.0,
      "budget_used_percent": 0.8714433973735
    },
    {
      "type": "training",
      "description": "Training step 607",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:28",
      "total_flops_so_far": 872874492745276.0,
      "budget_used_percent": 0.8728744927452761
    },
    {
      "type": "training",
      "description": "Training step 608",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:28",
      "total_flops_so_far": 874305588117052.0,
      "budget_used_percent": 0.874305588117052
    },
    {
      "type": "training",
      "description": "Training step 609",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:28",
      "total_flops_so_far": 875736683488828.0,
      "budget_used_percent": 0.875736683488828
    },
    {
      "type": "training",
      "description": "Training step 610",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:28",
      "total_flops_so_far": 877167778860604.0,
      "budget_used_percent": 0.877167778860604
    },
    {
      "type": "training",
      "description": "Training step 611",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:29",
      "total_flops_so_far": 878598874232380.0,
      "budget_used_percent": 0.8785988742323799
    },
    {
      "type": "training",
      "description": "Training step 612",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:29",
      "total_flops_so_far": 880029969604156.0,
      "budget_used_percent": 0.880029969604156
    },
    {
      "type": "training",
      "description": "Training step 613",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:29",
      "total_flops_so_far": 881461064975932.0,
      "budget_used_percent": 0.881461064975932
    },
    {
      "type": "training",
      "description": "Training step 614",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:29",
      "total_flops_so_far": 882892160347708.0,
      "budget_used_percent": 0.8828921603477081
    },
    {
      "type": "training",
      "description": "Training step 615",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:29",
      "total_flops_so_far": 884323255719484.0,
      "budget_used_percent": 0.884323255719484
    },
    {
      "type": "training",
      "description": "Training step 616",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:29",
      "total_flops_so_far": 885754351091260.0,
      "budget_used_percent": 0.88575435109126
    },
    {
      "type": "training",
      "description": "Training step 617",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:29",
      "total_flops_so_far": 887185446463036.0,
      "budget_used_percent": 0.887185446463036
    },
    {
      "type": "training",
      "description": "Training step 618",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:30",
      "total_flops_so_far": 888616541834812.0,
      "budget_used_percent": 0.888616541834812
    },
    {
      "type": "training",
      "description": "Training step 619",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:30",
      "total_flops_so_far": 890047637206588.0,
      "budget_used_percent": 0.8900476372065881
    },
    {
      "type": "training",
      "description": "Training step 620",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:30",
      "total_flops_so_far": 891478732578364.0,
      "budget_used_percent": 0.891478732578364
    },
    {
      "type": "training",
      "description": "Training step 621",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:30",
      "total_flops_so_far": 892909827950140.0,
      "budget_used_percent": 0.89290982795014
    },
    {
      "type": "training",
      "description": "Training step 622",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:30",
      "total_flops_so_far": 894340923321916.0,
      "budget_used_percent": 0.8943409233219161
    },
    {
      "type": "training",
      "description": "Training step 623",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:30",
      "total_flops_so_far": 895772018693692.0,
      "budget_used_percent": 0.8957720186936919
    },
    {
      "type": "training",
      "description": "Training step 624",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:30",
      "total_flops_so_far": 897203114065468.0,
      "budget_used_percent": 0.897203114065468
    },
    {
      "type": "training",
      "description": "Training step 625",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:30",
      "total_flops_so_far": 898634209437244.0,
      "budget_used_percent": 0.898634209437244
    },
    {
      "type": "training",
      "description": "Training step 626",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:31",
      "total_flops_so_far": 900065304809020.0,
      "budget_used_percent": 0.9000653048090199
    },
    {
      "type": "training",
      "description": "Training step 627",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:31",
      "total_flops_so_far": 901496400180796.0,
      "budget_used_percent": 0.901496400180796
    },
    {
      "type": "training",
      "description": "Training step 628",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:31",
      "total_flops_so_far": 902927495552572.0,
      "budget_used_percent": 0.902927495552572
    },
    {
      "type": "training",
      "description": "Training step 629",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:31",
      "total_flops_so_far": 904358590924348.0,
      "budget_used_percent": 0.9043585909243481
    },
    {
      "type": "training",
      "description": "Training step 630",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:31",
      "total_flops_so_far": 905789686296124.0,
      "budget_used_percent": 0.905789686296124
    },
    {
      "type": "training",
      "description": "Training step 631",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:31",
      "total_flops_so_far": 907220781667900.0,
      "budget_used_percent": 0.9072207816678999
    },
    {
      "type": "training",
      "description": "Training step 632",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:31",
      "total_flops_so_far": 908651877039676.0,
      "budget_used_percent": 0.908651877039676
    },
    {
      "type": "training",
      "description": "Training step 633",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:32",
      "total_flops_so_far": 910082972411452.0,
      "budget_used_percent": 0.910082972411452
    },
    {
      "type": "training",
      "description": "Training step 634",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:32",
      "total_flops_so_far": 911514067783228.0,
      "budget_used_percent": 0.9115140677832281
    },
    {
      "type": "training",
      "description": "Training step 635",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:32",
      "total_flops_so_far": 912945163155004.0,
      "budget_used_percent": 0.912945163155004
    },
    {
      "type": "training",
      "description": "Training step 636",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:32",
      "total_flops_so_far": 914376258526780.0,
      "budget_used_percent": 0.91437625852678
    },
    {
      "type": "training",
      "description": "Training step 637",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:32",
      "total_flops_so_far": 915807353898556.0,
      "budget_used_percent": 0.915807353898556
    },
    {
      "type": "training",
      "description": "Training step 638",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:32",
      "total_flops_so_far": 917238449270332.0,
      "budget_used_percent": 0.9172384492703319
    },
    {
      "type": "training",
      "description": "Training step 639",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:32",
      "total_flops_so_far": 918669544642108.0,
      "budget_used_percent": 0.918669544642108
    },
    {
      "type": "training",
      "description": "Training step 640",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:32",
      "total_flops_so_far": 920100640013884.0,
      "budget_used_percent": 0.920100640013884
    },
    {
      "type": "training",
      "description": "Training step 641",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:33",
      "total_flops_so_far": 921531735385660.0,
      "budget_used_percent": 0.9215317353856599
    },
    {
      "type": "training",
      "description": "Training step 642",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:33",
      "total_flops_so_far": 922962830757436.0,
      "budget_used_percent": 0.922962830757436
    },
    {
      "type": "training",
      "description": "Training step 643",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:33",
      "total_flops_so_far": 924393926129212.0,
      "budget_used_percent": 0.924393926129212
    },
    {
      "type": "training",
      "description": "Training step 644",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:33",
      "total_flops_so_far": 925825021500988.0,
      "budget_used_percent": 0.925825021500988
    },
    {
      "type": "training",
      "description": "Training step 645",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:33",
      "total_flops_so_far": 927256116872764.0,
      "budget_used_percent": 0.927256116872764
    },
    {
      "type": "training",
      "description": "Training step 646",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:33",
      "total_flops_so_far": 928687212244540.0,
      "budget_used_percent": 0.9286872122445399
    },
    {
      "type": "training",
      "description": "Training step 647",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:33",
      "total_flops_so_far": 930118307616316.0,
      "budget_used_percent": 0.930118307616316
    },
    {
      "type": "training",
      "description": "Training step 648",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:34",
      "total_flops_so_far": 931549402988092.0,
      "budget_used_percent": 0.931549402988092
    },
    {
      "type": "training",
      "description": "Training step 649",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:34",
      "total_flops_so_far": 932980498359868.0,
      "budget_used_percent": 0.9329804983598681
    },
    {
      "type": "training",
      "description": "Training step 650",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:34",
      "total_flops_so_far": 934411593731644.0,
      "budget_used_percent": 0.934411593731644
    },
    {
      "type": "training",
      "description": "Training step 651",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:34",
      "total_flops_so_far": 935842689103420.0,
      "budget_used_percent": 0.9358426891034201
    },
    {
      "type": "training",
      "description": "Training step 652",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:34",
      "total_flops_so_far": 937273784475196.0,
      "budget_used_percent": 0.937273784475196
    },
    {
      "type": "training",
      "description": "Training step 653",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:34",
      "total_flops_so_far": 938704879846972.0,
      "budget_used_percent": 0.9387048798469719
    },
    {
      "type": "training",
      "description": "Training step 654",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:34",
      "total_flops_so_far": 940135975218748.0,
      "budget_used_percent": 0.940135975218748
    },
    {
      "type": "training",
      "description": "Training step 655",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:34",
      "total_flops_so_far": 941567070590524.0,
      "budget_used_percent": 0.941567070590524
    },
    {
      "type": "training",
      "description": "Training step 656",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:35",
      "total_flops_so_far": 942998165962300.0,
      "budget_used_percent": 0.9429981659623001
    },
    {
      "type": "training",
      "description": "Training step 657",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:35",
      "total_flops_so_far": 944429261334076.0,
      "budget_used_percent": 0.944429261334076
    },
    {
      "type": "training",
      "description": "Training step 658",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:35",
      "total_flops_so_far": 945860356705852.0,
      "budget_used_percent": 0.9458603567058519
    },
    {
      "type": "training",
      "description": "Training step 659",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:35",
      "total_flops_so_far": 947291452077628.0,
      "budget_used_percent": 0.947291452077628
    },
    {
      "type": "training",
      "description": "Training step 660",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:35",
      "total_flops_so_far": 948722547449404.0,
      "budget_used_percent": 0.948722547449404
    },
    {
      "type": "training",
      "description": "Training step 661",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:35",
      "total_flops_so_far": 950153642821180.0,
      "budget_used_percent": 0.9501536428211801
    },
    {
      "type": "training",
      "description": "Training step 662",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:35",
      "total_flops_so_far": 951584738192956.0,
      "budget_used_percent": 0.951584738192956
    },
    {
      "type": "training",
      "description": "Training step 663",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:35",
      "total_flops_so_far": 953015833564732.0,
      "budget_used_percent": 0.953015833564732
    },
    {
      "type": "training",
      "description": "Training step 664",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:36",
      "total_flops_so_far": 954446928936508.0,
      "budget_used_percent": 0.9544469289365081
    },
    {
      "type": "training",
      "description": "Training step 665",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:36",
      "total_flops_so_far": 955878024308284.0,
      "budget_used_percent": 0.955878024308284
    },
    {
      "type": "training",
      "description": "Training step 666",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:36",
      "total_flops_so_far": 957309119680060.0,
      "budget_used_percent": 0.95730911968006
    },
    {
      "type": "training",
      "description": "Training step 667",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:36",
      "total_flops_so_far": 958740215051836.0,
      "budget_used_percent": 0.958740215051836
    },
    {
      "type": "training",
      "description": "Training step 668",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:36",
      "total_flops_so_far": 960171310423612.0,
      "budget_used_percent": 0.9601713104236119
    },
    {
      "type": "training",
      "description": "Training step 669",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:36",
      "total_flops_so_far": 961602405795388.0,
      "budget_used_percent": 0.961602405795388
    },
    {
      "type": "training",
      "description": "Training step 670",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:36",
      "total_flops_so_far": 963033501167164.0,
      "budget_used_percent": 0.963033501167164
    },
    {
      "type": "training",
      "description": "Training step 671",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:37",
      "total_flops_so_far": 964464596538940.0,
      "budget_used_percent": 0.96446459653894
    },
    {
      "type": "training",
      "description": "Training step 672",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:37",
      "total_flops_so_far": 965895691910716.0,
      "budget_used_percent": 0.965895691910716
    },
    {
      "type": "training",
      "description": "Training step 673",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:37",
      "total_flops_so_far": 967326787282492.0,
      "budget_used_percent": 0.9673267872824919
    },
    {
      "type": "training",
      "description": "Training step 674",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:37",
      "total_flops_so_far": 968757882654268.0,
      "budget_used_percent": 0.968757882654268
    },
    {
      "type": "training",
      "description": "Training step 675",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:37",
      "total_flops_so_far": 970188978026044.0,
      "budget_used_percent": 0.970188978026044
    },
    {
      "type": "training",
      "description": "Training step 676",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:37",
      "total_flops_so_far": 971620073397820.0,
      "budget_used_percent": 0.9716200733978201
    },
    {
      "type": "training",
      "description": "Training step 677",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:37",
      "total_flops_so_far": 973051168769596.0,
      "budget_used_percent": 0.973051168769596
    },
    {
      "type": "training",
      "description": "Training step 678",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:37",
      "total_flops_so_far": 974482264141372.0,
      "budget_used_percent": 0.974482264141372
    },
    {
      "type": "training",
      "description": "Training step 679",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:38",
      "total_flops_so_far": 975913359513148.0,
      "budget_used_percent": 0.9759133595131481
    },
    {
      "type": "training",
      "description": "Training step 680",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:38",
      "total_flops_so_far": 977344454884924.0,
      "budget_used_percent": 0.9773444548849239
    },
    {
      "type": "training",
      "description": "Training step 681",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:38",
      "total_flops_so_far": 978775550256700.0,
      "budget_used_percent": 0.9787755502567
    },
    {
      "type": "training",
      "description": "Training step 682",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:38",
      "total_flops_so_far": 980206645628476.0,
      "budget_used_percent": 0.980206645628476
    },
    {
      "type": "training",
      "description": "Training step 683",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:38",
      "total_flops_so_far": 981637741000252.0,
      "budget_used_percent": 0.9816377410002519
    },
    {
      "type": "training",
      "description": "Training step 684",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:38",
      "total_flops_so_far": 983068836372028.0,
      "budget_used_percent": 0.983068836372028
    },
    {
      "type": "training",
      "description": "Training step 685",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:38",
      "total_flops_so_far": 984499931743804.0,
      "budget_used_percent": 0.9844999317438039
    },
    {
      "type": "training",
      "description": "Training step 686",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:39",
      "total_flops_so_far": 985931027115580.0,
      "budget_used_percent": 0.98593102711558
    },
    {
      "type": "training",
      "description": "Training step 687",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:39",
      "total_flops_so_far": 987362122487356.0,
      "budget_used_percent": 0.987362122487356
    },
    {
      "type": "training",
      "description": "Training step 688",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:39",
      "total_flops_so_far": 988793217859132.0,
      "budget_used_percent": 0.9887932178591319
    },
    {
      "type": "training",
      "description": "Training step 689",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:39",
      "total_flops_so_far": 990224313230908.0,
      "budget_used_percent": 0.990224313230908
    },
    {
      "type": "training",
      "description": "Training step 690",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:39",
      "total_flops_so_far": 991655408602684.0,
      "budget_used_percent": 0.991655408602684
    },
    {
      "type": "training",
      "description": "Training step 691",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:39",
      "total_flops_so_far": 993086503974460.0,
      "budget_used_percent": 0.9930865039744601
    },
    {
      "type": "training",
      "description": "Training step 692",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:39",
      "total_flops_so_far": 994517599346236.0,
      "budget_used_percent": 0.994517599346236
    },
    {
      "type": "training",
      "description": "Training step 693",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:39",
      "total_flops_so_far": 995948694718012.0,
      "budget_used_percent": 0.9959486947180121
    },
    {
      "type": "training",
      "description": "Training step 694",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:40",
      "total_flops_so_far": 997379790089788.0,
      "budget_used_percent": 0.997379790089788
    },
    {
      "type": "training",
      "description": "Training step 695",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:40",
      "total_flops_so_far": 998810885461564.0,
      "budget_used_percent": 0.9988108854615639
    },
    {
      "type": "training",
      "description": "Training step 696",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:40",
      "total_flops_so_far": 1000241980833340.0,
      "budget_used_percent": 1.00024198083334
    },
    {
      "type": "training",
      "description": "Training step 697",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:40",
      "total_flops_so_far": 1001673076205116.0,
      "budget_used_percent": 1.001673076205116
    },
    {
      "type": "training",
      "description": "Training step 698",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:40",
      "total_flops_so_far": 1003104171576892.0,
      "budget_used_percent": 1.003104171576892
    },
    {
      "type": "training",
      "description": "Training step 699",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:40",
      "total_flops_so_far": 1004535266948668.0,
      "budget_used_percent": 1.004535266948668
    },
    {
      "type": "training",
      "description": "Training step 700",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:40",
      "total_flops_so_far": 1005966362320444.0,
      "budget_used_percent": 1.005966362320444
    },
    {
      "type": "training",
      "description": "Training step 701",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:41",
      "total_flops_so_far": 1007397457692220.0,
      "budget_used_percent": 1.00739745769222
    },
    {
      "type": "training",
      "description": "Training step 702",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:41",
      "total_flops_so_far": 1008828553063996.0,
      "budget_used_percent": 1.008828553063996
    },
    {
      "type": "training",
      "description": "Training step 703",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:41",
      "total_flops_so_far": 1010259648435772.0,
      "budget_used_percent": 1.010259648435772
    },
    {
      "type": "training",
      "description": "Training step 704",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:41",
      "total_flops_so_far": 1011690743807548.0,
      "budget_used_percent": 1.011690743807548
    },
    {
      "type": "training",
      "description": "Training step 705",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:41",
      "total_flops_so_far": 1013121839179324.0,
      "budget_used_percent": 1.013121839179324
    },
    {
      "type": "training",
      "description": "Training step 706",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:41",
      "total_flops_so_far": 1014552934551100.0,
      "budget_used_percent": 1.0145529345511
    },
    {
      "type": "training",
      "description": "Training step 707",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:41",
      "total_flops_so_far": 1015984029922876.0,
      "budget_used_percent": 1.015984029922876
    },
    {
      "type": "training",
      "description": "Training step 708",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:41",
      "total_flops_so_far": 1017415125294652.0,
      "budget_used_percent": 1.0174151252946522
    },
    {
      "type": "training",
      "description": "Training step 709",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:42",
      "total_flops_so_far": 1018846220666428.0,
      "budget_used_percent": 1.018846220666428
    },
    {
      "type": "training",
      "description": "Training step 710",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:42",
      "total_flops_so_far": 1020277316038204.0,
      "budget_used_percent": 1.020277316038204
    },
    {
      "type": "training",
      "description": "Training step 711",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:42",
      "total_flops_so_far": 1021708411409980.0,
      "budget_used_percent": 1.0217084114099801
    },
    {
      "type": "training",
      "description": "Training step 712",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:42",
      "total_flops_so_far": 1023139506781756.0,
      "budget_used_percent": 1.023139506781756
    },
    {
      "type": "training",
      "description": "Training step 713",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:42",
      "total_flops_so_far": 1024570602153532.0,
      "budget_used_percent": 1.0245706021535321
    },
    {
      "type": "training",
      "description": "Training step 714",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:42",
      "total_flops_so_far": 1026001697525308.0,
      "budget_used_percent": 1.026001697525308
    },
    {
      "type": "training",
      "description": "Training step 715",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:42",
      "total_flops_so_far": 1027432792897084.0,
      "budget_used_percent": 1.027432792897084
    },
    {
      "type": "training",
      "description": "Training step 716",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:43",
      "total_flops_so_far": 1028863888268860.0,
      "budget_used_percent": 1.02886388826886
    },
    {
      "type": "training",
      "description": "Training step 717",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:43",
      "total_flops_so_far": 1030294983640636.0,
      "budget_used_percent": 1.0302949836406359
    },
    {
      "type": "training",
      "description": "Training step 718",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:43",
      "total_flops_so_far": 1031726079012412.0,
      "budget_used_percent": 1.031726079012412
    },
    {
      "type": "training",
      "description": "Training step 719",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:43",
      "total_flops_so_far": 1033157174384188.0,
      "budget_used_percent": 1.033157174384188
    },
    {
      "type": "training",
      "description": "Training step 720",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:43",
      "total_flops_so_far": 1034588269755964.0,
      "budget_used_percent": 1.0345882697559639
    },
    {
      "type": "training",
      "description": "Training step 721",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:43",
      "total_flops_so_far": 1036019365127740.0,
      "budget_used_percent": 1.03601936512774
    },
    {
      "type": "training",
      "description": "Training step 722",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:43",
      "total_flops_so_far": 1037450460499516.0,
      "budget_used_percent": 1.037450460499516
    },
    {
      "type": "training",
      "description": "Training step 723",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:44",
      "total_flops_so_far": 1038881555871292.0,
      "budget_used_percent": 1.038881555871292
    },
    {
      "type": "training",
      "description": "Training step 724",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:44",
      "total_flops_so_far": 1040312651243068.0,
      "budget_used_percent": 1.040312651243068
    },
    {
      "type": "training",
      "description": "Training step 725",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:44",
      "total_flops_so_far": 1041743746614844.0,
      "budget_used_percent": 1.0417437466148438
    },
    {
      "type": "training",
      "description": "Training step 726",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:44",
      "total_flops_so_far": 1043174841986620.0,
      "budget_used_percent": 1.04317484198662
    },
    {
      "type": "training",
      "description": "Training step 727",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:44",
      "total_flops_so_far": 1044605937358396.0,
      "budget_used_percent": 1.044605937358396
    },
    {
      "type": "training",
      "description": "Training step 728",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:44",
      "total_flops_so_far": 1046037032730172.0,
      "budget_used_percent": 1.046037032730172
    },
    {
      "type": "training",
      "description": "Training step 729",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:44",
      "total_flops_so_far": 1047468128101948.0,
      "budget_used_percent": 1.047468128101948
    },
    {
      "type": "training",
      "description": "Training step 730",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:44",
      "total_flops_so_far": 1048899223473724.0,
      "budget_used_percent": 1.048899223473724
    },
    {
      "type": "training",
      "description": "Training step 731",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:45",
      "total_flops_so_far": 1050330318845500.0,
      "budget_used_percent": 1.0503303188455
    },
    {
      "type": "training",
      "description": "Training step 732",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:45",
      "total_flops_so_far": 1051761414217276.0,
      "budget_used_percent": 1.051761414217276
    },
    {
      "type": "training",
      "description": "Training step 733",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:45",
      "total_flops_so_far": 1053192509589052.0,
      "budget_used_percent": 1.053192509589052
    },
    {
      "type": "training",
      "description": "Training step 734",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:45",
      "total_flops_so_far": 1054623604960828.0,
      "budget_used_percent": 1.054623604960828
    },
    {
      "type": "training",
      "description": "Training step 735",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:45",
      "total_flops_so_far": 1056054700332604.0,
      "budget_used_percent": 1.0560547003326042
    },
    {
      "type": "training",
      "description": "Training step 736",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:45",
      "total_flops_so_far": 1057485795704380.0,
      "budget_used_percent": 1.05748579570438
    },
    {
      "type": "training",
      "description": "Training step 737",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:45",
      "total_flops_so_far": 1058916891076156.0,
      "budget_used_percent": 1.058916891076156
    },
    {
      "type": "training",
      "description": "Training step 738",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:46",
      "total_flops_so_far": 1060347986447932.0,
      "budget_used_percent": 1.060347986447932
    },
    {
      "type": "training",
      "description": "Training step 739",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:46",
      "total_flops_so_far": 1061779081819708.0,
      "budget_used_percent": 1.061779081819708
    },
    {
      "type": "training",
      "description": "Training step 740",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:46",
      "total_flops_so_far": 1063210177191484.0,
      "budget_used_percent": 1.0632101771914841
    },
    {
      "type": "training",
      "description": "Training step 741",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:46",
      "total_flops_so_far": 1064641272563260.0,
      "budget_used_percent": 1.06464127256326
    },
    {
      "type": "training",
      "description": "Training step 742",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:46",
      "total_flops_so_far": 1066072367935036.0,
      "budget_used_percent": 1.066072367935036
    },
    {
      "type": "training",
      "description": "Training step 743",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:46",
      "total_flops_so_far": 1067503463306812.0,
      "budget_used_percent": 1.0675034633068121
    },
    {
      "type": "training",
      "description": "Training step 744",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:46",
      "total_flops_so_far": 1068934558678588.0,
      "budget_used_percent": 1.0689345586785879
    },
    {
      "type": "training",
      "description": "Training step 745",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:46",
      "total_flops_so_far": 1070365654050364.0,
      "budget_used_percent": 1.070365654050364
    },
    {
      "type": "training",
      "description": "Training step 746",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:47",
      "total_flops_so_far": 1071796749422140.0,
      "budget_used_percent": 1.07179674942214
    },
    {
      "type": "training",
      "description": "Training step 747",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:47",
      "total_flops_so_far": 1073227844793916.0,
      "budget_used_percent": 1.0732278447939159
    },
    {
      "type": "training",
      "description": "Training step 748",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:47",
      "total_flops_so_far": 1074658940165692.0,
      "budget_used_percent": 1.074658940165692
    },
    {
      "type": "training",
      "description": "Training step 749",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:47",
      "total_flops_so_far": 1076090035537468.0,
      "budget_used_percent": 1.076090035537468
    },
    {
      "type": "training",
      "description": "Training step 750",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:47",
      "total_flops_so_far": 1077521130909244.0,
      "budget_used_percent": 1.077521130909244
    },
    {
      "type": "training",
      "description": "Training step 751",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:47",
      "total_flops_so_far": 1078952226281020.0,
      "budget_used_percent": 1.07895222628102
    },
    {
      "type": "training",
      "description": "Training step 752",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:47",
      "total_flops_so_far": 1080383321652796.0,
      "budget_used_percent": 1.0803833216527958
    },
    {
      "type": "training",
      "description": "Training step 753",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:48",
      "total_flops_so_far": 1081814417024572.0,
      "budget_used_percent": 1.081814417024572
    },
    {
      "type": "training",
      "description": "Training step 754",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:48",
      "total_flops_so_far": 1083245512396348.0,
      "budget_used_percent": 1.083245512396348
    },
    {
      "type": "training",
      "description": "Training step 755",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:48",
      "total_flops_so_far": 1084676607768124.0,
      "budget_used_percent": 1.084676607768124
    },
    {
      "type": "training",
      "description": "Training step 756",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:48",
      "total_flops_so_far": 1086107703139900.0,
      "budget_used_percent": 1.0861077031399
    },
    {
      "type": "training",
      "description": "Training step 757",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:48",
      "total_flops_so_far": 1087538798511676.0,
      "budget_used_percent": 1.087538798511676
    },
    {
      "type": "training",
      "description": "Training step 758",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:48",
      "total_flops_so_far": 1088969893883452.0,
      "budget_used_percent": 1.088969893883452
    },
    {
      "type": "training",
      "description": "Training step 759",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:48",
      "total_flops_so_far": 1090400989255228.0,
      "budget_used_percent": 1.090400989255228
    },
    {
      "type": "training",
      "description": "Training step 760",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:48",
      "total_flops_so_far": 1091832084627004.0,
      "budget_used_percent": 1.091832084627004
    },
    {
      "type": "training",
      "description": "Training step 761",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:49",
      "total_flops_so_far": 1093263179998780.0,
      "budget_used_percent": 1.09326317999878
    },
    {
      "type": "training",
      "description": "Training step 762",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:49",
      "total_flops_so_far": 1094694275370556.0,
      "budget_used_percent": 1.094694275370556
    },
    {
      "type": "training",
      "description": "Training step 763",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:49",
      "total_flops_so_far": 1096125370742332.0,
      "budget_used_percent": 1.096125370742332
    },
    {
      "type": "training",
      "description": "Training step 764",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:49",
      "total_flops_so_far": 1097556466114108.0,
      "budget_used_percent": 1.097556466114108
    },
    {
      "type": "training",
      "description": "Training step 765",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:49",
      "total_flops_so_far": 1098987561485884.0,
      "budget_used_percent": 1.0989875614858842
    },
    {
      "type": "training",
      "description": "Training step 766",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:49",
      "total_flops_so_far": 1100418656857660.0,
      "budget_used_percent": 1.10041865685766
    },
    {
      "type": "training",
      "description": "Training step 767",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:49",
      "total_flops_so_far": 1101849752229436.0,
      "budget_used_percent": 1.101849752229436
    },
    {
      "type": "training",
      "description": "Training step 768",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:50",
      "total_flops_so_far": 1103280847601212.0,
      "budget_used_percent": 1.103280847601212
    },
    {
      "type": "training",
      "description": "Training step 769",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:50",
      "total_flops_so_far": 1104711942972988.0,
      "budget_used_percent": 1.104711942972988
    },
    {
      "type": "training",
      "description": "Training step 770",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:50",
      "total_flops_so_far": 1106143038344764.0,
      "budget_used_percent": 1.1061430383447641
    },
    {
      "type": "training",
      "description": "Training step 771",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:50",
      "total_flops_so_far": 1107574133716540.0,
      "budget_used_percent": 1.10757413371654
    },
    {
      "type": "training",
      "description": "Training step 772",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:50",
      "total_flops_so_far": 1109005229088316.0,
      "budget_used_percent": 1.1090052290883161
    },
    {
      "type": "training",
      "description": "Training step 773",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:50",
      "total_flops_so_far": 1110436324460092.0,
      "budget_used_percent": 1.110436324460092
    },
    {
      "type": "training",
      "description": "Training step 774",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:50",
      "total_flops_so_far": 1111867419831868.0,
      "budget_used_percent": 1.1118674198318679
    },
    {
      "type": "training",
      "description": "Training step 775",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:51",
      "total_flops_so_far": 1113298515203644.0,
      "budget_used_percent": 1.113298515203644
    },
    {
      "type": "training",
      "description": "Training step 776",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:51",
      "total_flops_so_far": 1114729610575420.0,
      "budget_used_percent": 1.11472961057542
    },
    {
      "type": "training",
      "description": "Training step 777",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:51",
      "total_flops_so_far": 1116160705947196.0,
      "budget_used_percent": 1.116160705947196
    },
    {
      "type": "training",
      "description": "Training step 778",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:51",
      "total_flops_so_far": 1117591801318972.0,
      "budget_used_percent": 1.117591801318972
    },
    {
      "type": "training",
      "description": "Training step 779",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:51",
      "total_flops_so_far": 1119022896690748.0,
      "budget_used_percent": 1.1190228966907478
    },
    {
      "type": "training",
      "description": "Training step 780",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:51",
      "total_flops_so_far": 1120453992062524.0,
      "budget_used_percent": 1.120453992062524
    },
    {
      "type": "training",
      "description": "Training step 781",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:51",
      "total_flops_so_far": 1121885087434300.0,
      "budget_used_percent": 1.1218850874343
    },
    {
      "type": "training",
      "description": "Training step 782",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:51",
      "total_flops_so_far": 1123316182806076.0,
      "budget_used_percent": 1.123316182806076
    },
    {
      "type": "training",
      "description": "Training step 783",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:52",
      "total_flops_so_far": 1124747278177852.0,
      "budget_used_percent": 1.124747278177852
    },
    {
      "type": "training",
      "description": "Training step 784",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:52",
      "total_flops_so_far": 1126178373549628.0,
      "budget_used_percent": 1.126178373549628
    },
    {
      "type": "training",
      "description": "Training step 785",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:52",
      "total_flops_so_far": 1127609468921404.0,
      "budget_used_percent": 1.127609468921404
    },
    {
      "type": "training",
      "description": "Training step 786",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:52",
      "total_flops_so_far": 1129040564293180.0,
      "budget_used_percent": 1.12904056429318
    },
    {
      "type": "training",
      "description": "Training step 787",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:52",
      "total_flops_so_far": 1130471659664956.0,
      "budget_used_percent": 1.130471659664956
    },
    {
      "type": "training",
      "description": "Training step 788",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:52",
      "total_flops_so_far": 1131902755036732.0,
      "budget_used_percent": 1.131902755036732
    },
    {
      "type": "training",
      "description": "Training step 789",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:52",
      "total_flops_so_far": 1133333850408508.0,
      "budget_used_percent": 1.133333850408508
    },
    {
      "type": "training",
      "description": "Training step 790",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:53",
      "total_flops_so_far": 1134764945780284.0,
      "budget_used_percent": 1.134764945780284
    },
    {
      "type": "training",
      "description": "Training step 791",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:53",
      "total_flops_so_far": 1136196041152060.0,
      "budget_used_percent": 1.13619604115206
    },
    {
      "type": "training",
      "description": "Training step 792",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:53",
      "total_flops_so_far": 1137627136523836.0,
      "budget_used_percent": 1.137627136523836
    },
    {
      "type": "training",
      "description": "Training step 793",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:53",
      "total_flops_so_far": 1139058231895612.0,
      "budget_used_percent": 1.139058231895612
    },
    {
      "type": "training",
      "description": "Training step 794",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:53",
      "total_flops_so_far": 1140489327267388.0,
      "budget_used_percent": 1.140489327267388
    },
    {
      "type": "training",
      "description": "Training step 795",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:53",
      "total_flops_so_far": 1141920422639164.0,
      "budget_used_percent": 1.141920422639164
    },
    {
      "type": "training",
      "description": "Training step 796",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:53",
      "total_flops_so_far": 1143351518010940.0,
      "budget_used_percent": 1.14335151801094
    },
    {
      "type": "training",
      "description": "Training step 797",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:54",
      "total_flops_so_far": 1144782613382716.0,
      "budget_used_percent": 1.1447826133827161
    },
    {
      "type": "training",
      "description": "Training step 798",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:54",
      "total_flops_so_far": 1146213708754492.0,
      "budget_used_percent": 1.146213708754492
    },
    {
      "type": "training",
      "description": "Training step 799",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:54",
      "total_flops_so_far": 1147644804126268.0,
      "budget_used_percent": 1.147644804126268
    },
    {
      "type": "training",
      "description": "Training step 800",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:54",
      "total_flops_so_far": 1149075899498044.0,
      "budget_used_percent": 1.1490758994980441
    },
    {
      "type": "training",
      "description": "Training step 801",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:54",
      "total_flops_so_far": 1150506994869820.0,
      "budget_used_percent": 1.1505069948698199
    },
    {
      "type": "training",
      "description": "Training step 802",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:54",
      "total_flops_so_far": 1151938090241596.0,
      "budget_used_percent": 1.151938090241596
    },
    {
      "type": "training",
      "description": "Training step 803",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:54",
      "total_flops_so_far": 1153369185613372.0,
      "budget_used_percent": 1.153369185613372
    },
    {
      "type": "training",
      "description": "Training step 804",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:54",
      "total_flops_so_far": 1154800280985148.0,
      "budget_used_percent": 1.1548002809851479
    },
    {
      "type": "training",
      "description": "Training step 805",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:55",
      "total_flops_so_far": 1156231376356924.0,
      "budget_used_percent": 1.156231376356924
    },
    {
      "type": "training",
      "description": "Training step 806",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:55",
      "total_flops_so_far": 1157662471728700.0,
      "budget_used_percent": 1.1576624717286998
    },
    {
      "type": "training",
      "description": "Training step 807",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:55",
      "total_flops_so_far": 1159093567100476.0,
      "budget_used_percent": 1.159093567100476
    },
    {
      "type": "training",
      "description": "Training step 808",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:55",
      "total_flops_so_far": 1160524662472252.0,
      "budget_used_percent": 1.160524662472252
    },
    {
      "type": "training",
      "description": "Training step 809",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:55",
      "total_flops_so_far": 1161955757844028.0,
      "budget_used_percent": 1.1619557578440278
    },
    {
      "type": "training",
      "description": "Training step 810",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:55",
      "total_flops_so_far": 1163386853215804.0,
      "budget_used_percent": 1.163386853215804
    },
    {
      "type": "training",
      "description": "Training step 811",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:55",
      "total_flops_so_far": 1164817948587580.0,
      "budget_used_percent": 1.16481794858758
    },
    {
      "type": "training",
      "description": "Training step 812",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:56",
      "total_flops_so_far": 1166249043959356.0,
      "budget_used_percent": 1.166249043959356
    },
    {
      "type": "training",
      "description": "Training step 813",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:56",
      "total_flops_so_far": 1167680139331132.0,
      "budget_used_percent": 1.167680139331132
    },
    {
      "type": "training",
      "description": "Training step 814",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:56",
      "total_flops_so_far": 1169111234702908.0,
      "budget_used_percent": 1.169111234702908
    },
    {
      "type": "training",
      "description": "Training step 815",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:56",
      "total_flops_so_far": 1170542330074684.0,
      "budget_used_percent": 1.170542330074684
    },
    {
      "type": "training",
      "description": "Training step 816",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:56",
      "total_flops_so_far": 1171973425446460.0,
      "budget_used_percent": 1.17197342544646
    },
    {
      "type": "training",
      "description": "Training step 817",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:56",
      "total_flops_so_far": 1173404520818236.0,
      "budget_used_percent": 1.173404520818236
    },
    {
      "type": "training",
      "description": "Training step 818",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:56",
      "total_flops_so_far": 1174835616190012.0,
      "budget_used_percent": 1.174835616190012
    },
    {
      "type": "training",
      "description": "Training step 819",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:57",
      "total_flops_so_far": 1176266711561788.0,
      "budget_used_percent": 1.1762667115617882
    },
    {
      "type": "training",
      "description": "Training step 820",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:57",
      "total_flops_so_far": 1177697806933564.0,
      "budget_used_percent": 1.177697806933564
    },
    {
      "type": "training",
      "description": "Training step 821",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:57",
      "total_flops_so_far": 1179128902305340.0,
      "budget_used_percent": 1.17912890230534
    },
    {
      "type": "training",
      "description": "Training step 822",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:57",
      "total_flops_so_far": 1180559997677116.0,
      "budget_used_percent": 1.180559997677116
    },
    {
      "type": "training",
      "description": "Training step 823",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:57",
      "total_flops_so_far": 1181991093048892.0,
      "budget_used_percent": 1.181991093048892
    },
    {
      "type": "training",
      "description": "Training step 824",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:57",
      "total_flops_so_far": 1183422188420668.0,
      "budget_used_percent": 1.1834221884206682
    },
    {
      "type": "training",
      "description": "Training step 825",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:57",
      "total_flops_so_far": 1184853283792444.0,
      "budget_used_percent": 1.184853283792444
    },
    {
      "type": "training",
      "description": "Training step 826",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:58",
      "total_flops_so_far": 1186284379164220.0,
      "budget_used_percent": 1.18628437916422
    },
    {
      "type": "training",
      "description": "Training step 827",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:58",
      "total_flops_so_far": 1187715474535996.0,
      "budget_used_percent": 1.1877154745359961
    },
    {
      "type": "training",
      "description": "Training step 828",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:58",
      "total_flops_so_far": 1189146569907772.0,
      "budget_used_percent": 1.189146569907772
    },
    {
      "type": "training",
      "description": "Training step 829",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:58",
      "total_flops_so_far": 1190577665279548.0,
      "budget_used_percent": 1.1905776652795481
    },
    {
      "type": "training",
      "description": "Training step 830",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:58",
      "total_flops_so_far": 1192008760651324.0,
      "budget_used_percent": 1.192008760651324
    },
    {
      "type": "training",
      "description": "Training step 831",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:58",
      "total_flops_so_far": 1193439856023100.0,
      "budget_used_percent": 1.1934398560230999
    },
    {
      "type": "training",
      "description": "Training step 832",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:58",
      "total_flops_so_far": 1194870951394876.0,
      "budget_used_percent": 1.194870951394876
    },
    {
      "type": "training",
      "description": "Training step 833",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:58",
      "total_flops_so_far": 1196302046766652.0,
      "budget_used_percent": 1.1963020467666519
    },
    {
      "type": "training",
      "description": "Training step 834",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:59",
      "total_flops_so_far": 1197733142138428.0,
      "budget_used_percent": 1.197733142138428
    },
    {
      "type": "training",
      "description": "Training step 835",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:59",
      "total_flops_so_far": 1199164237510204.0,
      "budget_used_percent": 1.199164237510204
    },
    {
      "type": "training",
      "description": "Training step 836",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:59",
      "total_flops_so_far": 1200595332881980.0,
      "budget_used_percent": 1.2005953328819798
    },
    {
      "type": "training",
      "description": "Training step 837",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:59",
      "total_flops_so_far": 1202026428253756.0,
      "budget_used_percent": 1.202026428253756
    },
    {
      "type": "training",
      "description": "Training step 838",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:59",
      "total_flops_so_far": 1203457523625532.0,
      "budget_used_percent": 1.203457523625532
    },
    {
      "type": "training",
      "description": "Training step 839",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:59",
      "total_flops_so_far": 1204888618997308.0,
      "budget_used_percent": 1.204888618997308
    },
    {
      "type": "training",
      "description": "Training step 840",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:39:59",
      "total_flops_so_far": 1206319714369084.0,
      "budget_used_percent": 1.206319714369084
    },
    {
      "type": "training",
      "description": "Training step 841",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:00",
      "total_flops_so_far": 1207750809740860.0,
      "budget_used_percent": 1.20775080974086
    },
    {
      "type": "training",
      "description": "Training step 842",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:00",
      "total_flops_so_far": 1209181905112636.0,
      "budget_used_percent": 1.209181905112636
    },
    {
      "type": "training",
      "description": "Training step 843",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:00",
      "total_flops_so_far": 1210613000484412.0,
      "budget_used_percent": 1.210613000484412
    },
    {
      "type": "training",
      "description": "Training step 844",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:00",
      "total_flops_so_far": 1212044095856188.0,
      "budget_used_percent": 1.212044095856188
    },
    {
      "type": "training",
      "description": "Training step 845",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:00",
      "total_flops_so_far": 1213475191227964.0,
      "budget_used_percent": 1.213475191227964
    },
    {
      "type": "training",
      "description": "Training step 846",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:00",
      "total_flops_so_far": 1214906286599740.0,
      "budget_used_percent": 1.21490628659974
    },
    {
      "type": "training",
      "description": "Training step 847",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:00",
      "total_flops_so_far": 1216337381971516.0,
      "budget_used_percent": 1.216337381971516
    },
    {
      "type": "training",
      "description": "Training step 848",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:01",
      "total_flops_so_far": 1217768477343292.0,
      "budget_used_percent": 1.217768477343292
    },
    {
      "type": "training",
      "description": "Training step 849",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:01",
      "total_flops_so_far": 1219199572715068.0,
      "budget_used_percent": 1.219199572715068
    },
    {
      "type": "training",
      "description": "Training step 850",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:01",
      "total_flops_so_far": 1220630668086844.0,
      "budget_used_percent": 1.220630668086844
    },
    {
      "type": "training",
      "description": "Training step 851",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:01",
      "total_flops_so_far": 1222061763458620.0,
      "budget_used_percent": 1.22206176345862
    },
    {
      "type": "training",
      "description": "Training step 852",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:01",
      "total_flops_so_far": 1223492858830396.0,
      "budget_used_percent": 1.223492858830396
    },
    {
      "type": "training",
      "description": "Training step 853",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:01",
      "total_flops_so_far": 1224923954202172.0,
      "budget_used_percent": 1.224923954202172
    },
    {
      "type": "training",
      "description": "Training step 854",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:01",
      "total_flops_so_far": 1226355049573948.0,
      "budget_used_percent": 1.2263550495739481
    },
    {
      "type": "training",
      "description": "Training step 855",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:02",
      "total_flops_so_far": 1227786144945724.0,
      "budget_used_percent": 1.227786144945724
    },
    {
      "type": "training",
      "description": "Training step 856",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:02",
      "total_flops_so_far": 1229217240317500.0,
      "budget_used_percent": 1.2292172403175001
    },
    {
      "type": "training",
      "description": "Training step 857",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:02",
      "total_flops_so_far": 1230648335689276.0,
      "budget_used_percent": 1.2306483356892761
    },
    {
      "type": "training",
      "description": "Training step 858",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:02",
      "total_flops_so_far": 1232079431061052.0,
      "budget_used_percent": 1.2320794310610519
    },
    {
      "type": "training",
      "description": "Training step 859",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:02",
      "total_flops_so_far": 1233510526432828.0,
      "budget_used_percent": 1.233510526432828
    },
    {
      "type": "training",
      "description": "Training step 860",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:02",
      "total_flops_so_far": 1234941621804604.0,
      "budget_used_percent": 1.2349416218046039
    },
    {
      "type": "training",
      "description": "Training step 861",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:02",
      "total_flops_so_far": 1236372717176380.0,
      "budget_used_percent": 1.23637271717638
    },
    {
      "type": "training",
      "description": "Training step 862",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:02",
      "total_flops_so_far": 1237803812548156.0,
      "budget_used_percent": 1.237803812548156
    },
    {
      "type": "training",
      "description": "Training step 863",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:03",
      "total_flops_so_far": 1239234907919932.0,
      "budget_used_percent": 1.2392349079199318
    },
    {
      "type": "training",
      "description": "Training step 864",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:03",
      "total_flops_so_far": 1240666003291708.0,
      "budget_used_percent": 1.240666003291708
    },
    {
      "type": "training",
      "description": "Training step 865",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:03",
      "total_flops_so_far": 1242097098663484.0,
      "budget_used_percent": 1.242097098663484
    },
    {
      "type": "training",
      "description": "Training step 866",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:03",
      "total_flops_so_far": 1243528194035260.0,
      "budget_used_percent": 1.24352819403526
    },
    {
      "type": "training",
      "description": "Training step 867",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:03",
      "total_flops_so_far": 1244959289407036.0,
      "budget_used_percent": 1.244959289407036
    },
    {
      "type": "training",
      "description": "Training step 868",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:03",
      "total_flops_so_far": 1246390384778812.0,
      "budget_used_percent": 1.246390384778812
    },
    {
      "type": "training",
      "description": "Training step 869",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:03",
      "total_flops_so_far": 1247821480150588.0,
      "budget_used_percent": 1.247821480150588
    },
    {
      "type": "training",
      "description": "Training step 870",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:04",
      "total_flops_so_far": 1249252575522364.0,
      "budget_used_percent": 1.249252575522364
    },
    {
      "type": "training",
      "description": "Training step 871",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:04",
      "total_flops_so_far": 1250683670894140.0,
      "budget_used_percent": 1.25068367089414
    },
    {
      "type": "training",
      "description": "Training step 872",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:04",
      "total_flops_so_far": 1252114766265916.0,
      "budget_used_percent": 1.252114766265916
    },
    {
      "type": "training",
      "description": "Training step 873",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:04",
      "total_flops_so_far": 1253545861637692.0,
      "budget_used_percent": 1.253545861637692
    },
    {
      "type": "training",
      "description": "Training step 874",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:05",
      "total_flops_so_far": 1254976957009468.0,
      "budget_used_percent": 1.254976957009468
    },
    {
      "type": "training",
      "description": "Training step 875",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:05",
      "total_flops_so_far": 1256408052381244.0,
      "budget_used_percent": 1.256408052381244
    },
    {
      "type": "training",
      "description": "Training step 876",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:05",
      "total_flops_so_far": 1257839147753020.0,
      "budget_used_percent": 1.25783914775302
    },
    {
      "type": "training",
      "description": "Training step 877",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:05",
      "total_flops_so_far": 1259270243124796.0,
      "budget_used_percent": 1.259270243124796
    },
    {
      "type": "training",
      "description": "Training step 878",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:06",
      "total_flops_so_far": 1260701338496572.0,
      "budget_used_percent": 1.260701338496572
    },
    {
      "type": "training",
      "description": "Training step 879",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:06",
      "total_flops_so_far": 1262132433868348.0,
      "budget_used_percent": 1.262132433868348
    },
    {
      "type": "training",
      "description": "Training step 880",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:06",
      "total_flops_so_far": 1263563529240124.0,
      "budget_used_percent": 1.263563529240124
    },
    {
      "type": "training",
      "description": "Training step 881",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:06",
      "total_flops_so_far": 1264994624611900.0,
      "budget_used_percent": 1.2649946246119002
    },
    {
      "type": "training",
      "description": "Training step 882",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:06",
      "total_flops_so_far": 1266425719983676.0,
      "budget_used_percent": 1.266425719983676
    },
    {
      "type": "training",
      "description": "Training step 883",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:06",
      "total_flops_so_far": 1267856815355452.0,
      "budget_used_percent": 1.267856815355452
    },
    {
      "type": "training",
      "description": "Training step 884",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:06",
      "total_flops_so_far": 1269287910727228.0,
      "budget_used_percent": 1.2692879107272281
    },
    {
      "type": "training",
      "description": "Training step 885",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:07",
      "total_flops_so_far": 1270719006099004.0,
      "budget_used_percent": 1.270719006099004
    },
    {
      "type": "training",
      "description": "Training step 886",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:07",
      "total_flops_so_far": 1272150101470780.0,
      "budget_used_percent": 1.2721501014707801
    },
    {
      "type": "training",
      "description": "Training step 887",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:07",
      "total_flops_so_far": 1273581196842556.0,
      "budget_used_percent": 1.2735811968425559
    },
    {
      "type": "training",
      "description": "Training step 888",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:07",
      "total_flops_so_far": 1275012292214332.0,
      "budget_used_percent": 1.2750122922143319
    },
    {
      "type": "training",
      "description": "Training step 889",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:07",
      "total_flops_so_far": 1276443387586108.0,
      "budget_used_percent": 1.276443387586108
    },
    {
      "type": "training",
      "description": "Training step 890",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:07",
      "total_flops_so_far": 1277874482957884.0,
      "budget_used_percent": 1.2778744829578839
    },
    {
      "type": "training",
      "description": "Training step 891",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:07",
      "total_flops_so_far": 1279305578329660.0,
      "budget_used_percent": 1.27930557832966
    },
    {
      "type": "training",
      "description": "Training step 892",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:08",
      "total_flops_so_far": 1280736673701436.0,
      "budget_used_percent": 1.280736673701436
    },
    {
      "type": "training",
      "description": "Training step 893",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:08",
      "total_flops_so_far": 1282167769073212.0,
      "budget_used_percent": 1.2821677690732118
    },
    {
      "type": "training",
      "description": "Training step 894",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:09",
      "total_flops_so_far": 1283598864444988.0,
      "budget_used_percent": 1.283598864444988
    },
    {
      "type": "training",
      "description": "Training step 895",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:10",
      "total_flops_so_far": 1285029959816764.0,
      "budget_used_percent": 1.285029959816764
    },
    {
      "type": "training",
      "description": "Training step 896",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:10",
      "total_flops_so_far": 1286461055188540.0,
      "budget_used_percent": 1.28646105518854
    },
    {
      "type": "training",
      "description": "Training step 897",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:10",
      "total_flops_so_far": 1287892150560316.0,
      "budget_used_percent": 1.287892150560316
    },
    {
      "type": "training",
      "description": "Training step 898",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:10",
      "total_flops_so_far": 1289323245932092.0,
      "budget_used_percent": 1.289323245932092
    },
    {
      "type": "training",
      "description": "Training step 899",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:10",
      "total_flops_so_far": 1290754341303868.0,
      "budget_used_percent": 1.290754341303868
    },
    {
      "type": "training",
      "description": "Training step 900",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:10",
      "total_flops_so_far": 1292185436675644.0,
      "budget_used_percent": 1.292185436675644
    },
    {
      "type": "training",
      "description": "Training step 901",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:10",
      "total_flops_so_far": 1293616532047420.0,
      "budget_used_percent": 1.29361653204742
    },
    {
      "type": "training",
      "description": "Training step 902",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:11",
      "total_flops_so_far": 1295047627419196.0,
      "budget_used_percent": 1.295047627419196
    },
    {
      "type": "training",
      "description": "Training step 903",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:11",
      "total_flops_so_far": 1296478722790972.0,
      "budget_used_percent": 1.296478722790972
    },
    {
      "type": "training",
      "description": "Training step 904",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:11",
      "total_flops_so_far": 1297909818162748.0,
      "budget_used_percent": 1.297909818162748
    },
    {
      "type": "training",
      "description": "Training step 905",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:11",
      "total_flops_so_far": 1299340913534524.0,
      "budget_used_percent": 1.299340913534524
    },
    {
      "type": "training",
      "description": "Training step 906",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:11",
      "total_flops_so_far": 1300772008906300.0,
      "budget_used_percent": 1.3007720089063
    },
    {
      "type": "training",
      "description": "Training step 907",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:11",
      "total_flops_so_far": 1302203104278076.0,
      "budget_used_percent": 1.302203104278076
    },
    {
      "type": "training",
      "description": "Training step 908",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:11",
      "total_flops_so_far": 1303634199649852.0,
      "budget_used_percent": 1.3036341996498522
    },
    {
      "type": "training",
      "description": "Training step 909",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:12",
      "total_flops_so_far": 1305065295021628.0,
      "budget_used_percent": 1.305065295021628
    },
    {
      "type": "training",
      "description": "Training step 910",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:12",
      "total_flops_so_far": 1306496390393404.0,
      "budget_used_percent": 1.306496390393404
    },
    {
      "type": "training",
      "description": "Training step 911",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:12",
      "total_flops_so_far": 1307927485765180.0,
      "budget_used_percent": 1.3079274857651801
    },
    {
      "type": "training",
      "description": "Training step 912",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:12",
      "total_flops_so_far": 1309358581136956.0,
      "budget_used_percent": 1.309358581136956
    },
    {
      "type": "training",
      "description": "Training step 913",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:12",
      "total_flops_so_far": 1310789676508732.0,
      "budget_used_percent": 1.3107896765087321
    },
    {
      "type": "training",
      "description": "Training step 914",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:12",
      "total_flops_so_far": 1312220771880508.0,
      "budget_used_percent": 1.312220771880508
    },
    {
      "type": "training",
      "description": "Training step 915",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:12",
      "total_flops_so_far": 1313651867252284.0,
      "budget_used_percent": 1.313651867252284
    },
    {
      "type": "training",
      "description": "Training step 916",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:12",
      "total_flops_so_far": 1315082962624060.0,
      "budget_used_percent": 1.31508296262406
    },
    {
      "type": "training",
      "description": "Training step 917",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:13",
      "total_flops_so_far": 1316514057995836.0,
      "budget_used_percent": 1.3165140579958359
    },
    {
      "type": "training",
      "description": "Training step 918",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:13",
      "total_flops_so_far": 1317945153367612.0,
      "budget_used_percent": 1.317945153367612
    },
    {
      "type": "training",
      "description": "Training step 919",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:13",
      "total_flops_so_far": 1319376248739388.0,
      "budget_used_percent": 1.319376248739388
    },
    {
      "type": "training",
      "description": "Training step 920",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:13",
      "total_flops_so_far": 1320807344111164.0,
      "budget_used_percent": 1.3208073441111639
    },
    {
      "type": "training",
      "description": "Training step 921",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:13",
      "total_flops_so_far": 1322238439482940.0,
      "budget_used_percent": 1.32223843948294
    },
    {
      "type": "training",
      "description": "Training step 922",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:13",
      "total_flops_so_far": 1323669534854716.0,
      "budget_used_percent": 1.323669534854716
    },
    {
      "type": "training",
      "description": "Training step 923",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:13",
      "total_flops_so_far": 1325100630226492.0,
      "budget_used_percent": 1.325100630226492
    },
    {
      "type": "training",
      "description": "Training step 924",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:14",
      "total_flops_so_far": 1326531725598268.0,
      "budget_used_percent": 1.326531725598268
    },
    {
      "type": "training",
      "description": "Training step 925",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:14",
      "total_flops_so_far": 1327962820970044.0,
      "budget_used_percent": 1.3279628209700438
    },
    {
      "type": "training",
      "description": "Training step 926",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:14",
      "total_flops_so_far": 1329393916341820.0,
      "budget_used_percent": 1.32939391634182
    },
    {
      "type": "training",
      "description": "Training step 927",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:14",
      "total_flops_so_far": 1330825011713596.0,
      "budget_used_percent": 1.330825011713596
    },
    {
      "type": "training",
      "description": "Training step 928",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:14",
      "total_flops_so_far": 1332256107085372.0,
      "budget_used_percent": 1.332256107085372
    },
    {
      "type": "training",
      "description": "Training step 929",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:14",
      "total_flops_so_far": 1333687202457148.0,
      "budget_used_percent": 1.333687202457148
    },
    {
      "type": "training",
      "description": "Training step 930",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:14",
      "total_flops_so_far": 1335118297828924.0,
      "budget_used_percent": 1.335118297828924
    },
    {
      "type": "training",
      "description": "Training step 931",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:15",
      "total_flops_so_far": 1336549393200700.0,
      "budget_used_percent": 1.3365493932007
    },
    {
      "type": "training",
      "description": "Training step 932",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:15",
      "total_flops_so_far": 1337980488572476.0,
      "budget_used_percent": 1.337980488572476
    },
    {
      "type": "training",
      "description": "Training step 933",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:15",
      "total_flops_so_far": 1339411583944252.0,
      "budget_used_percent": 1.339411583944252
    },
    {
      "type": "training",
      "description": "Training step 934",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:15",
      "total_flops_so_far": 1340842679316028.0,
      "budget_used_percent": 1.340842679316028
    },
    {
      "type": "training",
      "description": "Training step 935",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:15",
      "total_flops_so_far": 1342273774687804.0,
      "budget_used_percent": 1.342273774687804
    },
    {
      "type": "training",
      "description": "Training step 936",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:15",
      "total_flops_so_far": 1343704870059580.0,
      "budget_used_percent": 1.34370487005958
    },
    {
      "type": "training",
      "description": "Training step 937",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:15",
      "total_flops_so_far": 1345135965431356.0,
      "budget_used_percent": 1.345135965431356
    },
    {
      "type": "training",
      "description": "Training step 938",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:16",
      "total_flops_so_far": 1346567060803132.0,
      "budget_used_percent": 1.3465670608031322
    },
    {
      "type": "training",
      "description": "Training step 939",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:16",
      "total_flops_so_far": 1347998156174908.0,
      "budget_used_percent": 1.347998156174908
    },
    {
      "type": "training",
      "description": "Training step 940",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:16",
      "total_flops_so_far": 1349429251546684.0,
      "budget_used_percent": 1.3494292515466841
    },
    {
      "type": "training",
      "description": "Training step 941",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:16",
      "total_flops_so_far": 1350860346918460.0,
      "budget_used_percent": 1.35086034691846
    },
    {
      "type": "training",
      "description": "Training step 942",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:16",
      "total_flops_so_far": 1352291442290236.0,
      "budget_used_percent": 1.352291442290236
    },
    {
      "type": "training",
      "description": "Training step 943",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:16",
      "total_flops_so_far": 1353722537662012.0,
      "budget_used_percent": 1.3537225376620121
    },
    {
      "type": "training",
      "description": "Training step 944",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:16",
      "total_flops_so_far": 1355153633033788.0,
      "budget_used_percent": 1.3551536330337879
    },
    {
      "type": "training",
      "description": "Training step 945",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:17",
      "total_flops_so_far": 1356584728405564.0,
      "budget_used_percent": 1.356584728405564
    },
    {
      "type": "training",
      "description": "Training step 946",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:17",
      "total_flops_so_far": 1358015823777340.0,
      "budget_used_percent": 1.35801582377734
    },
    {
      "type": "training",
      "description": "Training step 947",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:17",
      "total_flops_so_far": 1359446919149116.0,
      "budget_used_percent": 1.3594469191491159
    },
    {
      "type": "training",
      "description": "Training step 948",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:17",
      "total_flops_so_far": 1360878014520892.0,
      "budget_used_percent": 1.360878014520892
    },
    {
      "type": "training",
      "description": "Training step 949",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:17",
      "total_flops_so_far": 1362309109892668.0,
      "budget_used_percent": 1.362309109892668
    },
    {
      "type": "training",
      "description": "Training step 950",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:17",
      "total_flops_so_far": 1363740205264444.0,
      "budget_used_percent": 1.363740205264444
    },
    {
      "type": "training",
      "description": "Training step 951",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:17",
      "total_flops_so_far": 1365171300636220.0,
      "budget_used_percent": 1.36517130063622
    },
    {
      "type": "training",
      "description": "Training step 952",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:18",
      "total_flops_so_far": 1366602396007996.0,
      "budget_used_percent": 1.366602396007996
    },
    {
      "type": "training",
      "description": "Training step 953",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:18",
      "total_flops_so_far": 1368033491379772.0,
      "budget_used_percent": 1.368033491379772
    },
    {
      "type": "training",
      "description": "Training step 954",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:18",
      "total_flops_so_far": 1369464586751548.0,
      "budget_used_percent": 1.369464586751548
    },
    {
      "type": "training",
      "description": "Training step 955",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:18",
      "total_flops_so_far": 1370895682123324.0,
      "budget_used_percent": 1.370895682123324
    },
    {
      "type": "training",
      "description": "Training step 956",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:18",
      "total_flops_so_far": 1372326777495100.0,
      "budget_used_percent": 1.3723267774951
    },
    {
      "type": "training",
      "description": "Training step 957",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:18",
      "total_flops_so_far": 1373757872866876.0,
      "budget_used_percent": 1.373757872866876
    },
    {
      "type": "training",
      "description": "Training step 958",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:18",
      "total_flops_so_far": 1375188968238652.0,
      "budget_used_percent": 1.375188968238652
    },
    {
      "type": "training",
      "description": "Training step 959",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:18",
      "total_flops_so_far": 1376620063610428.0,
      "budget_used_percent": 1.376620063610428
    },
    {
      "type": "training",
      "description": "Training step 960",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:19",
      "total_flops_so_far": 1378051158982204.0,
      "budget_used_percent": 1.378051158982204
    },
    {
      "type": "training",
      "description": "Training step 961",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:19",
      "total_flops_so_far": 1379482254353980.0,
      "budget_used_percent": 1.37948225435398
    },
    {
      "type": "training",
      "description": "Training step 962",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:19",
      "total_flops_so_far": 1380913349725756.0,
      "budget_used_percent": 1.380913349725756
    },
    {
      "type": "training",
      "description": "Training step 963",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:19",
      "total_flops_so_far": 1382344445097532.0,
      "budget_used_percent": 1.382344445097532
    },
    {
      "type": "training",
      "description": "Training step 964",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:19",
      "total_flops_so_far": 1383775540469308.0,
      "budget_used_percent": 1.383775540469308
    },
    {
      "type": "training",
      "description": "Training step 965",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:19",
      "total_flops_so_far": 1385206635841084.0,
      "budget_used_percent": 1.3852066358410842
    },
    {
      "type": "training",
      "description": "Training step 966",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:19",
      "total_flops_so_far": 1386637731212860.0,
      "budget_used_percent": 1.38663773121286
    },
    {
      "type": "training",
      "description": "Training step 967",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:20",
      "total_flops_so_far": 1388068826584636.0,
      "budget_used_percent": 1.388068826584636
    },
    {
      "type": "training",
      "description": "Training step 968",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:20",
      "total_flops_so_far": 1389499921956412.0,
      "budget_used_percent": 1.389499921956412
    },
    {
      "type": "training",
      "description": "Training step 969",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:20",
      "total_flops_so_far": 1390931017328188.0,
      "budget_used_percent": 1.390931017328188
    },
    {
      "type": "training",
      "description": "Training step 970",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:20",
      "total_flops_so_far": 1392362112699964.0,
      "budget_used_percent": 1.3923621126999641
    },
    {
      "type": "training",
      "description": "Training step 971",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:20",
      "total_flops_so_far": 1393793208071740.0,
      "budget_used_percent": 1.39379320807174
    },
    {
      "type": "training",
      "description": "Training step 972",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:20",
      "total_flops_so_far": 1395224303443516.0,
      "budget_used_percent": 1.395224303443516
    },
    {
      "type": "training",
      "description": "Training step 973",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:20",
      "total_flops_so_far": 1396655398815292.0,
      "budget_used_percent": 1.396655398815292
    },
    {
      "type": "training",
      "description": "Training step 974",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:21",
      "total_flops_so_far": 1398086494187068.0,
      "budget_used_percent": 1.3980864941870679
    },
    {
      "type": "training",
      "description": "Training step 975",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:21",
      "total_flops_so_far": 1399517589558844.0,
      "budget_used_percent": 1.399517589558844
    },
    {
      "type": "training",
      "description": "Training step 976",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:21",
      "total_flops_so_far": 1400948684930620.0,
      "budget_used_percent": 1.40094868493062
    },
    {
      "type": "training",
      "description": "Training step 977",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:21",
      "total_flops_so_far": 1402379780302396.0,
      "budget_used_percent": 1.402379780302396
    },
    {
      "type": "training",
      "description": "Training step 978",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:21",
      "total_flops_so_far": 1403810875674172.0,
      "budget_used_percent": 1.403810875674172
    },
    {
      "type": "training",
      "description": "Training step 979",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:21",
      "total_flops_so_far": 1405241971045948.0,
      "budget_used_percent": 1.4052419710459478
    },
    {
      "type": "training",
      "description": "Training step 980",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:21",
      "total_flops_so_far": 1406673066417724.0,
      "budget_used_percent": 1.406673066417724
    },
    {
      "type": "training",
      "description": "Training step 981",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:22",
      "total_flops_so_far": 1408104161789500.0,
      "budget_used_percent": 1.4081041617895
    },
    {
      "type": "training",
      "description": "Training step 982",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:22",
      "total_flops_so_far": 1409535257161276.0,
      "budget_used_percent": 1.409535257161276
    },
    {
      "type": "training",
      "description": "Training step 983",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:22",
      "total_flops_so_far": 1410966352533052.0,
      "budget_used_percent": 1.410966352533052
    },
    {
      "type": "training",
      "description": "Training step 984",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:22",
      "total_flops_so_far": 1412397447904828.0,
      "budget_used_percent": 1.412397447904828
    },
    {
      "type": "training",
      "description": "Training step 985",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:22",
      "total_flops_so_far": 1413828543276604.0,
      "budget_used_percent": 1.413828543276604
    },
    {
      "type": "training",
      "description": "Training step 986",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:22",
      "total_flops_so_far": 1415259638648380.0,
      "budget_used_percent": 1.41525963864838
    },
    {
      "type": "training",
      "description": "Training step 987",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:22",
      "total_flops_so_far": 1416690734020156.0,
      "budget_used_percent": 1.416690734020156
    },
    {
      "type": "training",
      "description": "Training step 988",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:23",
      "total_flops_so_far": 1418121829391932.0,
      "budget_used_percent": 1.418121829391932
    },
    {
      "type": "training",
      "description": "Training step 989",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:23",
      "total_flops_so_far": 1419552924763708.0,
      "budget_used_percent": 1.419552924763708
    },
    {
      "type": "training",
      "description": "Training step 990",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:23",
      "total_flops_so_far": 1420984020135484.0,
      "budget_used_percent": 1.420984020135484
    },
    {
      "type": "training",
      "description": "Training step 991",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:23",
      "total_flops_so_far": 1422415115507260.0,
      "budget_used_percent": 1.42241511550726
    },
    {
      "type": "training",
      "description": "Training step 992",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:23",
      "total_flops_so_far": 1423846210879036.0,
      "budget_used_percent": 1.4238462108790362
    },
    {
      "type": "training",
      "description": "Training step 993",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:23",
      "total_flops_so_far": 1425277306250812.0,
      "budget_used_percent": 1.425277306250812
    },
    {
      "type": "training",
      "description": "Training step 994",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:23",
      "total_flops_so_far": 1426708401622588.0,
      "budget_used_percent": 1.426708401622588
    },
    {
      "type": "training",
      "description": "Training step 995",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:24",
      "total_flops_so_far": 1428139496994364.0,
      "budget_used_percent": 1.428139496994364
    },
    {
      "type": "training",
      "description": "Training step 996",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:24",
      "total_flops_so_far": 1429570592366140.0,
      "budget_used_percent": 1.42957059236614
    },
    {
      "type": "training",
      "description": "Training step 997",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:24",
      "total_flops_so_far": 1431001687737916.0,
      "budget_used_percent": 1.4310016877379161
    },
    {
      "type": "training",
      "description": "Training step 998",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:24",
      "total_flops_so_far": 1432432783109692.0,
      "budget_used_percent": 1.432432783109692
    },
    {
      "type": "training",
      "description": "Training step 999",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:24",
      "total_flops_so_far": 1433863878481468.0,
      "budget_used_percent": 1.433863878481468
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 0",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552080785760.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:25",
      "total_flops_so_far": 1434415959267228.0,
      "budget_used_percent": 1.4344159592672279
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 1",
      "context_len": 604,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 555682299984.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:27",
      "total_flops_so_far": 1434971641567212.0,
      "budget_used_percent": 1.434971641567212
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 2",
      "context_len": 602,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 553881182680.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:28",
      "total_flops_so_far": 1435525522749892.0,
      "budget_used_percent": 1.435525522749892
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 3",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552080785760.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:29",
      "total_flops_so_far": 1436077603535652.0,
      "budget_used_percent": 1.436077603535652
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 4",
      "context_len": 603,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 554781651284.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:30",
      "total_flops_so_far": 1436632385186936.0,
      "budget_used_percent": 1.436632385186936
    },
    {
      "type": "training",
      "description": "Training step 1000",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:31",
      "total_flops_so_far": 1438063480558712.0,
      "budget_used_percent": 1.438063480558712
    },
    {
      "type": "training",
      "description": "Training step 1001",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:31",
      "total_flops_so_far": 1439494575930488.0,
      "budget_used_percent": 1.439494575930488
    },
    {
      "type": "training",
      "description": "Training step 1002",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:31",
      "total_flops_so_far": 1440925671302264.0,
      "budget_used_percent": 1.440925671302264
    },
    {
      "type": "training",
      "description": "Training step 1003",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:31",
      "total_flops_so_far": 1442356766674040.0,
      "budget_used_percent": 1.44235676667404
    },
    {
      "type": "training",
      "description": "Training step 1004",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:31",
      "total_flops_so_far": 1443787862045816.0,
      "budget_used_percent": 1.443787862045816
    },
    {
      "type": "training",
      "description": "Training step 1005",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:32",
      "total_flops_so_far": 1445218957417592.0,
      "budget_used_percent": 1.445218957417592
    },
    {
      "type": "training",
      "description": "Training step 1006",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:32",
      "total_flops_so_far": 1446650052789368.0,
      "budget_used_percent": 1.446650052789368
    },
    {
      "type": "training",
      "description": "Training step 1007",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:32",
      "total_flops_so_far": 1448081148161144.0,
      "budget_used_percent": 1.448081148161144
    },
    {
      "type": "training",
      "description": "Training step 1008",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:32",
      "total_flops_so_far": 1449512243532920.0,
      "budget_used_percent": 1.44951224353292
    },
    {
      "type": "training",
      "description": "Training step 1009",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:32",
      "total_flops_so_far": 1450943338904696.0,
      "budget_used_percent": 1.450943338904696
    },
    {
      "type": "training",
      "description": "Training step 1010",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:32",
      "total_flops_so_far": 1452374434276472.0,
      "budget_used_percent": 1.452374434276472
    },
    {
      "type": "training",
      "description": "Training step 1011",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:32",
      "total_flops_so_far": 1453805529648248.0,
      "budget_used_percent": 1.453805529648248
    },
    {
      "type": "training",
      "description": "Training step 1012",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:33",
      "total_flops_so_far": 1455236625020024.0,
      "budget_used_percent": 1.455236625020024
    },
    {
      "type": "training",
      "description": "Training step 1013",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:33",
      "total_flops_so_far": 1456667720391800.0,
      "budget_used_percent": 1.4566677203918001
    },
    {
      "type": "training",
      "description": "Training step 1014",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:33",
      "total_flops_so_far": 1458098815763576.0,
      "budget_used_percent": 1.458098815763576
    },
    {
      "type": "training",
      "description": "Training step 1015",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:33",
      "total_flops_so_far": 1459529911135352.0,
      "budget_used_percent": 1.459529911135352
    },
    {
      "type": "training",
      "description": "Training step 1016",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:33",
      "total_flops_so_far": 1460961006507128.0,
      "budget_used_percent": 1.4609610065071281
    },
    {
      "type": "training",
      "description": "Training step 1017",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:33",
      "total_flops_so_far": 1462392101878904.0,
      "budget_used_percent": 1.462392101878904
    },
    {
      "type": "training",
      "description": "Training step 1018",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:33",
      "total_flops_so_far": 1463823197250680.0,
      "budget_used_percent": 1.46382319725068
    },
    {
      "type": "training",
      "description": "Training step 1019",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:34",
      "total_flops_so_far": 1465254292622456.0,
      "budget_used_percent": 1.4652542926224559
    },
    {
      "type": "training",
      "description": "Training step 1020",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:34",
      "total_flops_so_far": 1466685387994232.0,
      "budget_used_percent": 1.4666853879942319
    },
    {
      "type": "training",
      "description": "Training step 1021",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:34",
      "total_flops_so_far": 1468116483366008.0,
      "budget_used_percent": 1.468116483366008
    },
    {
      "type": "training",
      "description": "Training step 1022",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:34",
      "total_flops_so_far": 1469547578737784.0,
      "budget_used_percent": 1.4695475787377839
    },
    {
      "type": "training",
      "description": "Training step 1023",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:34",
      "total_flops_so_far": 1470978674109560.0,
      "budget_used_percent": 1.47097867410956
    },
    {
      "type": "training",
      "description": "Training step 1024",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:34",
      "total_flops_so_far": 1472409769481336.0,
      "budget_used_percent": 1.472409769481336
    },
    {
      "type": "training",
      "description": "Training step 1025",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:34",
      "total_flops_so_far": 1473840864853112.0,
      "budget_used_percent": 1.4738408648531118
    },
    {
      "type": "training",
      "description": "Training step 1026",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:35",
      "total_flops_so_far": 1475271960224888.0,
      "budget_used_percent": 1.475271960224888
    },
    {
      "type": "training",
      "description": "Training step 1027",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:35",
      "total_flops_so_far": 1476703055596664.0,
      "budget_used_percent": 1.476703055596664
    },
    {
      "type": "training",
      "description": "Training step 1028",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:35",
      "total_flops_so_far": 1478134150968440.0,
      "budget_used_percent": 1.47813415096844
    },
    {
      "type": "training",
      "description": "Training step 1029",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:35",
      "total_flops_so_far": 1479565246340216.0,
      "budget_used_percent": 1.479565246340216
    },
    {
      "type": "training",
      "description": "Training step 1030",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:35",
      "total_flops_so_far": 1480996341711992.0,
      "budget_used_percent": 1.480996341711992
    },
    {
      "type": "training",
      "description": "Training step 1031",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:35",
      "total_flops_so_far": 1482427437083768.0,
      "budget_used_percent": 1.482427437083768
    },
    {
      "type": "training",
      "description": "Training step 1032",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:35",
      "total_flops_so_far": 1483858532455544.0,
      "budget_used_percent": 1.483858532455544
    },
    {
      "type": "training",
      "description": "Training step 1033",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:36",
      "total_flops_so_far": 1485289627827320.0,
      "budget_used_percent": 1.48528962782732
    },
    {
      "type": "training",
      "description": "Training step 1034",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:36",
      "total_flops_so_far": 1486720723199096.0,
      "budget_used_percent": 1.486720723199096
    },
    {
      "type": "training",
      "description": "Training step 1035",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:36",
      "total_flops_so_far": 1488151818570872.0,
      "budget_used_percent": 1.488151818570872
    },
    {
      "type": "training",
      "description": "Training step 1036",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:36",
      "total_flops_so_far": 1489582913942648.0,
      "budget_used_percent": 1.489582913942648
    },
    {
      "type": "training",
      "description": "Training step 1037",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:36",
      "total_flops_so_far": 1491014009314424.0,
      "budget_used_percent": 1.491014009314424
    },
    {
      "type": "training",
      "description": "Training step 1038",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:36",
      "total_flops_so_far": 1492445104686200.0,
      "budget_used_percent": 1.4924451046862
    },
    {
      "type": "training",
      "description": "Training step 1039",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:36",
      "total_flops_so_far": 1493876200057976.0,
      "budget_used_percent": 1.493876200057976
    },
    {
      "type": "training",
      "description": "Training step 1040",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:37",
      "total_flops_so_far": 1495307295429752.0,
      "budget_used_percent": 1.4953072954297522
    },
    {
      "type": "training",
      "description": "Training step 1041",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:37",
      "total_flops_so_far": 1496738390801528.0,
      "budget_used_percent": 1.496738390801528
    },
    {
      "type": "training",
      "description": "Training step 1042",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:37",
      "total_flops_so_far": 1498169486173304.0,
      "budget_used_percent": 1.498169486173304
    },
    {
      "type": "training",
      "description": "Training step 1043",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:37",
      "total_flops_so_far": 1499600581545080.0,
      "budget_used_percent": 1.4996005815450801
    },
    {
      "type": "training",
      "description": "Training step 1044",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:37",
      "total_flops_so_far": 1501031676916856.0,
      "budget_used_percent": 1.501031676916856
    },
    {
      "type": "training",
      "description": "Training step 1045",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:37",
      "total_flops_so_far": 1502462772288632.0,
      "budget_used_percent": 1.5024627722886321
    },
    {
      "type": "training",
      "description": "Training step 1046",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:37",
      "total_flops_so_far": 1503893867660408.0,
      "budget_used_percent": 1.5038938676604081
    },
    {
      "type": "training",
      "description": "Training step 1047",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:38",
      "total_flops_so_far": 1505324963032184.0,
      "budget_used_percent": 1.5053249630321839
    },
    {
      "type": "training",
      "description": "Training step 1048",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:38",
      "total_flops_so_far": 1506756058403960.0,
      "budget_used_percent": 1.50675605840396
    },
    {
      "type": "training",
      "description": "Training step 1049",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:38",
      "total_flops_so_far": 1508187153775736.0,
      "budget_used_percent": 1.5081871537757359
    },
    {
      "type": "training",
      "description": "Training step 1050",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:38",
      "total_flops_so_far": 1509618249147512.0,
      "budget_used_percent": 1.509618249147512
    },
    {
      "type": "training",
      "description": "Training step 1051",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:38",
      "total_flops_so_far": 1511049344519288.0,
      "budget_used_percent": 1.511049344519288
    },
    {
      "type": "training",
      "description": "Training step 1052",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:38",
      "total_flops_so_far": 1512480439891064.0,
      "budget_used_percent": 1.5124804398910638
    },
    {
      "type": "training",
      "description": "Training step 1053",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:38",
      "total_flops_so_far": 1513911535262840.0,
      "budget_used_percent": 1.51391153526284
    },
    {
      "type": "training",
      "description": "Training step 1054",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:39",
      "total_flops_so_far": 1515342630634616.0,
      "budget_used_percent": 1.515342630634616
    },
    {
      "type": "training",
      "description": "Training step 1055",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:39",
      "total_flops_so_far": 1516773726006392.0,
      "budget_used_percent": 1.516773726006392
    },
    {
      "type": "training",
      "description": "Training step 1056",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:39",
      "total_flops_so_far": 1518204821378168.0,
      "budget_used_percent": 1.518204821378168
    },
    {
      "type": "training",
      "description": "Training step 1057",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:39",
      "total_flops_so_far": 1519635916749944.0,
      "budget_used_percent": 1.519635916749944
    },
    {
      "type": "training",
      "description": "Training step 1058",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:39",
      "total_flops_so_far": 1521067012121720.0,
      "budget_used_percent": 1.52106701212172
    },
    {
      "type": "training",
      "description": "Training step 1059",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:39",
      "total_flops_so_far": 1522498107493496.0,
      "budget_used_percent": 1.522498107493496
    },
    {
      "type": "training",
      "description": "Training step 1060",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:39",
      "total_flops_so_far": 1523929202865272.0,
      "budget_used_percent": 1.523929202865272
    },
    {
      "type": "training",
      "description": "Training step 1061",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:40",
      "total_flops_so_far": 1525360298237048.0,
      "budget_used_percent": 1.525360298237048
    },
    {
      "type": "training",
      "description": "Training step 1062",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:40",
      "total_flops_so_far": 1526791393608824.0,
      "budget_used_percent": 1.526791393608824
    },
    {
      "type": "training",
      "description": "Training step 1063",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:40",
      "total_flops_so_far": 1528222488980600.0,
      "budget_used_percent": 1.5282224889806
    },
    {
      "type": "training",
      "description": "Training step 1064",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:40",
      "total_flops_so_far": 1529653584352376.0,
      "budget_used_percent": 1.529653584352376
    },
    {
      "type": "training",
      "description": "Training step 1065",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:40",
      "total_flops_so_far": 1531084679724152.0,
      "budget_used_percent": 1.531084679724152
    },
    {
      "type": "training",
      "description": "Training step 1066",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:40",
      "total_flops_so_far": 1532515775095928.0,
      "budget_used_percent": 1.532515775095928
    },
    {
      "type": "training",
      "description": "Training step 1067",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:40",
      "total_flops_so_far": 1533946870467704.0,
      "budget_used_percent": 1.533946870467704
    },
    {
      "type": "training",
      "description": "Training step 1068",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:41",
      "total_flops_so_far": 1535377965839480.0,
      "budget_used_percent": 1.53537796583948
    },
    {
      "type": "training",
      "description": "Training step 1069",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:41",
      "total_flops_so_far": 1536809061211256.0,
      "budget_used_percent": 1.536809061211256
    },
    {
      "type": "training",
      "description": "Training step 1070",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:41",
      "total_flops_so_far": 1538240156583032.0,
      "budget_used_percent": 1.5382401565830321
    },
    {
      "type": "training",
      "description": "Training step 1071",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:41",
      "total_flops_so_far": 1539671251954808.0,
      "budget_used_percent": 1.539671251954808
    },
    {
      "type": "training",
      "description": "Training step 1072",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:41",
      "total_flops_so_far": 1541102347326584.0,
      "budget_used_percent": 1.5411023473265841
    },
    {
      "type": "training",
      "description": "Training step 1073",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:41",
      "total_flops_so_far": 1542533442698360.0,
      "budget_used_percent": 1.54253344269836
    },
    {
      "type": "training",
      "description": "Training step 1074",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:41",
      "total_flops_so_far": 1543964538070136.0,
      "budget_used_percent": 1.543964538070136
    },
    {
      "type": "training",
      "description": "Training step 1075",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:42",
      "total_flops_so_far": 1545395633441912.0,
      "budget_used_percent": 1.545395633441912
    },
    {
      "type": "training",
      "description": "Training step 1076",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:42",
      "total_flops_so_far": 1546826728813688.0,
      "budget_used_percent": 1.5468267288136879
    },
    {
      "type": "training",
      "description": "Training step 1077",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:42",
      "total_flops_so_far": 1548257824185464.0,
      "budget_used_percent": 1.548257824185464
    },
    {
      "type": "training",
      "description": "Training step 1078",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:42",
      "total_flops_so_far": 1549688919557240.0,
      "budget_used_percent": 1.54968891955724
    },
    {
      "type": "training",
      "description": "Training step 1079",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:42",
      "total_flops_so_far": 1551120014929016.0,
      "budget_used_percent": 1.5511200149290159
    },
    {
      "type": "training",
      "description": "Training step 1080",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:42",
      "total_flops_so_far": 1552551110300792.0,
      "budget_used_percent": 1.552551110300792
    },
    {
      "type": "training",
      "description": "Training step 1081",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:42",
      "total_flops_so_far": 1553982205672568.0,
      "budget_used_percent": 1.553982205672568
    },
    {
      "type": "training",
      "description": "Training step 1082",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:43",
      "total_flops_so_far": 1555413301044344.0,
      "budget_used_percent": 1.555413301044344
    },
    {
      "type": "training",
      "description": "Training step 1083",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:43",
      "total_flops_so_far": 1556844396416120.0,
      "budget_used_percent": 1.55684439641612
    },
    {
      "type": "training",
      "description": "Training step 1084",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:43",
      "total_flops_so_far": 1558275491787896.0,
      "budget_used_percent": 1.558275491787896
    },
    {
      "type": "training",
      "description": "Training step 1085",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:43",
      "total_flops_so_far": 1559706587159672.0,
      "budget_used_percent": 1.559706587159672
    },
    {
      "type": "training",
      "description": "Training step 1086",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:43",
      "total_flops_so_far": 1561137682531448.0,
      "budget_used_percent": 1.561137682531448
    },
    {
      "type": "training",
      "description": "Training step 1087",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:43",
      "total_flops_so_far": 1562568777903224.0,
      "budget_used_percent": 1.562568777903224
    },
    {
      "type": "training",
      "description": "Training step 1088",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:43",
      "total_flops_so_far": 1563999873275000.0,
      "budget_used_percent": 1.5639998732749998
    },
    {
      "type": "training",
      "description": "Training step 1089",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:44",
      "total_flops_so_far": 1565430968646776.0,
      "budget_used_percent": 1.565430968646776
    },
    {
      "type": "training",
      "description": "Training step 1090",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:44",
      "total_flops_so_far": 1566862064018552.0,
      "budget_used_percent": 1.566862064018552
    },
    {
      "type": "training",
      "description": "Training step 1091",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:44",
      "total_flops_so_far": 1568293159390328.0,
      "budget_used_percent": 1.5682931593903282
    },
    {
      "type": "training",
      "description": "Training step 1092",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:44",
      "total_flops_so_far": 1569724254762104.0,
      "budget_used_percent": 1.569724254762104
    },
    {
      "type": "training",
      "description": "Training step 1093",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:44",
      "total_flops_so_far": 1571155350133880.0,
      "budget_used_percent": 1.57115535013388
    },
    {
      "type": "training",
      "description": "Training step 1094",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:44",
      "total_flops_so_far": 1572586445505656.0,
      "budget_used_percent": 1.5725864455056562
    },
    {
      "type": "training",
      "description": "Training step 1095",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:44",
      "total_flops_so_far": 1574017540877432.0,
      "budget_used_percent": 1.574017540877432
    },
    {
      "type": "training",
      "description": "Training step 1096",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:45",
      "total_flops_so_far": 1575448636249208.0,
      "budget_used_percent": 1.575448636249208
    },
    {
      "type": "training",
      "description": "Training step 1097",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:45",
      "total_flops_so_far": 1576879731620984.0,
      "budget_used_percent": 1.5768797316209842
    },
    {
      "type": "training",
      "description": "Training step 1098",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:45",
      "total_flops_so_far": 1578310826992760.0,
      "budget_used_percent": 1.5783108269927602
    },
    {
      "type": "training",
      "description": "Training step 1099",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:45",
      "total_flops_so_far": 1579741922364536.0,
      "budget_used_percent": 1.579741922364536
    },
    {
      "type": "training",
      "description": "Training step 1100",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:45",
      "total_flops_so_far": 1581173017736312.0,
      "budget_used_percent": 1.5811730177363121
    },
    {
      "type": "training",
      "description": "Training step 1101",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:45",
      "total_flops_so_far": 1582604113108088.0,
      "budget_used_percent": 1.5826041131080881
    },
    {
      "type": "training",
      "description": "Training step 1102",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:45",
      "total_flops_so_far": 1584035208479864.0,
      "budget_used_percent": 1.584035208479864
    },
    {
      "type": "training",
      "description": "Training step 1103",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:46",
      "total_flops_so_far": 1585466303851640.0,
      "budget_used_percent": 1.58546630385164
    },
    {
      "type": "training",
      "description": "Training step 1104",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:46",
      "total_flops_so_far": 1586897399223416.0,
      "budget_used_percent": 1.586897399223416
    },
    {
      "type": "training",
      "description": "Training step 1105",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:46",
      "total_flops_so_far": 1588328494595192.0,
      "budget_used_percent": 1.5883284945951919
    },
    {
      "type": "training",
      "description": "Training step 1106",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:46",
      "total_flops_so_far": 1589759589966968.0,
      "budget_used_percent": 1.5897595899669679
    },
    {
      "type": "training",
      "description": "Training step 1107",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:46",
      "total_flops_so_far": 1591190685338744.0,
      "budget_used_percent": 1.591190685338744
    },
    {
      "type": "training",
      "description": "Training step 1108",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:46",
      "total_flops_so_far": 1592621780710520.0,
      "budget_used_percent": 1.59262178071052
    },
    {
      "type": "training",
      "description": "Training step 1109",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:46",
      "total_flops_so_far": 1594052876082296.0,
      "budget_used_percent": 1.5940528760822958
    },
    {
      "type": "training",
      "description": "Training step 1110",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:47",
      "total_flops_so_far": 1595483971454072.0,
      "budget_used_percent": 1.595483971454072
    },
    {
      "type": "training",
      "description": "Training step 1111",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:47",
      "total_flops_so_far": 1596915066825848.0,
      "budget_used_percent": 1.596915066825848
    },
    {
      "type": "training",
      "description": "Training step 1112",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:47",
      "total_flops_so_far": 1598346162197624.0,
      "budget_used_percent": 1.5983461621976238
    },
    {
      "type": "training",
      "description": "Training step 1113",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:47",
      "total_flops_so_far": 1599777257569400.0,
      "budget_used_percent": 1.5997772575694
    },
    {
      "type": "training",
      "description": "Training step 1114",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:47",
      "total_flops_so_far": 1601208352941176.0,
      "budget_used_percent": 1.601208352941176
    },
    {
      "type": "training",
      "description": "Training step 1115",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:47",
      "total_flops_so_far": 1602639448312952.0,
      "budget_used_percent": 1.6026394483129518
    },
    {
      "type": "training",
      "description": "Training step 1116",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:48",
      "total_flops_so_far": 1604070543684728.0,
      "budget_used_percent": 1.604070543684728
    },
    {
      "type": "training",
      "description": "Training step 1117",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:48",
      "total_flops_so_far": 1605501639056504.0,
      "budget_used_percent": 1.605501639056504
    },
    {
      "type": "training",
      "description": "Training step 1118",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:48",
      "total_flops_so_far": 1606932734428280.0,
      "budget_used_percent": 1.6069327344282802
    },
    {
      "type": "training",
      "description": "Training step 1119",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:48",
      "total_flops_so_far": 1608363829800056.0,
      "budget_used_percent": 1.608363829800056
    },
    {
      "type": "training",
      "description": "Training step 1120",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:48",
      "total_flops_so_far": 1609794925171832.0,
      "budget_used_percent": 1.609794925171832
    },
    {
      "type": "training",
      "description": "Training step 1121",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:48",
      "total_flops_so_far": 1611226020543608.0,
      "budget_used_percent": 1.6112260205436082
    },
    {
      "type": "training",
      "description": "Training step 1122",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:48",
      "total_flops_so_far": 1612657115915384.0,
      "budget_used_percent": 1.612657115915384
    },
    {
      "type": "training",
      "description": "Training step 1123",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:49",
      "total_flops_so_far": 1614088211287160.0,
      "budget_used_percent": 1.61408821128716
    },
    {
      "type": "training",
      "description": "Training step 1124",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:49",
      "total_flops_so_far": 1615519306658936.0,
      "budget_used_percent": 1.6155193066589362
    },
    {
      "type": "training",
      "description": "Training step 1125",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:49",
      "total_flops_so_far": 1616950402030712.0,
      "budget_used_percent": 1.616950402030712
    },
    {
      "type": "training",
      "description": "Training step 1126",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:49",
      "total_flops_so_far": 1618381497402488.0,
      "budget_used_percent": 1.618381497402488
    },
    {
      "type": "training",
      "description": "Training step 1127",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:49",
      "total_flops_so_far": 1619812592774264.0,
      "budget_used_percent": 1.619812592774264
    },
    {
      "type": "training",
      "description": "Training step 1128",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:49",
      "total_flops_so_far": 1621243688146040.0,
      "budget_used_percent": 1.6212436881460401
    },
    {
      "type": "training",
      "description": "Training step 1129",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:49",
      "total_flops_so_far": 1622674783517816.0,
      "budget_used_percent": 1.622674783517816
    },
    {
      "type": "training",
      "description": "Training step 1130",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:50",
      "total_flops_so_far": 1624105878889592.0,
      "budget_used_percent": 1.624105878889592
    },
    {
      "type": "training",
      "description": "Training step 1131",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:50",
      "total_flops_so_far": 1625536974261368.0,
      "budget_used_percent": 1.6255369742613681
    },
    {
      "type": "training",
      "description": "Training step 1132",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:50",
      "total_flops_so_far": 1626968069633144.0,
      "budget_used_percent": 1.6269680696331439
    },
    {
      "type": "training",
      "description": "Training step 1133",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:50",
      "total_flops_so_far": 1628399165004920.0,
      "budget_used_percent": 1.6283991650049199
    },
    {
      "type": "training",
      "description": "Training step 1134",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:50",
      "total_flops_so_far": 1629830260376696.0,
      "budget_used_percent": 1.629830260376696
    },
    {
      "type": "training",
      "description": "Training step 1135",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:50",
      "total_flops_so_far": 1631261355748472.0,
      "budget_used_percent": 1.631261355748472
    },
    {
      "type": "training",
      "description": "Training step 1136",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:50",
      "total_flops_so_far": 1632692451120248.0,
      "budget_used_percent": 1.6326924511202479
    },
    {
      "type": "training",
      "description": "Training step 1137",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:51",
      "total_flops_so_far": 1634123546492024.0,
      "budget_used_percent": 1.634123546492024
    },
    {
      "type": "training",
      "description": "Training step 1138",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:51",
      "total_flops_so_far": 1635554641863800.0,
      "budget_used_percent": 1.6355546418638
    },
    {
      "type": "training",
      "description": "Training step 1139",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:51",
      "total_flops_so_far": 1636985737235576.0,
      "budget_used_percent": 1.6369857372355758
    },
    {
      "type": "training",
      "description": "Training step 1140",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:51",
      "total_flops_so_far": 1638416832607352.0,
      "budget_used_percent": 1.638416832607352
    },
    {
      "type": "training",
      "description": "Training step 1141",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:51",
      "total_flops_so_far": 1639847927979128.0,
      "budget_used_percent": 1.639847927979128
    },
    {
      "type": "training",
      "description": "Training step 1142",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:51",
      "total_flops_so_far": 1641279023350904.0,
      "budget_used_percent": 1.6412790233509038
    },
    {
      "type": "training",
      "description": "Training step 1143",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:51",
      "total_flops_so_far": 1642710118722680.0,
      "budget_used_percent": 1.64271011872268
    },
    {
      "type": "training",
      "description": "Training step 1144",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:52",
      "total_flops_so_far": 1644141214094456.0,
      "budget_used_percent": 1.644141214094456
    },
    {
      "type": "training",
      "description": "Training step 1145",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:52",
      "total_flops_so_far": 1645572309466232.0,
      "budget_used_percent": 1.6455723094662322
    },
    {
      "type": "training",
      "description": "Training step 1146",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:52",
      "total_flops_so_far": 1647003404838008.0,
      "budget_used_percent": 1.647003404838008
    },
    {
      "type": "training",
      "description": "Training step 1147",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:52",
      "total_flops_so_far": 1648434500209784.0,
      "budget_used_percent": 1.648434500209784
    },
    {
      "type": "training",
      "description": "Training step 1148",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:52",
      "total_flops_so_far": 1649865595581560.0,
      "budget_used_percent": 1.6498655955815602
    },
    {
      "type": "training",
      "description": "Training step 1149",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:52",
      "total_flops_so_far": 1651296690953336.0,
      "budget_used_percent": 1.651296690953336
    },
    {
      "type": "training",
      "description": "Training step 1150",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:52",
      "total_flops_so_far": 1652727786325112.0,
      "budget_used_percent": 1.652727786325112
    },
    {
      "type": "training",
      "description": "Training step 1151",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:53",
      "total_flops_so_far": 1654158881696888.0,
      "budget_used_percent": 1.6541588816968882
    },
    {
      "type": "training",
      "description": "Training step 1152",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:53",
      "total_flops_so_far": 1655589977068664.0,
      "budget_used_percent": 1.6555899770686637
    },
    {
      "type": "training",
      "description": "Training step 1153",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:53",
      "total_flops_so_far": 1657021072440440.0,
      "budget_used_percent": 1.65702107244044
    },
    {
      "type": "training",
      "description": "Training step 1154",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:53",
      "total_flops_so_far": 1658452167812216.0,
      "budget_used_percent": 1.6584521678122162
    },
    {
      "type": "training",
      "description": "Training step 1155",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:53",
      "total_flops_so_far": 1659883263183992.0,
      "budget_used_percent": 1.6598832631839922
    },
    {
      "type": "training",
      "description": "Training step 1156",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:53",
      "total_flops_so_far": 1661314358555768.0,
      "budget_used_percent": 1.661314358555768
    },
    {
      "type": "training",
      "description": "Training step 1157",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:53",
      "total_flops_so_far": 1662745453927544.0,
      "budget_used_percent": 1.662745453927544
    },
    {
      "type": "training",
      "description": "Training step 1158",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:54",
      "total_flops_so_far": 1664176549299320.0,
      "budget_used_percent": 1.6641765492993201
    },
    {
      "type": "training",
      "description": "Training step 1159",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:54",
      "total_flops_so_far": 1665607644671096.0,
      "budget_used_percent": 1.665607644671096
    },
    {
      "type": "training",
      "description": "Training step 1160",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:54",
      "total_flops_so_far": 1667038740042872.0,
      "budget_used_percent": 1.667038740042872
    },
    {
      "type": "training",
      "description": "Training step 1161",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:54",
      "total_flops_so_far": 1668469835414648.0,
      "budget_used_percent": 1.668469835414648
    },
    {
      "type": "training",
      "description": "Training step 1162",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:54",
      "total_flops_so_far": 1669900930786424.0,
      "budget_used_percent": 1.6699009307864239
    },
    {
      "type": "training",
      "description": "Training step 1163",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:54",
      "total_flops_so_far": 1671332026158200.0,
      "budget_used_percent": 1.6713320261581999
    },
    {
      "type": "training",
      "description": "Training step 1164",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:54",
      "total_flops_so_far": 1672763121529976.0,
      "budget_used_percent": 1.672763121529976
    },
    {
      "type": "training",
      "description": "Training step 1165",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:55",
      "total_flops_so_far": 1674194216901752.0,
      "budget_used_percent": 1.674194216901752
    },
    {
      "type": "training",
      "description": "Training step 1166",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:55",
      "total_flops_so_far": 1675625312273528.0,
      "budget_used_percent": 1.6756253122735278
    },
    {
      "type": "training",
      "description": "Training step 1167",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:55",
      "total_flops_so_far": 1677056407645304.0,
      "budget_used_percent": 1.677056407645304
    },
    {
      "type": "training",
      "description": "Training step 1168",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:55",
      "total_flops_so_far": 1678487503017080.0,
      "budget_used_percent": 1.67848750301708
    },
    {
      "type": "training",
      "description": "Training step 1169",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:55",
      "total_flops_so_far": 1679918598388856.0,
      "budget_used_percent": 1.6799185983888558
    },
    {
      "type": "training",
      "description": "Training step 1170",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:55",
      "total_flops_so_far": 1681349693760632.0,
      "budget_used_percent": 1.681349693760632
    },
    {
      "type": "training",
      "description": "Training step 1171",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:55",
      "total_flops_so_far": 1682780789132408.0,
      "budget_used_percent": 1.682780789132408
    },
    {
      "type": "training",
      "description": "Training step 1172",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:56",
      "total_flops_so_far": 1684211884504184.0,
      "budget_used_percent": 1.6842118845041842
    },
    {
      "type": "training",
      "description": "Training step 1173",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:56",
      "total_flops_so_far": 1685642979875960.0,
      "budget_used_percent": 1.68564297987596
    },
    {
      "type": "training",
      "description": "Training step 1174",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:56",
      "total_flops_so_far": 1687074075247736.0,
      "budget_used_percent": 1.687074075247736
    },
    {
      "type": "training",
      "description": "Training step 1175",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:56",
      "total_flops_so_far": 1688505170619512.0,
      "budget_used_percent": 1.6885051706195122
    },
    {
      "type": "training",
      "description": "Training step 1176",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:56",
      "total_flops_so_far": 1689936265991288.0,
      "budget_used_percent": 1.689936265991288
    },
    {
      "type": "training",
      "description": "Training step 1177",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:56",
      "total_flops_so_far": 1691367361363064.0,
      "budget_used_percent": 1.691367361363064
    },
    {
      "type": "training",
      "description": "Training step 1178",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:56",
      "total_flops_so_far": 1692798456734840.0,
      "budget_used_percent": 1.6927984567348402
    },
    {
      "type": "training",
      "description": "Training step 1179",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:57",
      "total_flops_so_far": 1694229552106616.0,
      "budget_used_percent": 1.694229552106616
    },
    {
      "type": "training",
      "description": "Training step 1180",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:57",
      "total_flops_so_far": 1695660647478392.0,
      "budget_used_percent": 1.695660647478392
    },
    {
      "type": "training",
      "description": "Training step 1181",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:57",
      "total_flops_so_far": 1697091742850168.0,
      "budget_used_percent": 1.697091742850168
    },
    {
      "type": "training",
      "description": "Training step 1182",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:57",
      "total_flops_so_far": 1698522838221944.0,
      "budget_used_percent": 1.6985228382219442
    },
    {
      "type": "training",
      "description": "Training step 1183",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:57",
      "total_flops_so_far": 1699953933593720.0,
      "budget_used_percent": 1.69995393359372
    },
    {
      "type": "training",
      "description": "Training step 1184",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:57",
      "total_flops_so_far": 1701385028965496.0,
      "budget_used_percent": 1.701385028965496
    },
    {
      "type": "training",
      "description": "Training step 1185",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:57",
      "total_flops_so_far": 1702816124337272.0,
      "budget_used_percent": 1.7028161243372721
    },
    {
      "type": "training",
      "description": "Training step 1186",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:58",
      "total_flops_so_far": 1704247219709048.0,
      "budget_used_percent": 1.704247219709048
    },
    {
      "type": "training",
      "description": "Training step 1187",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:58",
      "total_flops_so_far": 1705678315080824.0,
      "budget_used_percent": 1.705678315080824
    },
    {
      "type": "training",
      "description": "Training step 1188",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:58",
      "total_flops_so_far": 1707109410452600.0,
      "budget_used_percent": 1.7071094104526001
    },
    {
      "type": "training",
      "description": "Training step 1189",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:58",
      "total_flops_so_far": 1708540505824376.0,
      "budget_used_percent": 1.7085405058243759
    },
    {
      "type": "training",
      "description": "Training step 1190",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:58",
      "total_flops_so_far": 1709971601196152.0,
      "budget_used_percent": 1.7099716011961519
    },
    {
      "type": "training",
      "description": "Training step 1191",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:58",
      "total_flops_so_far": 1711402696567928.0,
      "budget_used_percent": 1.711402696567928
    },
    {
      "type": "training",
      "description": "Training step 1192",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:58",
      "total_flops_so_far": 1712833791939704.0,
      "budget_used_percent": 1.712833791939704
    },
    {
      "type": "training",
      "description": "Training step 1193",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:59",
      "total_flops_so_far": 1714264887311480.0,
      "budget_used_percent": 1.7142648873114799
    },
    {
      "type": "training",
      "description": "Training step 1194",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:59",
      "total_flops_so_far": 1715695982683256.0,
      "budget_used_percent": 1.715695982683256
    },
    {
      "type": "training",
      "description": "Training step 1195",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:59",
      "total_flops_so_far": 1717127078055032.0,
      "budget_used_percent": 1.717127078055032
    },
    {
      "type": "training",
      "description": "Training step 1196",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:59",
      "total_flops_so_far": 1718558173426808.0,
      "budget_used_percent": 1.7185581734268078
    },
    {
      "type": "training",
      "description": "Training step 1197",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:59",
      "total_flops_so_far": 1719989268798584.0,
      "budget_used_percent": 1.719989268798584
    },
    {
      "type": "training",
      "description": "Training step 1198",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:59",
      "total_flops_so_far": 1721420364170360.0,
      "budget_used_percent": 1.72142036417036
    },
    {
      "type": "training",
      "description": "Training step 1199",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:40:59",
      "total_flops_so_far": 1722851459542136.0,
      "budget_used_percent": 1.7228514595421358
    },
    {
      "type": "training",
      "description": "Training step 1200",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:00",
      "total_flops_so_far": 1724282554913912.0,
      "budget_used_percent": 1.724282554913912
    },
    {
      "type": "training",
      "description": "Training step 1201",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:00",
      "total_flops_so_far": 1725713650285688.0,
      "budget_used_percent": 1.725713650285688
    },
    {
      "type": "training",
      "description": "Training step 1202",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:00",
      "total_flops_so_far": 1727144745657464.0,
      "budget_used_percent": 1.7271447456574642
    },
    {
      "type": "training",
      "description": "Training step 1203",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:00",
      "total_flops_so_far": 1728575841029240.0,
      "budget_used_percent": 1.72857584102924
    },
    {
      "type": "training",
      "description": "Training step 1204",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:00",
      "total_flops_so_far": 1730006936401016.0,
      "budget_used_percent": 1.730006936401016
    },
    {
      "type": "training",
      "description": "Training step 1205",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:00",
      "total_flops_so_far": 1731438031772792.0,
      "budget_used_percent": 1.7314380317727922
    },
    {
      "type": "training",
      "description": "Training step 1206",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:00",
      "total_flops_so_far": 1732869127144568.0,
      "budget_used_percent": 1.7328691271445678
    },
    {
      "type": "training",
      "description": "Training step 1207",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:01",
      "total_flops_so_far": 1734300222516344.0,
      "budget_used_percent": 1.734300222516344
    },
    {
      "type": "training",
      "description": "Training step 1208",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:01",
      "total_flops_so_far": 1735731317888120.0,
      "budget_used_percent": 1.7357313178881202
    },
    {
      "type": "training",
      "description": "Training step 1209",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:01",
      "total_flops_so_far": 1737162413259896.0,
      "budget_used_percent": 1.7371624132598957
    },
    {
      "type": "training",
      "description": "Training step 1210",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:01",
      "total_flops_so_far": 1738593508631672.0,
      "budget_used_percent": 1.738593508631672
    },
    {
      "type": "training",
      "description": "Training step 1211",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:01",
      "total_flops_so_far": 1740024604003448.0,
      "budget_used_percent": 1.740024604003448
    },
    {
      "type": "training",
      "description": "Training step 1212",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:01",
      "total_flops_so_far": 1741455699375224.0,
      "budget_used_percent": 1.7414556993752242
    },
    {
      "type": "training",
      "description": "Training step 1213",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:01",
      "total_flops_so_far": 1742886794747000.0,
      "budget_used_percent": 1.742886794747
    },
    {
      "type": "training",
      "description": "Training step 1214",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:02",
      "total_flops_so_far": 1744317890118776.0,
      "budget_used_percent": 1.744317890118776
    },
    {
      "type": "training",
      "description": "Training step 1215",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:02",
      "total_flops_so_far": 1745748985490552.0,
      "budget_used_percent": 1.7457489854905521
    },
    {
      "type": "training",
      "description": "Training step 1216",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:02",
      "total_flops_so_far": 1747180080862328.0,
      "budget_used_percent": 1.747180080862328
    },
    {
      "type": "training",
      "description": "Training step 1217",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:02",
      "total_flops_so_far": 1748611176234104.0,
      "budget_used_percent": 1.748611176234104
    },
    {
      "type": "training",
      "description": "Training step 1218",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:02",
      "total_flops_so_far": 1750042271605880.0,
      "budget_used_percent": 1.75004227160588
    },
    {
      "type": "training",
      "description": "Training step 1219",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:02",
      "total_flops_so_far": 1751473366977656.0,
      "budget_used_percent": 1.751473366977656
    },
    {
      "type": "training",
      "description": "Training step 1220",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:02",
      "total_flops_so_far": 1752904462349432.0,
      "budget_used_percent": 1.7529044623494319
    },
    {
      "type": "training",
      "description": "Training step 1221",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:03",
      "total_flops_so_far": 1754335557721208.0,
      "budget_used_percent": 1.754335557721208
    },
    {
      "type": "training",
      "description": "Training step 1222",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:03",
      "total_flops_so_far": 1755766653092984.0,
      "budget_used_percent": 1.755766653092984
    },
    {
      "type": "training",
      "description": "Training step 1223",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:03",
      "total_flops_so_far": 1757197748464760.0,
      "budget_used_percent": 1.7571977484647598
    },
    {
      "type": "training",
      "description": "Training step 1224",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:03",
      "total_flops_so_far": 1758628843836536.0,
      "budget_used_percent": 1.758628843836536
    },
    {
      "type": "training",
      "description": "Training step 1225",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:03",
      "total_flops_so_far": 1760059939208312.0,
      "budget_used_percent": 1.760059939208312
    },
    {
      "type": "training",
      "description": "Training step 1226",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:03",
      "total_flops_so_far": 1761491034580088.0,
      "budget_used_percent": 1.7614910345800878
    },
    {
      "type": "training",
      "description": "Training step 1227",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:03",
      "total_flops_so_far": 1762922129951864.0,
      "budget_used_percent": 1.762922129951864
    },
    {
      "type": "training",
      "description": "Training step 1228",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:04",
      "total_flops_so_far": 1764353225323640.0,
      "budget_used_percent": 1.76435322532364
    },
    {
      "type": "training",
      "description": "Training step 1229",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:04",
      "total_flops_so_far": 1765784320695416.0,
      "budget_used_percent": 1.7657843206954162
    },
    {
      "type": "training",
      "description": "Training step 1230",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:04",
      "total_flops_so_far": 1767215416067192.0,
      "budget_used_percent": 1.767215416067192
    },
    {
      "type": "training",
      "description": "Training step 1231",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:04",
      "total_flops_so_far": 1768646511438968.0,
      "budget_used_percent": 1.768646511438968
    },
    {
      "type": "training",
      "description": "Training step 1232",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:04",
      "total_flops_so_far": 1770077606810744.0,
      "budget_used_percent": 1.7700776068107442
    },
    {
      "type": "training",
      "description": "Training step 1233",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:04",
      "total_flops_so_far": 1771508702182520.0,
      "budget_used_percent": 1.77150870218252
    },
    {
      "type": "training",
      "description": "Training step 1234",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:04",
      "total_flops_so_far": 1772939797554296.0,
      "budget_used_percent": 1.772939797554296
    },
    {
      "type": "training",
      "description": "Training step 1235",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:05",
      "total_flops_so_far": 1774370892926072.0,
      "budget_used_percent": 1.774370892926072
    },
    {
      "type": "training",
      "description": "Training step 1236",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:05",
      "total_flops_so_far": 1775801988297848.0,
      "budget_used_percent": 1.7758019882978477
    },
    {
      "type": "training",
      "description": "Training step 1237",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:05",
      "total_flops_so_far": 1777233083669624.0,
      "budget_used_percent": 1.777233083669624
    },
    {
      "type": "training",
      "description": "Training step 1238",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:05",
      "total_flops_so_far": 1778664179041400.0,
      "budget_used_percent": 1.7786641790414
    },
    {
      "type": "training",
      "description": "Training step 1239",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:05",
      "total_flops_so_far": 1780095274413176.0,
      "budget_used_percent": 1.7800952744131762
    },
    {
      "type": "training",
      "description": "Training step 1240",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:05",
      "total_flops_so_far": 1781526369784952.0,
      "budget_used_percent": 1.781526369784952
    },
    {
      "type": "training",
      "description": "Training step 1241",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:05",
      "total_flops_so_far": 1782957465156728.0,
      "budget_used_percent": 1.782957465156728
    },
    {
      "type": "training",
      "description": "Training step 1242",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:06",
      "total_flops_so_far": 1784388560528504.0,
      "budget_used_percent": 1.7843885605285041
    },
    {
      "type": "training",
      "description": "Training step 1243",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:06",
      "total_flops_so_far": 1785819655900280.0,
      "budget_used_percent": 1.78581965590028
    },
    {
      "type": "training",
      "description": "Training step 1244",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:06",
      "total_flops_so_far": 1787250751272056.0,
      "budget_used_percent": 1.787250751272056
    },
    {
      "type": "training",
      "description": "Training step 1245",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:06",
      "total_flops_so_far": 1788681846643832.0,
      "budget_used_percent": 1.7886818466438321
    },
    {
      "type": "training",
      "description": "Training step 1246",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:06",
      "total_flops_so_far": 1790112942015608.0,
      "budget_used_percent": 1.7901129420156079
    },
    {
      "type": "training",
      "description": "Training step 1247",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:06",
      "total_flops_so_far": 1791544037387384.0,
      "budget_used_percent": 1.7915440373873839
    },
    {
      "type": "training",
      "description": "Training step 1248",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:06",
      "total_flops_so_far": 1792975132759160.0,
      "budget_used_percent": 1.79297513275916
    },
    {
      "type": "training",
      "description": "Training step 1249",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:07",
      "total_flops_so_far": 1794406228130936.0,
      "budget_used_percent": 1.794406228130936
    },
    {
      "type": "training",
      "description": "Training step 1250",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:07",
      "total_flops_so_far": 1795837323502712.0,
      "budget_used_percent": 1.7958373235027119
    },
    {
      "type": "training",
      "description": "Training step 1251",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:07",
      "total_flops_so_far": 1797268418874488.0,
      "budget_used_percent": 1.797268418874488
    },
    {
      "type": "training",
      "description": "Training step 1252",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:07",
      "total_flops_so_far": 1798699514246264.0,
      "budget_used_percent": 1.798699514246264
    },
    {
      "type": "training",
      "description": "Training step 1253",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:07",
      "total_flops_so_far": 1800130609618040.0,
      "budget_used_percent": 1.8001306096180398
    },
    {
      "type": "training",
      "description": "Training step 1254",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:07",
      "total_flops_so_far": 1801561704989816.0,
      "budget_used_percent": 1.801561704989816
    },
    {
      "type": "training",
      "description": "Training step 1255",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:08",
      "total_flops_so_far": 1802992800361592.0,
      "budget_used_percent": 1.802992800361592
    },
    {
      "type": "training",
      "description": "Training step 1256",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:08",
      "total_flops_so_far": 1804423895733368.0,
      "budget_used_percent": 1.8044238957333683
    },
    {
      "type": "training",
      "description": "Training step 1257",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:08",
      "total_flops_so_far": 1805854991105144.0,
      "budget_used_percent": 1.805854991105144
    },
    {
      "type": "training",
      "description": "Training step 1258",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:08",
      "total_flops_so_far": 1807286086476920.0,
      "budget_used_percent": 1.80728608647692
    },
    {
      "type": "training",
      "description": "Training step 1259",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:08",
      "total_flops_so_far": 1808717181848696.0,
      "budget_used_percent": 1.8087171818486962
    },
    {
      "type": "training",
      "description": "Training step 1260",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:08",
      "total_flops_so_far": 1810148277220472.0,
      "budget_used_percent": 1.8101482772204718
    },
    {
      "type": "training",
      "description": "Training step 1261",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:08",
      "total_flops_so_far": 1811579372592248.0,
      "budget_used_percent": 1.811579372592248
    },
    {
      "type": "training",
      "description": "Training step 1262",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:09",
      "total_flops_so_far": 1813010467964024.0,
      "budget_used_percent": 1.8130104679640242
    },
    {
      "type": "training",
      "description": "Training step 1263",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:09",
      "total_flops_so_far": 1814441563335800.0,
      "budget_used_percent": 1.8144415633357998
    },
    {
      "type": "training",
      "description": "Training step 1264",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:09",
      "total_flops_so_far": 1815872658707576.0,
      "budget_used_percent": 1.815872658707576
    },
    {
      "type": "training",
      "description": "Training step 1265",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:09",
      "total_flops_so_far": 1817303754079352.0,
      "budget_used_percent": 1.817303754079352
    },
    {
      "type": "training",
      "description": "Training step 1266",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:09",
      "total_flops_so_far": 1818734849451128.0,
      "budget_used_percent": 1.8187348494511282
    },
    {
      "type": "training",
      "description": "Training step 1267",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:09",
      "total_flops_so_far": 1820165944822904.0,
      "budget_used_percent": 1.820165944822904
    },
    {
      "type": "training",
      "description": "Training step 1268",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:09",
      "total_flops_so_far": 1821597040194680.0,
      "budget_used_percent": 1.82159704019468
    },
    {
      "type": "training",
      "description": "Training step 1269",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:10",
      "total_flops_so_far": 1823028135566456.0,
      "budget_used_percent": 1.8230281355664562
    },
    {
      "type": "training",
      "description": "Training step 1270",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:10",
      "total_flops_so_far": 1824459230938232.0,
      "budget_used_percent": 1.824459230938232
    },
    {
      "type": "training",
      "description": "Training step 1271",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:10",
      "total_flops_so_far": 1825890326310008.0,
      "budget_used_percent": 1.825890326310008
    },
    {
      "type": "training",
      "description": "Training step 1272",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:10",
      "total_flops_so_far": 1827321421681784.0,
      "budget_used_percent": 1.8273214216817841
    },
    {
      "type": "training",
      "description": "Training step 1273",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:10",
      "total_flops_so_far": 1828752517053560.0,
      "budget_used_percent": 1.82875251705356
    },
    {
      "type": "training",
      "description": "Training step 1274",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:10",
      "total_flops_so_far": 1830183612425336.0,
      "budget_used_percent": 1.830183612425336
    },
    {
      "type": "training",
      "description": "Training step 1275",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:10",
      "total_flops_so_far": 1831614707797112.0,
      "budget_used_percent": 1.831614707797112
    },
    {
      "type": "training",
      "description": "Training step 1276",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:11",
      "total_flops_so_far": 1833045803168888.0,
      "budget_used_percent": 1.833045803168888
    },
    {
      "type": "training",
      "description": "Training step 1277",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:11",
      "total_flops_so_far": 1834476898540664.0,
      "budget_used_percent": 1.8344768985406639
    },
    {
      "type": "training",
      "description": "Training step 1278",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:11",
      "total_flops_so_far": 1835907993912440.0,
      "budget_used_percent": 1.83590799391244
    },
    {
      "type": "training",
      "description": "Training step 1279",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:11",
      "total_flops_so_far": 1837339089284216.0,
      "budget_used_percent": 1.837339089284216
    },
    {
      "type": "training",
      "description": "Training step 1280",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:11",
      "total_flops_so_far": 1838770184655992.0,
      "budget_used_percent": 1.8387701846559918
    },
    {
      "type": "training",
      "description": "Training step 1281",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:11",
      "total_flops_so_far": 1840201280027768.0,
      "budget_used_percent": 1.840201280027768
    },
    {
      "type": "training",
      "description": "Training step 1282",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:11",
      "total_flops_so_far": 1841632375399544.0,
      "budget_used_percent": 1.841632375399544
    },
    {
      "type": "training",
      "description": "Training step 1283",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:12",
      "total_flops_so_far": 1843063470771320.0,
      "budget_used_percent": 1.8430634707713198
    },
    {
      "type": "training",
      "description": "Training step 1284",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:12",
      "total_flops_so_far": 1844494566143096.0,
      "budget_used_percent": 1.844494566143096
    },
    {
      "type": "training",
      "description": "Training step 1285",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:12",
      "total_flops_so_far": 1845925661514872.0,
      "budget_used_percent": 1.845925661514872
    },
    {
      "type": "training",
      "description": "Training step 1286",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:12",
      "total_flops_so_far": 1847356756886648.0,
      "budget_used_percent": 1.8473567568866482
    },
    {
      "type": "training",
      "description": "Training step 1287",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:12",
      "total_flops_so_far": 1848787852258424.0,
      "budget_used_percent": 1.848787852258424
    },
    {
      "type": "training",
      "description": "Training step 1288",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:12",
      "total_flops_so_far": 1850218947630200.0,
      "budget_used_percent": 1.8502189476302
    },
    {
      "type": "training",
      "description": "Training step 1289",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:12",
      "total_flops_so_far": 1851650043001976.0,
      "budget_used_percent": 1.851650043001976
    },
    {
      "type": "training",
      "description": "Training step 1290",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:13",
      "total_flops_so_far": 1853081138373752.0,
      "budget_used_percent": 1.8530811383737518
    },
    {
      "type": "training",
      "description": "Training step 1291",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:13",
      "total_flops_so_far": 1854512233745528.0,
      "budget_used_percent": 1.854512233745528
    },
    {
      "type": "training",
      "description": "Training step 1292",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:13",
      "total_flops_so_far": 1855943329117304.0,
      "budget_used_percent": 1.855943329117304
    },
    {
      "type": "training",
      "description": "Training step 1293",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:13",
      "total_flops_so_far": 1857374424489080.0,
      "budget_used_percent": 1.8573744244890797
    },
    {
      "type": "training",
      "description": "Training step 1294",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:13",
      "total_flops_so_far": 1858805519860856.0,
      "budget_used_percent": 1.858805519860856
    },
    {
      "type": "training",
      "description": "Training step 1295",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:13",
      "total_flops_so_far": 1860236615232632.0,
      "budget_used_percent": 1.860236615232632
    },
    {
      "type": "training",
      "description": "Training step 1296",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:13",
      "total_flops_so_far": 1861667710604408.0,
      "budget_used_percent": 1.8616677106044082
    },
    {
      "type": "training",
      "description": "Training step 1297",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:14",
      "total_flops_so_far": 1863098805976184.0,
      "budget_used_percent": 1.863098805976184
    },
    {
      "type": "training",
      "description": "Training step 1298",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:14",
      "total_flops_so_far": 1864529901347960.0,
      "budget_used_percent": 1.86452990134796
    },
    {
      "type": "training",
      "description": "Training step 1299",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:14",
      "total_flops_so_far": 1865960996719736.0,
      "budget_used_percent": 1.8659609967197361
    },
    {
      "type": "training",
      "description": "Training step 1300",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:14",
      "total_flops_so_far": 1867392092091512.0,
      "budget_used_percent": 1.867392092091512
    },
    {
      "type": "training",
      "description": "Training step 1301",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:14",
      "total_flops_so_far": 1868823187463288.0,
      "budget_used_percent": 1.868823187463288
    },
    {
      "type": "training",
      "description": "Training step 1302",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:14",
      "total_flops_so_far": 1870254282835064.0,
      "budget_used_percent": 1.8702542828350641
    },
    {
      "type": "training",
      "description": "Training step 1303",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:15",
      "total_flops_so_far": 1871685378206840.0,
      "budget_used_percent": 1.8716853782068401
    },
    {
      "type": "training",
      "description": "Training step 1304",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:15",
      "total_flops_so_far": 1873116473578616.0,
      "budget_used_percent": 1.8731164735786159
    },
    {
      "type": "training",
      "description": "Training step 1305",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:15",
      "total_flops_so_far": 1874547568950392.0,
      "budget_used_percent": 1.874547568950392
    },
    {
      "type": "training",
      "description": "Training step 1306",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:15",
      "total_flops_so_far": 1875978664322168.0,
      "budget_used_percent": 1.875978664322168
    },
    {
      "type": "training",
      "description": "Training step 1307",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:15",
      "total_flops_so_far": 1877409759693944.0,
      "budget_used_percent": 1.8774097596939439
    },
    {
      "type": "training",
      "description": "Training step 1308",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:15",
      "total_flops_so_far": 1878840855065720.0,
      "budget_used_percent": 1.87884085506572
    },
    {
      "type": "training",
      "description": "Training step 1309",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:15",
      "total_flops_so_far": 1880271950437496.0,
      "budget_used_percent": 1.880271950437496
    },
    {
      "type": "training",
      "description": "Training step 1310",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:16",
      "total_flops_so_far": 1881703045809272.0,
      "budget_used_percent": 1.8817030458092718
    },
    {
      "type": "training",
      "description": "Training step 1311",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:16",
      "total_flops_so_far": 1883134141181048.0,
      "budget_used_percent": 1.883134141181048
    },
    {
      "type": "training",
      "description": "Training step 1312",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:16",
      "total_flops_so_far": 1884565236552824.0,
      "budget_used_percent": 1.884565236552824
    },
    {
      "type": "training",
      "description": "Training step 1313",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:16",
      "total_flops_so_far": 1885996331924600.0,
      "budget_used_percent": 1.8859963319246003
    },
    {
      "type": "training",
      "description": "Training step 1314",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:16",
      "total_flops_so_far": 1887427427296376.0,
      "budget_used_percent": 1.8874274272963758
    },
    {
      "type": "training",
      "description": "Training step 1315",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:16",
      "total_flops_so_far": 1888858522668152.0,
      "budget_used_percent": 1.888858522668152
    },
    {
      "type": "training",
      "description": "Training step 1316",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:16",
      "total_flops_so_far": 1890289618039928.0,
      "budget_used_percent": 1.8902896180399282
    },
    {
      "type": "training",
      "description": "Training step 1317",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:17",
      "total_flops_so_far": 1891720713411704.0,
      "budget_used_percent": 1.8917207134117038
    },
    {
      "type": "training",
      "description": "Training step 1318",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:17",
      "total_flops_so_far": 1893151808783480.0,
      "budget_used_percent": 1.89315180878348
    },
    {
      "type": "training",
      "description": "Training step 1319",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:17",
      "total_flops_so_far": 1894582904155256.0,
      "budget_used_percent": 1.894582904155256
    },
    {
      "type": "training",
      "description": "Training step 1320",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:17",
      "total_flops_so_far": 1896013999527032.0,
      "budget_used_percent": 1.8960139995270318
    },
    {
      "type": "training",
      "description": "Training step 1321",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:17",
      "total_flops_so_far": 1897445094898808.0,
      "budget_used_percent": 1.897445094898808
    },
    {
      "type": "training",
      "description": "Training step 1322",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:17",
      "total_flops_so_far": 1898876190270584.0,
      "budget_used_percent": 1.898876190270584
    },
    {
      "type": "training",
      "description": "Training step 1323",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:17",
      "total_flops_so_far": 1900307285642360.0,
      "budget_used_percent": 1.9003072856423602
    },
    {
      "type": "training",
      "description": "Training step 1324",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:18",
      "total_flops_so_far": 1901738381014136.0,
      "budget_used_percent": 1.901738381014136
    },
    {
      "type": "training",
      "description": "Training step 1325",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:18",
      "total_flops_so_far": 1903169476385912.0,
      "budget_used_percent": 1.903169476385912
    },
    {
      "type": "training",
      "description": "Training step 1326",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:18",
      "total_flops_so_far": 1904600571757688.0,
      "budget_used_percent": 1.9046005717576882
    },
    {
      "type": "training",
      "description": "Training step 1327",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:18",
      "total_flops_so_far": 1906031667129464.0,
      "budget_used_percent": 1.906031667129464
    },
    {
      "type": "training",
      "description": "Training step 1328",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:18",
      "total_flops_so_far": 1907462762501240.0,
      "budget_used_percent": 1.90746276250124
    },
    {
      "type": "training",
      "description": "Training step 1329",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:18",
      "total_flops_so_far": 1908893857873016.0,
      "budget_used_percent": 1.9088938578730161
    },
    {
      "type": "training",
      "description": "Training step 1330",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:18",
      "total_flops_so_far": 1910324953244792.0,
      "budget_used_percent": 1.910324953244792
    },
    {
      "type": "training",
      "description": "Training step 1331",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:19",
      "total_flops_so_far": 1911756048616568.0,
      "budget_used_percent": 1.911756048616568
    },
    {
      "type": "training",
      "description": "Training step 1332",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:19",
      "total_flops_so_far": 1913187143988344.0,
      "budget_used_percent": 1.913187143988344
    },
    {
      "type": "training",
      "description": "Training step 1333",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:19",
      "total_flops_so_far": 1914618239360120.0,
      "budget_used_percent": 1.91461823936012
    },
    {
      "type": "training",
      "description": "Training step 1334",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:19",
      "total_flops_so_far": 1916049334731896.0,
      "budget_used_percent": 1.9160493347318959
    },
    {
      "type": "training",
      "description": "Training step 1335",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:19",
      "total_flops_so_far": 1917480430103672.0,
      "budget_used_percent": 1.917480430103672
    },
    {
      "type": "training",
      "description": "Training step 1336",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:19",
      "total_flops_so_far": 1918911525475448.0,
      "budget_used_percent": 1.918911525475448
    },
    {
      "type": "training",
      "description": "Training step 1337",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:20",
      "total_flops_so_far": 1920342620847224.0,
      "budget_used_percent": 1.9203426208472238
    },
    {
      "type": "training",
      "description": "Training step 1338",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:20",
      "total_flops_so_far": 1921773716219000.0,
      "budget_used_percent": 1.921773716219
    },
    {
      "type": "training",
      "description": "Training step 1339",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:20",
      "total_flops_so_far": 1923204811590776.0,
      "budget_used_percent": 1.923204811590776
    },
    {
      "type": "training",
      "description": "Training step 1340",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:20",
      "total_flops_so_far": 1924635906962552.0,
      "budget_used_percent": 1.9246359069625523
    },
    {
      "type": "training",
      "description": "Training step 1341",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:20",
      "total_flops_so_far": 1926067002334328.0,
      "budget_used_percent": 1.926067002334328
    },
    {
      "type": "training",
      "description": "Training step 1342",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:20",
      "total_flops_so_far": 1927498097706104.0,
      "budget_used_percent": 1.927498097706104
    },
    {
      "type": "training",
      "description": "Training step 1343",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:20",
      "total_flops_so_far": 1928929193077880.0,
      "budget_used_percent": 1.92892919307788
    },
    {
      "type": "training",
      "description": "Training step 1344",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:21",
      "total_flops_so_far": 1930360288449656.0,
      "budget_used_percent": 1.9303602884496558
    },
    {
      "type": "training",
      "description": "Training step 1345",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:21",
      "total_flops_so_far": 1931791383821432.0,
      "budget_used_percent": 1.931791383821432
    },
    {
      "type": "training",
      "description": "Training step 1346",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:21",
      "total_flops_so_far": 1933222479193208.0,
      "budget_used_percent": 1.933222479193208
    },
    {
      "type": "training",
      "description": "Training step 1347",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:21",
      "total_flops_so_far": 1934653574564984.0,
      "budget_used_percent": 1.9346535745649838
    },
    {
      "type": "training",
      "description": "Training step 1348",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:21",
      "total_flops_so_far": 1936084669936760.0,
      "budget_used_percent": 1.93608466993676
    },
    {
      "type": "training",
      "description": "Training step 1349",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:21",
      "total_flops_so_far": 1937515765308536.0,
      "budget_used_percent": 1.937515765308536
    },
    {
      "type": "training",
      "description": "Training step 1350",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:21",
      "total_flops_so_far": 1938946860680312.0,
      "budget_used_percent": 1.9389468606803122
    },
    {
      "type": "training",
      "description": "Training step 1351",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:22",
      "total_flops_so_far": 1940377956052088.0,
      "budget_used_percent": 1.940377956052088
    },
    {
      "type": "training",
      "description": "Training step 1352",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:22",
      "total_flops_so_far": 1941809051423864.0,
      "budget_used_percent": 1.941809051423864
    },
    {
      "type": "training",
      "description": "Training step 1353",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:22",
      "total_flops_so_far": 1943240146795640.0,
      "budget_used_percent": 1.9432401467956402
    },
    {
      "type": "training",
      "description": "Training step 1354",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:22",
      "total_flops_so_far": 1944671242167416.0,
      "budget_used_percent": 1.944671242167416
    },
    {
      "type": "training",
      "description": "Training step 1355",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:22",
      "total_flops_so_far": 1946102337539192.0,
      "budget_used_percent": 1.946102337539192
    },
    {
      "type": "training",
      "description": "Training step 1356",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:22",
      "total_flops_so_far": 1947533432910968.0,
      "budget_used_percent": 1.9475334329109681
    },
    {
      "type": "training",
      "description": "Training step 1357",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:23",
      "total_flops_so_far": 1948964528282744.0,
      "budget_used_percent": 1.948964528282744
    },
    {
      "type": "training",
      "description": "Training step 1358",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:23",
      "total_flops_so_far": 1950395623654520.0,
      "budget_used_percent": 1.95039562365452
    },
    {
      "type": "training",
      "description": "Training step 1359",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:23",
      "total_flops_so_far": 1951826719026296.0,
      "budget_used_percent": 1.9518267190262961
    },
    {
      "type": "training",
      "description": "Training step 1360",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:23",
      "total_flops_so_far": 1953257814398072.0,
      "budget_used_percent": 1.9532578143980721
    },
    {
      "type": "training",
      "description": "Training step 1361",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:23",
      "total_flops_so_far": 1954688909769848.0,
      "budget_used_percent": 1.9546889097698479
    },
    {
      "type": "training",
      "description": "Training step 1362",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:23",
      "total_flops_so_far": 1956120005141624.0,
      "budget_used_percent": 1.956120005141624
    },
    {
      "type": "training",
      "description": "Training step 1363",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:23",
      "total_flops_so_far": 1957551100513400.0,
      "budget_used_percent": 1.9575511005134
    },
    {
      "type": "training",
      "description": "Training step 1364",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:24",
      "total_flops_so_far": 1958982195885176.0,
      "budget_used_percent": 1.9589821958851759
    },
    {
      "type": "training",
      "description": "Training step 1365",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:24",
      "total_flops_so_far": 1960413291256952.0,
      "budget_used_percent": 1.960413291256952
    },
    {
      "type": "training",
      "description": "Training step 1366",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:24",
      "total_flops_so_far": 1961844386628728.0,
      "budget_used_percent": 1.961844386628728
    },
    {
      "type": "training",
      "description": "Training step 1367",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:24",
      "total_flops_so_far": 1963275482000504.0,
      "budget_used_percent": 1.9632754820005038
    },
    {
      "type": "training",
      "description": "Training step 1368",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:24",
      "total_flops_so_far": 1964706577372280.0,
      "budget_used_percent": 1.9647065773722798
    },
    {
      "type": "training",
      "description": "Training step 1369",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:24",
      "total_flops_so_far": 1966137672744056.0,
      "budget_used_percent": 1.966137672744056
    },
    {
      "type": "training",
      "description": "Training step 1370",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:25",
      "total_flops_so_far": 1967568768115832.0,
      "budget_used_percent": 1.9675687681158323
    },
    {
      "type": "training",
      "description": "Training step 1371",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:25",
      "total_flops_so_far": 1968999863487608.0,
      "budget_used_percent": 1.9689998634876078
    },
    {
      "type": "training",
      "description": "Training step 1372",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:25",
      "total_flops_so_far": 1970430958859384.0,
      "budget_used_percent": 1.970430958859384
    },
    {
      "type": "training",
      "description": "Training step 1373",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:25",
      "total_flops_so_far": 1971862054231160.0,
      "budget_used_percent": 1.97186205423116
    },
    {
      "type": "training",
      "description": "Training step 1374",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:25",
      "total_flops_so_far": 1973293149602936.0,
      "budget_used_percent": 1.9732931496029358
    },
    {
      "type": "training",
      "description": "Training step 1375",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:25",
      "total_flops_so_far": 1974724244974712.0,
      "budget_used_percent": 1.974724244974712
    },
    {
      "type": "training",
      "description": "Training step 1376",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:25",
      "total_flops_so_far": 1976155340346488.0,
      "budget_used_percent": 1.976155340346488
    },
    {
      "type": "training",
      "description": "Training step 1377",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:26",
      "total_flops_so_far": 1977586435718264.0,
      "budget_used_percent": 1.9775864357182638
    },
    {
      "type": "training",
      "description": "Training step 1378",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:26",
      "total_flops_so_far": 1979017531090040.0,
      "budget_used_percent": 1.97901753109004
    },
    {
      "type": "training",
      "description": "Training step 1379",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:26",
      "total_flops_so_far": 1980448626461816.0,
      "budget_used_percent": 1.980448626461816
    },
    {
      "type": "training",
      "description": "Training step 1380",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:26",
      "total_flops_so_far": 1981879721833592.0,
      "budget_used_percent": 1.9818797218335922
    },
    {
      "type": "training",
      "description": "Training step 1381",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:26",
      "total_flops_so_far": 1983310817205368.0,
      "budget_used_percent": 1.983310817205368
    },
    {
      "type": "training",
      "description": "Training step 1382",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:26",
      "total_flops_so_far": 1984741912577144.0,
      "budget_used_percent": 1.984741912577144
    },
    {
      "type": "training",
      "description": "Training step 1383",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:26",
      "total_flops_so_far": 1986173007948920.0,
      "budget_used_percent": 1.9861730079489202
    },
    {
      "type": "training",
      "description": "Training step 1384",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:27",
      "total_flops_so_far": 1987604103320696.0,
      "budget_used_percent": 1.987604103320696
    },
    {
      "type": "training",
      "description": "Training step 1385",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:27",
      "total_flops_so_far": 1989035198692472.0,
      "budget_used_percent": 1.989035198692472
    },
    {
      "type": "training",
      "description": "Training step 1386",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:27",
      "total_flops_so_far": 1990466294064248.0,
      "budget_used_percent": 1.9904662940642481
    },
    {
      "type": "training",
      "description": "Training step 1387",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:27",
      "total_flops_so_far": 1991897389436024.0,
      "budget_used_percent": 1.9918973894360241
    },
    {
      "type": "training",
      "description": "Training step 1388",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:27",
      "total_flops_so_far": 1993328484807800.0,
      "budget_used_percent": 1.9933284848078
    },
    {
      "type": "training",
      "description": "Training step 1389",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:27",
      "total_flops_so_far": 1994759580179576.0,
      "budget_used_percent": 1.994759580179576
    },
    {
      "type": "training",
      "description": "Training step 1390",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:27",
      "total_flops_so_far": 1996190675551352.0,
      "budget_used_percent": 1.996190675551352
    },
    {
      "type": "training",
      "description": "Training step 1391",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:28",
      "total_flops_so_far": 1997621770923128.0,
      "budget_used_percent": 1.9976217709231279
    },
    {
      "type": "training",
      "description": "Training step 1392",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:28",
      "total_flops_so_far": 1999052866294904.0,
      "budget_used_percent": 1.999052866294904
    },
    {
      "type": "training",
      "description": "Training step 1393",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:28",
      "total_flops_so_far": 2000483961666680.0,
      "budget_used_percent": 2.00048396166668
    },
    {
      "type": "training",
      "description": "Training step 1394",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:28",
      "total_flops_so_far": 2001915057038456.0,
      "budget_used_percent": 2.001915057038456
    },
    {
      "type": "training",
      "description": "Training step 1395",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:28",
      "total_flops_so_far": 2003346152410232.0,
      "budget_used_percent": 2.003346152410232
    },
    {
      "type": "training",
      "description": "Training step 1396",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:28",
      "total_flops_so_far": 2004777247782008.0,
      "budget_used_percent": 2.004777247782008
    },
    {
      "type": "training",
      "description": "Training step 1397",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:29",
      "total_flops_so_far": 2006208343153784.0,
      "budget_used_percent": 2.006208343153784
    },
    {
      "type": "training",
      "description": "Training step 1398",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:29",
      "total_flops_so_far": 2007639438525560.0,
      "budget_used_percent": 2.00763943852556
    },
    {
      "type": "training",
      "description": "Training step 1399",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:29",
      "total_flops_so_far": 2009070533897336.0,
      "budget_used_percent": 2.009070533897336
    },
    {
      "type": "training",
      "description": "Training step 1400",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:29",
      "total_flops_so_far": 2010501629269112.0,
      "budget_used_percent": 2.010501629269112
    },
    {
      "type": "training",
      "description": "Training step 1401",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:29",
      "total_flops_so_far": 2011932724640888.0,
      "budget_used_percent": 2.011932724640888
    },
    {
      "type": "training",
      "description": "Training step 1402",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:29",
      "total_flops_so_far": 2013363820012664.0,
      "budget_used_percent": 2.013363820012664
    },
    {
      "type": "training",
      "description": "Training step 1403",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:29",
      "total_flops_so_far": 2014794915384440.0,
      "budget_used_percent": 2.01479491538444
    },
    {
      "type": "training",
      "description": "Training step 1404",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:30",
      "total_flops_so_far": 2016226010756216.0,
      "budget_used_percent": 2.016226010756216
    },
    {
      "type": "training",
      "description": "Training step 1405",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:30",
      "total_flops_so_far": 2017657106127992.0,
      "budget_used_percent": 2.017657106127992
    },
    {
      "type": "training",
      "description": "Training step 1406",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:30",
      "total_flops_so_far": 2019088201499768.0,
      "budget_used_percent": 2.019088201499768
    },
    {
      "type": "training",
      "description": "Training step 1407",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:30",
      "total_flops_so_far": 2020519296871544.0,
      "budget_used_percent": 2.020519296871544
    },
    {
      "type": "training",
      "description": "Training step 1408",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:30",
      "total_flops_so_far": 2021950392243320.0,
      "budget_used_percent": 2.02195039224332
    },
    {
      "type": "training",
      "description": "Training step 1409",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:30",
      "total_flops_so_far": 2023381487615096.0,
      "budget_used_percent": 2.023381487615096
    },
    {
      "type": "training",
      "description": "Training step 1410",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:30",
      "total_flops_so_far": 2024812582986872.0,
      "budget_used_percent": 2.024812582986872
    },
    {
      "type": "training",
      "description": "Training step 1411",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:31",
      "total_flops_so_far": 2026243678358648.0,
      "budget_used_percent": 2.026243678358648
    },
    {
      "type": "training",
      "description": "Training step 1412",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:31",
      "total_flops_so_far": 2027674773730424.0,
      "budget_used_percent": 2.027674773730424
    },
    {
      "type": "training",
      "description": "Training step 1413",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:31",
      "total_flops_so_far": 2029105869102200.0,
      "budget_used_percent": 2.0291058691022
    },
    {
      "type": "training",
      "description": "Training step 1414",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:31",
      "total_flops_so_far": 2030536964473976.0,
      "budget_used_percent": 2.030536964473976
    },
    {
      "type": "training",
      "description": "Training step 1415",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:31",
      "total_flops_so_far": 2031968059845752.0,
      "budget_used_percent": 2.031968059845752
    },
    {
      "type": "training",
      "description": "Training step 1416",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:31",
      "total_flops_so_far": 2033399155217528.0,
      "budget_used_percent": 2.033399155217528
    },
    {
      "type": "training",
      "description": "Training step 1417",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:31",
      "total_flops_so_far": 2034830250589304.0,
      "budget_used_percent": 2.0348302505893043
    },
    {
      "type": "training",
      "description": "Training step 1418",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:32",
      "total_flops_so_far": 2036261345961080.0,
      "budget_used_percent": 2.03626134596108
    },
    {
      "type": "training",
      "description": "Training step 1419",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:32",
      "total_flops_so_far": 2037692441332856.0,
      "budget_used_percent": 2.037692441332856
    },
    {
      "type": "training",
      "description": "Training step 1420",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:32",
      "total_flops_so_far": 2039123536704632.0,
      "budget_used_percent": 2.0391235367046323
    },
    {
      "type": "training",
      "description": "Training step 1421",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:32",
      "total_flops_so_far": 2040554632076408.0,
      "budget_used_percent": 2.040554632076408
    },
    {
      "type": "training",
      "description": "Training step 1422",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:32",
      "total_flops_so_far": 2041985727448184.0,
      "budget_used_percent": 2.041985727448184
    },
    {
      "type": "training",
      "description": "Training step 1423",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:32",
      "total_flops_so_far": 2043416822819960.0,
      "budget_used_percent": 2.0434168228199603
    },
    {
      "type": "training",
      "description": "Training step 1424",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:33",
      "total_flops_so_far": 2044847918191736.0,
      "budget_used_percent": 2.0448479181917363
    },
    {
      "type": "training",
      "description": "Training step 1425",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:33",
      "total_flops_so_far": 2046279013563512.0,
      "budget_used_percent": 2.046279013563512
    },
    {
      "type": "training",
      "description": "Training step 1426",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:33",
      "total_flops_so_far": 2047710108935288.0,
      "budget_used_percent": 2.047710108935288
    },
    {
      "type": "training",
      "description": "Training step 1427",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:33",
      "total_flops_so_far": 2049141204307064.0,
      "budget_used_percent": 2.0491412043070643
    },
    {
      "type": "training",
      "description": "Training step 1428",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:33",
      "total_flops_so_far": 2050572299678840.0,
      "budget_used_percent": 2.05057229967884
    },
    {
      "type": "training",
      "description": "Training step 1429",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:33",
      "total_flops_so_far": 2052003395050616.0,
      "budget_used_percent": 2.052003395050616
    },
    {
      "type": "training",
      "description": "Training step 1430",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:33",
      "total_flops_so_far": 2053434490422392.0,
      "budget_used_percent": 2.0534344904223922
    },
    {
      "type": "training",
      "description": "Training step 1431",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:34",
      "total_flops_so_far": 2054865585794168.0,
      "budget_used_percent": 2.054865585794168
    },
    {
      "type": "training",
      "description": "Training step 1432",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:34",
      "total_flops_so_far": 2056296681165944.0,
      "budget_used_percent": 2.0562966811659438
    },
    {
      "type": "training",
      "description": "Training step 1433",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:34",
      "total_flops_so_far": 2057727776537720.0,
      "budget_used_percent": 2.05772777653772
    },
    {
      "type": "training",
      "description": "Training step 1434",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:34",
      "total_flops_so_far": 2059158871909496.0,
      "budget_used_percent": 2.059158871909496
    },
    {
      "type": "training",
      "description": "Training step 1435",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:34",
      "total_flops_so_far": 2060589967281272.0,
      "budget_used_percent": 2.0605899672812718
    },
    {
      "type": "training",
      "description": "Training step 1436",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:34",
      "total_flops_so_far": 2062021062653048.0,
      "budget_used_percent": 2.062021062653048
    },
    {
      "type": "training",
      "description": "Training step 1437",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:34",
      "total_flops_so_far": 2063452158024824.0,
      "budget_used_percent": 2.063452158024824
    },
    {
      "type": "training",
      "description": "Training step 1438",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:35",
      "total_flops_so_far": 2064883253396600.0,
      "budget_used_percent": 2.0648832533965997
    },
    {
      "type": "training",
      "description": "Training step 1439",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:35",
      "total_flops_so_far": 2066314348768376.0,
      "budget_used_percent": 2.066314348768376
    },
    {
      "type": "training",
      "description": "Training step 1440",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:35",
      "total_flops_so_far": 2067745444140152.0,
      "budget_used_percent": 2.067745444140152
    },
    {
      "type": "training",
      "description": "Training step 1441",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:35",
      "total_flops_so_far": 2069176539511928.0,
      "budget_used_percent": 2.0691765395119277
    },
    {
      "type": "training",
      "description": "Training step 1442",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:35",
      "total_flops_so_far": 2070607634883704.0,
      "budget_used_percent": 2.070607634883704
    },
    {
      "type": "training",
      "description": "Training step 1443",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:35",
      "total_flops_so_far": 2072038730255480.0,
      "budget_used_percent": 2.07203873025548
    },
    {
      "type": "training",
      "description": "Training step 1444",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:35",
      "total_flops_so_far": 2073469825627256.0,
      "budget_used_percent": 2.073469825627256
    },
    {
      "type": "training",
      "description": "Training step 1445",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:36",
      "total_flops_so_far": 2074900920999032.0,
      "budget_used_percent": 2.074900920999032
    },
    {
      "type": "training",
      "description": "Training step 1446",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:36",
      "total_flops_so_far": 2076332016370808.0,
      "budget_used_percent": 2.076332016370808
    },
    {
      "type": "training",
      "description": "Training step 1447",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:36",
      "total_flops_so_far": 2077763111742584.0,
      "budget_used_percent": 2.077763111742584
    },
    {
      "type": "training",
      "description": "Training step 1448",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:36",
      "total_flops_so_far": 2079194207114360.0,
      "budget_used_percent": 2.0791942071143596
    },
    {
      "type": "training",
      "description": "Training step 1449",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:36",
      "total_flops_so_far": 2080625302486136.0,
      "budget_used_percent": 2.080625302486136
    },
    {
      "type": "training",
      "description": "Training step 1450",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:36",
      "total_flops_so_far": 2082056397857912.0,
      "budget_used_percent": 2.082056397857912
    },
    {
      "type": "training",
      "description": "Training step 1451",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:37",
      "total_flops_so_far": 2083487493229688.0,
      "budget_used_percent": 2.0834874932296876
    },
    {
      "type": "training",
      "description": "Training step 1452",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:37",
      "total_flops_so_far": 2084918588601464.0,
      "budget_used_percent": 2.084918588601464
    },
    {
      "type": "training",
      "description": "Training step 1453",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:37",
      "total_flops_so_far": 2086349683973240.0,
      "budget_used_percent": 2.08634968397324
    },
    {
      "type": "training",
      "description": "Training step 1454",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:37",
      "total_flops_so_far": 2087780779345016.0,
      "budget_used_percent": 2.087780779345016
    },
    {
      "type": "training",
      "description": "Training step 1455",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:37",
      "total_flops_so_far": 2089211874716792.0,
      "budget_used_percent": 2.089211874716792
    },
    {
      "type": "training",
      "description": "Training step 1456",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:37",
      "total_flops_so_far": 2090642970088568.0,
      "budget_used_percent": 2.090642970088568
    },
    {
      "type": "training",
      "description": "Training step 1457",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:37",
      "total_flops_so_far": 2092074065460344.0,
      "budget_used_percent": 2.092074065460344
    },
    {
      "type": "training",
      "description": "Training step 1458",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:38",
      "total_flops_so_far": 2093505160832120.0,
      "budget_used_percent": 2.09350516083212
    },
    {
      "type": "training",
      "description": "Training step 1459",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:38",
      "total_flops_so_far": 2094936256203896.0,
      "budget_used_percent": 2.094936256203896
    },
    {
      "type": "training",
      "description": "Training step 1460",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:38",
      "total_flops_so_far": 2096367351575672.0,
      "budget_used_percent": 2.096367351575672
    },
    {
      "type": "training",
      "description": "Training step 1461",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:38",
      "total_flops_so_far": 2097798446947448.0,
      "budget_used_percent": 2.097798446947448
    },
    {
      "type": "training",
      "description": "Training step 1462",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:38",
      "total_flops_so_far": 2099229542319224.0,
      "budget_used_percent": 2.099229542319224
    },
    {
      "type": "training",
      "description": "Training step 1463",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:38",
      "total_flops_so_far": 2100660637691000.0,
      "budget_used_percent": 2.100660637691
    },
    {
      "type": "training",
      "description": "Training step 1464",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:38",
      "total_flops_so_far": 2102091733062776.0,
      "budget_used_percent": 2.102091733062776
    },
    {
      "type": "training",
      "description": "Training step 1465",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:39",
      "total_flops_so_far": 2103522828434552.0,
      "budget_used_percent": 2.103522828434552
    },
    {
      "type": "training",
      "description": "Training step 1466",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:39",
      "total_flops_so_far": 2104953923806328.0,
      "budget_used_percent": 2.104953923806328
    },
    {
      "type": "training",
      "description": "Training step 1467",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:39",
      "total_flops_so_far": 2106385019178104.0,
      "budget_used_percent": 2.106385019178104
    },
    {
      "type": "training",
      "description": "Training step 1468",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:39",
      "total_flops_so_far": 2107816114549880.0,
      "budget_used_percent": 2.10781611454988
    },
    {
      "type": "training",
      "description": "Training step 1469",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:39",
      "total_flops_so_far": 2109247209921656.0,
      "budget_used_percent": 2.109247209921656
    },
    {
      "type": "training",
      "description": "Training step 1470",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:39",
      "total_flops_so_far": 2110678305293432.0,
      "budget_used_percent": 2.110678305293432
    },
    {
      "type": "training",
      "description": "Training step 1471",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:39",
      "total_flops_so_far": 2112109400665208.0,
      "budget_used_percent": 2.1121094006652084
    },
    {
      "type": "training",
      "description": "Training step 1472",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:40",
      "total_flops_so_far": 2113540496036984.0,
      "budget_used_percent": 2.113540496036984
    },
    {
      "type": "training",
      "description": "Training step 1473",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:40",
      "total_flops_so_far": 2114971591408760.0,
      "budget_used_percent": 2.11497159140876
    },
    {
      "type": "training",
      "description": "Training step 1474",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:40",
      "total_flops_so_far": 2116402686780536.0,
      "budget_used_percent": 2.1164026867805363
    },
    {
      "type": "training",
      "description": "Training step 1475",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:40",
      "total_flops_so_far": 2117833782152312.0,
      "budget_used_percent": 2.117833782152312
    },
    {
      "type": "training",
      "description": "Training step 1476",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:40",
      "total_flops_so_far": 2119264877524088.0,
      "budget_used_percent": 2.119264877524088
    },
    {
      "type": "training",
      "description": "Training step 1477",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:40",
      "total_flops_so_far": 2120695972895864.0,
      "budget_used_percent": 2.120695972895864
    },
    {
      "type": "training",
      "description": "Training step 1478",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:41",
      "total_flops_so_far": 2122127068267640.0,
      "budget_used_percent": 2.12212706826764
    },
    {
      "type": "training",
      "description": "Training step 1479",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:41",
      "total_flops_so_far": 2123558163639416.0,
      "budget_used_percent": 2.123558163639416
    },
    {
      "type": "training",
      "description": "Training step 1480",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:41",
      "total_flops_so_far": 2124989259011192.0,
      "budget_used_percent": 2.124989259011192
    },
    {
      "type": "training",
      "description": "Training step 1481",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:41",
      "total_flops_so_far": 2126420354382968.0,
      "budget_used_percent": 2.1264203543829683
    },
    {
      "type": "training",
      "description": "Training step 1482",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:41",
      "total_flops_so_far": 2127851449754744.0,
      "budget_used_percent": 2.127851449754744
    },
    {
      "type": "training",
      "description": "Training step 1483",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:41",
      "total_flops_so_far": 2129282545126520.0,
      "budget_used_percent": 2.12928254512652
    },
    {
      "type": "training",
      "description": "Training step 1484",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:41",
      "total_flops_so_far": 2130713640498296.0,
      "budget_used_percent": 2.1307136404982963
    },
    {
      "type": "training",
      "description": "Training step 1485",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:42",
      "total_flops_so_far": 2132144735870072.0,
      "budget_used_percent": 2.132144735870072
    },
    {
      "type": "training",
      "description": "Training step 1486",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:42",
      "total_flops_so_far": 2133575831241848.0,
      "budget_used_percent": 2.133575831241848
    },
    {
      "type": "training",
      "description": "Training step 1487",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:42",
      "total_flops_so_far": 2135006926613624.0,
      "budget_used_percent": 2.1350069266136242
    },
    {
      "type": "training",
      "description": "Training step 1488",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:42",
      "total_flops_so_far": 2136438021985400.0,
      "budget_used_percent": 2.1364380219854
    },
    {
      "type": "training",
      "description": "Training step 1489",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:42",
      "total_flops_so_far": 2137869117357176.0,
      "budget_used_percent": 2.1378691173571758
    },
    {
      "type": "training",
      "description": "Training step 1490",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:42",
      "total_flops_so_far": 2139300212728952.0,
      "budget_used_percent": 2.139300212728952
    },
    {
      "type": "training",
      "description": "Training step 1491",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:42",
      "total_flops_so_far": 2140731308100728.0,
      "budget_used_percent": 2.140731308100728
    },
    {
      "type": "training",
      "description": "Training step 1492",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:43",
      "total_flops_so_far": 2142162403472504.0,
      "budget_used_percent": 2.1421624034725038
    },
    {
      "type": "training",
      "description": "Training step 1493",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:43",
      "total_flops_so_far": 2143593498844280.0,
      "budget_used_percent": 2.14359349884428
    },
    {
      "type": "training",
      "description": "Training step 1494",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:43",
      "total_flops_so_far": 2145024594216056.0,
      "budget_used_percent": 2.145024594216056
    },
    {
      "type": "training",
      "description": "Training step 1495",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:43",
      "total_flops_so_far": 2146455689587832.0,
      "budget_used_percent": 2.1464556895878317
    },
    {
      "type": "training",
      "description": "Training step 1496",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:43",
      "total_flops_so_far": 2147886784959608.0,
      "budget_used_percent": 2.147886784959608
    },
    {
      "type": "training",
      "description": "Training step 1497",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:43",
      "total_flops_so_far": 2149317880331384.0,
      "budget_used_percent": 2.149317880331384
    },
    {
      "type": "training",
      "description": "Training step 1498",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:44",
      "total_flops_so_far": 2150748975703160.0,
      "budget_used_percent": 2.1507489757031597
    },
    {
      "type": "training",
      "description": "Training step 1499",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:44",
      "total_flops_so_far": 2152180071074936.0,
      "budget_used_percent": 2.152180071074936
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 0",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552080785760.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:45",
      "total_flops_so_far": 2152732151860696.0,
      "budget_used_percent": 2.1527321518606963
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 1",
      "context_len": 604,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 555682299984.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:46",
      "total_flops_so_far": 2153287834160680.0,
      "budget_used_percent": 2.15328783416068
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 2",
      "context_len": 602,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 553881182680.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:48",
      "total_flops_so_far": 2153841715343360.0,
      "budget_used_percent": 2.15384171534336
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 3",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552080785760.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:49",
      "total_flops_so_far": 2154393796129120.0,
      "budget_used_percent": 2.1543937961291197
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 4",
      "context_len": 603,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 554781651284.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:50",
      "total_flops_so_far": 2154948577780404.0,
      "budget_used_percent": 2.154948577780404
    },
    {
      "type": "training",
      "description": "Training step 1500",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:50",
      "total_flops_so_far": 2156379673152180.0,
      "budget_used_percent": 2.15637967315218
    },
    {
      "type": "training",
      "description": "Training step 1501",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:50",
      "total_flops_so_far": 2157810768523956.0,
      "budget_used_percent": 2.157810768523956
    },
    {
      "type": "training",
      "description": "Training step 1502",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:50",
      "total_flops_so_far": 2159241863895732.0,
      "budget_used_percent": 2.159241863895732
    },
    {
      "type": "training",
      "description": "Training step 1503",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:51",
      "total_flops_so_far": 2160672959267508.0,
      "budget_used_percent": 2.160672959267508
    },
    {
      "type": "training",
      "description": "Training step 1504",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:51",
      "total_flops_so_far": 2162104054639284.0,
      "budget_used_percent": 2.162104054639284
    },
    {
      "type": "training",
      "description": "Training step 1505",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:51",
      "total_flops_so_far": 2163535150011060.0,
      "budget_used_percent": 2.16353515001106
    },
    {
      "type": "training",
      "description": "Training step 1506",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:51",
      "total_flops_so_far": 2164966245382836.0,
      "budget_used_percent": 2.164966245382836
    },
    {
      "type": "training",
      "description": "Training step 1507",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:51",
      "total_flops_so_far": 2166397340754612.0,
      "budget_used_percent": 2.166397340754612
    },
    {
      "type": "training",
      "description": "Training step 1508",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:51",
      "total_flops_so_far": 2167828436126388.0,
      "budget_used_percent": 2.167828436126388
    },
    {
      "type": "training",
      "description": "Training step 1509",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:52",
      "total_flops_so_far": 2169259531498164.0,
      "budget_used_percent": 2.169259531498164
    },
    {
      "type": "training",
      "description": "Training step 1510",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:52",
      "total_flops_so_far": 2170690626869940.0,
      "budget_used_percent": 2.17069062686994
    },
    {
      "type": "training",
      "description": "Training step 1511",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:52",
      "total_flops_so_far": 2172121722241716.0,
      "budget_used_percent": 2.172121722241716
    },
    {
      "type": "training",
      "description": "Training step 1512",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:52",
      "total_flops_so_far": 2173552817613492.0,
      "budget_used_percent": 2.173552817613492
    },
    {
      "type": "training",
      "description": "Training step 1513",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:52",
      "total_flops_so_far": 2174983912985268.0,
      "budget_used_percent": 2.174983912985268
    },
    {
      "type": "training",
      "description": "Training step 1514",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:52",
      "total_flops_so_far": 2176415008357044.0,
      "budget_used_percent": 2.1764150083570444
    },
    {
      "type": "training",
      "description": "Training step 1515",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:52",
      "total_flops_so_far": 2177846103728820.0,
      "budget_used_percent": 2.17784610372882
    },
    {
      "type": "training",
      "description": "Training step 1516",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:53",
      "total_flops_so_far": 2179277199100596.0,
      "budget_used_percent": 2.179277199100596
    },
    {
      "type": "training",
      "description": "Training step 1517",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:53",
      "total_flops_so_far": 2180708294472372.0,
      "budget_used_percent": 2.180708294472372
    },
    {
      "type": "training",
      "description": "Training step 1518",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:53",
      "total_flops_so_far": 2182139389844148.0,
      "budget_used_percent": 2.182139389844148
    },
    {
      "type": "training",
      "description": "Training step 1519",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:53",
      "total_flops_so_far": 2183570485215924.0,
      "budget_used_percent": 2.183570485215924
    },
    {
      "type": "training",
      "description": "Training step 1520",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:53",
      "total_flops_so_far": 2185001580587700.0,
      "budget_used_percent": 2.1850015805877
    },
    {
      "type": "training",
      "description": "Training step 1521",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:53",
      "total_flops_so_far": 2186432675959476.0,
      "budget_used_percent": 2.186432675959476
    },
    {
      "type": "training",
      "description": "Training step 1522",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:53",
      "total_flops_so_far": 2187863771331252.0,
      "budget_used_percent": 2.187863771331252
    },
    {
      "type": "training",
      "description": "Training step 1523",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:54",
      "total_flops_so_far": 2189294866703028.0,
      "budget_used_percent": 2.189294866703028
    },
    {
      "type": "training",
      "description": "Training step 1524",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:54",
      "total_flops_so_far": 2190725962074804.0,
      "budget_used_percent": 2.1907259620748043
    },
    {
      "type": "training",
      "description": "Training step 1525",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:54",
      "total_flops_so_far": 2192157057446580.0,
      "budget_used_percent": 2.19215705744658
    },
    {
      "type": "training",
      "description": "Training step 1526",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:54",
      "total_flops_so_far": 2193588152818356.0,
      "budget_used_percent": 2.193588152818356
    },
    {
      "type": "training",
      "description": "Training step 1527",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:54",
      "total_flops_so_far": 2195019248190132.0,
      "budget_used_percent": 2.1950192481901323
    },
    {
      "type": "training",
      "description": "Training step 1528",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:54",
      "total_flops_so_far": 2196450343561908.0,
      "budget_used_percent": 2.196450343561908
    },
    {
      "type": "training",
      "description": "Training step 1529",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:55",
      "total_flops_so_far": 2197881438933684.0,
      "budget_used_percent": 2.197881438933684
    },
    {
      "type": "training",
      "description": "Training step 1530",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:55",
      "total_flops_so_far": 2199312534305460.0,
      "budget_used_percent": 2.1993125343054603
    },
    {
      "type": "training",
      "description": "Training step 1531",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:55",
      "total_flops_so_far": 2200743629677236.0,
      "budget_used_percent": 2.200743629677236
    },
    {
      "type": "training",
      "description": "Training step 1532",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:55",
      "total_flops_so_far": 2202174725049012.0,
      "budget_used_percent": 2.202174725049012
    },
    {
      "type": "training",
      "description": "Training step 1533",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:55",
      "total_flops_so_far": 2203605820420788.0,
      "budget_used_percent": 2.2036058204207882
    },
    {
      "type": "training",
      "description": "Training step 1534",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:55",
      "total_flops_so_far": 2205036915792564.0,
      "budget_used_percent": 2.2050369157925642
    },
    {
      "type": "training",
      "description": "Training step 1535",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:55",
      "total_flops_so_far": 2206468011164340.0,
      "budget_used_percent": 2.2064680111643398
    },
    {
      "type": "training",
      "description": "Training step 1536",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:56",
      "total_flops_so_far": 2207899106536116.0,
      "budget_used_percent": 2.207899106536116
    },
    {
      "type": "training",
      "description": "Training step 1537",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:56",
      "total_flops_so_far": 2209330201907892.0,
      "budget_used_percent": 2.209330201907892
    },
    {
      "type": "training",
      "description": "Training step 1538",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:56",
      "total_flops_so_far": 2210761297279668.0,
      "budget_used_percent": 2.2107612972796677
    },
    {
      "type": "training",
      "description": "Training step 1539",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:56",
      "total_flops_so_far": 2212192392651444.0,
      "budget_used_percent": 2.212192392651444
    },
    {
      "type": "training",
      "description": "Training step 1540",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:56",
      "total_flops_so_far": 2213623488023220.0,
      "budget_used_percent": 2.21362348802322
    },
    {
      "type": "training",
      "description": "Training step 1541",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:56",
      "total_flops_so_far": 2215054583394996.0,
      "budget_used_percent": 2.2150545833949957
    },
    {
      "type": "training",
      "description": "Training step 1542",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:57",
      "total_flops_so_far": 2216485678766772.0,
      "budget_used_percent": 2.216485678766772
    },
    {
      "type": "training",
      "description": "Training step 1543",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:57",
      "total_flops_so_far": 2217916774138548.0,
      "budget_used_percent": 2.217916774138548
    },
    {
      "type": "training",
      "description": "Training step 1544",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:57",
      "total_flops_so_far": 2219347869510324.0,
      "budget_used_percent": 2.219347869510324
    },
    {
      "type": "training",
      "description": "Training step 1545",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:57",
      "total_flops_so_far": 2220778964882100.0,
      "budget_used_percent": 2.2207789648820997
    },
    {
      "type": "training",
      "description": "Training step 1546",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:57",
      "total_flops_so_far": 2222210060253876.0,
      "budget_used_percent": 2.222210060253876
    },
    {
      "type": "training",
      "description": "Training step 1547",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:57",
      "total_flops_so_far": 2223641155625652.0,
      "budget_used_percent": 2.223641155625652
    },
    {
      "type": "training",
      "description": "Training step 1548",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:57",
      "total_flops_so_far": 2225072250997428.0,
      "budget_used_percent": 2.2250722509974277
    },
    {
      "type": "training",
      "description": "Training step 1549",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:58",
      "total_flops_so_far": 2226503346369204.0,
      "budget_used_percent": 2.226503346369204
    },
    {
      "type": "training",
      "description": "Training step 1550",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:58",
      "total_flops_so_far": 2227934441740980.0,
      "budget_used_percent": 2.22793444174098
    },
    {
      "type": "training",
      "description": "Training step 1551",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:58",
      "total_flops_so_far": 2229365537112756.0,
      "budget_used_percent": 2.2293655371127556
    },
    {
      "type": "training",
      "description": "Training step 1552",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:58",
      "total_flops_so_far": 2230796632484532.0,
      "budget_used_percent": 2.230796632484532
    },
    {
      "type": "training",
      "description": "Training step 1553",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:58",
      "total_flops_so_far": 2232227727856308.0,
      "budget_used_percent": 2.232227727856308
    },
    {
      "type": "training",
      "description": "Training step 1554",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:58",
      "total_flops_so_far": 2233658823228084.0,
      "budget_used_percent": 2.233658823228084
    },
    {
      "type": "training",
      "description": "Training step 1555",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:58",
      "total_flops_so_far": 2235089918599860.0,
      "budget_used_percent": 2.23508991859986
    },
    {
      "type": "training",
      "description": "Training step 1556",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:59",
      "total_flops_so_far": 2236521013971636.0,
      "budget_used_percent": 2.236521013971636
    },
    {
      "type": "training",
      "description": "Training step 1557",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:59",
      "total_flops_so_far": 2237952109343412.0,
      "budget_used_percent": 2.237952109343412
    },
    {
      "type": "training",
      "description": "Training step 1558",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:59",
      "total_flops_so_far": 2239383204715188.0,
      "budget_used_percent": 2.239383204715188
    },
    {
      "type": "training",
      "description": "Training step 1559",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:59",
      "total_flops_so_far": 2240814300086964.0,
      "budget_used_percent": 2.240814300086964
    },
    {
      "type": "training",
      "description": "Training step 1560",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:59",
      "total_flops_so_far": 2242245395458740.0,
      "budget_used_percent": 2.24224539545874
    },
    {
      "type": "training",
      "description": "Training step 1561",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:41:59",
      "total_flops_so_far": 2243676490830516.0,
      "budget_used_percent": 2.243676490830516
    },
    {
      "type": "training",
      "description": "Training step 1562",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:00",
      "total_flops_so_far": 2245107586202292.0,
      "budget_used_percent": 2.245107586202292
    },
    {
      "type": "training",
      "description": "Training step 1563",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:00",
      "total_flops_so_far": 2246538681574068.0,
      "budget_used_percent": 2.246538681574068
    },
    {
      "type": "training",
      "description": "Training step 1564",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:00",
      "total_flops_so_far": 2247969776945844.0,
      "budget_used_percent": 2.247969776945844
    },
    {
      "type": "training",
      "description": "Training step 1565",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:00",
      "total_flops_so_far": 2249400872317620.0,
      "budget_used_percent": 2.24940087231762
    },
    {
      "type": "training",
      "description": "Training step 1566",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:00",
      "total_flops_so_far": 2250831967689396.0,
      "budget_used_percent": 2.250831967689396
    },
    {
      "type": "training",
      "description": "Training step 1567",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:00",
      "total_flops_so_far": 2252263063061172.0,
      "budget_used_percent": 2.252263063061172
    },
    {
      "type": "training",
      "description": "Training step 1568",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:00",
      "total_flops_so_far": 2253694158432948.0,
      "budget_used_percent": 2.253694158432948
    },
    {
      "type": "training",
      "description": "Training step 1569",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:01",
      "total_flops_so_far": 2255125253804724.0,
      "budget_used_percent": 2.255125253804724
    },
    {
      "type": "training",
      "description": "Training step 1570",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:01",
      "total_flops_so_far": 2256556349176500.0,
      "budget_used_percent": 2.2565563491765
    },
    {
      "type": "training",
      "description": "Training step 1571",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:01",
      "total_flops_so_far": 2257987444548276.0,
      "budget_used_percent": 2.2579874445482764
    },
    {
      "type": "training",
      "description": "Training step 1572",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:01",
      "total_flops_so_far": 2259418539920052.0,
      "budget_used_percent": 2.259418539920052
    },
    {
      "type": "training",
      "description": "Training step 1573",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:01",
      "total_flops_so_far": 2260849635291828.0,
      "budget_used_percent": 2.260849635291828
    },
    {
      "type": "training",
      "description": "Training step 1574",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:01",
      "total_flops_so_far": 2262280730663604.0,
      "budget_used_percent": 2.262280730663604
    },
    {
      "type": "training",
      "description": "Training step 1575",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:02",
      "total_flops_so_far": 2263711826035380.0,
      "budget_used_percent": 2.26371182603538
    },
    {
      "type": "training",
      "description": "Training step 1576",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:02",
      "total_flops_so_far": 2265142921407156.0,
      "budget_used_percent": 2.265142921407156
    },
    {
      "type": "training",
      "description": "Training step 1577",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:02",
      "total_flops_so_far": 2266574016778932.0,
      "budget_used_percent": 2.266574016778932
    },
    {
      "type": "training",
      "description": "Training step 1578",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:02",
      "total_flops_so_far": 2268005112150708.0,
      "budget_used_percent": 2.268005112150708
    },
    {
      "type": "training",
      "description": "Training step 1579",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:02",
      "total_flops_so_far": 2269436207522484.0,
      "budget_used_percent": 2.269436207522484
    },
    {
      "type": "training",
      "description": "Training step 1580",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:02",
      "total_flops_so_far": 2270867302894260.0,
      "budget_used_percent": 2.27086730289426
    },
    {
      "type": "training",
      "description": "Training step 1581",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:02",
      "total_flops_so_far": 2272298398266036.0,
      "budget_used_percent": 2.2722983982660363
    },
    {
      "type": "training",
      "description": "Training step 1582",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:03",
      "total_flops_so_far": 2273729493637812.0,
      "budget_used_percent": 2.273729493637812
    },
    {
      "type": "training",
      "description": "Training step 1583",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:03",
      "total_flops_so_far": 2275160589009588.0,
      "budget_used_percent": 2.275160589009588
    },
    {
      "type": "training",
      "description": "Training step 1584",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:03",
      "total_flops_so_far": 2276591684381364.0,
      "budget_used_percent": 2.2765916843813643
    },
    {
      "type": "training",
      "description": "Training step 1585",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:03",
      "total_flops_so_far": 2278022779753140.0,
      "budget_used_percent": 2.27802277975314
    },
    {
      "type": "training",
      "description": "Training step 1586",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:03",
      "total_flops_so_far": 2279453875124916.0,
      "budget_used_percent": 2.279453875124916
    },
    {
      "type": "training",
      "description": "Training step 1587",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:03",
      "total_flops_so_far": 2280884970496692.0,
      "budget_used_percent": 2.2808849704966923
    },
    {
      "type": "training",
      "description": "Training step 1588",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:03",
      "total_flops_so_far": 2282316065868468.0,
      "budget_used_percent": 2.282316065868468
    },
    {
      "type": "training",
      "description": "Training step 1589",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:04",
      "total_flops_so_far": 2283747161240244.0,
      "budget_used_percent": 2.283747161240244
    },
    {
      "type": "training",
      "description": "Training step 1590",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:04",
      "total_flops_so_far": 2285178256612020.0,
      "budget_used_percent": 2.2851782566120202
    },
    {
      "type": "training",
      "description": "Training step 1591",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:04",
      "total_flops_so_far": 2286609351983796.0,
      "budget_used_percent": 2.2866093519837962
    },
    {
      "type": "training",
      "description": "Training step 1592",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:04",
      "total_flops_so_far": 2288040447355572.0,
      "budget_used_percent": 2.2880404473555718
    },
    {
      "type": "training",
      "description": "Training step 1593",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:04",
      "total_flops_so_far": 2289471542727348.0,
      "budget_used_percent": 2.289471542727348
    },
    {
      "type": "training",
      "description": "Training step 1594",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:04",
      "total_flops_so_far": 2290902638099124.0,
      "budget_used_percent": 2.290902638099124
    },
    {
      "type": "training",
      "description": "Training step 1595",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:05",
      "total_flops_so_far": 2292333733470900.0,
      "budget_used_percent": 2.2923337334708997
    },
    {
      "type": "training",
      "description": "Training step 1596",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:05",
      "total_flops_so_far": 2293764828842676.0,
      "budget_used_percent": 2.2937648288426757
    },
    {
      "type": "training",
      "description": "Training step 1597",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:05",
      "total_flops_so_far": 2295195924214452.0,
      "budget_used_percent": 2.295195924214452
    },
    {
      "type": "training",
      "description": "Training step 1598",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:05",
      "total_flops_so_far": 2296627019586228.0,
      "budget_used_percent": 2.296627019586228
    },
    {
      "type": "training",
      "description": "Training step 1599",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:05",
      "total_flops_so_far": 2298058114958004.0,
      "budget_used_percent": 2.2980581149580037
    },
    {
      "type": "training",
      "description": "Training step 1600",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:05",
      "total_flops_so_far": 2299489210329780.0,
      "budget_used_percent": 2.29948921032978
    },
    {
      "type": "training",
      "description": "Training step 1601",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:05",
      "total_flops_so_far": 2300920305701556.0,
      "budget_used_percent": 2.300920305701556
    },
    {
      "type": "training",
      "description": "Training step 1602",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:06",
      "total_flops_so_far": 2302351401073332.0,
      "budget_used_percent": 2.3023514010733317
    },
    {
      "type": "training",
      "description": "Training step 1603",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:06",
      "total_flops_so_far": 2303782496445108.0,
      "budget_used_percent": 2.303782496445108
    },
    {
      "type": "training",
      "description": "Training step 1604",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:06",
      "total_flops_so_far": 2305213591816884.0,
      "budget_used_percent": 2.305213591816884
    },
    {
      "type": "training",
      "description": "Training step 1605",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:06",
      "total_flops_so_far": 2306644687188660.0,
      "budget_used_percent": 2.3066446871886597
    },
    {
      "type": "training",
      "description": "Training step 1606",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:06",
      "total_flops_so_far": 2308075782560436.0,
      "budget_used_percent": 2.308075782560436
    },
    {
      "type": "training",
      "description": "Training step 1607",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:06",
      "total_flops_so_far": 2309506877932212.0,
      "budget_used_percent": 2.309506877932212
    },
    {
      "type": "training",
      "description": "Training step 1608",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:07",
      "total_flops_so_far": 2310937973303988.0,
      "budget_used_percent": 2.310937973303988
    },
    {
      "type": "training",
      "description": "Training step 1609",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:07",
      "total_flops_so_far": 2312369068675764.0,
      "budget_used_percent": 2.312369068675764
    },
    {
      "type": "training",
      "description": "Training step 1610",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:07",
      "total_flops_so_far": 2313800164047540.0,
      "budget_used_percent": 2.31380016404754
    },
    {
      "type": "training",
      "description": "Training step 1611",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:07",
      "total_flops_so_far": 2315231259419316.0,
      "budget_used_percent": 2.315231259419316
    },
    {
      "type": "training",
      "description": "Training step 1612",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:07",
      "total_flops_so_far": 2316662354791092.0,
      "budget_used_percent": 2.316662354791092
    },
    {
      "type": "training",
      "description": "Training step 1613",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:07",
      "total_flops_so_far": 2318093450162868.0,
      "budget_used_percent": 2.318093450162868
    },
    {
      "type": "training",
      "description": "Training step 1614",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:07",
      "total_flops_so_far": 2319524545534644.0,
      "budget_used_percent": 2.319524545534644
    },
    {
      "type": "training",
      "description": "Training step 1615",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:08",
      "total_flops_so_far": 2320955640906420.0,
      "budget_used_percent": 2.32095564090642
    },
    {
      "type": "training",
      "description": "Training step 1616",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:08",
      "total_flops_so_far": 2322386736278196.0,
      "budget_used_percent": 2.322386736278196
    },
    {
      "type": "training",
      "description": "Training step 1617",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:08",
      "total_flops_so_far": 2323817831649972.0,
      "budget_used_percent": 2.323817831649972
    },
    {
      "type": "training",
      "description": "Training step 1618",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:08",
      "total_flops_so_far": 2325248927021748.0,
      "budget_used_percent": 2.325248927021748
    },
    {
      "type": "training",
      "description": "Training step 1619",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:08",
      "total_flops_so_far": 2326680022393524.0,
      "budget_used_percent": 2.326680022393524
    },
    {
      "type": "training",
      "description": "Training step 1620",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:08",
      "total_flops_so_far": 2328111117765300.0,
      "budget_used_percent": 2.3281111177653
    },
    {
      "type": "training",
      "description": "Training step 1621",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:09",
      "total_flops_so_far": 2329542213137076.0,
      "budget_used_percent": 2.329542213137076
    },
    {
      "type": "training",
      "description": "Training step 1622",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:09",
      "total_flops_so_far": 2330973308508852.0,
      "budget_used_percent": 2.330973308508852
    },
    {
      "type": "training",
      "description": "Training step 1623",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:09",
      "total_flops_so_far": 2332404403880628.0,
      "budget_used_percent": 2.332404403880628
    },
    {
      "type": "training",
      "description": "Training step 1624",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:09",
      "total_flops_so_far": 2333835499252404.0,
      "budget_used_percent": 2.333835499252404
    },
    {
      "type": "training",
      "description": "Training step 1625",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:09",
      "total_flops_so_far": 2335266594624180.0,
      "budget_used_percent": 2.33526659462418
    },
    {
      "type": "training",
      "description": "Training step 1626",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:09",
      "total_flops_so_far": 2336697689995956.0,
      "budget_used_percent": 2.336697689995956
    },
    {
      "type": "training",
      "description": "Training step 1627",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:09",
      "total_flops_so_far": 2338128785367732.0,
      "budget_used_percent": 2.338128785367732
    },
    {
      "type": "training",
      "description": "Training step 1628",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:10",
      "total_flops_so_far": 2339559880739508.0,
      "budget_used_percent": 2.339559880739508
    },
    {
      "type": "training",
      "description": "Training step 1629",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:10",
      "total_flops_so_far": 2340990976111284.0,
      "budget_used_percent": 2.340990976111284
    },
    {
      "type": "training",
      "description": "Training step 1630",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:10",
      "total_flops_so_far": 2342422071483060.0,
      "budget_used_percent": 2.34242207148306
    },
    {
      "type": "training",
      "description": "Training step 1631",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:10",
      "total_flops_so_far": 2343853166854836.0,
      "budget_used_percent": 2.343853166854836
    },
    {
      "type": "training",
      "description": "Training step 1632",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:10",
      "total_flops_so_far": 2345284262226612.0,
      "budget_used_percent": 2.345284262226612
    },
    {
      "type": "training",
      "description": "Training step 1633",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:10",
      "total_flops_so_far": 2346715357598388.0,
      "budget_used_percent": 2.346715357598388
    },
    {
      "type": "training",
      "description": "Training step 1634",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:11",
      "total_flops_so_far": 2348146452970164.0,
      "budget_used_percent": 2.348146452970164
    },
    {
      "type": "training",
      "description": "Training step 1635",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:11",
      "total_flops_so_far": 2349577548341940.0,
      "budget_used_percent": 2.3495775483419403
    },
    {
      "type": "training",
      "description": "Training step 1636",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:11",
      "total_flops_so_far": 2351008643713716.0,
      "budget_used_percent": 2.351008643713716
    },
    {
      "type": "training",
      "description": "Training step 1637",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:11",
      "total_flops_so_far": 2352439739085492.0,
      "budget_used_percent": 2.352439739085492
    },
    {
      "type": "training",
      "description": "Training step 1638",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:11",
      "total_flops_so_far": 2353870834457268.0,
      "budget_used_percent": 2.3538708344572683
    },
    {
      "type": "training",
      "description": "Training step 1639",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:11",
      "total_flops_so_far": 2355301929829044.0,
      "budget_used_percent": 2.355301929829044
    },
    {
      "type": "training",
      "description": "Training step 1640",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:11",
      "total_flops_so_far": 2356733025200820.0,
      "budget_used_percent": 2.35673302520082
    },
    {
      "type": "training",
      "description": "Training step 1641",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:12",
      "total_flops_so_far": 2358164120572596.0,
      "budget_used_percent": 2.3581641205725963
    },
    {
      "type": "training",
      "description": "Training step 1642",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:12",
      "total_flops_so_far": 2359595215944372.0,
      "budget_used_percent": 2.359595215944372
    },
    {
      "type": "training",
      "description": "Training step 1643",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:12",
      "total_flops_so_far": 2361026311316148.0,
      "budget_used_percent": 2.361026311316148
    },
    {
      "type": "training",
      "description": "Training step 1644",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:12",
      "total_flops_so_far": 2362457406687924.0,
      "budget_used_percent": 2.3624574066879243
    },
    {
      "type": "training",
      "description": "Training step 1645",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:12",
      "total_flops_so_far": 2363888502059700.0,
      "budget_used_percent": 2.3638885020597002
    },
    {
      "type": "training",
      "description": "Training step 1646",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:12",
      "total_flops_so_far": 2365319597431476.0,
      "budget_used_percent": 2.365319597431476
    },
    {
      "type": "training",
      "description": "Training step 1647",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:12",
      "total_flops_so_far": 2366750692803252.0,
      "budget_used_percent": 2.3667506928032522
    },
    {
      "type": "training",
      "description": "Training step 1648",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:13",
      "total_flops_so_far": 2368181788175028.0,
      "budget_used_percent": 2.3681817881750282
    },
    {
      "type": "training",
      "description": "Training step 1649",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:13",
      "total_flops_so_far": 2369612883546804.0,
      "budget_used_percent": 2.3696128835468038
    },
    {
      "type": "training",
      "description": "Training step 1650",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:13",
      "total_flops_so_far": 2371043978918580.0,
      "budget_used_percent": 2.37104397891858
    },
    {
      "type": "training",
      "description": "Training step 1651",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:13",
      "total_flops_so_far": 2372475074290356.0,
      "budget_used_percent": 2.372475074290356
    },
    {
      "type": "training",
      "description": "Training step 1652",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:13",
      "total_flops_so_far": 2373906169662132.0,
      "budget_used_percent": 2.3739061696621317
    },
    {
      "type": "training",
      "description": "Training step 1653",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:13",
      "total_flops_so_far": 2375337265033908.0,
      "budget_used_percent": 2.3753372650339077
    },
    {
      "type": "training",
      "description": "Training step 1654",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:14",
      "total_flops_so_far": 2376768360405684.0,
      "budget_used_percent": 2.376768360405684
    },
    {
      "type": "training",
      "description": "Training step 1655",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:14",
      "total_flops_so_far": 2378199455777460.0,
      "budget_used_percent": 2.37819945577746
    },
    {
      "type": "training",
      "description": "Training step 1656",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:14",
      "total_flops_so_far": 2379630551149236.0,
      "budget_used_percent": 2.3796305511492357
    },
    {
      "type": "training",
      "description": "Training step 1657",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:14",
      "total_flops_so_far": 2381061646521012.0,
      "budget_used_percent": 2.381061646521012
    },
    {
      "type": "training",
      "description": "Training step 1658",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:14",
      "total_flops_so_far": 2382492741892788.0,
      "budget_used_percent": 2.382492741892788
    },
    {
      "type": "training",
      "description": "Training step 1659",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:14",
      "total_flops_so_far": 2383923837264564.0,
      "budget_used_percent": 2.3839238372645637
    },
    {
      "type": "training",
      "description": "Training step 1660",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:14",
      "total_flops_so_far": 2385354932636340.0,
      "budget_used_percent": 2.38535493263634
    },
    {
      "type": "training",
      "description": "Training step 1661",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:15",
      "total_flops_so_far": 2386786028008116.0,
      "budget_used_percent": 2.386786028008116
    },
    {
      "type": "training",
      "description": "Training step 1662",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:15",
      "total_flops_so_far": 2388217123379892.0,
      "budget_used_percent": 2.3882171233798917
    },
    {
      "type": "training",
      "description": "Training step 1663",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:15",
      "total_flops_so_far": 2389648218751668.0,
      "budget_used_percent": 2.389648218751668
    },
    {
      "type": "training",
      "description": "Training step 1664",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:15",
      "total_flops_so_far": 2391079314123444.0,
      "budget_used_percent": 2.391079314123444
    },
    {
      "type": "training",
      "description": "Training step 1665",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:15",
      "total_flops_so_far": 2392510409495220.0,
      "budget_used_percent": 2.39251040949522
    },
    {
      "type": "training",
      "description": "Training step 1666",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:15",
      "total_flops_so_far": 2393941504866996.0,
      "budget_used_percent": 2.393941504866996
    },
    {
      "type": "training",
      "description": "Training step 1667",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:16",
      "total_flops_so_far": 2395372600238772.0,
      "budget_used_percent": 2.395372600238772
    },
    {
      "type": "training",
      "description": "Training step 1668",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:16",
      "total_flops_so_far": 2396803695610548.0,
      "budget_used_percent": 2.396803695610548
    },
    {
      "type": "training",
      "description": "Training step 1669",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:16",
      "total_flops_so_far": 2398234790982324.0,
      "budget_used_percent": 2.398234790982324
    },
    {
      "type": "training",
      "description": "Training step 1670",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:16",
      "total_flops_so_far": 2399665886354100.0,
      "budget_used_percent": 2.3996658863541
    },
    {
      "type": "training",
      "description": "Training step 1671",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:16",
      "total_flops_so_far": 2401096981725876.0,
      "budget_used_percent": 2.401096981725876
    },
    {
      "type": "training",
      "description": "Training step 1672",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:16",
      "total_flops_so_far": 2402528077097652.0,
      "budget_used_percent": 2.402528077097652
    },
    {
      "type": "training",
      "description": "Training step 1673",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:16",
      "total_flops_so_far": 2403959172469428.0,
      "budget_used_percent": 2.403959172469428
    },
    {
      "type": "training",
      "description": "Training step 1674",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:17",
      "total_flops_so_far": 2405390267841204.0,
      "budget_used_percent": 2.405390267841204
    },
    {
      "type": "training",
      "description": "Training step 1675",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:17",
      "total_flops_so_far": 2406821363212980.0,
      "budget_used_percent": 2.40682136321298
    },
    {
      "type": "training",
      "description": "Training step 1676",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:17",
      "total_flops_so_far": 2408252458584756.0,
      "budget_used_percent": 2.408252458584756
    },
    {
      "type": "training",
      "description": "Training step 1677",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:17",
      "total_flops_so_far": 2409683553956532.0,
      "budget_used_percent": 2.409683553956532
    },
    {
      "type": "training",
      "description": "Training step 1678",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:17",
      "total_flops_so_far": 2411114649328308.0,
      "budget_used_percent": 2.411114649328308
    },
    {
      "type": "training",
      "description": "Training step 1679",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:17",
      "total_flops_so_far": 2412545744700084.0,
      "budget_used_percent": 2.412545744700084
    },
    {
      "type": "training",
      "description": "Training step 1680",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:18",
      "total_flops_so_far": 2413976840071860.0,
      "budget_used_percent": 2.41397684007186
    },
    {
      "type": "training",
      "description": "Training step 1681",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:18",
      "total_flops_so_far": 2415407935443636.0,
      "budget_used_percent": 2.415407935443636
    },
    {
      "type": "training",
      "description": "Training step 1682",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:18",
      "total_flops_so_far": 2416839030815412.0,
      "budget_used_percent": 2.416839030815412
    },
    {
      "type": "training",
      "description": "Training step 1683",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:18",
      "total_flops_so_far": 2418270126187188.0,
      "budget_used_percent": 2.418270126187188
    },
    {
      "type": "training",
      "description": "Training step 1684",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:18",
      "total_flops_so_far": 2419701221558964.0,
      "budget_used_percent": 2.419701221558964
    },
    {
      "type": "training",
      "description": "Training step 1685",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:18",
      "total_flops_so_far": 2421132316930740.0,
      "budget_used_percent": 2.42113231693074
    },
    {
      "type": "training",
      "description": "Training step 1686",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:18",
      "total_flops_so_far": 2422563412302516.0,
      "budget_used_percent": 2.422563412302516
    },
    {
      "type": "training",
      "description": "Training step 1687",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:19",
      "total_flops_so_far": 2423994507674292.0,
      "budget_used_percent": 2.423994507674292
    },
    {
      "type": "training",
      "description": "Training step 1688",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:19",
      "total_flops_so_far": 2425425603046068.0,
      "budget_used_percent": 2.425425603046068
    },
    {
      "type": "training",
      "description": "Training step 1689",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:19",
      "total_flops_so_far": 2426856698417844.0,
      "budget_used_percent": 2.426856698417844
    },
    {
      "type": "training",
      "description": "Training step 1690",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:19",
      "total_flops_so_far": 2428287793789620.0,
      "budget_used_percent": 2.42828779378962
    },
    {
      "type": "training",
      "description": "Training step 1691",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:19",
      "total_flops_so_far": 2429718889161396.0,
      "budget_used_percent": 2.429718889161396
    },
    {
      "type": "training",
      "description": "Training step 1692",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:19",
      "total_flops_so_far": 2431149984533172.0,
      "budget_used_percent": 2.4311499845331723
    },
    {
      "type": "training",
      "description": "Training step 1693",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:20",
      "total_flops_so_far": 2432581079904948.0,
      "budget_used_percent": 2.432581079904948
    },
    {
      "type": "training",
      "description": "Training step 1694",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:20",
      "total_flops_so_far": 2434012175276724.0,
      "budget_used_percent": 2.434012175276724
    },
    {
      "type": "training",
      "description": "Training step 1695",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:20",
      "total_flops_so_far": 2435443270648500.0,
      "budget_used_percent": 2.4354432706485003
    },
    {
      "type": "training",
      "description": "Training step 1696",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:20",
      "total_flops_so_far": 2436874366020276.0,
      "budget_used_percent": 2.436874366020276
    },
    {
      "type": "training",
      "description": "Training step 1697",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:20",
      "total_flops_so_far": 2438305461392052.0,
      "budget_used_percent": 2.438305461392052
    },
    {
      "type": "training",
      "description": "Training step 1698",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:20",
      "total_flops_so_far": 2439736556763828.0,
      "budget_used_percent": 2.4397365567638283
    },
    {
      "type": "training",
      "description": "Training step 1699",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:20",
      "total_flops_so_far": 2441167652135604.0,
      "budget_used_percent": 2.441167652135604
    },
    {
      "type": "training",
      "description": "Training step 1700",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:21",
      "total_flops_so_far": 2442598747507380.0,
      "budget_used_percent": 2.44259874750738
    },
    {
      "type": "training",
      "description": "Training step 1701",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:21",
      "total_flops_so_far": 2444029842879156.0,
      "budget_used_percent": 2.4440298428791563
    },
    {
      "type": "training",
      "description": "Training step 1702",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:21",
      "total_flops_so_far": 2445460938250932.0,
      "budget_used_percent": 2.4454609382509322
    },
    {
      "type": "training",
      "description": "Training step 1703",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:21",
      "total_flops_so_far": 2446892033622708.0,
      "budget_used_percent": 2.446892033622708
    },
    {
      "type": "training",
      "description": "Training step 1704",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:21",
      "total_flops_so_far": 2448323128994484.0,
      "budget_used_percent": 2.448323128994484
    },
    {
      "type": "training",
      "description": "Training step 1705",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:21",
      "total_flops_so_far": 2449754224366260.0,
      "budget_used_percent": 2.4497542243662602
    },
    {
      "type": "training",
      "description": "Training step 1706",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:22",
      "total_flops_so_far": 2451185319738036.0,
      "budget_used_percent": 2.4511853197380358
    },
    {
      "type": "training",
      "description": "Training step 1707",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:22",
      "total_flops_so_far": 2452616415109812.0,
      "budget_used_percent": 2.4526164151098118
    },
    {
      "type": "training",
      "description": "Training step 1708",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:22",
      "total_flops_so_far": 2454047510481588.0,
      "budget_used_percent": 2.454047510481588
    },
    {
      "type": "training",
      "description": "Training step 1709",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:22",
      "total_flops_so_far": 2455478605853364.0,
      "budget_used_percent": 2.4554786058533637
    },
    {
      "type": "training",
      "description": "Training step 1710",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:22",
      "total_flops_so_far": 2456909701225140.0,
      "budget_used_percent": 2.4569097012251397
    },
    {
      "type": "training",
      "description": "Training step 1711",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:22",
      "total_flops_so_far": 2458340796596916.0,
      "budget_used_percent": 2.458340796596916
    },
    {
      "type": "training",
      "description": "Training step 1712",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:22",
      "total_flops_so_far": 2459771891968692.0,
      "budget_used_percent": 2.459771891968692
    },
    {
      "type": "training",
      "description": "Training step 1713",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:23",
      "total_flops_so_far": 2461202987340468.0,
      "budget_used_percent": 2.4612029873404677
    },
    {
      "type": "training",
      "description": "Training step 1714",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:23",
      "total_flops_so_far": 2462634082712244.0,
      "budget_used_percent": 2.462634082712244
    },
    {
      "type": "training",
      "description": "Training step 1715",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:23",
      "total_flops_so_far": 2464065178084020.0,
      "budget_used_percent": 2.46406517808402
    },
    {
      "type": "training",
      "description": "Training step 1716",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:23",
      "total_flops_so_far": 2465496273455796.0,
      "budget_used_percent": 2.4654962734557957
    },
    {
      "type": "training",
      "description": "Training step 1717",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:23",
      "total_flops_so_far": 2466927368827572.0,
      "budget_used_percent": 2.466927368827572
    },
    {
      "type": "training",
      "description": "Training step 1718",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:23",
      "total_flops_so_far": 2468358464199348.0,
      "budget_used_percent": 2.468358464199348
    },
    {
      "type": "training",
      "description": "Training step 1719",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:24",
      "total_flops_so_far": 2469789559571124.0,
      "budget_used_percent": 2.469789559571124
    },
    {
      "type": "training",
      "description": "Training step 1720",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:24",
      "total_flops_so_far": 2471220654942900.0,
      "budget_used_percent": 2.4712206549429
    },
    {
      "type": "training",
      "description": "Training step 1721",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:24",
      "total_flops_so_far": 2472651750314676.0,
      "budget_used_percent": 2.472651750314676
    },
    {
      "type": "training",
      "description": "Training step 1722",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:24",
      "total_flops_so_far": 2474082845686452.0,
      "budget_used_percent": 2.474082845686452
    },
    {
      "type": "training",
      "description": "Training step 1723",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:24",
      "total_flops_so_far": 2475513941058228.0,
      "budget_used_percent": 2.475513941058228
    },
    {
      "type": "training",
      "description": "Training step 1724",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:24",
      "total_flops_so_far": 2476945036430004.0,
      "budget_used_percent": 2.476945036430004
    },
    {
      "type": "training",
      "description": "Training step 1725",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:25",
      "total_flops_so_far": 2478376131801780.0,
      "budget_used_percent": 2.47837613180178
    },
    {
      "type": "training",
      "description": "Training step 1726",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:25",
      "total_flops_so_far": 2479807227173556.0,
      "budget_used_percent": 2.479807227173556
    },
    {
      "type": "training",
      "description": "Training step 1727",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:25",
      "total_flops_so_far": 2481238322545332.0,
      "budget_used_percent": 2.481238322545332
    },
    {
      "type": "training",
      "description": "Training step 1728",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:25",
      "total_flops_so_far": 2482669417917108.0,
      "budget_used_percent": 2.482669417917108
    },
    {
      "type": "training",
      "description": "Training step 1729",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:25",
      "total_flops_so_far": 2484100513288884.0,
      "budget_used_percent": 2.484100513288884
    },
    {
      "type": "training",
      "description": "Training step 1730",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:25",
      "total_flops_so_far": 2485531608660660.0,
      "budget_used_percent": 2.48553160866066
    },
    {
      "type": "training",
      "description": "Training step 1731",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:25",
      "total_flops_so_far": 2486962704032436.0,
      "budget_used_percent": 2.486962704032436
    },
    {
      "type": "training",
      "description": "Training step 1732",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:26",
      "total_flops_so_far": 2488393799404212.0,
      "budget_used_percent": 2.488393799404212
    },
    {
      "type": "training",
      "description": "Training step 1733",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:26",
      "total_flops_so_far": 2489824894775988.0,
      "budget_used_percent": 2.489824894775988
    },
    {
      "type": "training",
      "description": "Training step 1734",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:26",
      "total_flops_so_far": 2491255990147764.0,
      "budget_used_percent": 2.491255990147764
    },
    {
      "type": "training",
      "description": "Training step 1735",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:26",
      "total_flops_so_far": 2492687085519540.0,
      "budget_used_percent": 2.49268708551954
    },
    {
      "type": "training",
      "description": "Training step 1736",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:26",
      "total_flops_so_far": 2494118180891316.0,
      "budget_used_percent": 2.494118180891316
    },
    {
      "type": "training",
      "description": "Training step 1737",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:26",
      "total_flops_so_far": 2495549276263092.0,
      "budget_used_percent": 2.495549276263092
    },
    {
      "type": "training",
      "description": "Training step 1738",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:27",
      "total_flops_so_far": 2496980371634868.0,
      "budget_used_percent": 2.496980371634868
    },
    {
      "type": "training",
      "description": "Training step 1739",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:27",
      "total_flops_so_far": 2498411467006644.0,
      "budget_used_percent": 2.498411467006644
    },
    {
      "type": "training",
      "description": "Training step 1740",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:27",
      "total_flops_so_far": 2499842562378420.0,
      "budget_used_percent": 2.49984256237842
    },
    {
      "type": "training",
      "description": "Training step 1741",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:27",
      "total_flops_so_far": 2501273657750196.0,
      "budget_used_percent": 2.501273657750196
    },
    {
      "type": "training",
      "description": "Training step 1742",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:27",
      "total_flops_so_far": 2502704753121972.0,
      "budget_used_percent": 2.502704753121972
    },
    {
      "type": "training",
      "description": "Training step 1743",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:27",
      "total_flops_so_far": 2504135848493748.0,
      "budget_used_percent": 2.504135848493748
    },
    {
      "type": "training",
      "description": "Training step 1744",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:27",
      "total_flops_so_far": 2505566943865524.0,
      "budget_used_percent": 2.505566943865524
    },
    {
      "type": "training",
      "description": "Training step 1745",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:28",
      "total_flops_so_far": 2506998039237300.0,
      "budget_used_percent": 2.5069980392373
    },
    {
      "type": "training",
      "description": "Training step 1746",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:28",
      "total_flops_so_far": 2508429134609076.0,
      "budget_used_percent": 2.508429134609076
    },
    {
      "type": "training",
      "description": "Training step 1747",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:28",
      "total_flops_so_far": 2509860229980852.0,
      "budget_used_percent": 2.509860229980852
    },
    {
      "type": "training",
      "description": "Training step 1748",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:28",
      "total_flops_so_far": 2511291325352628.0,
      "budget_used_percent": 2.511291325352628
    },
    {
      "type": "training",
      "description": "Training step 1749",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:28",
      "total_flops_so_far": 2512722420724404.0,
      "budget_used_percent": 2.5127224207244043
    },
    {
      "type": "training",
      "description": "Training step 1750",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:28",
      "total_flops_so_far": 2514153516096180.0,
      "budget_used_percent": 2.51415351609618
    },
    {
      "type": "training",
      "description": "Training step 1751",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:29",
      "total_flops_so_far": 2515584611467956.0,
      "budget_used_percent": 2.515584611467956
    },
    {
      "type": "training",
      "description": "Training step 1752",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:29",
      "total_flops_so_far": 2517015706839732.0,
      "budget_used_percent": 2.5170157068397323
    },
    {
      "type": "training",
      "description": "Training step 1753",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:29",
      "total_flops_so_far": 2518446802211508.0,
      "budget_used_percent": 2.518446802211508
    },
    {
      "type": "training",
      "description": "Training step 1754",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:29",
      "total_flops_so_far": 2519877897583284.0,
      "budget_used_percent": 2.519877897583284
    },
    {
      "type": "training",
      "description": "Training step 1755",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:29",
      "total_flops_so_far": 2521308992955060.0,
      "budget_used_percent": 2.5213089929550603
    },
    {
      "type": "training",
      "description": "Training step 1756",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:29",
      "total_flops_so_far": 2522740088326836.0,
      "budget_used_percent": 2.522740088326836
    },
    {
      "type": "training",
      "description": "Training step 1757",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:29",
      "total_flops_so_far": 2524171183698612.0,
      "budget_used_percent": 2.524171183698612
    },
    {
      "type": "training",
      "description": "Training step 1758",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:30",
      "total_flops_so_far": 2525602279070388.0,
      "budget_used_percent": 2.5256022790703883
    },
    {
      "type": "training",
      "description": "Training step 1759",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:30",
      "total_flops_so_far": 2527033374442164.0,
      "budget_used_percent": 2.5270333744421642
    },
    {
      "type": "training",
      "description": "Training step 1760",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:30",
      "total_flops_so_far": 2528464469813940.0,
      "budget_used_percent": 2.52846446981394
    },
    {
      "type": "training",
      "description": "Training step 1761",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:30",
      "total_flops_so_far": 2529895565185716.0,
      "budget_used_percent": 2.529895565185716
    },
    {
      "type": "training",
      "description": "Training step 1762",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:30",
      "total_flops_so_far": 2531326660557492.0,
      "budget_used_percent": 2.5313266605574922
    },
    {
      "type": "training",
      "description": "Training step 1763",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:31",
      "total_flops_so_far": 2532757755929268.0,
      "budget_used_percent": 2.5327577559292678
    },
    {
      "type": "training",
      "description": "Training step 1764",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:31",
      "total_flops_so_far": 2534188851301044.0,
      "budget_used_percent": 2.5341888513010438
    },
    {
      "type": "training",
      "description": "Training step 1765",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:31",
      "total_flops_so_far": 2535619946672820.0,
      "budget_used_percent": 2.53561994667282
    },
    {
      "type": "training",
      "description": "Training step 1766",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:31",
      "total_flops_so_far": 2537051042044596.0,
      "budget_used_percent": 2.537051042044596
    },
    {
      "type": "training",
      "description": "Training step 1767",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:31",
      "total_flops_so_far": 2538482137416372.0,
      "budget_used_percent": 2.5384821374163717
    },
    {
      "type": "training",
      "description": "Training step 1768",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:31",
      "total_flops_so_far": 2539913232788148.0,
      "budget_used_percent": 2.539913232788148
    },
    {
      "type": "training",
      "description": "Training step 1769",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:32",
      "total_flops_so_far": 2541344328159924.0,
      "budget_used_percent": 2.541344328159924
    },
    {
      "type": "training",
      "description": "Training step 1770",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:32",
      "total_flops_so_far": 2542775423531700.0,
      "budget_used_percent": 2.5427754235316997
    },
    {
      "type": "training",
      "description": "Training step 1771",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:32",
      "total_flops_so_far": 2544206518903476.0,
      "budget_used_percent": 2.544206518903476
    },
    {
      "type": "training",
      "description": "Training step 1772",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:32",
      "total_flops_so_far": 2545637614275252.0,
      "budget_used_percent": 2.545637614275252
    },
    {
      "type": "training",
      "description": "Training step 1773",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:32",
      "total_flops_so_far": 2547068709647028.0,
      "budget_used_percent": 2.5470687096470277
    },
    {
      "type": "training",
      "description": "Training step 1774",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:32",
      "total_flops_so_far": 2548499805018804.0,
      "budget_used_percent": 2.548499805018804
    },
    {
      "type": "training",
      "description": "Training step 1775",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:32",
      "total_flops_so_far": 2549930900390580.0,
      "budget_used_percent": 2.54993090039058
    },
    {
      "type": "training",
      "description": "Training step 1776",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:33",
      "total_flops_so_far": 2551361995762356.0,
      "budget_used_percent": 2.551361995762356
    },
    {
      "type": "training",
      "description": "Training step 1777",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:33",
      "total_flops_so_far": 2552793091134132.0,
      "budget_used_percent": 2.552793091134132
    },
    {
      "type": "training",
      "description": "Training step 1778",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:33",
      "total_flops_so_far": 2554224186505908.0,
      "budget_used_percent": 2.554224186505908
    },
    {
      "type": "training",
      "description": "Training step 1779",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:33",
      "total_flops_so_far": 2555655281877684.0,
      "budget_used_percent": 2.555655281877684
    },
    {
      "type": "training",
      "description": "Training step 1780",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:33",
      "total_flops_so_far": 2557086377249460.0,
      "budget_used_percent": 2.55708637724946
    },
    {
      "type": "training",
      "description": "Training step 1781",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:33",
      "total_flops_so_far": 2558517472621236.0,
      "budget_used_percent": 2.558517472621236
    },
    {
      "type": "training",
      "description": "Training step 1782",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:34",
      "total_flops_so_far": 2559948567993012.0,
      "budget_used_percent": 2.559948567993012
    },
    {
      "type": "training",
      "description": "Training step 1783",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:34",
      "total_flops_so_far": 2561379663364788.0,
      "budget_used_percent": 2.5613796633647876
    },
    {
      "type": "training",
      "description": "Training step 1784",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:34",
      "total_flops_so_far": 2562810758736564.0,
      "budget_used_percent": 2.562810758736564
    },
    {
      "type": "training",
      "description": "Training step 1785",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:34",
      "total_flops_so_far": 2564241854108340.0,
      "budget_used_percent": 2.56424185410834
    },
    {
      "type": "training",
      "description": "Training step 1786",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:34",
      "total_flops_so_far": 2565672949480116.0,
      "budget_used_percent": 2.565672949480116
    },
    {
      "type": "training",
      "description": "Training step 1787",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:34",
      "total_flops_so_far": 2567104044851892.0,
      "budget_used_percent": 2.567104044851892
    },
    {
      "type": "training",
      "description": "Training step 1788",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:35",
      "total_flops_so_far": 2568535140223668.0,
      "budget_used_percent": 2.568535140223668
    },
    {
      "type": "training",
      "description": "Training step 1789",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:35",
      "total_flops_so_far": 2569966235595444.0,
      "budget_used_percent": 2.569966235595444
    },
    {
      "type": "training",
      "description": "Training step 1790",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:35",
      "total_flops_so_far": 2571397330967220.0,
      "budget_used_percent": 2.57139733096722
    },
    {
      "type": "training",
      "description": "Training step 1791",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:35",
      "total_flops_so_far": 2572828426338996.0,
      "budget_used_percent": 2.572828426338996
    },
    {
      "type": "training",
      "description": "Training step 1792",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:35",
      "total_flops_so_far": 2574259521710772.0,
      "budget_used_percent": 2.574259521710772
    },
    {
      "type": "training",
      "description": "Training step 1793",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:35",
      "total_flops_so_far": 2575690617082548.0,
      "budget_used_percent": 2.575690617082548
    },
    {
      "type": "training",
      "description": "Training step 1794",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:35",
      "total_flops_so_far": 2577121712454324.0,
      "budget_used_percent": 2.577121712454324
    },
    {
      "type": "training",
      "description": "Training step 1795",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:36",
      "total_flops_so_far": 2578552807826100.0,
      "budget_used_percent": 2.5785528078261
    },
    {
      "type": "training",
      "description": "Training step 1796",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:36",
      "total_flops_so_far": 2579983903197876.0,
      "budget_used_percent": 2.579983903197876
    },
    {
      "type": "training",
      "description": "Training step 1797",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:36",
      "total_flops_so_far": 2581414998569652.0,
      "budget_used_percent": 2.581414998569652
    },
    {
      "type": "training",
      "description": "Training step 1798",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:36",
      "total_flops_so_far": 2582846093941428.0,
      "budget_used_percent": 2.582846093941428
    },
    {
      "type": "training",
      "description": "Training step 1799",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:36",
      "total_flops_so_far": 2584277189313204.0,
      "budget_used_percent": 2.584277189313204
    },
    {
      "type": "training",
      "description": "Training step 1800",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:36",
      "total_flops_so_far": 2585708284684980.0,
      "budget_used_percent": 2.58570828468498
    },
    {
      "type": "training",
      "description": "Training step 1801",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:37",
      "total_flops_so_far": 2587139380056756.0,
      "budget_used_percent": 2.587139380056756
    },
    {
      "type": "training",
      "description": "Training step 1802",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:37",
      "total_flops_so_far": 2588570475428532.0,
      "budget_used_percent": 2.588570475428532
    },
    {
      "type": "training",
      "description": "Training step 1803",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:37",
      "total_flops_so_far": 2590001570800308.0,
      "budget_used_percent": 2.5900015708003084
    },
    {
      "type": "training",
      "description": "Training step 1804",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:37",
      "total_flops_so_far": 2591432666172084.0,
      "budget_used_percent": 2.591432666172084
    },
    {
      "type": "training",
      "description": "Training step 1805",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:37",
      "total_flops_so_far": 2592863761543860.0,
      "budget_used_percent": 2.59286376154386
    },
    {
      "type": "training",
      "description": "Training step 1806",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:37",
      "total_flops_so_far": 2594294856915636.0,
      "budget_used_percent": 2.5942948569156363
    },
    {
      "type": "training",
      "description": "Training step 1807",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:38",
      "total_flops_so_far": 2595725952287412.0,
      "budget_used_percent": 2.595725952287412
    },
    {
      "type": "training",
      "description": "Training step 1808",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:38",
      "total_flops_so_far": 2597157047659188.0,
      "budget_used_percent": 2.597157047659188
    },
    {
      "type": "training",
      "description": "Training step 1809",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:38",
      "total_flops_so_far": 2598588143030964.0,
      "budget_used_percent": 2.5985881430309643
    },
    {
      "type": "training",
      "description": "Training step 1810",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:38",
      "total_flops_so_far": 2600019238402740.0,
      "budget_used_percent": 2.60001923840274
    },
    {
      "type": "training",
      "description": "Training step 1811",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:38",
      "total_flops_so_far": 2601450333774516.0,
      "budget_used_percent": 2.601450333774516
    },
    {
      "type": "training",
      "description": "Training step 1812",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:38",
      "total_flops_so_far": 2602881429146292.0,
      "budget_used_percent": 2.602881429146292
    },
    {
      "type": "training",
      "description": "Training step 1813",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:38",
      "total_flops_so_far": 2604312524518068.0,
      "budget_used_percent": 2.6043125245180683
    },
    {
      "type": "training",
      "description": "Training step 1814",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:39",
      "total_flops_so_far": 2605743619889844.0,
      "budget_used_percent": 2.605743619889844
    },
    {
      "type": "training",
      "description": "Training step 1815",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:39",
      "total_flops_so_far": 2607174715261620.0,
      "budget_used_percent": 2.60717471526162
    },
    {
      "type": "training",
      "description": "Training step 1816",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:39",
      "total_flops_so_far": 2608605810633396.0,
      "budget_used_percent": 2.6086058106333962
    },
    {
      "type": "training",
      "description": "Training step 1817",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:39",
      "total_flops_so_far": 2610036906005172.0,
      "budget_used_percent": 2.610036906005172
    },
    {
      "type": "training",
      "description": "Training step 1818",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:39",
      "total_flops_so_far": 2611468001376948.0,
      "budget_used_percent": 2.611468001376948
    },
    {
      "type": "training",
      "description": "Training step 1819",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:39",
      "total_flops_so_far": 2612899096748724.0,
      "budget_used_percent": 2.6128990967487242
    },
    {
      "type": "training",
      "description": "Training step 1820",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:40",
      "total_flops_so_far": 2614330192120500.0,
      "budget_used_percent": 2.6143301921204998
    },
    {
      "type": "training",
      "description": "Training step 1821",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:40",
      "total_flops_so_far": 2615761287492276.0,
      "budget_used_percent": 2.6157612874922758
    },
    {
      "type": "training",
      "description": "Training step 1822",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:40",
      "total_flops_so_far": 2617192382864052.0,
      "budget_used_percent": 2.617192382864052
    },
    {
      "type": "training",
      "description": "Training step 1823",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:40",
      "total_flops_so_far": 2618623478235828.0,
      "budget_used_percent": 2.618623478235828
    },
    {
      "type": "training",
      "description": "Training step 1824",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:40",
      "total_flops_so_far": 2620054573607604.0,
      "budget_used_percent": 2.6200545736076037
    },
    {
      "type": "training",
      "description": "Training step 1825",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:40",
      "total_flops_so_far": 2621485668979380.0,
      "budget_used_percent": 2.62148566897938
    },
    {
      "type": "training",
      "description": "Training step 1826",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:41",
      "total_flops_so_far": 2622916764351156.0,
      "budget_used_percent": 2.622916764351156
    },
    {
      "type": "training",
      "description": "Training step 1827",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:41",
      "total_flops_so_far": 2624347859722932.0,
      "budget_used_percent": 2.6243478597229317
    },
    {
      "type": "training",
      "description": "Training step 1828",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:41",
      "total_flops_so_far": 2625778955094708.0,
      "budget_used_percent": 2.625778955094708
    },
    {
      "type": "training",
      "description": "Training step 1829",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:41",
      "total_flops_so_far": 2627210050466484.0,
      "budget_used_percent": 2.627210050466484
    },
    {
      "type": "training",
      "description": "Training step 1830",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:41",
      "total_flops_so_far": 2628641145838260.0,
      "budget_used_percent": 2.6286411458382597
    },
    {
      "type": "training",
      "description": "Training step 1831",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:41",
      "total_flops_so_far": 2630072241210036.0,
      "budget_used_percent": 2.630072241210036
    },
    {
      "type": "training",
      "description": "Training step 1832",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:41",
      "total_flops_so_far": 2631503336581812.0,
      "budget_used_percent": 2.631503336581812
    },
    {
      "type": "training",
      "description": "Training step 1833",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:42",
      "total_flops_so_far": 2632934431953588.0,
      "budget_used_percent": 2.632934431953588
    },
    {
      "type": "training",
      "description": "Training step 1834",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:42",
      "total_flops_so_far": 2634365527325364.0,
      "budget_used_percent": 2.634365527325364
    },
    {
      "type": "training",
      "description": "Training step 1835",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:42",
      "total_flops_so_far": 2635796622697140.0,
      "budget_used_percent": 2.63579662269714
    },
    {
      "type": "training",
      "description": "Training step 1836",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:42",
      "total_flops_so_far": 2637227718068916.0,
      "budget_used_percent": 2.637227718068916
    },
    {
      "type": "training",
      "description": "Training step 1837",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:42",
      "total_flops_so_far": 2638658813440692.0,
      "budget_used_percent": 2.638658813440692
    },
    {
      "type": "training",
      "description": "Training step 1838",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:42",
      "total_flops_so_far": 2640089908812468.0,
      "budget_used_percent": 2.640089908812468
    },
    {
      "type": "training",
      "description": "Training step 1839",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:43",
      "total_flops_so_far": 2641521004184244.0,
      "budget_used_percent": 2.641521004184244
    },
    {
      "type": "training",
      "description": "Training step 1840",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:43",
      "total_flops_so_far": 2642952099556020.0,
      "budget_used_percent": 2.6429520995560196
    },
    {
      "type": "training",
      "description": "Training step 1841",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:43",
      "total_flops_so_far": 2644383194927796.0,
      "budget_used_percent": 2.644383194927796
    },
    {
      "type": "training",
      "description": "Training step 1842",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:43",
      "total_flops_so_far": 2645814290299572.0,
      "budget_used_percent": 2.645814290299572
    },
    {
      "type": "training",
      "description": "Training step 1843",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:43",
      "total_flops_so_far": 2647245385671348.0,
      "budget_used_percent": 2.647245385671348
    },
    {
      "type": "training",
      "description": "Training step 1844",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:43",
      "total_flops_so_far": 2648676481043124.0,
      "budget_used_percent": 2.648676481043124
    },
    {
      "type": "training",
      "description": "Training step 1845",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:44",
      "total_flops_so_far": 2650107576414900.0,
      "budget_used_percent": 2.6501075764149
    },
    {
      "type": "training",
      "description": "Training step 1846",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:44",
      "total_flops_so_far": 2651538671786676.0,
      "budget_used_percent": 2.651538671786676
    },
    {
      "type": "training",
      "description": "Training step 1847",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:44",
      "total_flops_so_far": 2652969767158452.0,
      "budget_used_percent": 2.652969767158452
    },
    {
      "type": "training",
      "description": "Training step 1848",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:44",
      "total_flops_so_far": 2654400862530228.0,
      "budget_used_percent": 2.654400862530228
    },
    {
      "type": "training",
      "description": "Training step 1849",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:44",
      "total_flops_so_far": 2655831957902004.0,
      "budget_used_percent": 2.655831957902004
    },
    {
      "type": "training",
      "description": "Training step 1850",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:44",
      "total_flops_so_far": 2657263053273780.0,
      "budget_used_percent": 2.65726305327378
    },
    {
      "type": "training",
      "description": "Training step 1851",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:44",
      "total_flops_so_far": 2658694148645556.0,
      "budget_used_percent": 2.658694148645556
    },
    {
      "type": "training",
      "description": "Training step 1852",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:45",
      "total_flops_so_far": 2660125244017332.0,
      "budget_used_percent": 2.660125244017332
    },
    {
      "type": "training",
      "description": "Training step 1853",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:45",
      "total_flops_so_far": 2661556339389108.0,
      "budget_used_percent": 2.661556339389108
    },
    {
      "type": "training",
      "description": "Training step 1854",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:45",
      "total_flops_so_far": 2662987434760884.0,
      "budget_used_percent": 2.662987434760884
    },
    {
      "type": "training",
      "description": "Training step 1855",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:45",
      "total_flops_so_far": 2664418530132660.0,
      "budget_used_percent": 2.66441853013266
    },
    {
      "type": "training",
      "description": "Training step 1856",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:45",
      "total_flops_so_far": 2665849625504436.0,
      "budget_used_percent": 2.665849625504436
    },
    {
      "type": "training",
      "description": "Training step 1857",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:45",
      "total_flops_so_far": 2667280720876212.0,
      "budget_used_percent": 2.667280720876212
    },
    {
      "type": "training",
      "description": "Training step 1858",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:46",
      "total_flops_so_far": 2668711816247988.0,
      "budget_used_percent": 2.668711816247988
    },
    {
      "type": "training",
      "description": "Training step 1859",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:46",
      "total_flops_so_far": 2670142911619764.0,
      "budget_used_percent": 2.670142911619764
    },
    {
      "type": "training",
      "description": "Training step 1860",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:46",
      "total_flops_so_far": 2671574006991540.0,
      "budget_used_percent": 2.6715740069915404
    },
    {
      "type": "training",
      "description": "Training step 1861",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:46",
      "total_flops_so_far": 2673005102363316.0,
      "budget_used_percent": 2.673005102363316
    },
    {
      "type": "training",
      "description": "Training step 1862",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:46",
      "total_flops_so_far": 2674436197735092.0,
      "budget_used_percent": 2.674436197735092
    },
    {
      "type": "training",
      "description": "Training step 1863",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:46",
      "total_flops_so_far": 2675867293106868.0,
      "budget_used_percent": 2.6758672931068683
    },
    {
      "type": "training",
      "description": "Training step 1864",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:47",
      "total_flops_so_far": 2677298388478644.0,
      "budget_used_percent": 2.677298388478644
    },
    {
      "type": "training",
      "description": "Training step 1865",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:47",
      "total_flops_so_far": 2678729483850420.0,
      "budget_used_percent": 2.67872948385042
    },
    {
      "type": "training",
      "description": "Training step 1866",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:47",
      "total_flops_so_far": 2680160579222196.0,
      "budget_used_percent": 2.6801605792221963
    },
    {
      "type": "training",
      "description": "Training step 1867",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:47",
      "total_flops_so_far": 2681591674593972.0,
      "budget_used_percent": 2.681591674593972
    },
    {
      "type": "training",
      "description": "Training step 1868",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:47",
      "total_flops_so_far": 2683022769965748.0,
      "budget_used_percent": 2.683022769965748
    },
    {
      "type": "training",
      "description": "Training step 1869",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:47",
      "total_flops_so_far": 2684453865337524.0,
      "budget_used_percent": 2.684453865337524
    },
    {
      "type": "training",
      "description": "Training step 1870",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:47",
      "total_flops_so_far": 2685884960709300.0,
      "budget_used_percent": 2.6858849607093003
    },
    {
      "type": "training",
      "description": "Training step 1871",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:48",
      "total_flops_so_far": 2687316056081076.0,
      "budget_used_percent": 2.687316056081076
    },
    {
      "type": "training",
      "description": "Training step 1872",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:48",
      "total_flops_so_far": 2688747151452852.0,
      "budget_used_percent": 2.688747151452852
    },
    {
      "type": "training",
      "description": "Training step 1873",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:48",
      "total_flops_so_far": 2690178246824628.0,
      "budget_used_percent": 2.6901782468246282
    },
    {
      "type": "training",
      "description": "Training step 1874",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:48",
      "total_flops_so_far": 2691609342196404.0,
      "budget_used_percent": 2.691609342196404
    },
    {
      "type": "training",
      "description": "Training step 1875",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:48",
      "total_flops_so_far": 2693040437568180.0,
      "budget_used_percent": 2.69304043756818
    },
    {
      "type": "training",
      "description": "Training step 1876",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:48",
      "total_flops_so_far": 2694471532939956.0,
      "budget_used_percent": 2.6944715329399562
    },
    {
      "type": "training",
      "description": "Training step 1877",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:49",
      "total_flops_so_far": 2695902628311732.0,
      "budget_used_percent": 2.6959026283117318
    },
    {
      "type": "training",
      "description": "Training step 1878",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:49",
      "total_flops_so_far": 2697333723683508.0,
      "budget_used_percent": 2.6973337236835078
    },
    {
      "type": "training",
      "description": "Training step 1879",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:49",
      "total_flops_so_far": 2698764819055284.0,
      "budget_used_percent": 2.698764819055284
    },
    {
      "type": "training",
      "description": "Training step 1880",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:49",
      "total_flops_so_far": 2700195914427060.0,
      "budget_used_percent": 2.70019591442706
    },
    {
      "type": "training",
      "description": "Training step 1881",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:49",
      "total_flops_so_far": 2701627009798836.0,
      "budget_used_percent": 2.7016270097988357
    },
    {
      "type": "training",
      "description": "Training step 1882",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:49",
      "total_flops_so_far": 2703058105170612.0,
      "budget_used_percent": 2.703058105170612
    },
    {
      "type": "training",
      "description": "Training step 1883",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:50",
      "total_flops_so_far": 2704489200542388.0,
      "budget_used_percent": 2.704489200542388
    },
    {
      "type": "training",
      "description": "Training step 1884",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:50",
      "total_flops_so_far": 2705920295914164.0,
      "budget_used_percent": 2.7059202959141637
    },
    {
      "type": "training",
      "description": "Training step 1885",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:50",
      "total_flops_so_far": 2707351391285940.0,
      "budget_used_percent": 2.70735139128594
    },
    {
      "type": "training",
      "description": "Training step 1886",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:50",
      "total_flops_so_far": 2708782486657716.0,
      "budget_used_percent": 2.708782486657716
    },
    {
      "type": "training",
      "description": "Training step 1887",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:50",
      "total_flops_so_far": 2710213582029492.0,
      "budget_used_percent": 2.710213582029492
    },
    {
      "type": "training",
      "description": "Training step 1888",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:50",
      "total_flops_so_far": 2711644677401268.0,
      "budget_used_percent": 2.711644677401268
    },
    {
      "type": "training",
      "description": "Training step 1889",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:50",
      "total_flops_so_far": 2713075772773044.0,
      "budget_used_percent": 2.713075772773044
    },
    {
      "type": "training",
      "description": "Training step 1890",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:51",
      "total_flops_so_far": 2714506868144820.0,
      "budget_used_percent": 2.71450686814482
    },
    {
      "type": "training",
      "description": "Training step 1891",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:51",
      "total_flops_so_far": 2715937963516596.0,
      "budget_used_percent": 2.7159379635165957
    },
    {
      "type": "training",
      "description": "Training step 1892",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:51",
      "total_flops_so_far": 2717369058888372.0,
      "budget_used_percent": 2.717369058888372
    },
    {
      "type": "training",
      "description": "Training step 1893",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:51",
      "total_flops_so_far": 2718800154260148.0,
      "budget_used_percent": 2.718800154260148
    },
    {
      "type": "training",
      "description": "Training step 1894",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:51",
      "total_flops_so_far": 2720231249631924.0,
      "budget_used_percent": 2.7202312496319236
    },
    {
      "type": "training",
      "description": "Training step 1895",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:51",
      "total_flops_so_far": 2721662345003700.0,
      "budget_used_percent": 2.7216623450037
    },
    {
      "type": "training",
      "description": "Training step 1896",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:52",
      "total_flops_so_far": 2723093440375476.0,
      "budget_used_percent": 2.723093440375476
    },
    {
      "type": "training",
      "description": "Training step 1897",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:52",
      "total_flops_so_far": 2724524535747252.0,
      "budget_used_percent": 2.724524535747252
    },
    {
      "type": "training",
      "description": "Training step 1898",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:52",
      "total_flops_so_far": 2725955631119028.0,
      "budget_used_percent": 2.725955631119028
    },
    {
      "type": "training",
      "description": "Training step 1899",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:52",
      "total_flops_so_far": 2727386726490804.0,
      "budget_used_percent": 2.727386726490804
    },
    {
      "type": "training",
      "description": "Training step 1900",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:52",
      "total_flops_so_far": 2728817821862580.0,
      "budget_used_percent": 2.72881782186258
    },
    {
      "type": "training",
      "description": "Training step 1901",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:52",
      "total_flops_so_far": 2730248917234356.0,
      "budget_used_percent": 2.730248917234356
    },
    {
      "type": "training",
      "description": "Training step 1902",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:53",
      "total_flops_so_far": 2731680012606132.0,
      "budget_used_percent": 2.731680012606132
    },
    {
      "type": "training",
      "description": "Training step 1903",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:53",
      "total_flops_so_far": 2733111107977908.0,
      "budget_used_percent": 2.733111107977908
    },
    {
      "type": "training",
      "description": "Training step 1904",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:53",
      "total_flops_so_far": 2734542203349684.0,
      "budget_used_percent": 2.734542203349684
    },
    {
      "type": "training",
      "description": "Training step 1905",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:53",
      "total_flops_so_far": 2735973298721460.0,
      "budget_used_percent": 2.73597329872146
    },
    {
      "type": "training",
      "description": "Training step 1906",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:53",
      "total_flops_so_far": 2737404394093236.0,
      "budget_used_percent": 2.737404394093236
    },
    {
      "type": "training",
      "description": "Training step 1907",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:54",
      "total_flops_so_far": 2738835489465012.0,
      "budget_used_percent": 2.738835489465012
    },
    {
      "type": "training",
      "description": "Training step 1908",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:54",
      "total_flops_so_far": 2740266584836788.0,
      "budget_used_percent": 2.740266584836788
    },
    {
      "type": "training",
      "description": "Training step 1909",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:54",
      "total_flops_so_far": 2741697680208564.0,
      "budget_used_percent": 2.741697680208564
    },
    {
      "type": "training",
      "description": "Training step 1910",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:54",
      "total_flops_so_far": 2743128775580340.0,
      "budget_used_percent": 2.74312877558034
    },
    {
      "type": "training",
      "description": "Training step 1911",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:54",
      "total_flops_so_far": 2744559870952116.0,
      "budget_used_percent": 2.744559870952116
    },
    {
      "type": "training",
      "description": "Training step 1912",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:54",
      "total_flops_so_far": 2745990966323892.0,
      "budget_used_percent": 2.745990966323892
    },
    {
      "type": "training",
      "description": "Training step 1913",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:54",
      "total_flops_so_far": 2747422061695668.0,
      "budget_used_percent": 2.747422061695668
    },
    {
      "type": "training",
      "description": "Training step 1914",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:55",
      "total_flops_so_far": 2748853157067444.0,
      "budget_used_percent": 2.748853157067444
    },
    {
      "type": "training",
      "description": "Training step 1915",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:55",
      "total_flops_so_far": 2750284252439220.0,
      "budget_used_percent": 2.75028425243922
    },
    {
      "type": "training",
      "description": "Training step 1916",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:55",
      "total_flops_so_far": 2751715347810996.0,
      "budget_used_percent": 2.751715347810996
    },
    {
      "type": "training",
      "description": "Training step 1917",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:55",
      "total_flops_so_far": 2753146443182772.0,
      "budget_used_percent": 2.7531464431827724
    },
    {
      "type": "training",
      "description": "Training step 1918",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:55",
      "total_flops_so_far": 2754577538554548.0,
      "budget_used_percent": 2.754577538554548
    },
    {
      "type": "training",
      "description": "Training step 1919",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:55",
      "total_flops_so_far": 2756008633926324.0,
      "budget_used_percent": 2.756008633926324
    },
    {
      "type": "training",
      "description": "Training step 1920",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:56",
      "total_flops_so_far": 2757439729298100.0,
      "budget_used_percent": 2.7574397292981
    },
    {
      "type": "training",
      "description": "Training step 1921",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:56",
      "total_flops_so_far": 2758870824669876.0,
      "budget_used_percent": 2.758870824669876
    },
    {
      "type": "training",
      "description": "Training step 1922",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:56",
      "total_flops_so_far": 2760301920041652.0,
      "budget_used_percent": 2.760301920041652
    },
    {
      "type": "training",
      "description": "Training step 1923",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:56",
      "total_flops_so_far": 2761733015413428.0,
      "budget_used_percent": 2.761733015413428
    },
    {
      "type": "training",
      "description": "Training step 1924",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:56",
      "total_flops_so_far": 2763164110785204.0,
      "budget_used_percent": 2.7631641107852043
    },
    {
      "type": "training",
      "description": "Training step 1925",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:56",
      "total_flops_so_far": 2764595206156980.0,
      "budget_used_percent": 2.76459520615698
    },
    {
      "type": "training",
      "description": "Training step 1926",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:57",
      "total_flops_so_far": 2766026301528756.0,
      "budget_used_percent": 2.766026301528756
    },
    {
      "type": "training",
      "description": "Training step 1927",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:57",
      "total_flops_so_far": 2767457396900532.0,
      "budget_used_percent": 2.7674573969005323
    },
    {
      "type": "training",
      "description": "Training step 1928",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:57",
      "total_flops_so_far": 2768888492272308.0,
      "budget_used_percent": 2.768888492272308
    },
    {
      "type": "training",
      "description": "Training step 1929",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:57",
      "total_flops_so_far": 2770319587644084.0,
      "budget_used_percent": 2.770319587644084
    },
    {
      "type": "training",
      "description": "Training step 1930",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:57",
      "total_flops_so_far": 2771750683015860.0,
      "budget_used_percent": 2.7717506830158603
    },
    {
      "type": "training",
      "description": "Training step 1931",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:57",
      "total_flops_so_far": 2773181778387636.0,
      "budget_used_percent": 2.773181778387636
    },
    {
      "type": "training",
      "description": "Training step 1932",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:58",
      "total_flops_so_far": 2774612873759412.0,
      "budget_used_percent": 2.774612873759412
    },
    {
      "type": "training",
      "description": "Training step 1933",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:58",
      "total_flops_so_far": 2776043969131188.0,
      "budget_used_percent": 2.7760439691311882
    },
    {
      "type": "training",
      "description": "Training step 1934",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:58",
      "total_flops_so_far": 2777475064502964.0,
      "budget_used_percent": 2.777475064502964
    },
    {
      "type": "training",
      "description": "Training step 1935",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:58",
      "total_flops_so_far": 2778906159874740.0,
      "budget_used_percent": 2.7789061598747398
    },
    {
      "type": "training",
      "description": "Training step 1936",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:58",
      "total_flops_so_far": 2780337255246516.0,
      "budget_used_percent": 2.780337255246516
    },
    {
      "type": "training",
      "description": "Training step 1937",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:58",
      "total_flops_so_far": 2781768350618292.0,
      "budget_used_percent": 2.781768350618292
    },
    {
      "type": "training",
      "description": "Training step 1938",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:58",
      "total_flops_so_far": 2783199445990068.0,
      "budget_used_percent": 2.7831994459900677
    },
    {
      "type": "training",
      "description": "Training step 1939",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:59",
      "total_flops_so_far": 2784630541361844.0,
      "budget_used_percent": 2.784630541361844
    },
    {
      "type": "training",
      "description": "Training step 1940",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:59",
      "total_flops_so_far": 2786061636733620.0,
      "budget_used_percent": 2.78606163673362
    },
    {
      "type": "training",
      "description": "Training step 1941",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:59",
      "total_flops_so_far": 2787492732105396.0,
      "budget_used_percent": 2.7874927321053957
    },
    {
      "type": "training",
      "description": "Training step 1942",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:59",
      "total_flops_so_far": 2788923827477172.0,
      "budget_used_percent": 2.788923827477172
    },
    {
      "type": "training",
      "description": "Training step 1943",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:59",
      "total_flops_so_far": 2790354922848948.0,
      "budget_used_percent": 2.790354922848948
    },
    {
      "type": "training",
      "description": "Training step 1944",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:42:59",
      "total_flops_so_far": 2791786018220724.0,
      "budget_used_percent": 2.791786018220724
    },
    {
      "type": "training",
      "description": "Training step 1945",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:00",
      "total_flops_so_far": 2793217113592500.0,
      "budget_used_percent": 2.7932171135925
    },
    {
      "type": "training",
      "description": "Training step 1946",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:00",
      "total_flops_so_far": 2794648208964276.0,
      "budget_used_percent": 2.794648208964276
    },
    {
      "type": "training",
      "description": "Training step 1947",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:00",
      "total_flops_so_far": 2796079304336052.0,
      "budget_used_percent": 2.796079304336052
    },
    {
      "type": "training",
      "description": "Training step 1948",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:00",
      "total_flops_so_far": 2797510399707828.0,
      "budget_used_percent": 2.7975103997078277
    },
    {
      "type": "training",
      "description": "Training step 1949",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:00",
      "total_flops_so_far": 2798941495079604.0,
      "budget_used_percent": 2.798941495079604
    },
    {
      "type": "training",
      "description": "Training step 1950",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:00",
      "total_flops_so_far": 2800372590451380.0,
      "budget_used_percent": 2.80037259045138
    },
    {
      "type": "training",
      "description": "Training step 1951",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:01",
      "total_flops_so_far": 2801803685823156.0,
      "budget_used_percent": 2.8018036858231556
    },
    {
      "type": "training",
      "description": "Training step 1952",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:01",
      "total_flops_so_far": 2803234781194932.0,
      "budget_used_percent": 2.803234781194932
    },
    {
      "type": "training",
      "description": "Training step 1953",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:01",
      "total_flops_so_far": 2804665876566708.0,
      "budget_used_percent": 2.804665876566708
    },
    {
      "type": "training",
      "description": "Training step 1954",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:01",
      "total_flops_so_far": 2806096971938484.0,
      "budget_used_percent": 2.806096971938484
    },
    {
      "type": "training",
      "description": "Training step 1955",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:01",
      "total_flops_so_far": 2807528067310260.0,
      "budget_used_percent": 2.80752806731026
    },
    {
      "type": "training",
      "description": "Training step 1956",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:01",
      "total_flops_so_far": 2808959162682036.0,
      "budget_used_percent": 2.808959162682036
    },
    {
      "type": "training",
      "description": "Training step 1957",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:02",
      "total_flops_so_far": 2810390258053812.0,
      "budget_used_percent": 2.810390258053812
    },
    {
      "type": "training",
      "description": "Training step 1958",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:02",
      "total_flops_so_far": 2811821353425588.0,
      "budget_used_percent": 2.811821353425588
    },
    {
      "type": "training",
      "description": "Training step 1959",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:02",
      "total_flops_so_far": 2813252448797364.0,
      "budget_used_percent": 2.813252448797364
    },
    {
      "type": "training",
      "description": "Training step 1960",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:02",
      "total_flops_so_far": 2814683544169140.0,
      "budget_used_percent": 2.81468354416914
    },
    {
      "type": "training",
      "description": "Training step 1961",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:02",
      "total_flops_so_far": 2816114639540916.0,
      "budget_used_percent": 2.816114639540916
    },
    {
      "type": "training",
      "description": "Training step 1962",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:02",
      "total_flops_so_far": 2817545734912692.0,
      "budget_used_percent": 2.817545734912692
    },
    {
      "type": "training",
      "description": "Training step 1963",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:02",
      "total_flops_so_far": 2818976830284468.0,
      "budget_used_percent": 2.818976830284468
    },
    {
      "type": "training",
      "description": "Training step 1964",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:03",
      "total_flops_so_far": 2820407925656244.0,
      "budget_used_percent": 2.820407925656244
    },
    {
      "type": "training",
      "description": "Training step 1965",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:03",
      "total_flops_so_far": 2821839021028020.0,
      "budget_used_percent": 2.82183902102802
    },
    {
      "type": "training",
      "description": "Training step 1966",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:03",
      "total_flops_so_far": 2823270116399796.0,
      "budget_used_percent": 2.823270116399796
    },
    {
      "type": "training",
      "description": "Training step 1967",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:03",
      "total_flops_so_far": 2824701211771572.0,
      "budget_used_percent": 2.824701211771572
    },
    {
      "type": "training",
      "description": "Training step 1968",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:03",
      "total_flops_so_far": 2826132307143348.0,
      "budget_used_percent": 2.826132307143348
    },
    {
      "type": "training",
      "description": "Training step 1969",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:03",
      "total_flops_so_far": 2827563402515124.0,
      "budget_used_percent": 2.827563402515124
    },
    {
      "type": "training",
      "description": "Training step 1970",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:04",
      "total_flops_so_far": 2828994497886900.0,
      "budget_used_percent": 2.8289944978869
    },
    {
      "type": "training",
      "description": "Training step 1971",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:04",
      "total_flops_so_far": 2830425593258676.0,
      "budget_used_percent": 2.8304255932586764
    },
    {
      "type": "training",
      "description": "Training step 1972",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:04",
      "total_flops_so_far": 2831856688630452.0,
      "budget_used_percent": 2.831856688630452
    },
    {
      "type": "training",
      "description": "Training step 1973",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:04",
      "total_flops_so_far": 2833287784002228.0,
      "budget_used_percent": 2.833287784002228
    },
    {
      "type": "training",
      "description": "Training step 1974",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:04",
      "total_flops_so_far": 2834718879374004.0,
      "budget_used_percent": 2.8347188793740044
    },
    {
      "type": "training",
      "description": "Training step 1975",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:04",
      "total_flops_so_far": 2836149974745780.0,
      "budget_used_percent": 2.83614997474578
    },
    {
      "type": "training",
      "description": "Training step 1976",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:05",
      "total_flops_so_far": 2837581070117556.0,
      "budget_used_percent": 2.837581070117556
    },
    {
      "type": "training",
      "description": "Training step 1977",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:05",
      "total_flops_so_far": 2839012165489332.0,
      "budget_used_percent": 2.839012165489332
    },
    {
      "type": "training",
      "description": "Training step 1978",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:05",
      "total_flops_so_far": 2840443260861108.0,
      "budget_used_percent": 2.840443260861108
    },
    {
      "type": "training",
      "description": "Training step 1979",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:05",
      "total_flops_so_far": 2841874356232884.0,
      "budget_used_percent": 2.841874356232884
    },
    {
      "type": "training",
      "description": "Training step 1980",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:05",
      "total_flops_so_far": 2843305451604660.0,
      "budget_used_percent": 2.84330545160466
    },
    {
      "type": "training",
      "description": "Training step 1981",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:05",
      "total_flops_so_far": 2844736546976436.0,
      "budget_used_percent": 2.8447365469764363
    },
    {
      "type": "training",
      "description": "Training step 1982",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:06",
      "total_flops_so_far": 2846167642348212.0,
      "budget_used_percent": 2.846167642348212
    },
    {
      "type": "training",
      "description": "Training step 1983",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:06",
      "total_flops_so_far": 2847598737719988.0,
      "budget_used_percent": 2.847598737719988
    },
    {
      "type": "training",
      "description": "Training step 1984",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:06",
      "total_flops_so_far": 2849029833091764.0,
      "budget_used_percent": 2.8490298330917643
    },
    {
      "type": "training",
      "description": "Training step 1985",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:06",
      "total_flops_so_far": 2850460928463540.0,
      "budget_used_percent": 2.85046092846354
    },
    {
      "type": "training",
      "description": "Training step 1986",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:06",
      "total_flops_so_far": 2851892023835316.0,
      "budget_used_percent": 2.851892023835316
    },
    {
      "type": "training",
      "description": "Training step 1987",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:06",
      "total_flops_so_far": 2853323119207092.0,
      "budget_used_percent": 2.8533231192070923
    },
    {
      "type": "training",
      "description": "Training step 1988",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:06",
      "total_flops_so_far": 2854754214578868.0,
      "budget_used_percent": 2.854754214578868
    },
    {
      "type": "training",
      "description": "Training step 1989",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:07",
      "total_flops_so_far": 2856185309950644.0,
      "budget_used_percent": 2.856185309950644
    },
    {
      "type": "training",
      "description": "Training step 1990",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:07",
      "total_flops_so_far": 2857616405322420.0,
      "budget_used_percent": 2.8576164053224202
    },
    {
      "type": "training",
      "description": "Training step 1991",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:07",
      "total_flops_so_far": 2859047500694196.0,
      "budget_used_percent": 2.859047500694196
    },
    {
      "type": "training",
      "description": "Training step 1992",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:07",
      "total_flops_so_far": 2860478596065972.0,
      "budget_used_percent": 2.8604785960659718
    },
    {
      "type": "training",
      "description": "Training step 1993",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:07",
      "total_flops_so_far": 2861909691437748.0,
      "budget_used_percent": 2.861909691437748
    },
    {
      "type": "training",
      "description": "Training step 1994",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:07",
      "total_flops_so_far": 2863340786809524.0,
      "budget_used_percent": 2.863340786809524
    },
    {
      "type": "training",
      "description": "Training step 1995",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:08",
      "total_flops_so_far": 2864771882181300.0,
      "budget_used_percent": 2.8647718821812997
    },
    {
      "type": "training",
      "description": "Training step 1996",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:08",
      "total_flops_so_far": 2866202977553076.0,
      "budget_used_percent": 2.866202977553076
    },
    {
      "type": "training",
      "description": "Training step 1997",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:08",
      "total_flops_so_far": 2867634072924852.0,
      "budget_used_percent": 2.867634072924852
    },
    {
      "type": "training",
      "description": "Training step 1998",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:08",
      "total_flops_so_far": 2869065168296628.0,
      "budget_used_percent": 2.8690651682966277
    },
    {
      "type": "training",
      "description": "Training step 1999",
      "seq_len": 128,
      "batch_size": 4,
      "forward_flops": 477031790592.0,
      "backward_flops": 954063581184.0,
      "flops": 1431095371776.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:08",
      "total_flops_so_far": 2870496263668404.0,
      "budget_used_percent": 2.8704962636684037
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 0",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552080785760.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:10",
      "total_flops_so_far": 2871048344454164.0,
      "budget_used_percent": 2.8710483444541643
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 1",
      "context_len": 604,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 555682299984.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:11",
      "total_flops_so_far": 2871604026754148.0,
      "budget_used_percent": 2.871604026754148
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 2",
      "context_len": 602,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 553881182680.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:12",
      "total_flops_so_far": 2872157907936828.0,
      "budget_used_percent": 2.872157907936828
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 3",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552080785760.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:13",
      "total_flops_so_far": 2872709988722588.0,
      "budget_used_percent": 2.8727099887225878
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 4",
      "context_len": 603,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 554781651284.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:15",
      "total_flops_so_far": 2873264770373872.0,
      "budget_used_percent": 2.873264770373872
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 0",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552080785760.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:17",
      "total_flops_so_far": 2873816851159632.0,
      "budget_used_percent": 2.873816851159632
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 1",
      "context_len": 604,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 555682299984.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:18",
      "total_flops_so_far": 2874372533459616.0,
      "budget_used_percent": 2.874372533459616
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 2",
      "context_len": 602,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 553881182680.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:19",
      "total_flops_so_far": 2874926414642296.0,
      "budget_used_percent": 2.874926414642296
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 3",
      "context_len": 600,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 552080785760.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:20",
      "total_flops_so_far": 2875478495428056.0,
      "budget_used_percent": 2.875478495428056
    },
    {
      "type": "inference",
      "description": "Validation inference on sequence 4",
      "context_len": 603,
      "gen_len": 48,
      "batch_size": 1,
      "flops": 554781651284.0,
      "lora_r": 4,
      "lora_target_modules": [
        "q_proj",
        "v_proj"
      ],
      "timestamp": "2025-03-23 14:43:22",
      "total_flops_so_far": 2876033277079340.0,
      "budget_used_percent": 2.87603327707934
    }
  ],
  "total_flops": 2876033277079340.0,
  "budget_used_percent": 2.87603327707934
}